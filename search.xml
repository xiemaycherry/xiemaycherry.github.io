<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F03%2F%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%2FFeatureExtraction%2F</url>
    <content type="text"><![CDATA[Principal Component Analysis** : 主成分分析 ¶形象理解 如图，下面是一张3d的图片，从不同的方向投影出来的二维图，可以看出右往左投影的含有更多信息。 如图，下面是一个高斯分布，二维点往两个正交的方向投影，长轴含有的信息更多。 ¶PCA的过程示意 **Step 1 ** : 去中心。中心在坐标轴在（0,0)，均值在坐标轴原点 Step 2 : Remove correlation(去除相关性) 通过坐标变化，坐标旋转，矩阵作用 ¶数学推导 目标：变换后的矩阵，对角非零，非对角线全为零。S(Y)有非零的对角元素，所有非对角元素都是零 ¶理论推导 ¶PCA Examples ¶PCA bias]]></content>
  </entry>
  <entry>
    <title><![CDATA[心路历程]]></title>
    <url>%2F2020%2F09%2F03%2Frecording%20of%20master%2FMyMain%2F</url>
    <content type="text"><![CDATA[From 2019-09-31 to 2019-11-10 过完了研一的第一个十周，内心很空虚，极度的空虚，不知道怎么回事？我觉得原因是：自己对自己的要求太高了，要求自己做的事情太多了？结果什么都没有做好。 对于自己的建设，我尝试了很多的东西，化妆和打扮。我觉得我还没有漂亮的资本，没钱，没房。所以一定要非常的努力才行。我只希望我最爱的人，配得上我，我希望我们是共同奋斗的状态了，而不是依靠。所以尽量不化妆出门，除了重要场合。 对于学习方面，了解了高铁背景，还是没有进入状态，所以要更努力才行。最近的课程太多了，平衡啊！我心有余而力不足的。还有一定要会说，不好说。接下来一定要马力十足的出发。 对于人，可能这里只是三年的一段时光，很好相处就好了，最重要的是男朋友和室友。 对不起，我还有奋斗，我要奋斗，我要奋斗。还有健身。 我的时间都分散在其他视频的事情上了，杜绝啊！每天最多两小时。尽量不玩手机了！！！！]]></content>
      <tags>
        <tag>成长</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目录——数据分析]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据分析</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[目录——深度学习]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[目录——机器学习]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[生活攻略]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%94%9F%E6%B4%BB%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[¶2020 ¶202008 ¶电脑文件管理 第一次就要把文件位置确定。 主要是梳理电脑文件管理的技巧，方便以后提高工作效率。 命名方法。采用3W1X的理念，when-work-who-X(备注)，“3W”分别指：When时间——20200630；Work事项——销售部营销计划；Who主体——客户A。 “1X”是指：X备注——第三版。 同一文件，多个修改版本。文件名前面加上修改人，在最后加上版本号。 同一任务（主题）文件夹管理。同级最多7个文件夹，最多5层。 及时复盘很关键。 1. 每星期要整理一次文件夹。 2. 重要文件要同步。]]></content>
      <categories>
        <category>生活攻略</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BLOG の 目录]]></title>
    <url>%2F2020%2F08%2F28%2Fcategories%2F</url>
    <content type="text"><![CDATA[BLOG の 目录 统一用中文 数学 (Mathematics) 数学知识 机器学习（Machine Learning) 总目录 算法，模型 实现 深度学习（Deep Learning） 1. 总目录 算法 实现 编程语言 （Program Language） 总目录 C Python 计算机相关知识 数据分析 总目录 可视化 业务知识 分析思维 数据库 数据挖掘 项目实战 学习日常 （Studying Diary） 主要是每天的学习记录 杂七杂八（Mixed) 其他领域的知识 生活攻略 学习历程（Journey of Studying) 主要是书籍资料的学习（一本一篇）详细的记录在机器学习、深度学习里面]]></content>
      <categories>
        <category>Categories</category>
      </categories>
      <tags>
        <tag>Categories</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析之数据分析职责]]></title>
    <url>%2F2020%2F08%2F27%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E8%B4%A3%2F</url>
    <content type="text"><![CDATA[技术+业务 业务+技术，至少懂这些 术业有专攻，知识要广泛，是职业发展的基本准则。特别对数据分析师这样一个多面手型角色。那么我们应该了解到什么程度呢？这里有个建议： **业务方向分析师：**数据采集方式、数据字段格式、指标的计算口径与更新时间这三个是必须必须知道的。因为这三点涉及到数据真实性与可靠性。没有数据质量做保证，什么分析都是空谈。对基础数量越了解，越能从细节中找到思路；算法模型的种类与应用场景是必须了解的。因为这涉及到如何选择分析方法，如何提升分析质量。具体代码怎么写，弄懂就懂。 **技术方向分析师：**业务部门分工、职责、流程必须要了解。至少职责清晰，知道自己要对接的人到底是干什么。自己对应部门常见的业务需求，如销售分析、经营分析、促销分析、商品管理的方法要有所了解。在面对业务部门需求的时候，大概知道他们在想什么，有什么套路。帮助自己更好的理解需求，规避需求大坑。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>职位要求</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语Daily]]></title>
    <url>%2F2020%2F08%2F25%2F%E8%8B%B1%E8%AF%ADDaily%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[数据分析技能]]></title>
    <url>%2F2020%2F08%2F25%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD%2F</url>
    <content type="text"><![CDATA[https://ask.hellobi.com/blog/qinlu/sitemap/ SQL ¶学会直接把别人的知识装进自己的脑子里 https://www.zhihu.com/xen/market/personal-works-all/houziliaorenwu?zh_hide_tab_bar=true ¶LeetCode &amp; NowCoder https://leetcode.com/problemset/database/ https://www.nowcoder.com/ta/sql ¶关系型数据库 ¶MySQL数据类型 主要提供了三种类型，分别是文本，数字和日期。 ¶MySQL 数据类型 在 MySQL 中，有三种主要的类型：文本、数字和日期/时间类型。 ¶Text 类型： 数据类型 描述 CHAR(size) 保存固定长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的长度。最多 255 个字符。 VARCHAR(size) 保存可变长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的最大长度。最多 255 个字符。注释：如果值的长度大于 255，则被转换为 TEXT 类型。 TINYTEXT 存放最大长度为 255 个字符的字符串。 TEXT 存放最大长度为 65,535 个字符的字符串。 BLOB 用于 BLOBs (Binary Large OBjects)。存放最多 65,535 字节的数据。 MEDIUMTEXT 存放最大长度为 16,777,215 个字符的字符串。 MEDIUMBLOB 用于 BLOBs (Binary Large OBjects)。存放最多 16,777,215 字节的数据。 LONGTEXT 存放最大长度为 4,294,967,295 个字符的字符串。 LONGBLOB 用于 BLOBs (Binary Large OBjects)。存放最多 4,294,967,295 字节的数据。 ENUM(x,y,z,etc.) 允许你输入可能值的列表。可以在 ENUM 列表中列出最大 65535 个值。如果列表中不存在插入的值，则插入空值。注释：这些值是按照你输入的顺序存储的。可以按照此格式输入可能的值：ENUM(‘X’,‘Y’,‘Z’) SET 与 ENUM 类似，SET 最多只能包含 64 个列表项，不过 SET 可存储一个以上的值。 ¶Number 类型： 数据类型 描述 TINYINT(size) -128 到 127 常规。0 到 255 无符号*。在括号中规定最大位数。 SMALLINT(size) -32768 到 32767 常规。0 到 65535 无符号*。在括号中规定最大位数。 MEDIUMINT(size) -8388608 到 8388607 普通。0 to 16777215 无符号*。在括号中规定最大位数。 INT(size) -2147483648 到 2147483647 常规。0 到 4294967295 无符号*。在括号中规定最大位数。 BIGINT(size) -9223372036854775808 到 9223372036854775807 常规。0 到 18446744073709551615 无符号*。在括号中规定最大位数。 FLOAT(size,d) 带有浮动小数点的小数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DOUBLE(size,d) 带有浮动小数点的大数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DECIMAL(size,d) 作为字符串存储的 DOUBLE 类型，允许固定的小数点。 * 这些整数类型拥有额外的选项 UNSIGNED。通常，整数可以是负数或正数。如果添加 UNSIGNED 属性，那么范围将从 0 开始，而不是某个负数。 ¶Date 类型： 数据类型 描述 DATE() 日期。格式：YYYY-MM-DD注释：支持的范围是从 ‘1000-01-01’ 到 ‘9999-12-31’ DATETIME() *日期和时间的组合。格式：YYYY-MM-DD HH:MM:SS注释：支持的范围是从 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ TIMESTAMP() *时间戳。TIMESTAMP 值使用 Unix 纪元(‘1970-01-01 00:00:00’ UTC) 至今的描述来存储。格式：YYYY-MM-DD HH:MM:SS注释：支持的范围是从 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-09 03:14:07’ UTC TIME() 时间。格式：HH:MM:SS 注释：支持的范围是从 ‘-838:59:59’ 到 ‘838:59:59’ YEAR() 2 位或 4 位格式的年。注释：4 位格式所允许的值：1901 到 2155。2 位格式所允许的值：70 到 69，表示从 1970 到 2069。 * 即便 DATETIME 和 TIMESTAMP 返回相同的格式，它们的工作方式很不同。在 INSERT 或 UPDATE 查询中，TIMESTAMP 自动把自身设置为当前的日期和时间。TIMESTAMP 也接受不同的格式，比如 YYYYMMDDHHMMSS、YYMMDDHHMMSS、YYYYMMDD 或 YYMMDD。 ¶Day Ox00 入门： https://www.w3school.com.cn/sql/sql_syntax.asp 通过SQL使得数据操作员有能力查询，修改数据库。 ¶What SQL：结构化查询语言。SQL对大小写不敏感。 SQL语句后面的分号？有些数据库系统要求每条SQL命令的末端使用分号，来表示语句的结束。 分类： 数据操作语言（DML) 这部分包括查询和更新指令。 SELECT - 从数据库表中获取数据 UPDATE - 更新数据库表中的数据 DELETE - 从数据库表中删除数据 INSERT INTO - 向数据库表中插入数据 数据定义语言 (DDL) 这部分包括创建和删除表格，还有定义索引(键)，规定表之间的链接，和表间的约束。 SQL 中最重要的 DDL 语句: ​ CREATE DATABASE - 创建新数据库 ​ ALTER DATABASE - 修改数据库 ​ CREATE TABLE - 创建新表 ​ ALTER TABLE - 变更（改变）数据库表 ​ DROP TABLE - 删除表 ​ CREATE INDEX - 创建索引（搜索键） ​ DROP INDEX - 删除索引 ¶Day Ox00 简单查询： ¶SELECT : 查询语句 不带条件查询语句 123SELECT 列名称1, 列名称2 FROM 表名称SELECT * FROM 表名称SELECT DISTINCT 列名称 FROM 表名称 //去除重复值 有条件查询语句 1SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 WHERE 过滤单条记录 12345678910操作符 描述= 等于&lt;&gt; 不等于&gt; 大于&lt; 小于&gt;= 大于等于&lt;= 小于等于BETWEEN 在某个范围内LIKE 搜索某种模式注释：在某些版本的 SQL 中，操作符 &lt;&gt; 可以写为 !=。 WHERE 过滤两个以上的条件记录 AND / OR]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析实战项目]]></title>
    <url>%2F2020%2F08%2F25%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[研二の学习]]></title>
    <url>%2F2020%2F08%2F15%2F%E7%A0%94%E4%BA%8C%E3%81%AE%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[记录日常，日常留念。 闭关修炼，修炼成金刚不坏之身！ 立下Flag, 三个月后，看看自己，努力😀😀 清单😀😀 what how 日志 公众号、博客、CSDN、Github 主要输出 搬砖+项目 主要输入 数据分析+新经济 8:00~11:20 2h 14:10-17:20 3h 19:00-22:00 3h 每天 每天的规划；每天半小时瑜伽（哑铃)； 接下来有意义的事情，转过去转过来又回到最初的起点： 1. @可视化。封装一下matplotlib修改一些默认参数。主要就是修改字体，字号，主题，背景。 2. @填充简历。a)基本信息 b) 项目经历(三四个吧) c)实习经历 d) 知识技能(要进一步补充)。较弱的地方:落地的项目(好想好想实习)；英语啊； 3. @研究生完满的结束。毕业设计每章对应发一篇文章吧（产业)。加油，加油！这半年要做完，再找数据 4. @英语。新概念英语二和新概念英语三天天学习喔 5. @刻意练习。如果狠不下心，那就每时每刻的刻意，每时每刻的殚精竭虑 6. @公文写作。嗯嗯嗯。刻意的训练自己 每天追踪公众号文章。 猴子数据分析。 ¶20200903 终于考完了啊 高高兴兴，认认真真搞科研了！ 这个月把高铁重新更新一下 这个月把时间序列跑出来结果 这个月可视化资料弄一下 这个月 必修环节 6400006003 学术活动 研究生院 0 1 春与秋 其他 考查 是 必修环节 6400006009 论文开题报告及文献阅读综述II 研究生院 0 1 春与秋 其他 考查 是 实践教学环节：还有五个学分。 实践教学环节6个学分中，基地实践必须完成2-4个学分，按照实践时间1-3个月、4-6个月、7-12个月及以上作为实践时间单位，分别认定为2学分、3学分和4学分。要求提交实践总结报告，实践基地（单位）就学生提交的报告给予相关支撑书面材料证明，根据实际实践时间，经导师审核通过，可获得2-4个学分。 实践教学课程主要指突出实践训练的实验课程，全校可通选，完成者取得相应学分。 3个学分(实习)+学位论文写作规范(2)个学分 虽然我很喜欢天天睡大觉，躺在床上睡觉。但是呢？好好工作，规律的生活作息，这还是我的追求。 虽然在成为那个独特的自己的时候，会走很多的弯路，然后才知道怎么样的自己适合自己。什么的东西是应该丢掉的。 修炼，修炼，修炼 不能再吃外卖了！ ¶20200902 复习 今天复习软件安全性分析 ¶20200901 复习 今天早上复习背诵 今天下午敢报告 今天晚上Android漏洞，哎，虽然写过android apk,但是安全问题好难啊 202008 ¶2020-831 复习+玩耍 今天早上复习软件安全性分析 今天下午和鹏哥出去看电影了 今天晚上复习软件安全性分析 ¶20200830 复习ing 今天继续软件安全性分析（无聊，低效率) 决定晚上把报告完成了 突然想看论文了，我发现是的的确确爱上社会经济学的东西了，糟了啊。感觉要断送多年去互联网公司的梦想了（其实自己学的也不好)，是不是要去体制内工作了啊！感觉去体制内工作要混个博士学位才行啊。看了实验室博士毕业的条件和奖励规则，突然发现读博好难啊！(主要是我想3-4年达标啊）。那我断不断送去互联网工作的想法啊？？？？？ 按照硕士要求干？ 1**）博士生四年时间应该有一个比较好的研究规划。博士大论文一般只需要6-7章节，基本上每一学期完成一章节就可以了。博士生第一年，学校安排大家上课。有很多学生在这一年时间里面延续本科生学习习惯，将考试成绩放在第一位上。对于取得好的学习成绩、打好扎实的学科基础，固然有必要， 但博士生第一学年一定不能够只做“小镇读书青年”，除了书本考试，一定要尽可能早点动手开展研究工作。与此同时，我一直觉得博士生第一学年结束时，应该撰写完成博士论文第一章“研究背景和国内外研究进展”95%以上的工作，同时，撰写完成博士论文第二章“实验方法与基本理论”的基本内容。 博士第二学年，努力完成第三、四章的研究内容，并根据研究内容撰写1-2篇中等水准的学术论文。 博士第三学年，完成博士论文第五章、第六章的研究内容，根据研究结果发表2-3篇较高水准的学术论文。 博士第四学年上半年，补充、完善博士论文第二章-第六章研究内容，撰写第七章结论部分。通过对博士研究内容进行系统性总结，发表一篇高水平的学术论文。与此同时，博士生在第四年上半年将自己的博士论文第一稿递交给导师，让其有充足的时间帮助你修改。如果导师发现有不适合的部分，可以抓紧时间进行补充和完善。到第四学年下半年，就是安排送审、准备答辩，还有足够的时间找工作。 如果博士生能够按照上面的这个计划去开展工作，博士期间可以发表5篇以上学术论文，应该都会超过学校的毕业要求，博士不正常毕业是没有理由的。** 突然发现读研读博跟工作性质是差不多的，都是靠自己的本事给老板服务。嗯嗯，就是这种相处模式。 ¶20200829 复习ing 今天早上和同学聊天，居然出去实习了 今天晚上和下午复习软件安全性分析（难） ¶202008028 密码学考试 今天早上靠密码学 今天下午收拾博客文章 今天晚上，由于下大雨，回寝室看剧了 ¶20200827 工程伦理 今天早上，搜索很多数据分析的资料，感觉业务型数据分析师要接触太多业务（转行的人多啊，大厂能发挥作用)，技术型数据分析师要算法学的很好（我又没有很特别的头脑，项目经历）。但是呢？数据处理，数据建模，数据可视化是干什么都要用到的。还是我本科的水平。但是我还是想跨界啊，果然是爱一行，爱上一行。鱼和熊掌不可兼得啊，要取舍。 https://ask.hellobi.com/blog/qinlu/10261 今天下午，考工程伦理。心塞塞。 今天晚上，看了我在颐和园。历史文物，园林风景太棒了。英语：《breakfast or lunch》。又进一步进行了职业规划； 复习密码学；学习了tableau，果然漂亮啊！ 我想了想，把毕业设计做完了，把时间序列项目做好，把找实习相关准备做好了，看看剧，养养花，这样的研究生多好啊，干嘛要不自己搞的那么累。吃好喝好，时不时给家人买礼物。 啦啦啦啦啦啦啦啦啦啦啦啦啦啦。不要追一匹马，你用追马的时间去种草，待春暖花开时，能吸引一批骏马来供你选择；所以只要自己足够优秀，你就有多大的权力选择自己的喜好。就自己努力的动力啊！ ¶202007826 Deadline 今天早上，复习了全部的密码学。 今天下午，复习了工程伦理的分析题。 今天晚上，学习了数据分析中的逻辑思维，如何精准化产品设计，产业运营。 我已经受够了这样的生活了。尽早实习，有人内推，就看自己了。 @@@@@@@ 我不是一个热脸特冷屁股的人。 ¶20200825 七夕快乐 今天早上，起床发现臀部好疼啊 今天下午继续复习密码学 可证明的加密安全性；数字签名安全性相关概念。公钥体制的安全性 今天下午学习了A/B(what，why, how)，用于评估某种产品和设计是否有效的提供了某项指标，进而有助于辅助决策。 无论是公司，同级，普通朋友，男女朋友——利益第一，感情倒数第一。能实现双赢是最好。 论赚钱的重要性，我又不是非你不可。不喜欢的东西，我怎么都不会将就。 ¶20200824 复习ing 今天早上在寝室复习控制流完整性 今天下午复习模糊测试，fuzzing，各种细节 今天晚上低效率复习密码学分组密码和基本概念，还可证明安全性，第七章的基本概念，区别公钥密码体制（三种）， 《像鱼》好听 5W2H分析法在数据分析中的应用 期末考试咋回事背诵呢？还是数学好，一个定理做几十道题，这种学科几个点都不一定考 下周，全新全意的看视频，看PPT，打印论文背诵 背诵，完成课程报告。 ¶20200823 复习ing 今天早上寝室洗衣服（周末嘛，多睡会) 今天下午继续复习工程伦理，。。。文科。。。还看了我在颐和园等你。我还在想怎么用工程伦理分析生活中的小三。 今天晚上写了工程伦理的课件， 回寝室健身，哑铃到了 偏僻之地，偏僻之地，偏僻之地 刻意的练习！不会什么，就补充什么。团结就是力量 ¶20200822 平淡无奇的生活 今天早上低效率的复习了密码学和软件安全性分析，太难记忆了。看剧日常 今天下午复习继续 今天晚上继续复习，啊，为什么那么多要背的东西啊 ¶20200821 无聊的生活 昨天晚上睡不好，盖被子太热，不盖又太冷，折腾着睡不着，我的天啊。 今天早上备份资料。 今天下午和晚上继续复习。好心塞啊，太难背了，感觉在考文科啊。下面时间全部复习了。 看下如何通过Python爬取微信公众号上的全部文章 对不起，其实是最没有用的话语了。 为了每天少往返实验室一个来回，我决定早上在寝室学习了，这样还可以在床上躺到7:45，也不打扰室友起床。 ¶20200820 返校记 想不到我马上研二了，感觉还是一事无成的样子。得给自己选定方向，快速发展了 ¶20200819 路漫漫其修远兮 再不努力，你就生锈了。亲爱的，女孩子。 你见 或者不见我 我就在那里 不悲不喜 你念 或者不念我 情就在那里 不来不去 你爱 或者不爱我 爱就在那里 不增不减 你跟 或者不跟我 我的手就在你手里 不舍不弃 来我的怀里 或者 让我住进你的心里 默然 相爱 寂静 喜欢]]></content>
      <categories>
        <category>学习の历程(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析与机器学习之语言篇]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%AF%AD%E8%A8%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[神经网络Pytorch ¶基础语法 ¶常见神经网络的实现 ¶线性模型 ¶多层感知机 ¶CNN ¶LSTM ¶GAN]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习之模型性能]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>正则化</tag>
        <tag>交叉验证</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Book-Learning]]></title>
    <url>%2F2020%2F07%2F29%2FBook-Learning%2F</url>
    <content type="text"><![CDATA[分享看书笔记 数据挖掘——概念与技术 ¶数据挖掘的概念 数据挖掘是从大量数据中提取或挖掘知识。强调：从大量的，未加工的材料中发现少量金块这一过程。 基本过程： 数据清理。(消除噪音或者不一致的数据) 数据集成（多种数据集成可以组合在一起） 数据选择（从数据库中提取与分析任务相关的数据) 数据变换。(数据变换或统一成适合挖掘形式) 数据挖掘(使用智能方法提取数据) 模式评估 知识表示（可视化等手段，展示挖掘的知识) ¶数据预处理 问题：现实中数据极易受噪音数据、遗漏数据和不一致性数据的干扰。 不完整（属性值缺失） 噪音(错误属性值，离群值) 不一致性（编码) 数据清理。包括填写遗漏值，平滑噪音数据，识别、删除局外者，并解决不一致来“清理数据”。脏数据转化为干净数据。 数据集成。不同数据源的数据集成。 ¶数据清洗 ¶遗漏值 忽略 人工填写 全局变量 平均值 分组填充 ¶噪音数据 噪音是指测量变量的随机误差或偏差。平滑数据。 分箱。存储值被分布到一些箱子中，然后局部平滑。按平均值平滑。按中值平滑。按边界平滑。 聚类。 回归 ¶不一致数据 ¶数据集成 实体识别。 冗余。 ¶数据变换 将数据转换成适用于挖掘的形式 平滑。 聚集。对数据进行汇总和聚集。日、月和年销售额。多粒度数据分析构造数据方 数据泛化。street-&gt;city; age–&gt;young, middle-age,senior 规范化。 属性数据按比例缩放，缩放到特定区间。 属性构造。 最小-最大规范化 $$ v = \frac{v-min}{max-min}(new_max-new_min)+new_min $$ z-score规范化 $$ v = \frac{v-mean}{\delta} $$ ¶数据归约 数据方聚集 维归约 数据压缩 数值压缩 概念描述：特征与比较 数据挖掘分为两类: 描述式和预测式挖掘。描述式提供数据的有趣的一般性质。建立一个或一组模型，并试图预测新数据集的行为。 描述式数据挖掘称为概念描述。不同的粒度和角度描述数据集。 度量可以根据其所用的聚集函数分成三类： 分布的：一个聚集函数是分布的，如果它能以如下分布方式进行计算：设数据被划分为 n 个集合，函数在每一部分上的计算得到一个聚集值。如果将函数用于 n 个聚集值得到的结果，与将函数 用于所有数据得到的结果一样，则该函数可以用分布方式计算。 代数的：ave(); 整体的：rank(),median() ¶描述性统计度量 ¶度量中心趋势 平均值 加权算术平均（加权平均) 中位数 分位数 挖掘大型数据库中的关联规则 关联规则挖掘发现大量数据中项集的关联或者相关联系。可用于于分类设计，交叉购物和贱卖分析。 购买计算机也趋向于同时购买财务管理软件的关联规则 $$ computer =&gt; finanical_management_software\ [support = 2%, confidence = 60%] $$ 支持度：有用性。同时购买计算机和财务管理软件。 置信度：确定性。购买计算机的顾客有多少购买财务管理软件。 可最小支持度阙值和最小置信度阙值。 ¶Apriori 算法： 使用候选项集找频繁项集 分类和预测 分类和预测是数据分析的两种形式，可以用于提取描述重要数据类的模型或预测未来的数据趋势。 分类预测分类标号（类），而预测建立连续值函数模型。 预测的准确率、计算速度、鲁棒性、可规模性和可解释性是评估分类和预测方法的五条标准。 聚类分析 数据对象的集合进行分析，但与分类不同的是，聚类分析 (clustering) 属于非监督学习，也就是不知道要划分类是未知的。聚类分析就是要将数据对象分组成为多个类或簇(cluster)。每一个簇中的对象之间具有较高的相似度，而不同簇对象差别较大。常常采用距离作为相异度的衡量。]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[向着永恒出发]]></title>
    <url>%2F2020%2F07%2F28%2Fprepare-for-work%2F</url>
    <content type="text"><![CDATA[编程语言的学习 第一周：Python基础知识 https://github.com/jackfrued/Python-100-Days/tree/master/Day01-15 ¶Day Ox00 基本的数据结构类型，以及提供的常用方法。 编码的风格和规范性 ¶初识python Python简介 - Python的历史 / Python的优缺点 / Python的应用领域 搭建编程环境 - Windows环境 / Linux环境 / MacOS环境 从终端运行Python程序 - Hello, world / print函数 / 运行程序 使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE 注释 - 注释的作用 / 单行注释 / 多行注释 代码注释风格 12345678910111213141516def func(arg1, arg2): &quot;&quot;&quot;在这里写函数的一句话总结(如: 计算平均值). 这里是具体描述. 参数 ---------- arg1 : int arg1的具体描述 arg2 : int arg2的具体描述 返回值 ------- int 返回值的具体描述 变量的定义 12345678910模块尽量使用小写命名，首字母保持小写，尽量不要用下划线(除非多个单词，且数量不多的情况)类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头函数名一律小写，如有多个单词，用下划线隔开变量名尽量小写, 如有多个单词，用下划线隔开常量采用全大写，如有多个单词，使用下划线隔开 ¶语言元素 程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制 变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换 数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码 运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级 ¶分支结构 分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图 if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if ¶循环结构 循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图 while循环 - 基本结构 / break语句 / continue语句 for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序 ¶函数和模块的使用 函数的作用 - 代码的坏味道 / 用函数封装功能模块 定义函数 - def语句 / 函数名 / 参数列表 / return语句 / 调用自定义函数 调用函数 - Python内置函数 / 导入模块和函数 函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数 函数的返回值 - 没有返回值 / 返回单个值 / 返回多个值 作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字 用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块） Lambda表达式 ¶字符串和常用的数据结构 这一句非常重要，python提供的数据结构，和内置的方法很实用。 字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法 列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历 像 insert ，remove 或者 sort 方法，只修改列表，没有打印出返回值——它们返回默认值 None 。这是Python中所有可变数据结构的设计原则。 列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找 生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器 元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换 集合基本用法 - 集合和列表的区别 / 创建集合 / 添加元素 / 删除元素 / 清空 集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集 字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空 字典常用操作 - keys()方法 / values()方法 / items()方法 / setdefault()方法 12list(d1.keys())in not in python list 常用方法总结 12345678910111213141516171819201. 创建 1.1 l = [1, 2] 1.2 list = []2. 添加 2.1 末尾增加一个 append 2.2 指定位置增加一个 insert 2.3 增加list extend +3. 查 [start: stop: step]4. 改5. 删 1. pop 2. remove(元素) 3. del 列表6. 排序和反转 reverse(); sort(); sort(reverse = True)7. 属性 len max/min8. 复制 python string 12345678910111213141516171819202122231. 检测 str 是否包含在 mystr中，如果是，返回开始的索引值；否则返回-1。也可以指定在一定的范围内。mystr.find(str, start=0, end=len(mystr))2. 跟find()方法一样，只不过如果str不在 mystr中会报一个异常.mystr.index(str, start=0, end=len(mystr))3. 把 mystr 中的 str1 替换成 str2,如果 count 指定，则替换不超过 count 次.mystr.replace(str1, str2, mystr.count(str1))4. 以 str 为分隔符切片 mystr，如果 maxsplit有指定值，则仅分隔 maxsplit 个子字符串mystr.split(str=&quot; &quot;, 2)5. 删除 mystr 左边的空白字符mystr.lstrip()6. 删除 mystr 字符串末尾的空白字符mystr.rstrip()7. 删除mystr字符串两端的空白字符 ¶Day Ox01 ¶定义类 12classclass classname(object): __init__是创建对象时进行初始化操作 12345678910111213141516171819202122232425262728 def __init__(self, name, age): self.name = name self.age = age创建实列std = classname(&apos;xiemay&apos;,&apos;24&apos;)私有和公开的属性和函数：用__开头@property 装饰器如果想访问属性可以通过属性的getter（访问器）和setter（修改器）方法进行对应的操作。 # 访问器 - getter方法 @property def age(self): return self._age静态方法和类方法 # 修改器 - setter方法 @age.setter def age(self, age): self._age = age @staticmethod def is_valid(a, b, c): return a + b &gt; c and b + c &gt; a and a + c &gt; b## 继承和多态class person(): class woman(person): super.__init__() ¶文件操作 文件操作基本上没什么问题了 操作模式 具体含义 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 'r' 读取 （默认） 'w' 写入（会先截断之前的内容） 'x' 写入，如果文件已经存在会产生异常 'a' 追加，将内容写入到已有文件的末尾 'b' 二进制模式 't' 文本模式（默认） '+' 更新（既可以读又可以写） r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 12with open(filename, moder, encoding) as f1: for line in f1: ¶读取方法 ¶按字节 12fileObject.read([count]); 在这里，被传递的参数是要从已打开文件中读取的字节计数。该方法从文件的开头开始读入，如果没有传入count，它会尝试尽可能多地读取更多的内容，很可能是直到文件的末尾。 ¶单独一行 123456readline()方法f.readline() 会从文件中读取单独的一行。换行符为 &apos;\n&apos;。f.readline() 如果返回一个空字符串, 说明已经已经读取到最后一行。with open() as f1: while True: lines = f.readline() if lines: ¶全部行 12345readlines()方法 f.readlines() 将以列表的形式返回该文件中包含的所有行，列表中的一项表示文件的一行。如果设置可选参数 sizehint, 则读取指定长度的字节, 并且将这些字节按行分割。with open() as f1: lines = f1.readlines() ¶json 文件读取 12345678910json模块主要有四个比较重要的函数，分别是：dump - 将Python对象按照JSON格式序列化到文件中dumps - 将Python对象处理成JSON格式的字符串 infor = json.dumps(neww) f.write(infor+&apos;\n&apos;)load - 将文件中的JSON数据反序列化成对象loads - 将字符串的内容反序列化成Python对象 b = json.loads(lines) ¶excel 单独操作excel的库 创建/打开(对象)，定位(sheet)，定位行列, 保存 就是这几个方法 ¶xlrd 12345678910111213141516171819202122232425262728293031323334353637383940### 导入 xlrd 库import xlrd### 打开刚才我们写入的 test_w.xls 文件wb = xlrd.open_workbook(&quot;test_w.xls&quot;)### 获取并打印 sheet 数量print( &quot;sheet 数量:&quot;, wb.nsheets)### 获取并打印 sheet 名称print( &quot;sheet 名称:&quot;, wb.sheet_names())### 根据 sheet 索引获取内容sh1 = wb.sheet_by_index(0)### 或者### 也可根据 sheet 名称获取内容### sh = wb.sheet_by_name(&apos;成绩&apos;)### 获取并打印该 sheet 行数和列数print( u&quot;sheet %s 共 %d 行 %d 列&quot; % (sh1.name, sh1.nrows, sh1.ncols))### 获取并打印某个单元格的值print( &quot;第一行第二列的值为:&quot;, sh1.cell_value(0, 1))### 获取整行或整列的值rows = sh1.row_values(0) # 获取第一行内容cols = sh1.col_values(1) # 获取第二列内容### 打印获取的行列值print( &quot;第一行的值为:&quot;, rows)print( &quot;第二列的值为:&quot;, cols)### 获取单元格内容的数据类型print( &quot;第二行第一列的值类型为:&quot;, sh1.cell(1, 0).ctype)### 遍历所有表单内容for sh in wb.sheets(): for r in range(sh.nrows): # 输出指定行 print( sh.row(r)) ¶xlwt 123456789101112131415161718192021222324252627### excel_w.py### 导入 xlwt 库import xlwt### 创建 xls 文件对象wb = xlwt.Workbook()### 新增两个表单页sh1 = wb.add_sheet(&apos;成绩&apos;)sh2 = wb.add_sheet(&apos;汇总&apos;)### 然后按照位置来添加数据,第一个参数是行，第二个参数是列### 写入第一个sheetsh1.write(0, 0, &apos;姓名&apos;)sh1.write(0, 1, &apos;成绩&apos;)sh1.write(1, 0, &apos;张三&apos;)sh1.write(1, 1, 88)sh1.write(2, 0, &apos;李四&apos;)sh1.write(2, 1, 99.5)### 写入第二个sheetsh2.write(0, 0, &apos;总分&apos;)sh2.write(1, 0, 187.5)### 最后保存文件即可wb.save(&apos;test_w.xls&apos;) pandas 也可以操作 123456789101112ExcelWriter: Class for writing DataFrame objects into excel sheets.with ExcelWriter(&apos;path_to_file.xlsx&apos;, mode=&apos;a&apos;) as writer: df.to_excel(writer, sheet_name=&apos;Sheet3&apos;) writer = pd.ExcelWriter(&apos;exam.xlsx&apos;) for i in all_grad_pair: inflowdata = pd.read_csv(newfiledir+i+precitypair+&apos;.txt&apos;,\ sep = &apos;\t&apos;,header = 0, index_col = 0,encoding = &apos;utf-8&apos;) inflowdata.to_excel(writer,sheet_name = CityName[j])writer.save() ​12345678910111213import pandas as pd #读取两个表格data1=pd.read_excel('文件路径')data2=pd.read_excel('文件路径') #将两个表格输出到一个excel文件里面writer=pd.ExcelWriter('D:新表.xlsx')data1.to_excel(writer,sheet_name='sheet1')data2.to_excel(writer,sheet_name='sheet2') #必须运行writer.save()，不然不能输出到本地writer.save() 第二周：numpy https://cloudxlab.com/blog/numpy-pandas-introduction/ ¶对象 Numpy 提供了n维数组对象（ndarray, A multidimensional array object) ¶创建 1234np.arange(6)array([0,1, 2, 3, 4, 5])np.zeros(10) # 1-nnp.zeros((3, 6)) # 2-n ¶types 123arr1 = np.array([1, 2, 3], dtype=np.float64)arr1.dtypefloat_arr = arr.astype(np.float64) ¶索引 就是用中括号，注意切片是一维数组还是多少维数组！[, ], 如果，后面省略表示全部索引。 布尔类型索引 12345data[names == &apos;Bob&apos;]表示索引行data[names == &apos;Bob&apos;, 2:]表示行列索引 ¶增 ¶改 1result = np.where(cond, xarr, yarr) ¶索引 ¶值 ¶删 ¶计算函数 ±*/ **都是元素对齐 np.sqrt() np.exp() pandas ¶对象 ¶创建 ¶索引 ¶增 ¶改 ¶索引 ¶值 ¶删 ¶计算函数 matplotlib seaborn 第三周：sklearn 第五周：sql 第六周： Linux 第七周和八周：机器学习算法和数据挖掘]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习]]></title>
    <url>%2F2020%2F07%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[线性回归 逻辑斯特回归 决策树]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>监督学习与非监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data-Analysis]]></title>
    <url>%2F2020%2F07%2F25%2FData-Analysis%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学]]></title>
    <url>%2F2020%2F07%2F17%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[统计学 统计学 day Ox00 day Ox00 首先介绍随机实验的基本概念，包括随机实验，样本点，样本空间，基本事件，随机事件；其次介绍概率论的基本概念，包括概率的公理化定义，古典概率，条件概率，全概率，贝叶斯公式等等。特别注意两个容易混淆的概念：事件的独立性和互斥。 day Ox01 首先引 出随机变量的定义，从离散随机变量和连续随机变量两个维度，介绍典型的分布函数。其中概率函数和分布函数是非常重要的概念。 ¶基本概念 随机试验：记作$E$ 样本点： 随机试验中出现的可能结果称为样本点，记作 $\omega$ 样本空间： 所有样本点组成的集合称为样本空间，随机实验所有的结果的集合，记作$\Omega$ 事件： 样本空间的子集，叫做随机事件，记作A,B,C。 ​ 分类：基本事件（由一个样本点构成），不可能事件（不包含任何样本点），必然事件（样本空间的所有样本点组成） 事件的关系和运算 ​ A与B互斥（互不相容），并为空集。不可能同时发生。 ​ 对立（互逆）：A,B在一次实验中有且仅有一个发生。 ¶事件间的关系 包含 相等 互不相容性：不可能同时发生，没有交集 ¶事件的概率 ¶概率的公理化定义 ¶计算方法 ¶古典方法 随机事件的要求：(1). 涉及的随机现象只有有限个基本结果（2). 每个基本结果出现的可能性是相同的（等可能性） 事件的基本结果： $$ P(A) = \frac{k}{n} = \frac{事件包含的基本事件的个数}{全空间包含的基本结果总数} $$ ¶事件的独立性 两个事件的独立性是指一个事件的发生不影响另一个事件的发生， $$ P(AB) = P(A)P(B) $$ 多个事件的独立性 $$ P(A_iA_j) = P(A_i)P(A_j)\ P(A_iA_jA_k) = P(A_i)P(A_j)P(A_k)\ \vdots P(A_1A_2\cdots A_n) = P(A_1)P(A_2)\cdots P(A_n) $$ ¶实验的独立性 实验$E_1$的任意一个结果（事件）与实验$E_2$的任一个结果都是相互独立的事件，则称实验相互独立 ¶条件概率 $$ P(A|B) = \frac{P(AB)}{P(B)} $$ ¶乘法公式 $$ P(A_1A_2A_3) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2) $$ ¶全概率公式 $$ P(A) = P(A|B)P(B)+P(A|\hat{B})P(\hat{B}) $$ $$ P(A) = \sum_{i = 1}^nP(A|B_i)P(B_i) $$ ¶贝叶斯公式 $$ P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i = 1}^nP(A|B_k)P(B_k)} $$ 随机变量 day Ox01 随机变量表示随机现象结果，一般大写字母X,Y,Z, 随机变量取值用小写字母x,y,z等表示。 用等号或者不等号把X与x联系起来就很多有趣的事件，X=x,Y&lt;y,等等构成了事件。 ¶随机变量 定义在基本空间$\Omega$上的实值函数$X = X(w)$成为随机空间 $$ X: w-&gt;实数域（映射) $$ ¶随机变量的分布函数 分布函数的定义 $$ F(x) = P(X&lt;=x) $$ 离散随机变量：分段函数 连续随机变量：连续函数 ¶离散随机变量 ${p(x)}$ 成为随机变量X的分布列，或概率分布 $X ~ {p(x_i)}$ 其分布函数$F(x) = \sum_{x_i&lt;x}p(x_i)$ ¶常见分布 ¶二项分布 特点 重复进行$n$次相互独立的实验 每次实验只可能有两个结果 每次实验出现成功的概率相同，且为p 符号说明 $ B_{n,k}$表示n重贝努里实验中成功出现的k次 X:n重贝努里实验中成功的次数，则有 $B_{n,k} =‘X=k’$ $$ P(X=x)=\left ( \begin{matrix} n\ x \end{matrix}\right )px(1-p){n-x} $$ ¶泊松分布 $P(X = x) = \frac{\lambdax}{x!}e{-\lambda}$ ¶连续随机变量 概率密度函数 ¶均匀分布 $$ p(x) = \left{\begin{array}{c} \frac{1}{b-a}&amp; a&lt;=x&lt;=b\ 0, others \end{array} \right. $$ 分布函数 $$ F(x)=\left{\begin{array}{c} 0, x&lt;a\ \frac{x-a}{b-a}, a&lt;=x&lt;=b\ 1, x&gt;b \end{array}\right. $$ ¶指数分布 X~Exp($\lambda$) $$ p(x) = \left{\begin{array}{c} \lambda e^{-\lambda x},x&gt;=0\ 0, x&lt;0 \end{array}\right. $$ $$ F(x) = \left{\begin{array}{c} 0,x&lt;0\ 1-e^{-\lambda x}, x&gt;=0 \end{array} \right. $$ ¶正太分布X~N(u,$\sigma^2$) 概率密度函数 $$ p(x) = \frac{1}{\sqrt{2\pi}\sigma}exp{-\frac{(x-u)2}{2\sigma2}} $$ ¶伽马分布Ga(a,$\lambda$) $$ p(x)=\left{\begin{array}{c} \frac{\lambda{a}}{\Gamma(a)}x{a-1}e^{-\lambda x},x&gt;0\ 0,x&lt;=0 \end{array}\right. $$ 含义两个参数$a$和$\lambda$,$a&gt;0$称为形状参数，$\lambda&gt;0$ 称为尺度参数。当$a&gt;1$密度函数是单峰，峰值位于$x = (a-1)/\lambda$ ; 当$1&lt;a&lt;=2$,其密度函数是先上凸，后下凸；对$a&gt;2$, 其密度是先下凸，中间上凸，最后又下凸 随机变量的数字特征 day Ox02 ¶期望 E(X) $$ E(X) = \left{ \begin{array}{c} \sum_{i}x_ip(x_i)\ \int_{-\infty}^{+\infty}xp(x)dx \end{array}\right. $$ ¶方差 Var(X) 偏差平方的数学期望 $$ Var(X) = E(X-E(X))^2 $$ ¶标准差 $\sigma_X$ 方差的正平方根（开根号） ¶k阶（原点）矩($u_k$) $$ u_k = E(X^k) $$ ¶k阶中心矩 $v_k$ $$ v_k = E(X-E(X))^k $$ ¶变异系数$C_v$ $$ C_V = \frac{\sqrt{Var(X)}}{E(X)} $$ ¶偏度 $$ \beta_s = \frac{E(X-E(X))3}{[Var(X)]{3/2}} $$ 称为偏度系数。$\beta_s&gt;0$ 称该分布为正偏，或右偏。$\beta_s&lt;0$ 称该分布为负偏，又称左偏。刻画的是描述分布偏离对称性程度的一个特征数。 ¶峰度 $$ \beta_k = \frac{v_4}{v_2^2}-3 = \frac{E(X-EX)4}{var(X)2}-3 $$ 叫峰度系数，简称峰度。峰度是描述分布尖梢程度和/或尾部粗细的一个特征数。相对于正态分布而言的超出量。 $\beta_k&gt;0$ 表示标准化后的分布比标准正态分布更尖梢和/或尾部更粗 $\beta_k &lt; 0 $ 表示标准化后的分布比标准化状态分布更平坦和/或尾部更细 偏度和峰度都是描述分布形状的特征数 ¶中位数 ¶分位数 概率累积 ¶众数 多维随机变量及其联合分布 day Ox03 ¶n维随机向量 $$ X(\omega) = (X_1(\omega),X_2(\omega),…,X_n(\omega)) $$ ¶联合分布函数 $$ F(x_1,x_2,…,x_n) = \P(X_1&lt;=x_1,X_2&lt;=x_2,X_3&lt;=x_3,…,X_n&lt;=x_n) $$ ¶边际密度函数 $$ p_Y(y) = \int_{-\infty}^{+\infty}p(x,y)dx $$ ¶独立性 $$ F(x_1,x_2,…,x_n) = F(x_1)F(x_2)…F(x_3) $$ ¶卷积公式 X与Y相互独立的连续随机变量，其密度函数$P_X(x)$和$P_Y(y)$，则其和$Z = X+Y$ 的密度函数为 $$ p_Z(z) = \int_{-\infty}^{+\infty}p_X(z-y)p_Y(y)dy $$ ¶数字特征 期望 ¶协方差 $$ Cov(X,Y) = E[(X-E(X))(Y-E(Y))] $$ ¶相关系数 $$ Corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y} $$ ¶条件分布 $$ P(X=x_i|Y = y_i) = \frac{P(X=x_i,Y = y_i)}{P(Y = y_i)} = \frac{p_{ij}}{p_{.j}} $$ $$ p(x|y) = \frac{p(x,y)}{P_Y(y)} $$ 数理统计 day Ox04 概率论研究的是概率、各种分布的性质。数量统计则是对随机现象的观察或试验来获取数据，对已知的数据进行分析，并推断隐藏在数据背后的统计规律性。 ¶相关术语 研究对象的全体成为总体；构成总体的每个成员叫个体。 ¶从样本去认识总体 ¶频数频率分布 样本直方图描述总体概率密度函数的大致形状 ¶经验分布函数 描述总体分布函数的大致形状 ¶统计量与抽样分布 统计量（抽样分布）,$X = (X_1,X_2,…,X_n)$是来自总体的一个容量$n$的样本。 $$ T = T(X_1,X_2,…,X_n) $$ 则$T$为统计量，统计量的分布称为抽样分布。 观测值，$x = x_1,x_2,…,x_n$后，带入统计量 $$ t = T(x) = T(x_1,x_2,…,x_n) $$ 统计量不能含有未知参数。 ¶样本均值及其分布 $$ \hat{X} = \frac{1}{n}\sum_{i = 1}^{n}X_i $$ ¶样本方差与样本标准差 $$ S_n^2 = \frac{1}{n}\sum_{i = 1}n(X_i-\hat{X})2 $$ ¶样本的高阶矩 $$ A_k = \frac{1}{n}\sum_{i = 1}nX_ik $$ $$ B_k = \frac{1}{n}\sum_{i = 1}n(X_i-\hat{X})k $$ ¶分位数 $m_d$为样本中位数 $X_1,X_2,…,X_n$是来自总体的一个样本，其次序统计量为$X_{(1)}&lt;=X_{(2)}&lt;=…&lt;=X_{(n)}$，样本的p分位数$m_p$ $$ m_p=\left{\begin{array}{c} X_{(k)},\frac{k}{n+1} = p\ X_{(k)}+[X_{k+1}-X_{k}][(n+1)p-k],\frac{k}{n+1}&lt;p&lt;\frac{k+1}{n+1} \end{array}\right. $$ ¶箱线图 ¶矩估计 Ox05 ¶矩估计 想法:样本矩估计代替总体矩 ¶无偏估计 $$ \hat{\theta} = \hat{\theta}(X_1,X_2,…,X_n) $$ 为参数$\theta$的估计量 $$ E(\hat{\theta}) = \theta $$ ¶极大似然估计 ¶区间估计 $$ p(|\bar{x}-\mu|&lt;\Delta)=1-\alfha $$ 如果$\hat{x}$的分布已知，则可以求解出$\Delta$,就是区间概率，求解边界 ¶点估计 ¶贝叶斯估计 ¶假设检验 Step 1: 建立假设 原假设和备择假设 Step 2: 选择检验统计量 Step3: 选择显著性水平 第一类错误：原假设H_0为真，样本观察值落入拒绝域W,其发生的概率为，$\alfha$ Step 4: 确定临界值，给出拒绝域 专题系列 ¶专题一：参数估计 数据-&gt; 推断：概率密度函数-&gt;先确定：概率密度函数的形式和参数。 参数估计多大方法: 极大似然估计、最大后验估计、贝叶斯估计、最大熵估计、混合模型估计。 ¶极大似然估计(MLE) 形式: 模型已定，参数未知 属于频率派-》优化问题》点估计 假设： 采样独立同分布 想法：似然函数最大，就是不断改变参数，使得事件集发生的概率最大。$\theta$是定值。 $$ p(x|\theta) $$ 如果$\theta$确定，$x$是变量，这个函数叫做概率函数（probability function) 如果$x$已知，$\theta$未知，叫似然函数（likelihood function),描述对于不同参数的模型，在这种情况下，出现这个样本点的概率是多少 $$ L(\theta) = P(x_1,x_2,…,x_n|\theta)=\Pi_{i=1}^{n}P(x_i|\theta) $$ $$ \theta = arg max_{\theta}\Pi_{i = 1}^{n}P(x_i|\theta) $$ ¶最大后验估计（MAP) $\theta$是随机变量，最大后验估计要求$P(\theta|X)$最大。 $$ P(\theta|X) = \frac{P(\theta)P(X|\theta)}{p(X)} $$ 因为$P(X)$和$\theta$是独立的，所以直接忽略$p(X)$ $$ \theta_{max}= argmax_{\theta}p(\theta)p(X|\theta) $$ $p(\theta)$称为先验概率。如果服从均匀分布，$p(\theta)$服从均匀分布， ¶专题二： 常见分布 https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247510542&amp;idx=1&amp;sn=40a49b52f65ea475a71c3756bc3443d5&amp;chksm=e8737b43df04f25565b4c1d58a8c0e7e5985271da20a60c289ac3c4a7d4427ebe33bc9efc48d&amp;scene=0&amp;xtrack=1#rd ¶专题三 ：假设检验 https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&amp;mid=2648938280&amp;idx=2&amp;sn=dc6184ab880a735be9aadd0bce3383ed&amp;chksm=87940502b0e38c1499e6247e91d65b15e8354b202aba53790859d2d0ffc9081c4cb4b7ae8369&amp;scene=0&amp;xtrack=1#rd https://mp.weixin.qq.com/s?__biz=Mzg2NzIzNzg4NQ==&amp;mid=2247483764&amp;idx=1&amp;sn=5ad227215a9c634cb7114c36289e2cea&amp;chksm=cebfebe6f9c862f0ff6c2bb71648740c21129494b34da747ddd0a4e2028404401b1487d44577&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[西瓜书]]></title>
    <url>%2F2020%2F07%2F17%2F%E5%AD%A6%E4%B9%A0%E3%81%AE%E5%8E%86%E7%A8%8B-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E5%91%A8%E5%BF%97%E5%8D%8E%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[¶阅读目录 [TOC] ¶第一章 What is the machine learning? 非常官方的定义： Tom mitchell(1998) Well-posed Learning Problem:A compute program is said to learn from experience E with respect to same task T and some performance measure P,if its performance on T,as measured by P, improves with experience E。（这个我莫法翻译喔） 大概意思是强大的计算机能够事先地完成人为非显示编程好的任务，怎么完成呢？对于某个任务T,给定一个性能度量方法P,在经验E的影响下，如果P对T的测量结果得到了改进，则说明该程序从E中学习了 机器学习的过程大致如此：让计算机从数据中产生模型(model)，首先提供经验数据，给定学习算法(learning algorithm)和性能测量方法，它就能根据数据产生模型。 模型： 泛指从数据中学得的结果 模式： 局部性的结果 基本术语 数据集: data set 样本： sample 属性（特征）： attribute（feature) 属性值： attribute value 属性空间（特征空间）： attribute space （ sample space） 特征向量： feature vector 学习（训练）：learning（training） 训练数据： training data 训练集： training set 假设：hypothesis 学得模型对应了关于数据的某种潜在规律 泛函能力: generalization 假设空间 归纳（induction）： 从特殊到一般的“泛化”(generalization)过程 演绎（deduction)： 从一般到特殊的“特化”(specialization)过程 机器学习显然是归纳学习（inductive learning) 归纳学习分狭义与广义，狭义是指要求从training set 中学得概念，广义是指从sample中学习 学习过程（训练过程）看作是在所以假设组成的空间中进行搜索的过程，搜索目标是找到与training set匹配的假设。如果假设的表示一旦确定，假设空间与其规模就确定了。想更详细了解假设空间，戳我啦5.2 现实问题中常面临很大的假设空间，我们可以寻找一个与训练集一致的假设集合，称之为版本空间。版本空间从假设空间剔除了与正例不一致和与反例一致的假设，它可以看成是对正例的最大泛化。 归纳偏好 机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias),也就是学习算法在一个可能很庞大的假设空间中对假设进行选择的启发式或者“价值观” 奥卡姆剃刀定律： 若有多个假设与观测一致，则选择做简单的哪个。 没有免费的无餐定理（No Free Lunch Theorem[NFL]) 在所以问题出现的机会相同，或者所以问题同等重要下，所有算法的期望一样。但在实际问题中，针对具体的问题，不同的算法才会出现相对优劣。 发展历程 推理期：二十世纪五十年代到七十年代初，AI处于推理区，代表性工作主要是A.Newell 和H.Simon的“逻辑理论家”程序和此后的“通用问题求解”程序等。“逻辑理论家”程序证明了数学家罗素和怀特海的《数学原理》里面的某些定理，获得图灵奖。 知识期：从二十世纪七十年代中期开始，AI的研究进入了“知识期”，大量的专家系统出现，E.A.Feigenbaum（知识工程之父）在1994获得图灵奖。人们意识到，专家系统面临“知识工程瓶颈&quot;,在那个时候，有人把知识总结出来再教给计算机是相当困难的。 1950年，图灵再关于图灵测试的文章中，曾提到机器学习的可能 二十世纪五十年代初，A.Samuel著名跳棋程序。五十年代中后期，基于神经网络的”连接主义“学习，如F.Rosenblatt的感知器（Perceptro），B.Widrem的Adaline,六七十年代，基于逻辑表示的”符号主义学习技术蓬勃发展 学习期：二十世纪八十年代是机器学习百花初放的时期。一大主流是符号主义学习，代表决策树（decision tree).二十世纪九十年代中期之前，另外一大主流技术是基于神经网络的连接主义学习。二十世纪九十年代中期，”统计学习“占据主流，代表支持向量机。二十一世纪初，连接主义学习掀起了”深度学习“为名的热潮。 ¶第二章 ： 模型评估与选择 ¶经验误差与过拟合、欠拟合 训练误差（training error) or 经验误差（empirical error): 学习器在训练集上的输出与训练集之间的差异 过拟合（over fitting）：在训练集上表现非常好，泛化能力太差，最常见的情况是学习能力太强学习到不太一般的特性，无法彻底避免，只能“缓解” 欠拟合（under fitting）：这种情况容易克服 模型选择(model selection): 不同的参数配置，产生不同的模型。理论上最好的模型是对泛化能力进行评估，最好的就是泛化误差最小的，泛化误差是无法直接获取的 ¶评估方法 设置一个&quot;测试集（testing set)&quot;来测试学习器在新样本的判断能力，用测试误差近似泛化误差 要求： 测试样本与训练样本独立同分布的 测试集应该尽可能与训练集互斥，测试样本尽量不出现在训练集中 ¶如何产生training set 和 testing set 留出法（hold-out) 要求：数据集($D$)划分成两个互斥的集合（训练集($S$,测试集$T$),需要注意的是，划分后，尽量可能的保持数据分布的一致性。 不同的划分结果，得到不同的测试误差。单次使用留出法得到的结果是不够稳定的，所以一般采用若干次的随机划分，重复进行实验评估后去平均值 交叉验证法（cross validation) I. 将数据($D$)划分成$k$个大小相似的互斥子集，每个子集$D_i$都尽可能保持数据分布的一致性 II. 每次都用$k-1$作为训练集，余下的哪个子集作为测试集，于是乎都到了k个测试结果的均值 值得注意的是，$k$的取值对结果的稳定性和保真性有很大的影响，因此也叫k者交叉验证（k-flold cross validation) k的通常取值是10 同样的，数据集$D$划分为$k$个子集有很多的划分方式，可重复$P$次$k$折交叉验证。 自助法 (bootstrapping) 注意的是我们希望通过所以的训练集（$D$)训练出模型，但是流出法和交叉验证的方法，都保留一部分作为测试集，因此实际评估的模型所使用的训练集更下，这也许会导致估计偏差。 自助法： 可重复采样或者有放回采样 记采样产生的数据集（$D’$),每次从$D$中挑选应该样本，将其拷贝至($D’$),并再将采样的样本放回数据集($D$),重复($m$)次以后，得到了包含($m$)个样本的数据集($D’$) 对于可重复采样，样本始终不采到的概率是$(1-\frac{1}{m})^m$,取极限得到：初式数据集中$36.8%$为出现在采样数据集中，因此可将($D$)作为训练集，($D\D’$)作为测试集，又称外包估计(out-of-bag estimate) 自助法适用于数据量少，难区别测试集和训练集时，自助法会改变初始数据的分布，在初始数据足够的情况下，流出法和交叉验证更常用一些 ¶调参和最终的模型 学习算法都有参数(parameter),不同的参数配置，学得模型的性能也往往不同 验证集(validation set): 模型评估和选择中用于估计测试的数据集称为的数据集 往往将训练集划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参 ¶性能度量(performance measure) ¶假设检验 （其实我一直都并不是特别了解） 假设检验的基本原理 是重要的统计推断问题之一，根据样本提供的信息，检验关于总体某个假设是否正确。包括参数的假设检验（均值、方差等）和非参数（分布啊）的假设检验。 参数检验： 提出假设H—&gt;在构造统计量，确定统计量的分布—&gt; 确定拒绝域和接受域的分界线—&gt; 在根据样本计算统计量的值u —&gt; 推断 分布拟合检验 ¶偏差和方差 通过概率论分析对学习算法的期望泛化错误率进行拆解 $x$: 测试样本 $y_D$： $x$在数据集中的标记 $y$: $x$的真实标记 $f(x:D)$: 在训练集上学得的模型$f$在$x$上预测输出 以回归任务为例子： 学习算法的期望预测为： $$ \hat{f}(x) = E_D[f(x;D)]$$ 方差：度量同样的样本大小的训练集的变动所导致的学习性能的变化，即刻画数据扰动所造成的影响 $$ var(x)= E_D[(f(x;D)-\hat{f}(x))^2]$$ 噪声： 表达了当前任务上任务学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。 $$ \epsilon2=E_D[(y_D-y)2] $$ 期望输出和真实标记的差别称为偏差(bias): 度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力 $$ bias2(x)=(f(x)-y)2$$ 若假设噪声期望为零，那么算法的期望泛化误差： $$ E(f;D)=E_D[(f(x;D)-y)^2]\ =…=E_D[(f(x;D)-\hat{f}(x))2]+(\hat{f}(x)-y)2+E_D[(y_D-y)^2] $$ $$E(f;D)=bias2(x)+var(x)+\epsilon2$$ 由上式可知，泛化能力由学习算法的能力、数据的充分性、学习任务本身的难度共同决定的。 underfitting: 偏差主导泛化误差 over fitting： 训练数据发生的扰动渐渐被学习到，方差主导了泛化误差 ¶第三章 线性模型 我自己其实是一直停留在线性模型学习过程，因为每次开头都是这一张，所以我就学习了很多次。这次不准备再细看了。 ¶线性判别分析 Linear Discriminant Analysis (LDA) 基本思想： 在训练样例集上，设法将样本例子投影到一条直线上使得同类样例的投影尽可能接近、异类投影点尽可能远离。 数学表达： $D={(x_i,y_i)}{i=1}^{m}$: data set $X_i$: 第$i$类集合 $u_i$: 第$i$类集合均值向量 $\sum{i}$: 第$i$类集合协方差矩阵 $ w^Tu_i$： 第$i$类集合在直线上的投影 $ w^T\sum{i}w$: 样本点的在直线上的投影 学习算法： 同类更近： $\min \sum_{i=1}{n}(wT\sum_{i}w)$ 类中心越大： $\max ||w{T}u_1-(\sum_{i=2}(w{T}u_i))||_2^2$ 因此，想最大化的目标 考虑$i = 2$的情况 $$J = \frac{||wTu_0-wTu_1||22}{wT\sum{i=1}w+w^T\sum_{i=2}w} =\frac{wT(u_0-u_1)(u_0-u_1)Tw}{w^T(\sum_1+\sum_2)w} $$ $$ 应用空间几何和矩阵的关系描述 类内散度矩阵($S_W$) $$ $$\sum_1+\sum_2$$ $$ 类间散度矩阵： $$ $$(u_0-u_1)(u_0-u_1)^T$$ $$ 所以，我们想优化目标如下： $$ $$J = \frac{wT_Sbw}{wTS_ww}$$ 如何确定$w$呢？注意到分子分母都是关于$w$的二次型，因此解这和w的方向有关系，因此，可令 $w^TS_ww=1$ ,优化问题可是如下： $$\min -w^TS_bw \ s.t. w^TS_ww = 1$$ 构造lagrange 函数 $$ L = -wTS_bw+r(wTS_ww-1)$$ 对$w$求导可得： $$S_bw =rS_ww$$ $S_b w$和$ u_0 - u_1 $ 方向是$u_0-u_1$,不妨设 $$ S_nw=r(u_0-u_1)$$ so,$$w = s_w^{-1}(u_0-u_1)$$ 这里考虑到数值解的稳定性，因此往往把$S_w$进行奇异值分解 ¶第四章 决策树 决策树是一种特别普通的符合生活做决策的过程。 ¶第五章 神经网络 神经网络最开始出现是根据生物神经网络来的。 ¶最简单的神经网络：神经元模型(neuron|unit) McCulloch and Pitts抽象出“M-P神经元模型&quot; ¶感知器（Perceptron) 输入层和输出层，输出层：M-P神经元 感知器的学习过程一定是收敛的 ¶多层前馈神经网络 （multi-layer feddforward neural networks) 前馈：网络的拓扑结构不存在环或者回路 神经元的学习过程：就是根据训练数据来调整神经元之间的”连接权&quot;(connection weight),以及每个功能神经元的阙值 ¶误差逆传播算法： error BackPropagation (BP) ¶全局最小和局部最小 神经网络的训练过程其实也就是参数寻优的过程，基于梯度的搜素是使用最为广泛的参数寻优方法，但是如果误差函数在当前点的梯度为零，则很有可能达到局部极小。 ¶第六章 支持向量机 支持向量机的学习原理很简单也很有趣，从分类问题，怎么一步一步建立的优化问题，一步一步的完善优化问题以及求解，从硬间隔到软间隔，分类问题是考虑分对，而回归问题希望预测值和原始值尽可能的接近，这样就造成了约束条件，目标性的不同。 最重要的是引入了核方法，低维空间的非线性关系映射成了高维空间线性关系，这是特别重要的思想 第八章 集成学习 ¶基本思想 构建一组基学习器（base learner)，在结合 a. 如果集成中是相同类型的个体学习器，如决策树，全是神经网络的集成“同质”（homogeneous),个体学习器叫基学习器 b. 不同的学习器，异质（heterogeneous)，个体学习器叫组件学习器 ¶为什么有效 多样性的基学习器 不同的模型取长补短 每个基学习器都犯错误，综合起来可能性不大 举个栗子 也许一个线性模型不能简单分类，但是多个线性模型综合，可将数据集成功分类 ¶构建不同的机器学习 Q 1: 如何建立基学习器 尽量满足多样性 M1: 不同的学习算法 M2: 相同学习算法、不同的参数 M3: 不同的数据集（不同的样本子集、数据集上不同的特征） homogenous ensemble 采用相同的学习算法、不同的训练集 Bagging Boosting 相同算法，不同的参数设置 相同的训练集，不同的学习算法 Q2: 如何综合呢？ t投票法：majority voting weighted voting 训练一个新模型确定如何综合 Stacking 偏好的简单模型 ¶综合 ¶Bagging = Boostrap AGGregatING 有放回采样，同质学习器 ¶算法 1234567891011Input : 训练集 D=&#123;(x1,y1)&#125; 基学习算法A 训练轮数 T过程 for t = 1,2,...,T do h_t= A(D,Dt) // Dt第t次采样的分布 end for输出 回归：Average 分类：投票法 ¶优点 没有用于建模的样本，可以用作验证集来对泛化能力进行包外估计，可以得出Bagging泛化误差的包外估计 ¶random forest（RF) 输入为样本集$D={(x,y1),(x2,y2),…(xm,ym)}$，弱分类器迭代次数T。 输出为最终的强分类器f(x)f(x) 1）对于t=1,2…,T: a)对训练集进行第t次随机采样，共采集m次，得到包含m个样本的采样集$Dt$ b)用采样集$Dt$训练第t个决策树模型$Gt(x)$，在训练决策树模型的节点的时候， 在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分 如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。 参数设置 利用00B样本评估变量的重要性 ¶Boosting 提高 顺次建立学习器，就是先从训练集上训练一个基学习器，再根据学习器的表现对训练集分布进行调整，让先学习器错误训练的样本在后续收到更多的关注，然后基于调整的分布训练下一个学习器，最后，在将这T个学习器进行加权结合 基学习器的线性组合 $$ H_N(x;P)=\sum_{t=1}^{N}\alpha_th_t(x;a_t) $$ $a_t$是第$i$个弱学习器的最优参数，$\alpha_t$是在强分类器中的比重，$P$是$a_t$和$\alpha_t$的组合 最小化指数损失函数 $$ l_{exp}(H|D)=E_{x~D}[e^{-f(x)H(x)}] $$ $$ H_n(x)=H_{n-1}(x)+\alpha_{n}h_{n}(x,a_n) $$ $$l(h_i(x,a_t)|D)=E_{x~D}(exp(-f(x)h_i(x)))\=p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))$$ $$ \frac{\partial l(h_i(x,a_t)|D)}{\partial h_i(x,a_t)}=\ -p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))=0 $$ $$h(x)=\frac{1}{2}ln\frac{P(f(x)=1)}{P(f(x)=-1)}$$ 采取不同的损失函数，得到不同的类型 https://blog.csdn.net/luanpeng825485697/article/details/79383492 ¶GBDT ¶Stacking 不同学习器，相同数据集 第一层 第二层：不用第一层的数据 可用交叉验证 注意事项： 过拟合问题：第二层线性回归 第一层尽可能的多样性： 综合好的模型 防止过拟合 1. 随机性 2. Bagging Boosting Stacking ¶极大似然估计 似然： 相似的样子 对于一组数据，假设符合正态分布，希望已知点在这个正态分布的情况下，所有点对于的概率之和或者积最大， ，蓝色表示数据，红色就是做得正态分布 ¶第十章 降维与度量学习 ¶k近邻学习 k-Nearest Neighbor 原理： 基于某种距离度量找出训练集中与其最靠近的k个训练样本，根据k个邻居的信息进行预测。 给定测试样本$x$,如果最邻近样本$z$,最邻近分类器出错的概率就是$x$与$z$不再同一类 $$ p(err) = 1-\sum_{c \in y}p(c|x)P(c|z) $$ ¶低维嵌入 缓解维数灾难的重要途经之一是降维（dimension reduction）这样使得子空间中样本密度大幅度提高，距离计算变得更容易， ¶多维缩放（Multiple Dimensional,Scaling） MDS 假定m个样本在原始空间的距离矩阵$D$,在低维空间中，两个样本欧式距离等于原空间的距离，$||z_i-z_j|| = dist_{ij}$, 令$B=Z^TZ$为降维后样本的内积矩阵, $$ dist_{ij}2=||z_i||2+||z_j||^2-2z_iz_j=b_{ii}+b_{jj}-2b_{ij} $$ 对降维后数据中心化，均值为0,$\sum_{i=1}{m}z_i$,于是乎就有$\sum_{i=1}{M}b_{ij}=z_j(z_1+z_2+…+z_m)=0=\sum_{j=1}^{m}x_{ij}$ ,可得 $$ \sum_{i=1}{m}dist_{ij}2=\sum_{i=1}^{m}(b_{ii}+b_{jj}-2b_{ij})=tr(B)mb{jj}\ \sum_{i=1}{m}\sum_{j=1}{m}dist_{ij}^2 = 2m tr(B)\ tr(B)=\sum_{i=1}{m}||z_i||2 $$ 可得 $$ b_{ij}=-\frac{1}{2}(dist_{ij}2-dist_{i.}2-dist_{.j}2+dist{…}2) $$ 对矩阵B做特征值分解(eigenvalue decomposition)，$B = V \land V$,则 $$ Z = \land_{}^{1/2}V_{} $$ 欲获得低维子空间，最简单是对原始高维空间进行线性变换，$Z = W^TX$,特别的，$W$取正交变换，$W={w_1,w_2,…,w_{d’}}$W是d’个d维基向量， ¶主成分分析 Principal Component Analysis ：PCA 在正交空间里面的样本，用一个超平面对样本进行恰当的表达，至少这个样本点满足 最近重构性： 样本点到这个超平面的距离足够近 最大可分性： 样本点在这超平面上的投影尽可能分开 对于最近重构性： 假设样本去中心化，再假设投影变换后得到欣的正交坐标系${w_1,w_2,…,w_d}$,d维空间里面的一组单位正交基，$||w_i||2=0$,$||w_iTw_j||=0$,如果再新坐标系中丢掉一部分坐标，样本点在新坐标的投影是$z_i={w_1Tx{i1}},…,w_{d’}^Tx_{i}$,于是又$z_{ij} =w_{j}Tx_i$,$\hat{x_i}=\sum_{j}{d’}w_jx_i$ $$ \sum_{i=1}{m}||\sum_{j=1}{d’}z_{ij}w_j-x_i||22=\sum_{i=1}{m}z_iTz_i-2\sum_{i=1}{m}z_iTWTx_i+x_i^Tx_i\ =\sum{i=1}{m}x_iTWWTx_i-2\sum_{i=1}{m}x_iTWWTx_i+x_i^Tx_i\ min -\sum_{i=1}{m}z_iTz_i=-tr(Z^TZ)\ min -tr(\sum_{i=1}{m}WTx_ix_iTW)=-tr(WT(\sum_{i=1}{m}x_iTx_i)W）=-tr(WTXXTW)\ s.t W^TW = I $$ 对于最大可分性$(W^T\hat{X}=0)$ $$ max tr(WTXXTW)\s.t W^TW = I $$ 根据lagrange $$ L(W,\lambda)=-tr(WTXXTW)-\lambda(W^TW-I)\ \frac{\partial L}{\partial w_i}=-2w_iXX^T-2\lambda_i w_i=0\ XX^Tw_i = \lambda w_i $$ $XX^T$是协方差矩阵,$\lambda$是特征值，$w_i$是特征向量 特别提示，$x$需要中心化 对于线性PCA降维方法是从高维空间映射到低维空间，$Z= W^TX$,然而不少情况，则需要非线性映射才能找到恰当的低维嵌入， $\phi(x)$ $$ \max tr(\phi(X)\phi(X)^T)=tr( WT\varphi(x)\varphi(x)TW)\ W^TW = I $$ 于是有 $$ \varphi(x)^T\varphi(x)w_i=\lambda_iw_i\ w_i=\frac{tr(\varphi(x)^T\varphi(x))}{\lambda_iw_i} $$ $$ z_j = \frac{\sum_{i=1}{m}\varphi(x)T\varphi(x)}{\lambda_iw_i}\varphi(x_i) =\frac{\sum_{i=1}^{m}\varphi(x_i)K(x_i,x)}{\lambda_iw_i} $$ ¶流形学习（表示学习有点困难) 第十一章 特征选择与稀疏学习 对于一个学习任务，对任务有用的特征,称为&quot;relevant feature&quot;，对于没有用的属性”irrelevant feature&quot;,因此从给定特征集选择出相关特征子集的过程，特征选择（feature selection),原因一，降维；原因二：降低学习的任务。 无关特征，包括一类冗余特征（redundant feature），能够从其他特征里面推演出来。 ¶特征搜索 ¶前向（forward)搜索 对于特征集合${a_1,a_2,…,a_d }$,每个特征看作一个候选集，对这$d$候选的单特征子集进行评价，可选出最优子集，然后，再下一轮子集中，构成了两个特征候选的子集， ¶后向 (backward) 搜索 每次尝试去掉一个无关特征 ¶双向(bidirectional)搜索 上述操作只是贪心策略，仅仅考虑了本轮选定集合最优 ​ ¶子集评价（subset evaluation) 已知一个数据集$D$,假定第$i$类样本所占比例$p_i$,对于属性子集$A$,假设根据取值D分成V个子集${D1,D2,…,D^V}$,则子集A的信心 增益 $$ Gain(A) = Ent(D)-\sum_{i=1}V\frac{|Di|}{|D|}Ent(D^i)\ Ent(D)=\sum_{i=1}{|y|}p_ilog{-p_i} $$ ​ 信息增益Gain(A)越大，说明特征子集A包含的有助于分类的信息越多，特征子集A是对数据集D的一个划分，样本D的标记信息Y则对应着D的真实划分，就能对A进行评价，对Y对应的划分的差异越小，则说明A越好， ¶过滤式选择 Relief （Relevant Feature） 设计一个“相关统计量”来描述度量特征的重要性，该统计量是一个向量，每个分量对应一个初式特征，而特征子集的重要性则是每个特征对应统计量分量之和来决定，最终只需指定一个阙值，根据阙值选择统计量分量对应的特征即可 如何确定相关统计量 给定训练集$(x_i,y_i)$,对于实例$x_i$,在其同类样本中找最近邻（near-hit),在从异类样本中寻找其最近邻$x_{x,nm}$称为“猜错近邻”， $$ \delta^j =\sum_i-diff(x_ij,x_{i.nh}j)2+diff(x_ij,x_{i,nm}j)2 $$ 分值越大，说明对应属性的分类能力越强 对于多分类问题 $$ \delta^j = \sum_i-diff(x_ij,x_{i,nh}j)^2+\sum_{l \neq k}p_l\ diff(x_ij,x_{i,l,nm}j) $$ 这种方法看一个属性（特征）重不重要，先计算出每个属性的统计分量，按照公式，子集的评价就是对于分量的和 ¶包裹式选择 直接把最终将要使用的学习器的性能作为特征子集的评价准则，特征选择的目的就是为给定学习期选择有利其性能的特征子集。 LVW（Las Vegas Wrapper）是典型的包裹式特征选择方法，拉斯维加斯方法（Las Vegas method）框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价准则 算法 ¶嵌入式选择 学习器自动地进行特征选择 L-P范数 $$ L_P = ||X||P = p\sqrt{\sum{i=1}{n}x_ip} $$ L0范数 $$ ||X||_0=向量中非零元素的个数 $$ L1范数 $$ ||x||_1 = \sum|x_i| $$ L2范数，最常用 $$ ||X||_2=\sqrt{x_i^2} $$ 无穷范数 $$ ||x||=max|x_i| $$ 对于线性回归模型，防止过拟合，如果使用L2,称为岭回归(ridge regression),如果采取L1范数，则有称为LASSO，L1比L2更易于稀疏解，可以看得出L1范数正则化的过程得到了仅采用一部分初始化特征的模型。 L1正则化求解可使用近端梯度下降法(Proximal Gradient Descent)PGD L-Lipschitz条件 设函数$Φ(x)$在有限 区间$[a,b]$上满足如下条件： (1) 当$x∈[a,b]$时，$Φ(x)∈[a,b]$，即$a≤Φ(x)≤b$. (2) 对任意的$x1，x2∈[a,b]$， 恒成立：$|Φ(x1)-Φ(x2)|≤L|x1-x2|$. 如果$f(x)$可导，并且$\nabla f$满足L-Lipschitz条件， $$ ||\nabla f(x’)-\nabla f(x)||_22&lt;L||x’-x||_22 $$ 在$x_k$附近 $$ \hat{f}(x)=f(x_k)+f{’}(x_k)(x-x_k)+\frac{L}{2}||x-x_k||2\ =\frac{L}{2}||x-(x_k)-\frac{1}{L}\nabla f(x_k)||2^2+const $$ 可知 $$ x{k+1}=x_k-\frac{1}{L}\nabla f(x_k) $$ 对于原始问题，可先计算$z=x_k-\frac{1}{L}\nabla f(x_k)$, $x_{k+1}=arg \ \ min_{x} \frac{L}{2}||x-z||_2^2+\lambda||x||_1$ 由于各个分量相互不影响 $$ x_{k+1}i=\begin{cases}zi-\frac{\lambda}{L}, \frac{\lambda}{L}&lt;z^i\ 0, |z^i| &lt;= \frac{\lambda}{L} \ zi+\frac{\lambda}{L},zi&lt;-\frac{\lambda}{L}\end{cases} $$ ¶稀疏学习]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>西瓜书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PageRank算法]]></title>
    <url>%2F2020%2F07%2F15%2FPageRank%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PageRank是一种网页排序算法，基于页面的质量和数量。可应用于评估网页节点重要性。 PageRank算法 PageRank,即****网页排名*，又称网页级别*、Google左侧排名或**佩奇排名。**PageRank是Google用于用来标识网页的等级/重要性的一种方法，是Google用来衡量一个网站的好坏的唯一标准。 假设 数量假设: 如果一个页面节点入链数量越多，则这个页码越重要。 质量假设：指向页面A的入链质量不同，考虑权重的影响，则这个页面越是重要。 ¶算法求解 第一阶段：通过网页链接关系构建起Web图，初始每个页面相同的PageRank值，再通过若干轮得到每个页面的最终pagerank. 每一轮更新页面PageRank得分的计算方法 ¶权重 $$ PR(T)/L(T)\ where PR(T)的PageRank值，L(T)为T的出链数目 $$ ¶修正 $L(T)$为0的情况，孤立网页，使得很多网页能被访问到。$q = 0.85$ $$ PR(A) = (\frac{PR(B)}{L(B)}+\frac{PR©}{L©}+\dots)q+1-q $$ ¶其他网络属性度量方法 Centrality indices: degree, betweenness, and closeness. ¶reference 提出者： The anatomy of a large-scale hypertextual Web search engine https://en.wikipedia.org/wiki/PageRank]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言]]></title>
    <url>%2F2020%2F07%2F03%2FR%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[https://bookdown.org/qiyuandong/intro_r/-r-basics-2.html#section-3.3 入门： https://rc2e.com/ http://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/intro.html 全面： https://github.com/harryprince/R-Tutor 视频： 中文： https://www.youtube.com/watch?v=rPj5FsTRboE 英文：https://www.youtube.com/watch?v=32o0DnuRjfg 这个教程好： https://sites.google.com/site/econometricsacademy/econometrics-models/linear-regression https://www.youtube.com/watch?v=YMt5K68ZvjQ&amp;list=PLRW9kMvtNZOh7Xt1m5Mlhhz2wtr0tCUEE]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xgboost]]></title>
    <url>%2F2020%2F07%2F03%2FXgboost%2F</url>
    <content type="text"><![CDATA[理论部分 该算法思想就是不断地添加树，不断地进行特征分裂来生长一棵树，每次添加一个树，其实是学习一个新函数，去拟合上次预测的残差。当我们训练完成得到k棵树，我们要预测一个样本的分数，其实就是根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点就对应一个分数，最后只需要将每棵树对应的分数加起来就是该样本的预测值。 boosting: https://zhuanlan.zhihu.com/p/38329631 Xgboost 就是回归树的集成 https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/ https://blog.csdn.net/github_38414650/article/details/76061893?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare https://blog.csdn.net/qq_24519677/article/details/81809157 有空再推导了 调用库 Python 提供了两种库 xgboost xgboost sklearn接口 搭建模型 参数设置 GridSearchCV 调参(网格法) 调参步骤，参数范围 https://blog.csdn.net/han_xiaoyang/article/details/52665396 12345678import xgboost as xgbfrom xgboost import XGBRegressorfrom sklearn.metrics import mean_absolute_error,make_scorerfrom sklearn.grid_search import GridSearchCVfrom sklearn.cross_validation import KFold, train_test_splitfrom sklearn.datasets import load_boston https://blog.csdn.net/s09094031/article/details/94871596?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare 1sklearn.model_selection.``train_test_split test_size train_size： ​ 三种类型。float，int，None。 float：0.0-1.0之间，代表训练数据集占总数据集的比例。 int：代表训练数据集具体的样本数量。 None：设置为test_size的补。 default：默认为None。 random_state：三种类型。int，randomstate instance，None。 int：是随机数生成器的种子。每次分配的数据相同。 randomstate：random_state是随机数生成器的种子。（这里没太理解） None：随机数生成器是使用了np.random的randomstate。 种子相同，产生的随机数就相同。种子不同，即使是不同的实例，产生的种子也不相同。 shuffle：布尔值，可选参数。默认是None。在划分数据之前先打乱数据。如果shuffle=FALSE，则stratify必须是None。 stratify：array-like或者None，默认是None。如果不是None，将会利用数据的标签将数据分层划分。 若为None时，划分出来的测试集或训练集中，其类标签的比例也是随机的。 若不为None时，划分出来的测试集或训练集中，其类标签的比例同输入的数组中类标签的比例相同，可以用于处理不均衡的数据集。 x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.23, random_state=2) https://blog.csdn.net/qq_43288098/article/details/105407204?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare 参数：分开调 https://blog.csdn.net/zc02051126/article/details/46711047 https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn ¶模型保存 https://www.fatrabbids.com/2018/10/19/xgboost%e7%9a%84%e4%bf%9d%e5%ad%98%e6%a8%a1%e5%9e%8b%e3%80%81%e5%8a%a0%e8%bd%bd%e6%a8%a1%e5%9e%8b%e3%80%81%e7%bb%a7%e7%bb%ad%e8%ae%ad%e7%bb%83/#more-235 XGBoost的特性重要性和特性选择 模型复杂度 特征数量衡量：特征重要性阙值的增加，选择特征数量减少，模型的准确率会下降。当然，特征数量的减少反而会是准确率升高，因为这些被剔除特征是噪声。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[English-Daily]]></title>
    <url>%2F2020%2F06%2F23%2FEnglish-Daily%2F</url>
    <content type="text"><![CDATA[2020-7-6 coincide with v. 与…相符 stalk v. 潜近（猎物或人）；（非法）跟踪；怒冲冲地走；趾高气扬地走 n. 秆；柄；（叶）柄；（花）梗 verge Bella was on the verge of tears when she heard the news. 听到这个消息时，贝拉差点就要哭了。 resistant adj. 抵制的，反抗的，抗拒的；有抵抗力的；抵抗…的；不受……损害的 People are usually resistant to change. 人们通常抗拒改变。 liar The tall guy was a notorious liar. 那个高个子是个臭名昭著的骗子。 politics n. 政治；政治事物（活动）；政见；权术 oblige (以法律、义务等)强迫, 迫使; 帮忙, 效劳; [常用被动]使感激; 使(行为等)成为必要 phrase. (feel obliged to do sth.)觉得有义务做；不得不做 I felt obliged to leave after such an unpleasant quarrel. 发生了这样不愉快的争吵之后，我觉得有必要离开。 2020-7-1 jelly n. 果冻；肉冻；果酱；胶状物，胶凝物；轻便塑料鞋 oval adj. 椭圆形的；卵形的 n. 椭圆形；卵形 rigorous /'rɪɡərəs/ adj. 谨慎的，细致的；严格的，严厉的 He makes a rigorous study of the plants in the area. 他对该地的植物进行了缜密的研究。 ultimately UK/'ʌltɪmətli/ adv. 最终, 最后, 归根结底, 终究 Everything will ultimately depend on what is said at the meeting. 一切将最终取决于会议的内容。 sturdy UK/'stɜːdi/ adj. 结实的，坚固的；强壮的；健壮的；坚决的，顽强的 broaden UK/'brɔːdn/ You should broaden your experience by travelling more. 你应该多到各地走走以增广见识. broaden the horizon 开拓视野 propel UK/prə’pel/ v. 推进，推动；驱使；迫使 voyage UK/'vɔɪɪdʒ/ n. 航行, （尤指）航海 v. 航行, 远行, （尤指）远航 例句 The voyage from England to India used to take 3 weeks. 从英格兰到印度的航行曾经需要三周。 2020-6-28 moist UK/mɔɪst/ adj. 微湿的, 湿润的 insult UK/ɪn’sʌlt/v. 侮辱，辱骂 n. 侮辱，辱骂 spontaneous UK/spɒn’teɪniəs/ They greeted him with spontaneous applause. 他们自发地鼓起掌来欢迎他。 slender UK/'slendə®/ perimeter UK/pə’rɪmɪtə®/ n. 周长；外缘，边缘 blouse UK/blaʊz/ He pointed out a woman passing by who was wearing a skirt and blouse. 他指出了一个穿着裙子和衬衫的过路女子。 perfume UK/'pɜːfjuːm/ n. 香水, 香料, 芳香 v. 使…发出香气, 洒香水 2020-6-27 2020-6-26 Functional foods are food products that have a potentially positive effect on health beyond basic nutritional benefits. Functional foods aim to solve not only all the needs that regular foods provide, but also to address functional needs, which can range from maintaining and improving physical or mental health to adjusting energy levels and moods. Food has been historically used as preventive medicine in many cultures around the world, but the recent rise of functional foods can be directly linked to the rise of the wellness economy, which, in turn, is largely driven by influencer marketing and social media use. 2020-6-25 IT IS A truth universally acknowledged that inequality（不平等）in the rich world（发达国家）is high and rising. Or, at least, it used to be. A growing band of economists are challenging the received（被公认的）wisdom, pointing out that trends in the distribution（分布，分配）of income and wealth may not be as bad as is often thought. 众所周知，富裕国家的不平等现象非常严重，而且还在加剧。或者说，至少曾经是这样的。越来越多的经济学家开始质疑既有的观点，他们指出收入和财富的分布趋势可能不是像通常被认为的那么糟糕。 ¶2020-6-24 imaginary adj. 想象中的, 幻想的, 虚构的 carriage n. 运输；运费，（旧时）马车；火车车厢；仪态，姿态，举止 message messenger n. 信使, 送信人, 通信员, 邮递员 pavement n. 人行道 postpone v. 延期, 延迟, 暂缓 We’ll have to postpone the meeting until next week. 我们将不得不把会议推迟到下周举行。 velocity n. 速度，速率；高速 reconcile v. 使和谐一致，调和；使和解；将就，妥协 It’s difficult to reconcile these two different points of view. 很难兼顾这两种不同的观点。 2020-6-23 ￼The success of the brand wasn’t built through big marketing campaigns, but through a savvy digital marketing strategy that increased brand awareness and generated high engagement, traffic, and conversions. 该品牌的成功并不建立于大型营销活动，而是建立于精准的数字营销策略，该策略提高了品牌的知名度，获得了很高的参与度、流量和转化率。 traffic: 信息流量，通信量 With only 40 physical stores, which are mostly used to drive consumers to e-commerce portals, Perfect Diary maintains momentum primarily through its digital footprint. Currently, it has a powerful presence on Little Red Book, Bilibili, Weibo, WeChat, Tmall, and Douyin. Thereafter she wrote articles for papers and magazines for a living. 此后她给报纸和杂志撰稿谋生。 adv. 此后, 之后, 以后 spur n. 刺激, 激励, 鞭策; 踢马刺, 靴刺; 骨刺; 山嘴, 尖坡 v. 刺激, 激励, 促进, 鞭策 stick adj. 黏（性）的, 一面带黏胶的, 闷热的, 感到热得难受的 n. 告事贴 I have to take a shower before going out because the sweat had made my skin sticky. 出门前我得冲个澡，因为汗水让我的皮肤黏乎乎的 devotion n. 关爱，关照；奉献；忠诚；宗教礼拜 The career needs our devotion for all our lives. 这项事业需要我们毕生的奉献。 reckless adj. 鲁莽的；不计后果的；无所顾忌的 wag v. 摇动；摆（尾巴），（尾巴）摇，摆动 n. 摇摆，摆动；老开玩笑的人，爱闹着玩的人 keen adj. 热衷的, 热情的; 渴望的; 敏捷的; 灵敏的; 锋利的; 强烈的 n. 恸哭; 挽歌 v. (为死者)恸哭 be keen on sth对 感兴趣 be keen to do 渴望做某事 offspring n. 子女，后代；幼崽；幼苗 receipt n. 收据，收入]]></content>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day]]></title>
    <url>%2F2020%2F06%2F22%2Ftime-series-01%2F</url>
    <content type="text"><![CDATA[时间序列及其分解 ¶时间序列分类 ¶平稳序列（stationary series) 序列中的各观察值基本上在某个固定的水平上波动，在不同时F间段波动程度不同，但不存在某种规律。平稳性时间序列的均值和方差都是常数。 方法：a) 看原图。是否在某个常数附近波动，且波动范围有界。如果有明显的趋势性或者周期性，则不是。b) ADF单位根检测。p值。 ¶非平稳序列（non-stationary series) 涉及趋势、季节性和周期三种特性，包含其中一种或者多种成分。 ¶趋势(trend) 时间序列在长时期内呈现出来的某种上升或者下降的趋势。分为线性和非线性。 ¶季节性（seasonality) 是指时间序列在一年内重复出现的周期波动。因季节不同而发生变化，如旅游旺季，旅游淡季。 ¶周期性（cyclicity） 是指时间序列呈现出的长期趋势。周期性不同于趋势变动，它是涨落相间的交替波动。不同意季节变动，它无固定规律，变动周期多在一年以上，且周期长短不一。周期性通常是由经济环境的变化引起的。 ¶偶然性因素 其导致时间序列呈现出某种随机波动。 时间序列的成分可分为：趋势（T),季节性（S),周期性（C),随机性（I)。 ¶平稳时间序列分析 ¶AR模型 自回归模型AR 自回归模型描述当前值与历史值之间的关系，用变量自身的历史时间数据对自身进行预测。自回归模型必须满足平稳性的要求。 移动平均模型MA 移动平均模型关注的是自回归模型中的误差项的累加 自回归移动平均模型ARMA 自回归模型AR和移动平均模型MA模型相结合，我们就得到了自回归移动平均模型ARMA(p,q) 差分自回归移动平均模型ARIMA 将自回归模型、移动平均模型和差分法结合，我们就得到了差分自回归移动平均模型ARIMA(p,d,q) ¶参数确定 拖尾和截尾 拖尾指序列以指数率单调递减或震荡衰减，而截尾指序列从某个时点变得非常小。 ¶ARIMA建模过程 将序列平稳（差分法确定d） p和q阶数确定：ACF与PACF ARIMA（p,d,q） 模型 ACF PACF AR（p） 衰减趋于零（几何型或振荡型） p阶后截尾 MA（q） q阶后截尾 衰减趋于零（几何型或振荡型） ARMA（p,q） q阶后衰减趋于零（几何型或振荡型） p阶后衰减趋于零（几何型或振荡型） ¶参数 p,q 的自动确定方式 ¶信息准则 在参数估计的时候，我们可以采用似然函数作为目标函数。可以通过加入模型复杂度的惩罚项避免过拟合问题。比如赤池信息准则（AIC)和贝叶斯信息准则(BIC) $$ AIC=2k−2ln(L) $$ 一方面引入惩罚项，使得模型参数尽快少，减少过拟合。另一方面，也希望提高模型的拟合度（极大似然） $$ BIC=kLn(n)−2ln(L) $$ k为模型参数个数，n为样本数量，L为似然函数。引入$Kln(n)$惩罚项在维度过大且样本数据相对较少的情况下，可以有效避免出现维度灾难。 ¶时间序列的分解 加法模型 $$ X_t = T_t + C_t+S_t + I_t ,t = 1,2,…,n $$ 每个时间序列看成是三个部分的叠加，分别是趋势项、循环项，季节项，随机项 乘法模型 $$ X_t = T_tC_tS_t*I_t $$ ¶趋势分析 趋势拟合法就是把时间作为自变量，相应的序列观察值作为因变量，建立序列值随时间变化的回归模型。可分为线性拟合和曲线拟合。 ¶线性拟合 如果长期趋势呈现出线性特征，可用线性模型拟合， $$ \left{\begin{array}{c} x_t = a+bt+I_t\ E(I_t) = 0,Var(I_t) = \sigma^2 \end{array} \right. $$ 其中，$T_t = a+bt$就是消除随机波动影响后的该序列的长期趋势。 ¶曲线拟合 如果长期趋势呈现出线性特征，可用曲线模型来拟合 $$ \left{ \begin{array}{c|c|c} 二次型&amp; T_t = a+bt+ct^2&amp; 变换后，线性最小二乘法\ 指数型&amp;T_t = ab^t&amp; 对数变化 &amp; 最小二乘法\ 修正指数型&amp;T_t = a+bc^t&amp; &amp;迭代法\ Gompertz型&amp; T_t = e{a+bct}&amp; &amp; 迭代法\ Logistic &amp; T_t = \frac{1}{a+bc^t}&amp; 迭代法 \end{array} \right. $$ ¶平滑法 ¶移动平均法 假设在比较短的时间间隔里，序列的取值是较稳定的，这种差异是由随机波动造成的。由此，可用一定时间间隔内的平均值作为某一期的估计值。 n期中心移动平均 $$ \widetilde{x_t} = \frac{1}{n}(\frac{1}{2}x_{t-\frac{n}{2}}+x_{t-\frac{n}{2}+1}+\dots+x_{t+\frac{n}{2}-1}+\frac{1}{2}x_{t+\frac{n}{2}}) $$ n期移动平均 $$ \widetilde{x_t} = \frac{1}{n}(x_t+x_{t-1}+\dots+x_{t-n+1}) $$ ¶指数平滑法 简单指数平滑 $$ \widetilde{x_t} = \alpha x_t+\alpha (1-\alpha )x_{t-1}+\dots) $$ ¶季节效应 季节性效应的存在，使得气温会在不同年份的相同月份呈现出相似的性质。 如果只是存在季节性和随机波动性 $$ x_{ij} = \hat{x}S_j+I_{ij} $$ 其中$S_j$表示第j个月的季节指数，$\hat{x}$为各月平均气温。 季节指数的计算: Step1: 计算周期内各期的平均数 $$ \hat{x}k = \frac{\sum{i= 1}^{n}x_{ik}}{n}（k = 1,2,…,m) $$ 其中，m表示周期，n表示周期的数量 Step2: 计算总平均数 $$ \hat{x} = \frac{\sum_{i = 1}^{n}\sum_{k = 1}^{m}x_{ik}}{nm} $$ Step3: 计算季节指数 $$ S_k = \frac{\hat{x}_k}{\hat{x}} $$ ¶混合效应 加法模型 $$ x_t = T_t + S_t + I_t $$ 乘法模型 $$ x_t = T_tS_tI_t $$ 混合模型 $$ x_t = S_tT_t+I_t\ x_t = S_t(T_t+I_t) $$ 如果季节波动的振幅不受趋势变动的影响，则说明季节性与趋势之间没有相互作用关系，可加。如果季节波动的振幅随趋势的变化而变化，是相互作用的关系，可尝试混合模型和乘法模型。 Tool in Python: xfresh ¶特征提取 官网： https://tsfresh.readthedocs.io/en/latest/text/quick_start.html 中文： https://github.com/SimaShanhe/tsfresh-feature-translation ¶Data Formats column_id: Features will be extracted individually for each entity(id); one row per id. column_sort: sorting the time series. 特征提取: 可以一次性提取完；也可以单独提取kind_to_parameters 设置参数；还可以提取 可分布式计算 the rolling mechanism 首先确定滑动窗口 Step1 : 实现单变量特征的提取 Step2 : 实现多变量特征的提取 ¶Day Ox 01 知识清单: 特征提取：大概上千种特征（几十种方法） tsfresh.feature_extraction.extraction.extract_features(timeseries_container,default_fc_parameters=None**,** kind_to_fc_parameters=None**,** column_id=None**,** column_sort=None**,** column_kind=None**,** column_value=None**,** chunksize=None**,** n_jobs=1**,** show_warnings=False**,** disable_progressbar=False**,** impute_function=None**,** profile=False**,** profiling_filename=‘profile.txt’, profiling_sorting=‘cumulative’, distributor=None**)** pandas.DataFrame containing the different time series column_id (str) – The name of the id column to group by. column_sort (str) – The name of the sort column. n_jobs (int) – The number of processes to use for parallelization. 时间序列的滑动窗口（单序列划分成多序列） tsfresh.utilities.dataframe_functions.``roll_time_series(df_or_dict, column_id**,** column_sort=None**,** column_kind=None**,** rolling_direction=1**,** max_timeshift=None**,** min_timeshift=0**,** chunksize=None**,** n_jobs=1**,** show_warnings=False**,** disable_progressbar=False**,** distributor=None**)** max_timeshift (int) – If not None, the cut-out window is at maximum max_timeshift large. If none, it grows infinitely. min_timeshift (int) – Throw away all extracted forecast windows smaller or equal than this. Must be larger than or equal 0. n_jobs (int) – The number of processes to use for parallelization. If zero, no parallelization is used. show_warnings=False （指定）特征提取 显著性检测 https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_selection.html?highlight=select_features#tsfresh.feature_selection.selection.select_features 相关性检测 https://tsfresh.readthedocs.io/en/latest/text/parallelization.html#parallelization-of-feature-selection 123456789101112131415161718192021222324252627282930313233from tsfresh import extract_features, select_features,extract_relevant_featuresfrom tsfresh.utilities.dataframe_functions import imputefrom tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frameimport pandas as pdimport tsfresh as tsf fc_parameters_value1 = &#123;"length": None, "sum_values": None&#125;fc_parameters_value2 = &#123;"maximum": None, "minimum": None&#125;kind_to_fc_parameters = &#123; "value1": fc_parameters_value1, "value2": fc_parameters_value2&#125;if __name__ == '__main__': # ceate data rawdata = &#123;'id1': [0,0,0,0,0,1,1,1,1,1],'time': [1,2,3,4,5,10,11,12,13,14],\ 'value1': [1,2,3,4,5,6,7,8,9,10], 'value2': [1,2,3,4,5,6,7,8,9,10] &#125; df = pd.DataFrame(rawdata)# 设置长度+1 = 真实长度,是当前编号往上数. df_rolled = roll_time_series(df, column_id="id1", column_sort="time", max_timeshift=1, min_timeshift=0)# roll_time_series的返回值 print(df_rolled) df_rolled = df_rolled.drop('id1',axis = 1)# column_id: 聚合列 column_sort:排序，一个column_id就对应一个特征 extracted_features = extract_features(df_rolled, column_id='id', column_sort='time', kind_to_fc_parameters = kind_to_fc_parameters, show_warnings=False) print(extracted_features) ¶Day Ox 02 查看提取特征 可根据此提取自动提取的特征，用于预测时候的提取特征 1kind_to_fc_parameters = tsf.feature_extraction.settings.from_columns(extracted_features) 1234# 5. 特征抽取与过滤同时进行（一步到位，省去多余计算）# column_id: group by #features_filtered_direct = extract_relevant_features(timeseries, y, column_id='id', column_sort='time')#print(features_filtered_direct.head()) 学习路径： 1. 数据格式 2. 滑动窗口设置 3. 特征提取 4. 特征选择 专题 时间序列的竞赛方案 https://mp.weixin.qq.com/s?__biz=MzU1Nzc1NjI0Nw==&amp;mid=2247485604&amp;idx=1&amp;sn=6283ec080344665bfad90570bf1504a4&amp;chksm=fc31b29ccb463b8acac7acf4d89494aaad0c76620becb2b07c370ccbfaff850edc3c1ad4e0fd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1593390448780&amp;sharer_shareid=fb5716a8ad12ea6329433df53d4cbf64#rd https://www.zhihu.com/question/21229371/answer/533770345 Prophet 工具]]></content>
  </entry>
  <entry>
    <title><![CDATA[回归分析]]></title>
    <url>%2F2020%2F06%2F20%2F%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[[TOC] 回归分析 最简单的线性回归，避免多重共线性，过拟合，引入正则项的线性回归模型。涉及到的数学知识：一范数，二范数，多元函数求极值。模型的含义，参数求解算法，目标函数，以及各种模型的优缺点。 ¶定义 回归分析是寻找自变量和因变量之间的数量关系，用于预测建模的方法。其一，它可以揭示自变量和因变量之间的显著性检测。其二，揭示多个自变量对一个因变量的影响程度大小。 ¶回归类型 1）独立变量的数量 2）度量变量的类型 3）回归线的形状 ¶1. 线性回归（Linear Regression) 因变量：连续； 自变量：连续或者离散 ¶模型的形式 $$ Y = a+bX+𝜀\ \left(\begin{array}{c} y_{1} \ y_{2} \ \vdots \ y_{n} \end{array}\right)=\left(\begin{array}{cccc} 1 &amp; x_{11} &amp; \cdots &amp; x_{1(p-1)} \ 1 &amp; x_{21} &amp; \cdots &amp; x_{2(p-1)} \ \vdots &amp; \vdots &amp; \vdots &amp; \vdots \ 1 &amp; x_{n 1} &amp; \cdots &amp; x_{n(p-1)} \end{array}\right) \beta+\left(\begin{array}{c} e_{1} \ e_{2} \ \vdots \ e_{n} \end{array}\right)\ Y_{n1} = X_{np}\beta+𝜀 $$ where $a$ and $b$ are the regression coefficients, and 𝜀 is the random error. ¶目标函数 $$ min SSR = \sum_{i}(y_i-f(x_i))^2\ min_{w}||Xw-y||_2^2 $$ ¶参数估计 最小二乘法（Lease Square Method)（OLS) This approach is called the method of ordinary least squares. ¶模型评估 ¶拟合优度 R-square , coefficient of determination Larger $R^2$ indicates a better fit and means that the model can better explain the variation of the output with different inputs. https://realpython.com/linear-regression-in-python/ ¶要求 自变量和因变量之间必须满足线性关系。 多元回归存在多重共线性，自相关性和异方差性。 线性回归对异常值非常敏感。异常值会严重影响回归线和最终的预测值。 多重共线性会增加系数估计的方差，并且使得估计对模型中的微小变化非常敏感。结果是系数估计不稳定。 在多个自变量的情况下，我们可以采用正向选择、向后消除和逐步选择的方法来选择最重要的自变量。 ¶逻辑回归（Logistic Regression) Logistic 回归的本质是：假设数据服从这个分布，然后使用极大似然估计做参数的估计。 ¶Logistic 分布 $$ F(x) = P(X&lt;=x) = \frac{1}{1+e^{-(x-u)/\gamma}} $$ $$ f(x) = F’(X&lt;=x) = \frac{e{-(x-u)/\gamma}}{\gamma(1+e{-1(x-u)/\gamma})^2} $$ where $u$ 表示位置参数，$\gamma$是形状参数 ¶模型形式 $$ y = \frac{1}{1+e{-(wTx+b)}} $$ $$ P(Y=1|x) = \frac{1}{1+e{-(wTx+b)}} $$ ¶损失函数 $$ P(Y=1|x)=p(x)\ p(Y=0|x) = 1-p(x) $$ 似然函数 $$ L(w) $$ ¶多项式回归（Polynomial Regression） ¶逐步回归（Stepwise Regrssion) ¶岭回归（Ridge Regression) L2正则化(The ridge coefficients minimize a penalized residual sum of squares) 惩罚函数 ¶损失函数 $$ argmin_{w}||y-X\beta||_22+\lambda||\beta||_22 $$ 岭回归分析是一种用于存在多重共线性（自变量高度相关）数据的技术。在多重共线性情况下，尽管最小二乘法（OLS）对每个变量很公平，但它们的差异很大，使得观测值偏移并远离真实值。岭回归通过给回归估计上增加一个偏差度，来降低标准误差。 ¶套索回归（ Lasso Regression） ¶L1正则化 损失函数 $$ argmin_{w}||y-X\beta||_2^2+\lambda||\beta||_1 $$ The larger the value of $\lambda$ , the greater the amount of shrinkage and thus the coefficients become more robust to collinearity. ¶弹性回归 ElasticNet Regression ¶损失函数 $$ argmin_{w}||y-X\beta||_22+\lambda_1||\beta||_22+\lambda_2||\beta||_1 $$ ¶贝叶斯回归 频率派（优化问题） 贝叶斯派 在极大似然估计线性回归中我们把参数看成是一个未知的固定值，而贝叶斯学派则把看成是一个随机变量。 Model $$ f(x) = w^Tx = x^Tw $$ Bayesian Method Inference and Prediction ¶reference https://courses.analyticsvidhya.com/courses/Fundamentals-of-Regression-Analysis?utm_source=blog&amp;utm_medium=introduction_to_regression https://www.analyticsvidhya.com/blog/2016/12/45-questions-to-test-a-data-scientist-on-regression-skill-test-regression-solution/ Linear Regression by Sklearn ¶OLS 1234567891011121314151617181920212223242526272829303132333435363738print(__doc__)import matplotlib.pyplot as pltimport numpy as np from sklearn import datasets, linear_modelfrom sklearn.metrics import mean_squared_error, r2_score # Load the diabetes datasetdiabetes_X, diabetes_Y = datasets.load_diabetes(return_X_y= True)# select one featurediabetes_X = diabetes_X[:, np.newaxis, 2]# Split the data set into training/testing setsX_train = diabetes_X[:-20]X_test = diabetes_X[-20:]Y_train = diabetes_Y[:-20]Y_test = diabetes_Y[-20:]# Create linear regression objectregr = linear_model.LinearRegression()# Train regression modelregr.fit(X_train, Y_train)# Predict Y_pred = regr.predict(X_test)# Evaluateprint('Mean squared error: %.2f'% mean_squared_error(Y_test, Y_pred))print('R2_score:%.2f'% r2_score(Y_test,Y_pred))# Plotplt.scatter(X_test,Y_test, color = 'black')plt.plot(X_test,Y_pred, color = 'blue',linewidth = 3)plt.show() ¶Ridge &amp; Lasso 12345678910from sklearn import linear_modelreg = line_model.Ridge(alpha = .2)reg.fit([[0,0],[1,2],[3,8]],[0,1,2])reg.coef_reg.intercept_reg1 = line_model.RidgeCV(alphas = np.logspace(-6,6,13))reg1.fit([[0,0],[1,2],[3,8]],[0,1,2])reg.alpha_ 12345678910from sklearn import linear_modelreg = line_model.Lasso(alpha = .2)reg.fit([[0,0],[1,2],[3,8]],[0,1,2])reg.coef_reg.intercept_reg1 = line_model.LassoCV(alphas = np.logspace(-6,6,13))reg1.fit([[0,0],[1,2],[3,8]],[0,1,2])reg.alpha_ ¶正则系数选择 交叉验证 LassoCV。 LassoLarsCV基于Least Angle Regression 算法 坐标下降法 ¶弹性回归 Elastic-Net ¶最小角回归 ¶LARS Lasso ¶贝叶斯岭回归 123456from sklearn import linear_modelX = [[0, 0], [1, 1], [2, 2], [3, 3]]Y = [0, 1, 2, 3]reg = linear_mode.BayesianRidge()reg.fit(X, Y) ¶逻辑斯特回归 123from sklearn import linear_modelreg = linear_model.LogisticRegression() 参数 penalty**{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’** tolfloat, default=1e-4 Tolerance for stopping criteria. Cfloat, default=1.0 Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization. solver*{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’* Algorithm to use in the optimization problem. max_iterint, default=100 n_jobsint, default=None]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识清单]]></title>
    <url>%2F2020%2F06%2F19%2F%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[主要是列出关于日常中遇到的很好的资料，自己不清楚的文章和资料。 ¶2020-8-24 5W2H 5W2H分别对应着7个关键问号： What：何事？ Who：何人？ When：何时？ Where：何地？ Why：何因？ How：怎么做？ How much：多少钱？ 5W2H梳理销售下降问题 文章最开头，小P老板提了一个极其模糊的问题： “最近销售额为什么下降了？” 如果用5W2H法，应该怎么理清头绪呢？ 很简单，跟着问就完事儿了！ What（何事-问题是什么？） 问题是老板抛出的销售额下降原因分析，但这个需求太过笼统，我们需要进一步询问来界定和解构问题。 When（什么时候？） 是什么时间段销售开始下滑？下滑是环比还是同比，亦或是和平均相比？从趋势上看，是持续性下滑，还是某些时间节点的突然下跌？ Where（什么地方？） 是所有渠道的普遍下跌还是某个重点渠道的折戟？是全国各地普遍销售下降，还是某个地区销售下降的厉害？ Who（是哪群人？） 是新客户还是老客户的销售贡献乏力？是普通客户的减少，还是品牌忠诚客户的流失？ Why（为什么？） 回答完上面4个W，综合起来基本能够回答为什么销售下跌这个问题，但是这样还不够，数据分析更重要的是指导该怎么做 How（怎么做？） 如果是某个渠道老客流失严重，应该快速做客户原因定位，以及用CRM关怀来挽回客户。 如果是各渠道、全国性普遍销售下跌，市场份额被对手侵蚀，那应该紧密观察市场，紧盯竞品动作。 How much（量化做多少？） 结合上一步的行动，具体衡量通过短信或者其他方式触达花费多少，需要投入多少折扣，预计唤回多少客户，提升多少销售额，这些都可以基于历史数据量化。 怎么样？ 对于一个模糊的销售下跌问题，通过这7步的拆解，很快就打开了分析思路。不过，要完全精准的定位问题，找到本质解决办法，还需要进一步的定位、假设和验证。 2020-6-29 Z检测和T检测 https://mp.weixin.qq.com/s?__biz=MzI4MjkzNTUxMw==&amp;mid=2247485455&amp;idx=1&amp;sn=857066158bf8c2de38939f3037416035&amp;chksm=eb9321b9dce4a8afd68d764c295f8bcc69c62f2b1d000f3e1c5e61a7d9b6e2ec3de8df068174&amp;mpshare=1&amp;scene=24&amp;srcid=&amp;sharer_sharetime=1593403964973&amp;sharer_shareid=0e2d0ffe45c3a6dfb66aa422c3a1381d#rd 2020-6-28 视频： http://www.julyedu.com/video/play/58/405 2020-6-19 SQL 中文: https://www.liaoxuefeng.com/wiki/1177760294764384 英文： https://www.codecademy.com/courses/learn-sql/lessons/manipulation/exercises/sql 视频： https://www.jikexueyuan.com/course/sql/ 基础 https://study.163.com/course/courseMain.htm?courseId=215012&amp;trace_c_p_k2=f68f3d2867a343789ac2d3cfa92dd308 https://www.nowcoder.com/discuss/95812?type=2 https://www.cnblogs.com/zsh-blogs/category/1413021.html]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data-Science]]></title>
    <url>%2F2020%2F06%2F11%2FData-Science%2F</url>
    <content type="text"><![CDATA[Course Tsinghua Dr. Yuan Data Mining: Theories and Algorithms for Tackling Big Data Tools Stata: https://www.stata.com/why-use-stata/ https://www.youtube.com/watch?v=AyXeh7iojuA BOOOOOOK https://www-users.cs.umn.edu/~kumar001/dmbook/index.php]]></content>
      <categories>
        <category>数据科学(Data Science)</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密码学]]></title>
    <url>%2F2020%2F06%2F11%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[科普 Day1 ¶现代信息安全的基本要求： 信息的保密性 Confidentiality：防止信息泄漏给未经授权的人（加密解密技术）机密性 信息的完整性 Integrity：防止信息被未经授权的篡改（消息认证码，数字签名） 认证性 Authentication：保证信息来自正确的发送者（消息认证码，数字签名）认为 其他 不可否认性 Non-repudiation：保证发送者不能否认他们已发送的消息（数字签名） 第一章 引言 涉及的知识点包括信息安全的要求（主要四个方面），密码学基本概念，安全的定义，密码算法的设计要求，古典密码（替换，代替） o密码学基本概念**,**如密码编码学、密码分析学、明文、密文、加密、解密 o对称密码体制和非对称密码体制 o古典密码体制，如置换密码、单表代换密码、多表代换密码（要会计算） 现代信息安全的基本要求： 信息的保密性 Confidentiality：防止信息泄漏给未经授权的人（加密解密技术） 信息的完整性 Integrity：防止信息被未经授权的篡改（消息认证码，数字签名） 认证性 Authentication：保证信息来自正确的发送者（消息认证码，数字签名） 不可否认性 Non-repudiation：保证发送者不能否认他们已发送的消息（数字签名） http://yuqiangcoder.com/2019/10/07/%E5%AF%86%E7%A0%81%E5%AD%A6%E6%A6%82%E8%BF%B0.html ¶密码学 就是要通过算法和协议实现相应的功能 凯撒密码：移动2位，H K 恺撒密码 ¶安全 p无条件安全的(不可破译的)： p无论截获多少密文，都没有足够信息来唯一确定明文，则该密码是无条件安全的，即对算法的破译不比猜测有优势 p计算上安全的： p使用有效资源对一个密码系统进行分析而未能破译，则该密码是强的或计算上安全的 ¶密码算法要求 密码算法只要满足以下两条准则之一就行： （1） 破译密文的代价超过被加密信息的价值。 （2 ) 破译密文所花的时间超过信息的有用期。 满足以上两个准则的密码算法在实际中是可用的。 ¶单表代替密码 单表代替密码可分为 • 加法密码 • 乘法密码 • 仿射密码 ¶古典密码 置换密码 单表代替密码算法 多表代替密码算法 第二章 流密码 一次一密，流密码，密钥流三个概念。 o流密码基本概念、特点 o线性反馈移位寄存器 oRC4 一次一密（理想） •优点： •密钥随机产生，仅使用一次 •无条件安全 •加密和解密为加法运算，效率较高 •缺点： •密钥长度至少与明文长度一样长，密钥共享困难，不太实用 ¶流密码 密码体制 序列密码 •流密码的基本思想 •利用密钥k产生一个密钥流 •密钥流 •由密钥流发生器 f 产生： Ø内部记忆元件的状态σi独立于明文字符的叫做同步流密码，否则叫做自同步流密码。 密码分析学的目标在于破译（ BC ） A. 明文 B. 密文 C. 密钥 D. 算法结构 ¶保密通信系统的安全威胁 保密通信的安全威胁： 被动攻击：窃听，嗅探流量分析等，主要是破坏消息的机密性； 主动攻击：中断，篡改，假冒等。 中断破坏了信息的可用性 篡改破坏了信息的完整性 假冒破坏了真实性（认证） 所以保密通信系统的安全需求有： 机密性——采用加密机制 完整性——采用完整性验证机制，如Hash函数，消息认证码 真实性——采用认证机制，如数字签名，认证协议 中断——用密码学的技术没有太好的办法（这是我个人的理解） ¶古典密码学 置换密码：又称换位密码，加密过程中明文的字母保持相同，但是顺序被打乱。只要把位置恢复，就能得到明文。 代换密码：明文中的每一个字符被替换成密文中的另一个字符。接收者对密文做反向替换就可以恢复明文。 多名或同音代替密码 多字母代替密码 多表代替密码 总结古典密码学的特点：加密对象；方法；保密内容；破解； 计算强度小 出现在 DES 之前 数据安全基于算法的保密。这和现代密码有很大的差距，只要知道加密方法，就能轻易的获取明文。现代的密码基于秘钥的加密，算法都是公开的，而且公开的密码算法安全性更高，能被更多人评论和使用，加强漏洞的修补。 以字母表为主要加密对象。古典密码大多数是对有意义的文字进行加密，而现代密码是对比特序列进行加密。这也是现代密码和古典密码的区别，而且古典密码的分析方法也是用字母频率分析表来破解的。 替换和置换技术 密码分析方法基于字母与字母组合的频率特性以及明文的可读性 ¶现代密码学 1976：由 Diffie 和 Hellman 在《 密码学的新方向》（《New Directions in Cryptography》）提出了公钥密码学体制的思想 1977年：美国国家标准局颁布数据加密标准 DES（Data Encryption Standard） 1978年：第一个公钥算法 RSA 算法（由 Ron Rivest、Adi Shamir 和 Leonard Adleman 的姓氏首字母组成） 现代密码学主要有三个方向：私钥密码（对称密码）、公钥密码（非对称密码）、安全协议。 私钥密码也称对称密码，是对文字的加密转换成对比特序列的加密（相对于古典密码），用同一个密钥进行加密和解密操作，这个密钥发送方和接收方都是要保密的，所以称为私钥密码。它的两个基本操作就是代换和置换就是来源于古典密码学的。 对称密码有两个设计原则，一个是扩散（Diffusion）：明文的统计结构被扩散消失到密文的长程统计特性，使得明文和密文之间的统计关系尽量复杂。 另一个是混乱（confusion）：使得密文的统计特性与密钥的取值之间的关系尽量复杂。 对称密码的代表有 DES 算法和 AES 算法， ¶公钥密码 DH 密钥交换协议 RSA 算法是第一个公钥密码算法，也是第一个数字签名算法。 p q pi(n) =(p-1)(q-1);与n互质的书&lt;=n 选e 与pi(n)最大公约数1，互质， 找d，e*d/pi(n)=1 (n,e)共（n,d)私钥 a^emod n =b b^d mod n=c 根据以上密钥对的生成过程： 如果想知道 d 需要知道欧拉函数 φ(n) 如果想知道欧拉函数 φ(n) 需要知道 P 和 Q 要知道 P 和 Q 需要对 n 进行因数分解。 对于本例中的 4757 你可以轻松进行因数分解，但对于大整数的因数分解，是一件很困难的事情，目前除了暴力破解，还没有更好的办法，如果以目前的计算速度，破解需要50年以上，则这个算法就是安全的 椭圆曲线加密算法，简称ECC，是基于椭圆曲线数学理论实现的一种非对称加密算法。相比RSA，ECC优势是可以使用更短的密钥，来实现与RSA相当或更高的安全，RSA加密算法也是一种非对称加密算法 重合 ¶四、同余运算 同余就是有相同的余数，两个整数 a、 b，若它们除以正整数 m所得的余数相等，则称 a， b对于模m同余。 乘法逆元； ¶六、乘法逆元 在模7乘法中： 1的逆元为1 (1*1)%7=1 2的逆元为4 (2*4)%7=1 3的逆元为5 (3*5)%7=1 4的逆元为2 (4*2)%7=1 5的逆元为3 (5*3)%7=1 6的逆元为6 (6*6)%7=1 https://zhuanlan.zhihu.com/p/101907402 第三章现代密码 o分组密码基本概念、特点 oFeistel 网络 oDES，密钥长度、分组长度、S盒、多重DES o分组密码的四种运行模式 oAES，密钥长度、分组长度 太难记住了，原理也太难了 Day 2 现代密码 ¶一次性密码 Frank Miller 在1882 年提出了一次性密码（One-time pad）的概念——加密：将消息和私钥进行异或运算得到密文；解密：将密钥和密文进行异或运算得到原消息，这个过程类似于前面提到的 a ⊕ b ⊕ a = b 。一次性密码的定义如下所示： 无条件安全 密钥随机产生的，只能用一次 异或 1+1 =0 ，0+1 = 1 共享密钥难 ¶流密码体制 密钥k,产生密钥流（发 同步流密码（状态无光） 一.加密方法的分类： 按照不同的标准有不同的分类标准： 1.按照密钥的特征不同，可以分为对称密码与非对称密码。 2.按照加密方式的不同，可以分为流密码和分组密码。 3.非对称密码均属于分组密码。 ¶1.流密码。 又名序列密码。明文称为明文流，以序列的方式表示。加密时候，先由种子密钥生成一个密钥流。然后利用加密算法把明文流和密钥流进行加密，产生密文流。流密码每次只针对明文流中的单个比特位进行加密变换，加密过程所需要的密钥流由种子密钥通过密钥流生成器产生。流密码的主要原理是通过随机数发生器产生性能优良的伪随机序列，使用该序列加密明文流（按比特位加密），得到密文流。由于每一个明文都对应一个随机的加密密钥，所以流密码在绝对理想的条件下应该是算一种无条件安全的一次一密密码。 机密流程： 种子密码-&gt;随机数发生器-&gt;密钥流 明文流-&gt;(通过密钥流)-&gt;加密变换-&gt;密文流 设明文流为：m=m1m2·····mi·····，密钥流由密钥流发生器f产生：zi=f（k，ai），ai指加密器存储器在i时刻的状态，f是由种子密钥k和ai产生的函数，设最终的密钥流为k=k1k2···ki·····，加密结果为c=c1c2····ci·····=Ek1（m1）.。。。Eki（mi），解密结果为m=Dk1（c1）Dk2（c2）···Dki（ci）=m1m2···mi，无论加密解密，其关键都是密钥流。 ¶2.流密码的分类 分为同步流密码和自同步流密码 3.流密码的特性：极大的周期，良好的统计特性，抗线性分析。 4.流密码的安全性取决于密钥流的安全性，要求密钥流序列有较好的随机性。 5.不明密钥的人如何对流密码进行分析。 这种密钥流一般都是周期的，做到完全随机是困难的，这样伪随机序列，理论上是可以分析出来的。 举个例子。 敌方截获了密文串：101101011110010 明文串：011001111111001 密钥流：110100100001011 可以根据前10个比特建立如下方程 密钥流生成器： 高要求关键 要求： 游程：周期 0.1 发聩函数 产生密钥流的要求，方法、设计 反馈移位寄存器 ​ ：寄存器 ​ ： 返回函数 初始状态 线性反馈移位寄存器 快 周期“ 输出形状：发聩函数 算法 RC4 ¶流密码是一次一密吗？不是 RC4没有实现的 ¶m-序列 不可约《2^n-1 充要 本原多项式 反馈函数形式 伪随机性 ¶求你 12 Day 3 3_13 分组密码 ¶应用 ¶设计结构原理 ¶安全性原则 混淆原则 扩散原则 ¶算法要求 分组长度足够大 密钥量足够大 ¶DES算法 56-64 IBM第一个商业 后面出现了AES ¶算法框图 IP 初始置换 论函数 16论 分左右32bit 公式：函数（R,轮密钥） S盒 输入六位，8个盒子 输出32bit step1; 32bit-48bit() 选择扩展运算 E 8*4-》两端 置换 S盒 4*16 选择压缩运算 ​ 输入输出 ​ 输入：6bit 二进制-》十进制 确定位置 P盒置换 32 -32 密钥编排 置换-》两组-》循环左移》16轮密钥 性质：互补性和弱密钥性 2DES 56+1 = 57 中间人相遇工具 3DES ¶分组密码的工作模式 为什么？分组长度是固定，而数据长度和格式是不同的， 电码本模式 密码分组链接模式 ​ CBC加密 完整性（认证码生成）加密，对比 明文校验码-》CBC(M.r)&gt;对比 解决：明文统计规律隐藏 工作模式 2 数据格式： ​ 字节、比特、等等故事 ¶分组密码概述 共享密钥 IV ¶有限域的基本概念 单位元：加法 逆元：乘法 ¶AES 字节为处理单元 8bits 加法：mod 2 多项式除法 8 4 3 1 0 的末多项式取模 多项式运算 128 128，192，256 S-按列 四个基本做出 10 12 14 s:16 字节代换 She 16*16 S里面查表代换 二进制 十六进展 求逆 混淆效应 乱了 行移位 ​ 循环左移 列混淆 ​ 每一列矩阵现场 ​ 看成多项式 ​ 矩阵选择 轮密钥加 异或：子密钥 居住 ​ 初始密钥， AES ​ 四个位-》一个字节-》16进制 一个字节=》两个十六进数 密钥扩展算法 逆S盒 Day 4 现代密码学 3-27 公钥：密钥管理， 非对称密码体制 密钥对 pk sk 加密：公钥 优势： ​ 密钥分发 ​ 密钥管理 ：1 N-1 ​ 开放系统 ¶RSA加密算法 数学知识 ​ 算法 大数据分解 密钥生成 最大公因子和乘法逆元的计算方法。 https://blog.csdn.net/boksic/article/details/7014386 https://blog.csdn.net/a745233700/article/details/102341542?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5 https://blog.csdn.net/weixin_34138377/article/details/92199465?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4 https://blog.csdn.net/weixin_41482303/article/details/85417302?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 签名 证书 https://blog.csdn.net/weixin_34007879/article/details/85528967?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2]]></content>
      <categories>
        <category>科普</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[or]]></title>
    <url>%2F2019%2F12%2F01%2For%2F</url>
    <content type="text"><![CDATA[运筹学 目的是在决策时为管理人员提供科学依据。 利用统计学，数学模型和算法等方法，寻找复杂问题中的最佳或者近似最佳的解答。 解决问题的优化算法。 ¶模型建立 实际问题 决策变量 影响所要到达目的的因素找到决策变量 目标函数 约束条件 ¶线性规划 ¶整数规划 1、纯整数规划：所有决策变量均要求为整数的整数规划 2、混合整数规划：部分决策变量均要求为整数的整数规划 3、纯0－1整数规划：所有决策变量均要求为0－1的整数规划 4、混合0－1规划：部分决策变量均要求为0－1的整数规划 分支定界法 : 精确算法–分支定界法(Branch and Bound Algorithm, B&amp;B) 这就意味着，要么花钱买以上求解器的使用权，要么就自己写B&amp;B算法的Code，然后忍受Cplex 1分钟可以求解的问题却要花1天时间的求解。（很多问题时间就是金钱，例如航班延误后剩余航班重新排班的问题，通常需要在10分钟内求解） 想法： 首先，可以确定的是这是个航班重新排班的问题，数学上，航班安排属于运筹学的问题之一，需要应用建立优化模型解决。建立最优化问题，最重要的两步是模型建立和模型求解。模型的建立：需要确定决策变量（整数规划，混合整数规划)，目标函数（多目标），约束条件。 模型的求解： 分层序列法 。 ¶课堂背景 航班的重排班问题，最优化问题，运筹学范畴的问题。 ¶约束： 算法能够在满足多种实际约束条件的前提下，可以对航班计划进行恢复，并快速给出最优的航班调整替换方案 ； 航班运行与机组编排的各类约束条件 ； 根据航班计划对机组排班计划进行调整，使得机组的资质等与航班计划可以匹配， 川航一个月内的全部航班计划与机组排班计划 备用飞机 有限 调整分机飞行顺序 航班延迟 不能提前起飞 不能超过延误时间 航班取消 如果超过了延误时间，目标函数增加调整成本 旅客转签 只能一次转，还有座位限制 航班直飞 航班由于天气或流控等原因无法顺畅运行时，将联程航班中段取消直飞最终目的地，并妥善处置旅客是航班调整方法之一。（联程航班定义为，前后段衔接并且航班号相同的多个航班） ¶机组调整 （一） 备份机组 在航班计划出现机组实力缺口时，可以在航班的出发地寻找空闲机组，安排其执行该航班。 （二） 调换机组 将多个机组的航班计划进行调换。 （三） 机组摆渡 当遇到机组计划不衔接（机组的上个航班的目的地与下个航班的出发地不一致）时，可以通过摆渡的方式，采用飞机或是其他交通工具到达下个航班的出发地。 ¶目标： 将航班运行情况受到的影响降到最低 从而使得航班与机组计划得到快速恢复、减少航班延误、提高航班正常率，使旅客有更好的出行体验，并提升公司的运行效率与经济效益。 航公公司： 损失最小 游客: 航班延时短]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux]]></title>
    <url>%2F2019%2F11%2F27%2Flinux%2F</url>
    <content type="text"><![CDATA[linux内核，linux发行版（带桌面环境），服务器的访问方式（三种），linux操作系统的相关使用，通过命令行和键盘输入搞定（用户权限，用户分组，用户之间的关系，用户操作；文件结构，文件使用，文件权限，文件编辑，文件压缩和解压，这系列操作类比操作系统，只是linux系统里面，都是命令行完成，不是可视化界面罢了；帮助，终止操作，root，sudo,超级管理员，管理员组，普通用户）windows操作系统可以干的事情，在linux服务器里面，都可以干，通过命令行配置，安装，完成！ Linux ¶Linux 的科普 Linux 是一套免费使用和自由传播的类 Unix 操作系统 ，支持多用户，多任务，支持多线程和对CPU的操作系统。，就像你多少已经了解的 Windows（xp，7，8）和 Mac OS 。 或许你之前不知道 Linux ，要知道，你之前在 Windows 使用百度、谷歌，上淘宝，聊 QQ 时，支撑这些软件和服务的，是后台成千上万的 Linux 服务器主机，它们时时刻刻都在忙碌地进行着数据处理和运算，可以说世界上大部分软件和服务都是运行在 Linux 之上的。 明确目的：你是要用 Linux 来干什么，搭建服务器、做程序开发、日常办公，还是娱乐游戏； 兼具图形界面操作（需要使用带有桌面环境的发行版）和完全的命令行操作，可以只用键盘完成一切操作，新手入门较困难，需要一些学习和指导（这正是我们要做的事情），一旦熟练之后效率极高。 一般命令行操作，通过键盘完成 因为linux的哲学就是：没有结果就是最好的结果 如果只是执行，执行失败会告诉你哪里错了，如果执行成功那么会没有输出，因为linux的哲学就是：没有结果就是最好的结果 ¶Linux的发行版 Linux发行版 = linux内核+应用软件的打包 知名的发行版： ubuntu，redhat,centos Linux系统 用户登录系统 （1）命令行 （2）ssh登录 SSH 为 [Secure Shell](https://baike.baidu.com/item/Secure Shell) 的缩写 ，用于远程登陆的协议 远程连接工具客户端：xshell, putty, (3) 图形界面登录 文件目录以及权限 Linux 中创建、删除用户，及用户组等操作。 Linux 中的文件权限设置。 1.2 实验知识点 Linux 用户管理 Linux 权限管理 用户管理 通过第一节课程的学习，你应该已经知道，Linux 是一个可以实现多用户登录的操作系统，比如“李雷”和“韩梅梅”都可以同时登录同一台主机，他们共享一些主机的资源，但他们也分别有自己的用户空间，用于存放各自的文件。但实际上他们的文件都是放在同一个物理磁盘上的甚至同一个逻辑分区或者目录里，但是由于 Linux 的 用户管理和 权限机制，不同用户不可以轻易地查看、修改彼此的文件。 在 Linux 系统里， root 账户拥有整个系统至高无上的权利，比如 新建/添加 用户。 sudo adduser lilei 创建用户（sudo 组） 我们一般登录系统时都是以普通账户的身份登录的，要创建用户需要 root 权限，这里就要用到 sudo 这个命令了。不过使用这个命令有两个大前提，一是你要知道当前登录用户的密码，二是当前用户必须在 sudo 用户组。 sudo命令：获得root权限 用户组 查看： 在 Linux 里面每个用户都有一个归属（用户组），用户组简单地理解就是一组用户的集合，它们共享一些资源和权限，同时拥有私有资源 。 groups shiyanlou 加入sudo用户组 su ：切换用户user，需要输入目标用户和密码 sudo usermod -G sudo lilei 文件所以者 su -l lilei su chown 修改权限 `sudo ` 可以以特权级别运行 cmd 命令，需要当前用户属于 sudo 组，且需要输入当前用户的密码。 文档编辑 vim编辑器 i esc :wq linux文件系统与磁盘管理 $ tree / pwd cd …: 上一级目录 …/ /:根目录：绝对路径 cd /home/shiyanlou touch test mkdir mydir cp（copy）命令复制一个文件到指定目录 要成功复制目录需要加上 -r 或者 -R 参数，表示递归复制 cd /home/shiyanlou mkdir family ​ cp -r father family rm test 跟复制目录一样，要删除一个目录，也需要加上 `-r` 或 `-R` 参数 mv 源目录文件 目的目录 ，可以用来重命名文件 $ cd /home/shiyanlou/ 使用通配符批量创建 5 个文件: $ touch file{1…5}.txt 批量将这 5 个后缀为 .txt 的文本文件重命名为以 .c 为后缀的文件: $ rename ‘s/.txt/.c/’ *.txt 批量将这 5 个文件，文件名和后缀改为大写: $ rename ‘y/a-z/A-Z/’ *.c 文件打包和解压缩 zip： 打包 ：zip something.zip something （目录请加 -r 参数） 解包：unzip something.zip 指定路径：-d 参数 tar： 打包：tar -cf something.tar something 解包：tar -xf something.tar 指定路径：-C 参数、 tar -cf shiyanlou.tar /home/shiyanlou/Desktop `-c` 表示创建一个 tar 包文件，`-f` 用于指定创建的文件名，注意文件名必须紧跟在 `-f` 参数之后 tar -xf shiyanlou.tar -C tardir 解包一个文件（`-x` 参数）到指定路径的**已存在**目录（`-C` 参数） tar -xzf shiyanlou.tar.gz 压缩文件格式 参数 *.tar.gz -z *.tar.xz -J *tar.bz2 -j linux安装软件 ¶输入，输出 输入：输入当然就是打开终端，然后按键盘输入，然后按回车，输入格式一般就是这类的 输出： 输出会返回你想要的结果，比如你要看什么文件，就会返回文件的内容。 如果只是执行，执行失败会告诉你哪里错了，如果执行成功那么会没有输出，因为linux的哲学就是：没有结果就是最好的结果 Tab: 命令补全 Ctrl+C:强制终止 学会使用通配符：通配符：*,? 学会在命令行中获取帮助：man命令调用手册页， 区段 说明 1 一般命令 2 系统调用 3 库函数，涵盖了C标准函数库 4 特殊文件（通常是/dev中的设备）和驱动程序 5 文件格式和约定 6 游戏和屏保 7 杂项 8 系统管理命令和守护进程 1man 1 ls 1ls --help]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清晰有效的数据分析思路]]></title>
    <url>%2F2019%2F11%2F26%2F%E6%B8%85%E6%99%B0%E6%9C%89%E6%95%88%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[¶如何做数据分析汇报 ¶1. 描述数据的表征 描述性统计： 平均数 中位数 众数 几何平均数 调和平均数 平均值 中间位置的数 出现次数最多 方差 标准差 分布 得到第一份数据结论 ¶2. 寻找变化，深入观察 发生变化的指标一般就是指标关联的业务环境发生了某种变化。通过观察变化量，寻找可能的业务问题点。 同比 对比同期的变化 如：上周五和去年过年 环比 对比连续周期 如：今天和昨天；本月和上月； 增长率 评估累计型指标的有力工具 如：收入 时间上的对比，也称为纵比 ：环比，同比 同级单位之间的比较，简称横比 ： 不同省份之间的分析 得到第二份数据结论，可以分析到问题所在。 ¶3.全面评估，多维分析 多维分析： 维度是描述指标 不同角度，通过多维分析，来寻求指标的变化的可以的原因。 广义的多维分析，不仅仅包括从指标的不同维度进行分析，也包含拆分为多个子指标进行分析。 指标体系+维度体系 基础/通用 年龄、性别、学历、地域、手机型号、操作系统 产品 产品类型、归属业务 运营 归属渠道、投放周期、活动类型 营销 市场推广、营销方式、营销目的 如粽子的维度 产品维度 肉粽，大枣棕，糖总 渠道维度 线上：自有APP,电商渠道，合作渠道；线下：合作门店，大屏广告 时间维度 投放周期；投放时段 地域维度 直辖市；省会；二三线城市 年龄维度 年龄段 线上入口 splash,banner,弹窗，角标 输入：第三份结论；单指标分析：得到分析到上升，下降的原因。 ¶4. 多指标交叉分析 维度偏差： 大数据涉及的维度很多单一维度分析会出现偏差，多个维度组合起来的时候可能得到相反的结论。 幸存者偏差：样本的丢失问题 第四份分析结论：分析得到出现的问题？ ¶5. 量化评估，寻找归因 相关性分析： 在业务中，通过是为了量化评估各种因素对于核心指标的影响程度，寻找对业务影响的原因。 相关性分析： 单因素相关性分析 多因素的相关性分析 第五份分析结论： 找到了核心影响因素了 ¶6. 回到未来、趋势预测 趋势预测： 预测分析是一种统计或数据挖掘解决方案 时间序列预测：一般时间序列预测；季节性时间序列预测；复合时间序列预测 数学层面是严谨的 用一些数据预测方法和算法：指数平滑模型 业务层面是易变的 实际业务环境中，影响未来发展的还会有行业环境的突变，资源的突变，产品客群的突变等，人为的干扰较大。业务层面的趋势预测是不稳定的，且易变的 得到第五份结论：未来效果 ¶7. 分析的实相，落地业务 分析的结论和数据逻辑与业务方—确认，数据分析一定要闭环，即从业务中来，到业务中去。 ¶指标和维的概念 指标 ​ 指标:衡量事物发展程度的单位和方法，也叫度量。如：人口数，GDP, 收入，用户数，利润利，留存率，覆盖率等。 ​ 指标分为：绝对数指标和相对数指标。绝对指标：反映了规模大小；相对指标：反映了质量好坏的指标。 维度 事物或者现象的某种特征，如性别，地区，时间。 ​ 分为定量维度和定性维度。定性：字符型数据；定量：数值型。 只有通过事物发展的数量、质量两大方面，从横比、纵比角度进行全方位的比较，我们才能够全面的了解事物发展的好坏 通俗举个例子：2019年各个省级的经济发展状况：GDP总量：指标；省份，二三线城市：维度； ​ 总结： 数据分析的典型过程；指标拆分，维度对比； 产品（Product），是用来满足人们需求和欲望的物体或无形的载体。产品的实体称为一般产品。产品包含了产品的核心利益（向消费者提供的基本效用和利益） 1. 软件，通讯，手机，科技产品 市场是指一种货物或劳务的潜在购买者的集合需求。 在市场营销组合中， 4P 分别是产品( product) 、价格( price) 、地点( place) 、促销( promotion) 营销是创造、沟通与传送价值给顾客，及经营顾客关系以便让组织与其利益关系人（stakeholder）受益的一种组织功能与程序。 通俗地讲，就是通过宣传、推广，进而促进产品或服务的销售。 互联网产品公司三个业务部分：产品，技术，运营 产品：把东西想出来 技术：把东西做出来 运营：把东西用起来 从字面上看，运，是让产品维持运转；营，是让产品运转得更好，就是要对用户群体进行有目的地组织和管理，增加用户数量、用户粘性、用户贡献和用户忠诚度，这也就涉及到运营工作的三个重要方面：拉新、留存、促活。 理解问题–&gt; 设计解决方案–&gt; 迭代方案，直到问题解决 ¶数据分析师的技能之路 week 01: Excel学习掌握 week 02: 数据可视化 week 03： 分析思维的训练 week 04: 数据库学习 week 05: 统计知识学习 week 06: 业务学习（用户行为，产品，运营） week 07： Python/R学习 ¶数据分析应有的逻辑思维及分析方法 提出问题➟分析问题➟提出假设➟验证假设➟输出结论 ¶01 目标思维 在陈述问题时所使用的KWIC方法，其实也是逻辑要素的延伸： 1）K（KEY）：核心观点 2）W（Widen）：扩展核心观点包含的内容 3）I（Illustrate）：举例说明佐证观点 4）C（Conclude）：总结 ¶02 结构化思维 结构化思维能够帮助我们将无序、散乱的信息进行聚焦、归纳、分类。 ¶03 推理思维 确认论点，结构化论据，下一步是论证。在论证中运用推理思维能够帮助我们迅速找到问题的异同点，从而发现它们的规律。 归纳法，指从特殊（部分样本）到一般（全量样本）的过程，通俗的说是从个别的经验归纳出普遍规律的方法。 这实质上是以偏概全的方法，一旦有一个用户不满足这个前提，这个结论就无法成立。 在输出结论之前需要判断样本是否足够有代表性，判断是必然事件还是随机事件。 3-2、演绎法 演绎法则与归纳法相反,是从既有经证实的普遍性结论，推导出个别性结论的一种方法，常见的表现形式是逻辑三段论。 逻辑三段论的格式为：大前提、小前提、结论。 3-3、因果关系分析法 枚举完毕后，辩证时提问3个问题： 1）原因是否真实？ 2）结果是否真实 3）这个原因一定会引起这个结果吗？是否有其他的原因？ ¶数据分析的方法 ¶01 数据分析前的准备 1-1、分清楚目标和指标 数据分析，能帮助我们了解业务运行状况，并从中发现问题、优化问题。其次，还能够帮助洞察下一个增长点。 **数据分析的意义，往往在数据产生之前。**我们应围绕产品目标，进行产品设计以及运营策划。 目标是结果，而指标是对结果分拆的具体要求，是对目标的衡量。 假设我们的目标是提升年度成交金额，那衡量这个目标的方法是什么呢？ 根据衡量的方法我们才能定向的设置调整产品设计及运营策略。如果缺少可衡量目标的单位和方法，目标会难以达成。 而围绕目标设置数据的采集方案，可以大大节省数据过滤和清洗的时间。 甚至于在明确指标后再最开始就设置好分析模型，通过监测模型中的数据情况更及时的发现问题，做出更高质、高效的决策。 1-2、辨别指标的目的 结果指标用于衡量目标，过程指标用于体现如何完成。观察指标则指的受影响指标，其是否会受到自变量（结果指标）的影响，导致上升或下降。 在上图中，基于成交订单数，设置过程指标为订单平均金额及商品分布能帮助我们了解完成的方式。 1-3、确认分析类型 在完成目标和指标后，下一步就是应用结构化思维进行拆解和延伸。 拆解出的指标目的是什么？根据目的我们才能有倾向性的分析。 1）描述性分析 表现形式：数据报表 数据报表能够帮助我们描述事件发展的情况，但很难解释某种结果发生的原因和未来可能的趋势。 它更偏向结果性的描述，此前的结果对此后是不具备太多参考意义的。 2）测性分析 表现形式：用户相似度及物品相似度计算、用户购买饱和度、用户成交影响因子 预测性分析可以理解为对结果和变量的关系进行预测的过程，包含相似度、相关性分析、回归分析等。 相似度多用于推荐算法，通过计算用户的相似度和商品相似度从而推荐给用户。而相关分析用于预测变量的关联性，如用户的成交会受什么因素影响。 3）实证性分析及规范性分析 表现形式：A/B实验 实证性分析，指是什么，偏向于客观；规范性分析指应当做什么，偏向于主观。 在实际使用过程，上述的4种分析类型常常会被混合使用，混合使用时应明确不同类型我们应采取的分析维度。 数据分析是有顺承关系的，先采集事实，再根据事实或者预测，提出我们的假设。逐步灰度地验证假设，最终才输出我们的结论。 不能将主观猜测强加于事实之上，已经发生的结果并不一定是未来的结果 02 数据分析如何带来长期价值 为了使有用功更多，下文将从用户和收益2个维度分享数据如何为我们沉淀长期价值。 2-1、了解我们的用户 1）基础信息 基础信息，指用户本身的属性。 身份特征，可以从自然属性、社会属性向下细分，包含用户的性别、年龄、职业、教育等。 渠道属性，指用户的注册时间、注册平台、注册来源等。 2）决策类型 **决策类型，主要分为决策周期、品类偏好、促销偏好、对象偏好，**这是用户分析中常常被忽略的一方面。 决策周期中的首次访问，指的首次触及该商品的时间。结合次数、时长以及成交时间，从而了解用户的决策周期。 品类偏好，结合品牌和历史成交单数，能够帮助我们获悉品牌、价格综合对用户的影响。 而成交品类、商品、单数则是帮助我们理解其品类购买深度及路径，用于进行关联推荐和评判用户的价值。 促销偏好，结合品类和折扣金额了解用户的敏感度，能更好的提高其转化率。对象偏好，同样是了解购买深度及路径，不过维度不同。 在用户层面的分析，此前接触的一些朋友都非常热衷于使用RFM模型，在使用过程中也应“因地制宜”。 ** ** 3）购买路径 品类深度、对象深度是影响决策类型的因子，当它们在购买路径时则聚焦于次序。 根据次序，制定运营的发力点，再遵循用户的购买路径制定转化路径。 在用户分布相对稳定的前提下，应顺从用户的购买规律而非倾力于另一条主线。 一专多强的前提是专，只有聚焦优势品类或主题建立了优势，才能为其他的方向供应炮弹。 4）增长观察 前面解决的问题是：他是谁，买什么以及怎么买。最后一点，则是增长观察。 购买路径聚焦于次序，增长观察聚焦于深度。购买的次序是运营的主线，购买的深度用于精细化运营。 了解用户在品类和对象的购买深度，再辅以ARPU与LTV的比对，从用户的剩余潜力寻找平台增长点的方式。 2-2、建立你的用户模型 当时我把平台用户的地域年龄、性别等分布介绍了一番。紧接着他提问：“根据这样的画像你能够做什么呢？” 基于对用户的认识建立模型，以上一小节的决策模型为例。 将决策类型、品类偏好、对象偏好、促销偏好4个因子的关联，并辅以用户的基础信息进行组合。 如：“精打细算、专注大牌、疼爱孩子的母亲”。 这样一来冰冷的数据也被赋予了情感化的表达，无论是产品设计、交互设计、产品运营都会变得容易的多。 建立起用户模型，才能够更好地进行情感化设计、精细化运营。 https://mp.weixin.qq.com/s/eWYiHNJ57aXtqygitnwVqw]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apriori]]></title>
    <url>%2F2019%2F11%2F25%2FApriori%2F</url>
    <content type="text"><![CDATA[Apriori 算法是一种挖掘关联规则的频繁项集的算法。 ¶引言 对于特征构成的集合$A$, 如果列出非空集合有$a^{|A|}-1$种，太恐怖了。 Aprior算法：核心想法是 L_1是频繁的，则其子集也是频繁的。 L_1是非频繁的，则其超集是非频繁的 这样的化，就大大减小了搜索空间了。 Aprior算法的过程： $C_i$：表示数据集生成候选项集 $L_i$:表示生成的频繁项集 $C_{k-1}$产生$L_k$ ¶支持度 $$ support({A,B}) = num{AUB}/W = P(A \ bing \ B) $$ W:总的记录， ¶置信度 $$ Confidence(A-&gt;B) = support({A,B})/support(B) = P(B/A) $$ 注意：support(B)和Confidence(A-&gt;B)的影响， ¶序列模型 考虑时间，如周一买一堆对象，周二买一堆东西 $$ t= {t_1,t_2,…,t_n}\ s = {s_1,s_2,…,s_n} $$ &lt;{s1},{s_2}&gt;是正确的 &lt;{s1,s2}}&gt;是错误的表达]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>关联规则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的数据探索]]></title>
    <url>%2F2019%2F11%2F20%2F%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[简单的探索数据的方法 总结一些简单的数据分析方法，以及常用的python 库 Pandas里面相应的函数。 ¶统计汇总 ¶单个特征 1decrible() # 给出样本的基本统计量 频率 众数 百分位数 位置度量 均值和方差 散布度量： 极差和方差]]></content>
      <categories>
        <category>数据挖掘</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据探索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F11%2F15%2Ftest%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Python Basics]]></title>
    <url>%2F2019%2F05%2F28%2FPython-basic%2F</url>
    <content type="text"><![CDATA[重新学习 开始很乱的学习Python，现在想系统学习基础，真正了解pythonic,]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Networks]]></title>
    <url>%2F2019%2F05%2F12%2FDeel%20Learning%20ai_Convolutional%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[C4 : Convolutional Neural Networks(卷积神经网络) ¶W1 :Convolutional Neural Networks(卷积神经网络) ¶L1: Computer Vision Image classification Object detection Neural Style Transfer Problem : input big 神经网络结构复杂，数据量相对较少，容易出现过拟合； 所需内存和计算量巨大。 ¶L2: Edge detection example 我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。 **卷积运算（Convolutional Operation）**是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。 常见的边缘检测 垂直边缘（Vertical Edges) 和 水平边缘（horizontal Edges) ![](Deel Learning ai_Convolutional Neural Networks\Different-edges.png) 这张图的栏杆就对应垂直线，栏杆的水平线是水平边缘。 那么图片是怎么检测边缘的呢？ 过滤器：filter 在数学中“”就是卷积的标准标志，但是在Python中，这个标识常常被用来表示乘法或者元素乘法。 ![](Deel Learning ai_Convolutional Neural Networks\example_1.png) Output; 4 by 4 ![](Deel Learning ai_Convolutional Neural Networks\example_1——2.png) 具体运算： 1） 为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（element-wise products）运算 ![](Deel Learning ai_Convolutional Neural Networks\example_1_3png.png) 2）为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉： ![](Deel Learning ai_Convolutional Neural Networks\example_1_4png.png) 6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器。 ![](Deel Learning ai_Convolutional Neural Networks\Convolutional-operation.jpg) 举例说明： Vertical edge detection ![](Deel Learning ai_Convolutional Neural Networks\example_1_5.png) 这里在结果可能有点不对头，检测到的边缘太粗了，主要是图片太小了， 卷积操作API 在 Python 中，卷积用conv_forward()表示； 在 Tensorflow 中，卷积用tf.nn.conv2d()表示； 在 keras 中，卷积用Conv2D()表示。 ¶L3: Edge Detection Example 颜色由暗到亮，还是亮到暗 ![](Deel Learning ai_Convolutional Neural Networks\example_2_1.png) ![](Deel Learning ai_Convolutional Neural Networks\example_2_2.png) 这种滤波器可以区分明暗变化，取绝对值没有区别了 水平边缘 上边相对较亮，而下方相对较暗 ![](Deel Learning ai_Convolutional Neural Networks\example_2_3.png) 复杂栗子 ![](Deel Learning ai_Convolutional Neural Networks\example_2_4.png) 这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。 filter ![](Deel Learning ai_Convolutional Neural Networks\example_2_5.png) sobel过滤器，优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。 charr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。 学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_6.png) 这样可能得到一个出色的边缘检测 相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。 不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。 ¶Padding 按照我们上面讲的图片卷积，如果原始图片尺寸为$n x n$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n-f+1) x (n-f+1)$，注意f一般为奇数。这样会带来两个问题： 卷积运算后，输出图片尺寸缩小 原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息 边缘像素点只被一个输出所触碰或者使用， 为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行填充（Padding），以增加矩阵的大小。通常将 0 作为填充值。 ![](Deel Learning ai_Convolutional Neural Networks\Padding.jpg) 经过padding之后，填充p,原始图片尺寸为$(n+2p) x (n+2p)$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n+2p-f+1) x (n+2p-f+1)$。若要保证卷积前后图片尺寸不变，则p应满足：$ p=(f-1)/2$,f通常是奇数，如果是偶数，造成不对称填充，第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置 p=0,Valid convolution p=((f-1))/2,Same convolution ¶L05: Strided convolution（卷积步长） Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。 ![](Deel Learning ai_Convolutional Neural Networks\Stride.jpg) 我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为： $$ \left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor $$ 向下取整 目前为止我们学习的“卷积”实际上被称为互相关（cross-correlation），而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_6.png) 互相关：过滤器沿水平和垂直轴翻转，元素相乘来计算，这些视频中定义卷积运算时，我们跳过了这个镜像操作。（不进行翻转操作）叫做卷积操作 ¶L06: Convolution over volumes(三维卷积) 卷积运算 ![](Deel Learning ai_Convolutional Neural Networks\Convolutions-on-RGB-image.png) 过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。 不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_8.png) 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_9.png) 若输入图片的尺寸为n x n x nc，nc: 通道数目，filter尺寸为f x f x nc，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x nc′。其中，nc为图片通道数目，nc′为滤波器组个数。 ¶L7 : One layer of a convolution network (单层神经网络) ![](Deel Learning ai_Convolutional Neural Networks\example_2_10.png) ![](Deel Learning ai_Convolutional Neural Networks\example_2_11.png) ![](Deel Learning ai_Convolutional Neural Networks\example_2_12.png) CNN单层的所以标记符号，设层数$l$, $$ \begin{array}{l}{f^{[l]}=\text { filter size }} \ {p^{[l]}=\text { padding }} \ {g^{[l]}=\text { stride }} \ {n_{c}^{[l]}=\text { number of filters }}\end{array} $$ ![](Deel Learning ai_Convolutional Neural Networks\example_2_13.png) $$ \begin{array}{c}{n_{H}{[l]}=\left\lfloor\frac{n_{H}{[l-1]}+2 p{[l]}-f{[l]}}{s^{[l]}}+1\right\rfloor} \ { n_{W}{[l]}=\left\lfloor\frac{n_{W}{[l-1]}+2 p{[l]}-f{[l]}}{s^{[l]}}+1\right\rfloor}\end{array} $$ 如果$m$个样本，进行向量化运算，相应的输出维度，为 $$ \mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]} $$ ¶L8 : A simple convolution network example（简单卷积网络示例） ![](Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-33.jpg) 一般而言，图片的height $n^{[l]}_{H}$和width $n^{[l]}_W$随着层数的增加逐渐降低，但channel $n^{[l]}_C$逐渐增加。 CNN有三种类型的layer： Convolution层（CONV） Pooling层（POOL） Fully connected层（FC） ¶L9: Pooling layers(池化层) 卷积神经网络除了卷积层，还有池化层来缩减模型的大小，提高运算速度和鲁棒性 池的类型有max pooling(最大池化) ![](Deel Learning ai_Convolutional Neural Networks\example_2_14.png) ![](Deel Learning ai_Convolutional Neural Networks\example_2_15.png) 这里步幅是s=2，filter = 2*2是最大池化的超参数,如果是三维，则单独在每个通道执行最大池化操作 关于max pooling的直觉解释： 元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。 Pooling layer: Average pooling ![](Deel Learning ai_Convolutional Neural Networks\example_2_16.png) 但是最大池化更好用 summary : 输入$n_Hn_Wn_C$,如果没有padding,输出$(n_h-f)/s+1*(n_w-f)/s+1*n_c$ ![](Deel Learning ai_Convolutional Neural Networks\example_2_17.png) ¶L10: Convolutional neural network example (卷积神经网络实例) 做一个识别数字的CNN网络 LeNet-5架构如下： ![](Deel Learning ai_Convolutional Neural Networks\CNN.jpg) 通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练 常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax 最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。 在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。 关于CNN如何选择超参：可以参考论文的经验。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_18.png) Activation shape Activation Size #parameters Input: (32, 32, 3) 3072 0 CONV1(f=5, s=1) (28, 28, 6) 4704 156 (=556+6) POOL1 (14, 14, 6) 1176 0 CONV2(f=5, s=1) (10, 10, 16) 1600 416 (=5516+16) POOL2 (5, 5, 16) 400 0 FC3 (120, 1) 120 48120 (=120*400+120) FC4 (84, 1) 84 10164 (=84*120+84) Softmax (10, 1) 10 850 (=10*84+10) ¶L11 Why convolution 参数共享（parameter sharing) 如果用FC的话，参数爆炸啊！如果conv layer 就需要filter检测器，这个参数就少了，还参数共享 ![](Deel Learning ai_Convolutional Neural Networks\example_2_19.png) 稀疏连接(sparsity of connection) 输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_20.png) ¶summary 1. 卷积神经网络的基本构造和计算过程 2. 如何整合这些模型 3. 哪些超参数 4. 为什么使用卷积 ¶W2 : Deep convolutional models: case studies(深度卷积网络：实例探究) ¶L1 : Why look at case studies?(为什么要进行实例探究？) 本文将主要介绍几个典型的CNN案例。通过对具体CNN模型及案例的研究，来帮助我们理解知识并训练实际的模型。 典型的CNN模型包括： LeNet-5 AlexNet VGG 还会介绍Residual Network（ResNet）。其特点是可以构建很深很深的神经网络（目前最深的好像有152层）。还会介绍Inception Neural Network ¶L2 : Classic networks(经典网络) ¶1. LeNet-5 LeNet-5是针对灰度图片训练的，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，padding为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。 ![](Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-34.jpg) 该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。 ¶1. AlexNet AlexNet模型是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton共同提出的，其结构如下所示： ![](Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-35.jpg) AlexNet首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层,f=3，步幅为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，padding之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次same卷积，相同的padding，得到的结果是13×13×384，384个过滤器。再做一次same卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用softmax函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。 实际上，这种神经网络与LeNet有很多相似之处，不过AlexNet要大得多。正如前面讲到的LeNet或LeNet-5大约有6万个参数，而AlexNet包含约6000万个参数。当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点AlexNet表现出色。AlexNet比LeNet表现更为出色的另一个原因是它使用了ReLu激活函数。原作者还提到了一种优化技巧，叫做Local Response Normalization(LRN)。 而在实际应用中，LRN的效果并不突出。 ¶3. VGG-16 ![](Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-36.jpg) 首先用3×3，步幅为1的过滤器构建卷积层，padding参数为same卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此VGG网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。 数字16，就是指在这个网络中包含16个卷积层和全连接层。总共包含约1.38亿个参数 ¶L3 : Residual Networks (ResNets)(残差网络(ResNets)) 我们知道，如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功。解决的方法之一是人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为Residual Networks(ResNets)。 ![](Deel Learning ai_Convolutional Neural Networks\example_2_21.png) ![](Deel Learning ai_Convolutional Neural Networks\Residual-Network.jpg) ![](Deel Learning ai_Convolutional Neural Networks\ResNet-Training-Error.jpg) ¶L4: Why ResNets work?(残差网络为什么有用？) ![](Deel Learning ai_Convolutional Neural Networks\example_2_22.png) 因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。 注意，如果$ a[l]$与 $a[l+2]$的维度不同，需要引入矩阵 $W_s$与 $a_{[l]}$相乘，使得二者的维度相匹配。参数矩阵 $W_s$既可以通过模型训练得到，也可以作为固定值，仅使 $a[l]$截断或者补零。 ![](Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-37.jpg) ¶L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积) 作用 假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_c$）的方法，对于池化层我只是压缩了这些层的高度和宽度 ![](Deel Learning ai_Convolutional Neural Networks\example_2_23.png) doing something pretty non-trivial 它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。 ¶L6 : Inception network motivation(谷歌 Inception 网络简介) ![](Deel Learning ai_Convolutional Neural Networks\99f8fc7dbe7cd0726f5271aae11b9872.png) 有了这样的Inception模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。有了这样的Inception模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。 1x1 的卷积层通常被称作瓶颈层（Bottleneck layer） 计算量为 28x28x32x5x5x192 = 1.2亿 ![](Deel Learning ai_Convolutional Neural Networks\The-problem-of-computational-cost.png) ![](Deel Learning ai_Convolutional Neural Networks\Using-1x1-convolution.png) 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。 ¶L7 : Inception network(Inception 网络) ![](Deel Learning ai_Convolutional Neural Networks\example_2_24.png) ![](Deel Learning ai_Convolutional Neural Networks\example_2_25.png) ¶L8 : Using open-source implementations( 使用开源的实现方案) 开源项目 ¶L9 ： Transfer Learning（迁移学习） 如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。 只有很小数据集： 可以你只需要训练softmax层的权重，把前面这些层的权重都冻结。 稍微更大的数据集： 你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元；或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的softmax输出层，这些方法值得一试。 大量数据： 你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。 ¶L10 ： Data augmentation（数据增强） 数据量远远不够 Mirroring ![](Deel Learning ai_Convolutional Neural Networks\Mirroring.png) Random Cropping ![](Deel Learning ai_Convolutional Neural Networks\Mirroring_1.png) 彩色转换color shifting r,g,b数据改变 ![](Deel Learning ai_Convolutional Neural Networks\Mirroring_2.png) 除了随意改变RGB通道数值外，还可以更有针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法。这样也能增加有效的样本数量。具体的PCA color augmentation做法可以查阅AlexNet的相关论文。 ![](Deel Learning ai_Convolutional Neural Networks\Mirroring_3.png) 常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。 ¶L11：The state of computer vision(计算机视觉现状) 神经网络需要数据，不同的网络模型所需的数据量是不同的。Object dection，Image recognition，Speech recognition所需的数据量依次增加。一般来说，如果data较少，那么就需要更多的hand-engineering，对已有data进行处理。 ![](Deel Learning ai_Convolutional Neural Networks\Mirroring_4.png) hand-engineering是一项非常重要也比较困难的工作。很多时候，hand-engineering对模型训练效果影响很大，特别是在数据量不多的情况下。 当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。在别人做好的基础上研究 提升性能 ![](Deel Learning ai_Convolutional Neural Networks\Mirroring_5.png)* 由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。 所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。 ¶summary 1. CNN的常见网络结构 重点说了一些残差网络 2.数据增加的方法 3. 多用开源框架，不用从头开始训练 W3 Object detection(目标检测) ¶L1 :Object localization(目标定位) 目标定位和目标检测 ![](Deel Learning ai_Convolutional Neural Networks\Detering_1.png) 模型 ![](Deel Learning ai_Convolutional Neural Networks\Detering_2.png) 输入还包括位置信息 ![](Deel Learning ai_Convolutional Neural Networks\Detering_3.png) 损失函数 情况一：检测到了 ![](Deel Learning ai_Convolutional Neural Networks\Detering_4.png) 情况二： ![](Deel Learning ai_Convolutional Neural Networks\Detering_5.png) ¶L2: Landmark detection(特征点检测) ![](Deel Learning ai_Convolutional Neural Networks\Detering_6.png) 该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值。通过检测人脸特征点可以进行情绪分类与判断，或者应用于AR领域等等。 除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示： ![](Deel Learning ai_Convolutional Neural Networks\Detering_7.png) ¶L3 :Object detection(目标检测) 学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_8.png) 训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。 选定特定大小的窗口，窗口圈定输入卷积神经网络，卷积神经网络开始预测。 重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或![](Deel Learning ai_Convolutional Neural Networks\Detering_10.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_11.png) 如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。 这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。 滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。但是其缺点也很明显，首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。所以，滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活。 ¶L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现) 全连接层转化为卷积层 ![](Deel Learning ai_Convolutional Neural Networks\Detering_12.png) 单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，步进长度为2，CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_13.png) 之前的滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。值得一提的是，窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。 ¶L5 ： Bounding box predictions（Bounding Box预测） ![](Deel Learning ai_Convolutional Neural Networks\Detering_14.png) YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_16.png) 如果目标中心坐标(bx,by)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。判断有目标的网格中，bx,by,bh,bw限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(bx,by)范围限定在[0,1]之间，但是bh,bw可以大于1。因为目标可能超出该网格，横跨多个区域，如上图所示。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_15.png) ¶L6 ：Intersection over union（交并比) ![](Deel Learning ai_Convolutional Neural Networks\Detering_17.png) 一般约定，在计算机检测任务中，如果lou&gt;=0.5，就说检测正确，如果预测器和实际边界框完美重叠，loU就是1，因为交集就等于并集。但一般来说只要lou&gt;=0.5，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将loU定得更高，比如说大于0.6或者更大的数字，但loU越高，边界框越精确。 ¶L7: Non-max suppression(非极大值抑制) 到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_18.png) 假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_19.png) 实际情况是格子1，2，3，4，5，6都认为里面有车。因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc,我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。 非最大值抑制（Non-max Suppression）做法很简单，图示每个网格的Pc值可以求出，Pc值反映了该网格包含目标中心坐标的可信度。首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示： ![](Deel Learning ai_Convolutional Neural Networks\Detering_20.png) 总结一下非最大值抑制算法的流程： 剔除Pc值小于某阈值（例如0.6）的所有网格； 选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格； 对剩下的网格，重复步骤2。 到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用anchor box这个概念，我们从一个例子开始讲吧。方法是使用不同形状的Anchor Boxes。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_21.png) 这就是anchor box的概念，我们建立anchor box这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生 ¶L9 : YOLO 算法（Putting it together: YOLO algorithm） ![](Deel Learning ai_Convolutional Neural Networks\Detering_22.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_23.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_24.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_25.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_26.png) 这就是YOLO对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路 ¶Region proposals (Optional)（候选区域（选修）） 之前介绍的滑动窗算法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，例如下图所示。这样会降低算法运行效率，耗费时间。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_27.png) 为了解决这一问题，尽量避免对无用区域的扫描，可以使用Region Proposals的方法。具体做法是先对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。 ![](Deel Learning ai_Convolutional Neural Networks\Detering_28.png) ![](Deel Learning ai_Convolutional Neural Networks\Detering_29.png) Region Proposals共有三种方法： R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。 Fast R-CNN: 利用卷积实现滑动窗算法，类似第4节做法。 Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。 ¶W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换) ¶C1 ： What is face recognition? 首先简单介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。 人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。 人脸识别：输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题。 ¶L2 ： One-shot learning One-shot learning就是说数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型来进行人脸识别。若数据库有K个人，则CNN模型输出softmax层就是K维的。 但是One-shot learning的性能并不好，其包含了两个缺点： 每个人只有一张图片，训练样本少，构建的CNN网络不够健壮。 若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活。 为了解决One-shot learning的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用： d(img1,img2)≤τ : 一样 d(img1,img2)&gt;τ : 不一样 ![](Deel Learning ai_Convolutional Neural Networks\congtion_1.png) 现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数。 ¶L3: Siamese network 最后一层去掉softmax单元做分类 ![](Deel Learning ai_Convolutional Neural Networks\congtion_2.png) ![](Deel Learning ai_Convolutional Neural Networks\congtion_3.png) 如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x{(2)})$。这里我用$x{(1)}$和$x^{(2)}$仅仅代表两个输入图片, $$ d(x{(1)},x{(2)})=||f(x{(1)}-f(x{(2)}||^2 $$ 不同的图片的CNN网络结构和参数都是一样的，目标就是利用梯度下降算法，调整网络参数]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Deep Learning Specialization]]></title>
    <url>%2F2019%2F05%2F05%2FDeep%20Learning%20ai_Deep%20Learning%20Specialization%2F</url>
    <content type="text"><![CDATA[C3 Improving Model Performance ¶W1 ML Strategy(1) ¶L01 Improving Model Performance 需要提高训练结果的表现，表现得更好的措施 Machine Learning Strategy ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-24_21-03-13.jpg) ¶L2 : Orthogonalization(正交化) 所谓正交，就是你的操控效果尽量只影响一个方面。比如以老式电视机为例，调节图像的大小、左右偏移、上下偏移。而不是一个按钮可以同时调节图像大小和左右偏移，那样会很难操作。 具体到supervised learning，有以下4个假设是正交的？ Fit training set well in cost function If it doesn’t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help. Fit development set well on cost function If it doesn’t fit well, regularization or using bigger training set might help. Fit test set well on cost function If it doesn’t fit well, the use of a bigger development set might help Performs well in real world If it doesn’t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing. 在训练集上表现欠佳，需要切换到好的优化算法 在验证集上表现不好，一组正则化按钮 在测试集表现不好，需要更好的验证集 在用户体验不好，需要改变测试集大小或者成本函数 ¶L3 Single number evaluation metric(单一数字评估指标) ¶classification ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-25_20-42-10.jpg) ¶Precesion （查准率） ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-25_20-47-46.jpg) ¶recall（查全率） ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-25_20-48-11.jpg) $$ F 1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2 P R}{P+R} $$ ¶L4 Satisficing and optimizing metrics(满足和优化指标) 如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。这时，我们可以将某些指标作为优化指标（Optimizing Matric），寻求它们的最优值；而将某些指标作为满足指标（Satisficing Matric），只要在一定阈值以内即可。 在这个例子中，准确率就是一个优化指标，因为我们想要分类器尽可能做到正确分类；而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个阈值，那最终选择的分类器就应该是以这个阈值为界里面准确率最高的那个。 如此，accuracy就变成了optimizing metric，而running time则是satisfying metric，statisfying metric只要达到标准即可，而optimizing metric则追求更好。一般的，选择一项metric作为optimizing metric，其他的则设置为satisfying metric： ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-09-36.jpg) ¶L 5: Train/dev/test distributions(训练/开发/测试集划分) 开发（dev）集也叫做开发集（development set），有时称为保留交叉验证集（hold out cross validation set）。 如何设置Train/dev/test集，很大程度上影响了机器学习的速度。 Train/dev/test的区别 Workflow in machine learning is that you try a lot of ideas, train up different models on the training set, and then use the dev set to evaluate the different ideas and pick one. And, keep innovating to improve dev set performance until, finally, you have one class that you’re happy with that you then evaluate on your test set. ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-09-37.jpg) 开发集合和开发集合来自同一分布，如果是不同分布，相当于靶心移动了 ¶L 6: Size of dev and test sets(开发集和测试集的大小) ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-29-51.jpg) ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-25.jpg) ¶L7 : When to change dev/test sets and metrics(什么时候该改变开发/测试集和指标) 如果发现设定目标和实际期望不符，那就调整目标。 举个例子 A可能把一些色情照片也分类成猫了，因此改变优化指标 ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-26.jpg) ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-27.jpg) 我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。 后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，$J=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)$你要最小化训练集上的损失。你可以做的其中一件事是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，$J=\frac{1}{\sum w^{(i)}} \sum_{i=1}^{m} w^{(i)} L\left(\hat{y}^{(i)}, y^{(i)}\right)$ 再次，如何定义J并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数J。 ¶L8 : Why human-level performance?(为什么是人的表现？) ![](Deep Learning ai_Deep Learning Specialization\Bayes-Optimal-Error.png) 上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为贝叶斯最优误差（Bayes Optimal Error）。 也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。 当模型的表现超过人类后，这些手段起的作用就微乎其微了。 ![](Deep Learning ai_Deep Learning Specialization\e1ef954731399bb4fbf18f2fb99b863a.png) ¶L9 : Avoidable bias(可避免偏差) training error 我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。 ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-28.jpg) dev error ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-29.jpg) 贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差 ¶L 10: Understanding human-level performance(理解人的表现) 还记得上个视频中，我们用过这个词“人类水平错误率”用来估计贝叶斯误差，那就是理论最低的错误率，任何函数不管是现在还是将来，能够到达的最低值 ¶L11 : Surpassing human- level performance(超过人的表现) 现在，机器学习有很多问题已经可以大大超越人类水平了。 ![](Deep Learning ai_Deep Learning Specialization\de2eb0ddc7918f6e9213871e07b8fa56.png) ¶L12 : Improving your model performance(改善你的模型的表现) 你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。 ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-39.jpg) method ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-49.jpg) ¶summary 这一周的内容主要是改善模型的表现，主要是按照正交化，使得更好的满足 1. 评价指标 2. 数据集的划分 3. 人的表现的重要性 4. 当出现表现不好的时候，如何改善呢，有哪些方法呢？ ¶W2 ML Strategy(2) ¶C 1: Carrying out error analysis(进行误差分析) ¶1. simple analysis ![](Deep Learning ai_Deep Learning Specialization\e1ef954731399bb4fbf18f2fb99b863.png) 通过观察发现算法分类出错的例子，是把狗分成猫，提高准确率的方法就是如何针对狗的图片优化算法。你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。现在考虑的是应该不应该这么去做呢？统计一下dev set里面多少是错误标记是狗的个数，分析出可以改善的算法的上限。 ¶mutiply analysis ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-51.jpg) ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-50.jpg) ¶C2 : Cleaning up Incorrectly labeled data(清除标注错误的数据) ¶incorrct label ¶traning set DL algorithms are quite robust to random errors in the traning set so long as your errors or your labeled example to once those errors are not too far from random . ¶distribution 首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。开发集确定了你的目标，当你击中目标后，你希望算法能够推广到测试集上，这样你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正以确保它们继续来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。 ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-52.jpg) ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-53.jpg) ¶suggestion 最后我讲几个建议： 首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。 其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。 这就是错误分析过程，在下一个视频中，我想分享一下错误分析是如何在启动新的机器学习项目中发挥作用的。 ¶C3: Build your first system quickly, then iterate(快速搭建你的第一个系统，并进行迭代) ¶1. iteration I recommend that you first quickly set up a definition and metrics so this is really you know deciding where to place your target and you get it wrong you can always move it later we just set up a target somewhere and then I recommend you build an inital machine learning system quickly find the traning set train it and see start to see and understand how well your are doing against your Devon chess setting evaluation metric when you build your initial system you then be able to use bias variance analysis we should talk about earlier as well as error analysis whick we talked about just in last several videos to prioritize the next step in particular if error analysis causes you to realize that a lot of the errors are from the spearker being very far from the mirophone which causes special challenges speech recognitin then that would give you a good reason to focus on techniques to address this it called fast used speech recognition which basically means handling when the speaker is very far from microphone along the value of building this inital system it can be a quick and diry implementation you know do not overthink it but all the value of the inital system is having some learning system having some tranin system allows you lok at bias and variance to do error analysis look at some mistakes to figure out all the different directins you could go in. 我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。 ¶C4 : Training and testing on different distributions(使用来自不同分布的数据，进行训练和测试) this is resulted in many teams sometimes taking one of the days you can find and just shoving it into the training set . Cat app example ![](Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-54.jpg) 假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这10,000张图片，因为这样你的训练集就太小了，使用这20万张图片似乎有帮助。但是，困境在于，这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢？ 我们真正关心的是来自手机手机收集的数据，而不是来自网页。方法一，随机分配训练集、验证集、测试集，这样的后果就是花了大量时间在实际不关心的数据分布去优化。 训练集20万张网络，5000手机，验证集和测试集各2500，这样可以保证验证集和测试集更接近实际应用场景，我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。 ¶C5: Bias and Variance with mismatched data distributions（数据分布不匹配时，偏差与方差的分析） 首先算法只看过训练集数据，没看过开发集数据。第二，开发集数据来自不同的分布。很难确认这增加的9%误差率有多少是因为算法没看到开发集中的数据导致的，这么评估呢？到底哪个影响元素更大， 评估方法，训练集的分布挖出，traning-dev set : Same distributation as traning set ,but not used for training. 现在，我们有了训练集错误率、训练-验证集错误率，以及验证集错误率。其中，训练集错误率和训练-验证集错误率的差值反映了方差；而训练-验证集错误率和验证集错误率的差值反映了样本分布不一致的问题，从而说明模型擅长处理的数据和我们关心的数据来自不同的分布，我们称之为**数据不匹配（Data Mismatch）**问题。 ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Analysis-With-Data-Mismatch.png) ¶C6: Addressing data mismatch（处理数据不匹配问题） I![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-55.jpg) Data: Artifical data synthesis 所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。 ¶C7: Transfer learning（迁移学习） **迁移学习（Tranfer Learning）**是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。 例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（$W[L]$、$b[L]$），随后用新的训练集进行训练，就完成了以上的迁移学习。 如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即$W[L]$$、b[L]$，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为预训练（Pre-Training），之后的权重更新过程称为微调（Fine-Tuning）。 ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-56.jpg) ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-57.jpg) 在下述场合进行迁移学习是有意义的： 两个任务有同样的输入（比如都是图像或者都是音频）； 拥有更多数据的任务迁移到数据较少的任务； 某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。 ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-58.jpg) ¶C8; Multi-task learning （多任务学习） For example, autonomous driving example,check cars,stop signs,trfffic lights ,输出也是一个向量， ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-59.jpg) ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-60.jpg) ¶C9 : What is end-to-end deep learning?(什么是端到端的深度学习) 在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而**端到端深度学习（End-to-end Deep Learning）**只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。 ![](K:\MyBlog\hexo\source_posts\Deep Learning ai_Deep Learning Specialization\End-to-end-Deep-Learning.png) ¶优点与缺点 应用端到端学习的优点： 只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析； 所需手工设计的组件更少，简化设计工作流程； 缺点： 需要大量的数据； 排除了可能有用的人工设计组件； 根据以上分析，决定一个问题是否应用端到端学习的关键点是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？ ¶Whether to use end-to-end learning?(是否要使用端到端的深度学习?) Pros: ​ let the data speak : x-&gt;y ​ less hand-designing of components needed Cons: ​ May need large amount of data ​ excludes potentially useful hand-designed components Key question: Do you hava sufficient data to learn a function of the complexity needed to map x to y? 如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的x到y映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。 Summary 学习如何通过一些手段提高模型的表现，首先了解模型的性能的体现，bias、variance、贝叶斯误差。以及如何一步步的改善性能。具体解决了如下问题，1. 数据的划分 2. 人的表现与机器性能的关系、偏差、方差 3. 训练集和验证集的分布问题，当数据样本对于解决问题不足的时候的解决办法，4. 迁移学习 5. 端到端的学习 6. 多任务学习。6. 在性能不好的情况下，可能需要手动的分析误差，对测试集错误样例做统计等等，]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aiai_]]></title>
    <url>%2F2019%2F04%2F17%2FImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning%2C%20Regularization%20and%20Optimization%2F</url>
    <content type="text"><![CDATA[C2W1 ¶L01 : Train/Dev/Test Sets ¶1. process 应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_2.png) ¶2. data split 训练集（train set）：用训练集对算法或模型进行训练过程； 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行交叉验证，选择出最好的模型或者验证不同算法的有效性。 测试集（test set）：最后利用测试集对模型进行测试，获取模型运行的无偏估计（对学习方法进行评估）。 假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（dev set），其实都是同一个概念，最后一部分则作为测试集。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_3.png) 在机器学习发展的小数据量时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分： 无验证集的情况：70% / 30%； 有验证集的情况：60% / 20% / 20%； 在如今的大数据时代，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。 验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。 测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。 100 万数据量：98% / 1% / 1%； 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%） ¶3. 建议 验证集要和训练集来自于同一个分布（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。 如果不需要用无偏估计来评估模型的性能，则可以不需要测试集。如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。 ¶L02 : Bias/Variance **“偏差-方差分解”（bias-variance decomposition）**是解释学习算法泛化性能的一种重要工具。 泛化误差可分解为偏差、方差与噪声之和： 偏差：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力； 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响； 噪声：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了学习问题本身的难度。 high bias ,underfitting high variance, overfitting just right ¶1. example ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_5.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_6.png) Your algorithms ever on the training set and dev set you can try to diganose whether has problems high barriers or high variances or both or neither. ¶L03 Basic Recipe for Machine learning ¶1. METHOD ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_8.png) Training a bigger network almost never hurts. And the main cost of training a neural network that’s too big is just computational time, so long as you’re regularizing. 今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高，我们下节课再细讲，以便大家更好理解如何实现神经网络的正则化。 第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同 只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。 ¶L04 ¶1. over fitting ¶regularization L2 regularization L1 regularizaion: w will be sparse L1 正则化最后得到 w 向量中将存在大量的 0 为什么只正则化参数w？为什么不再加上参数b 呢？你可以这么做，只是我习惯省略不写，因为通常w是一个高维参数矢量，w已经可以表达高偏差问题，可能w包含有很多参数，我们不可能拟合所有参数，而只是b单个数字，所以w几乎涵盖所有参数，而不是，如果加了参数b，其实也没太大影响，因为b只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_9.png) 2.![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_10.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_11.png)矩阵范数被称作“弗罗贝尼乌斯范数”，用下标标注F 反向传播时，填上正则化的一项 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_12.png) 因此L2正则化也被称为“权重衰减”。 to get more training data ¶L05 :Why Regularization Reduces Overfitting 我们添加正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩范数，或者弗罗贝尼乌斯范数或者参数可以减少过拟合？我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单.Regularization其实是让函数变得简化。 直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。 总结一下，如果正则化参数变得很大，w参数很小，z也会相对变小，此时忽略的b影响，z会相对变小，实际上，z的取值范围很小，这个激活函数tanh，也就是曲线函数会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。 L2 regularization的不足：要通过不断的选用不同的λ进行测试，计算量加大了。 ¶L06 : Dropout Regularization ¶1. 工作原理 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_15.png) 如果上面这幅图存在over fitting。复制这个神经网络，dropout会遍历网络的每一层。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用backprop方法进行训练。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_13.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_14.png) 我们针对每个训练样本训练规模极小的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练极小的网络。 ¶2. inverted dropout（反向随机失活） 对第L 1234keep_prob = 0.8 # 设置神经元保留概率dl = np.random.rand(al.shape[0], al.shape[1]) &lt; keep_probal = np.multiply(al, dl)al /= keep_prob 最后一步al /= keep_prob是因为 a[l]a[l]中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z[l+1]=W[l+1]a[l]+b[l+1]$的期望值，因此除以一个keep_prob。举例解释我们假设第三隐藏层上有50个单元或50个神经元，在一维上是50，我们通过因子分解将它拆分成维的，保留和删除它们的概率分别为80%和20%，这意味着最后被删除或归零的单元平均有10（50×20%=10）个，现在我们看下$z{[4]}$，，我们的预期是$z{[4]}=w{[4]}a{[3]}$，$a{[3]}$减少20%，也就是说中有$a{[3]}$20%的元素被归零，为了不影响的$a{[4]}$期望值，我们需要用$w{[4]}a{[3]}/keep_prob$，它将会修正或弥补我们所需的那20%，$a{[3]}$的期望值不会变，划线部分就是所谓的dropout方法。 ¶L07 : Understanding Dropout 直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_16.png) 计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以dropout在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，dropout是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用dropout的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于dropout函数的原因。直观上我认为不能概括其它学科。dropout将产生收缩权重的平方范数的效果。当然，不同的层，值可以设置成不同，如果你觉得某一层容易过拟合，把值设置小一点。 dropout 的一大缺点是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将keep_prob全部设置为 1.0 后运行代码，确保 $J(w,b)$函数单调递减，再打开 dropout。 ¶L08 : Other Regularization Methods 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_17.png) 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，当训练集误差降低但验证集误差升高，两者开始发生较大偏差时及时停止迭代，并返回具有最小验证集误差的连接权和阈值，以避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_18.png) 但对我来说early stopping的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数，因为现在你不再尝试降低代价函数，所以代价函数的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。 Early stopping的优点是，只运行一次梯度下降，你可以找出的w较小值，中间值和较大值，而无需尝试正则化超级参数的很多值。 ¶L09 ： Normalizing inputs 零均值 $u=\frac{1}{m}\sum x^{(i)}$,$x-u$ 归一化方差； $\delta2=\frac{1}{m}(x{(i)})^2$,每个特征的方差，每个特征数据除以它，就归一化方差了 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_19.png) ¶why ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_20.png) 在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。 ¶L10 : Vanishing /Exploding Gradients 训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。 在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与相关的指数级数增长或下降，它也适用于与层数相关的导数或梯度函数，也是呈指数级增长或呈指数递减。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_21.png) 假定 g(z)=z,b[l]=0g(z)=z,b[l]=0，对于目标输出有： $y^=W[L]W[L−1]…W[2]W[1]X$ 对于$ W[l]$的值大于 1 的情况，激活函数的值将以指数级递增； 对于 $W[l]$的值小于 1 的情况，激活函数的值将以指数级递减。 对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。 ¶L11 : Weight initialization in a deep network 为了预防值z过大或过小，你可以看到n越大，你希望w越小，因为z是wx+b的和,最合理的方法$w_i=1/n$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_22.png) 因此，实际上，你要做的就是设置某层权重矩阵 $w^{[l]}=n p . random. randn (shape) * np.sqrt \left(\frac{1}{n^{[l-1]}}\right)$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_23.png) 当多个节点时，也一样的看，使得这个节点$z^{L}$不要太大，单独看每个节点既可以 relu : var(w(i)) = 2/n or $\frac{2}{n{[l-1]}*n{[l]}}$ tanh: var(w(i)) = 1/n 通过设置初始化化权重矩阵，使得不会增长太快或者太慢 ¶L12 ： Numerical Approximations of Gradients 单边误差 $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0} \frac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}$ 误差$O(\varepsilon)$ 双边误差 $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0}=\frac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2 \varepsilon}$ $O\left(\varepsilon^{2}\right)$ ¶L 13 Gradient Checking 梯度检验帮我们节省了很多时间，也多次帮我发现backprop实施过程中的bug，接下来，我们看看如何利用它来调试或检验backprop的实施是否正确。 首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵w转换成一个向量，把所有矩阵w转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数J是所有W和b的函数，现在你得到了一个的代价函数（即）。接着，你得到与和顺序相同的数据，你同样可以把$dW{[l]}$,和$db{[l]}$ 转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。 梯度的逼近值 $$ d \theta_{\text { approx }}[i]=\frac{J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}+\varepsilon, \ldots\right)-J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}-\varepsilon, \ldots\right)}{2 \varepsilon} $$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_24.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_25.png) 现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多bug，希望它对你也有所帮助。 L 14 : Gradient Checking Implementation notes 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；太慢了 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大； 当成本函数包含正则项时，也需要带上正则项进行检验； 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout； ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week1_25.png) ¶Summary 回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如正则化和dropout，还有加快神经网络训练速度的技巧，最后是梯度检验。 C2W2 :Optimization Algorithm ¶L 01 : Mini Batch Gradient Descent Vectorization Mini batch not entire training set bady training set i，$x^$ mini batch training set ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_1.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_2.png) mini batch gradient descent ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_3.png) ¶L 02 : Understanding Mini-Batch Gradient Decent ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_4.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_6.png) 左图，随着iterations increased, it should decrease .if it ever goes up on iteration,something is wrong. 右图 : it’s as if on every iteration you’re training on a different training set or really training on a different mini batch. It should trend downwards, but it’s also going to be a little bit noisier.So if you plot J{t}, as you’re training mini batch in descent it may be over multiple epochs,you might expect to see a curve like this. ¶Choosing your mini-batch size ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_5.png) ¶1. 优缺点 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_7.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_8.png) 通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的mini-batch尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果mini-batch大小为1000个样本，你就可以对1000个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每次训练集允许我们采取5000个梯度下降步骤，所以实际上一些位于中间的mini-batch大小效果最好。 使用batch梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数是迭代次数的一个函数，它应该会随着每次迭代而减少，如果在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。 在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。 用mini-batch梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会讲到学习率衰减，也就是如何减小学习率。 batch : too long,too time 随机： lose speeding ,噪声大 mini-batch和stochastic都存在噪声问题，且在local optima附近会徘徊。但设置合适大小的mini-batch size，噪声和徘徊问题可接受的范围内。 size=1,又叫随机梯度下降法 stochastic gradient descent ¶how 如何选择mini-batch size（这是一个hyperparameter）： 小数据量，比如总的样本只有几千个，完全可以直接用batch gradient descent 大数量，mini-batch size倾向于选择2^n个，比如64, 128, 256等 mini-batch 与CPU/GPU memory的内存容量。 In practice of course the mini batch size is another hyper parameter that you might do a quick search over to try to figure out which one is most sufficient of reducing the cost function j. 按照上面的方法 ¶L 03: Exponentially Weighted Averages In order to understand those algorithms, you need to be able they use something called exponentially weighted averages. Also called exponentially weighted moving averages in statistics. ¶1. 指数加权平均数（Exponentially weighted averages） ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_9.png) $\theta _i$表示每一日的温度值，蓝色的点，$v_t$表示加权平均后的,红色 权平均方法是：每天的温度值加权值$vt$设置为前一天的温度加权值$vt−1$和当天的温度实际值$θt$做加权平均： $$ v_{t}=\beta v_{t-1}+(1-\beta) \theta_{t} $$ 由于以后我们要考虑的原因，在计算时可视$v_T$大概是$\frac{1}{(1-\beta)}$的每日温度的加权平均， 如果是$\beta$=0.9，这是十天的平均值，红色 如果$\beta$=0.98,是50天的结果，绿色 如果$beta$=0.5,是2day的结果，黄色 由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。 当 $\beta$较大时，指数加权平均值适应地更缓慢一些。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_10.png) $ ¶L 04 : Understanding Exponentially Weighted Averages 假如β=0.9，每个v的计算如下： $$ \begin{aligned} v_{100} &amp;=0.9 v_{99}+0.1 \theta_{100} \ v_{99} &amp;=0.9 v_{98}+0.1 \theta_{99} \ v_{98} &amp;=0.9 v_{97}+0.1 \theta_{98} \end{aligned} $$ 递推可得： $$ v_{100}=0.1 \theta_{100}+0.1 * 0.9 \theta_{99}+0.1 *(0.9)^{2} \theta_{98}+\ldots $$ 指数的衰减规律 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_11.png) 一般的 $$ v_{t}=\sum_{i=1}^{t}(1-\beta) \beta^{t-i} \theta_{i} $$ 无穷级数求和： $$ \sum_{t=1}^{n}(1-\beta) \beta^{t}=1 $$ 因此可以近似的认为所有项的系数之和正好为100%。 即，$vt$是对t日之前所有的实际温度的加权平均,权重是指数递减的。 十天后，曲线高度下降到了1/3,赋予权重$\beta^{t-i}$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_12.png) $$ 0.9^{10}=0.35=1/e $$ 一般认为，$v_t$近似前$\frac{1}{1-\beta}$的加权平均值 ¶L05 : Bias correction in exponentially weighted averages 指数加权平均的偏差修正 由于计算$v1$的时候，并没有历史值做加权，这个时候令其前一个加权值$v0=0$，则会导致$v_1$远小于$\theta_1$,依次类推，在靠近前面的值会出现显著的小于实际值的情况 因此做一个修正 $$ v_{t}=\frac{\beta v_{t-1}+(1-\beta) \theta_{t}}{1-\beta^{t}} $$ 你会发现随着$\beta^t$增加，接近于0，所以当t很大的时候，偏差修正几乎没有作用，因此当t较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_13.png) 因为在Machine Learning中看重的是很多次迭代后的结果，初期的偏差影响并不大。 ¶L 06 : Gradient Descent With Momentum 动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法， ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_14.png) 当慢慢下降到最小值，上下波动的梯度下降法的速度减缓，无法使用更大的学习率， ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_15.png) 在纵轴上，希望学校慢一点，不需要摆动，横着上，加快学校，基于此就有了Gradient descent with momentum。 $$ \begin{array}{c}{v_{d W} :=\beta v_{d W}+(1-\beta) d W} \ {v_{d b} :=\beta v_{d b}+(1-\beta) d b} \ {w=w-\alpha v_{d W}} \ {b=b-\alpha v_{d b}}\end{array} $$ 这样，可以让gradient更平滑 对于上图垂直方向，原来是会上下震荡，但引入了exponentially weighted average，相当于对前面的震荡进行了平均，结果就是上下震荡互相抵消了。而水平方向都是向右没有震荡，因此平均后还是向右。最终导致呈现上图红色的下降路线。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_18.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_16.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_17.png) ¶L 07 : RMSprop RMSprop (Root Mean Square Propagation，均方根传递)，与momentum一样，也是降低梯度的抖动。而是平抑不同大小梯度的更新速率。实际上 作用在α上的 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_19.png) 回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设b纵轴代表参数，横轴代表参数W，可能有w1，或者w2其它重要的参数，为了便于理解，被称为b和w。 我们希望学习速度快，而在垂直方向，也就是例子中的方向，我们希望减缓纵轴上的摆动，所以有了$S_{d W} $和$ S_{d b}$，我们希望$S_{d W} $会相对较小，所以我们要除以一个较小的数，而希望$ S_{d b}$又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。 这些微分，垂直方向的要比水平方向的大得多，所以斜率在方向特别大，所以这些微分中，db较大，dw较小，因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是方向上W。db的平方较大，所以$Sdb$也会较大，而相比之下，dw会小一些，亦或dw平方会小一些，因此$Sdw$会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。 RMSprop的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率，然后加快学习，而无须在纵轴上垂直方向偏离。 实际中dw是一个高维度的参数向量，db也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是RMSprop，全称是均方根，因为你将微分进行平方，然后最后使用平方根。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_20.png) 解释平方： 垂直方向，比较陡，梯度比较大，但我们又希望它下降的慢。因此对梯度除以一个较大的值，所以用梯度的平方的平均来表示。让不同的参数拥有不同的learning rate。 从某种角度看，RMSprop会根据当前的梯度自动调整参数的learning rate，梯度大降低learning rate，梯度小的时候提高learning rate，从而一方面避免了震荡，另一方面避免在平坦的地方徘徊太久。 为了避免出现分母为0 $$ \begin{array}{c}{s_{d w}=\beta s_{d w}+(1-\beta)(d w)^{2}} \ {s_{d b}=\beta s_{d b}+(1-\beta)(d b)^{2}} \ {w :=w-\alpha \frac{d w}{\sqrt{s_{d w}+\varepsilon}}} \ {b :=b-\alpha \frac{d b}{\sqrt{s_{d b}+\varepsilon}}}\end{array} $$ $\varepsilon$取$10^{-8}$不错的选择. 补充： RMSProp算法对梯度计算了微分平方加权平均数。这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快 ¶L 08 Adam optimization algorithm Adam（Adaptive Moment Estimation，自适应矩估计）就是momentum和RMSprop的结合。momentum负责平滑梯度，而RMSprop负责调解learning rate。 ¶1. Adam a. 引入的变量有： $v$ : 计算同momentum算法，将梯度进行指数加权平均 $s$: 计算同RMSprop，将梯度的平方进行指数加权平均 $β1$ : 计算vv的加权参数 $β2$ : 计算ss的加权参数 b. 在迭代前，初始化参数v和s $$ v_{d W}=0, s_{d W}=0, v_{d b}=0, s_{d b}=0 $$ c. 对第t次梯度下降的迭代 a. 首先计算dw和db的v和s $$ \begin{array}{c}{v_{d W}=\beta_{1} v_{d W}+\left(1-\beta_{1}\right) d W} \ {s_{d W}=\beta_{2} s_{d W}+\left(1-\beta_{2}\right)(d W)^{2}} \ {v_{d b}=\beta_{1} v_{d b}+\left(1-\beta_{1}\right) d b} \ {s_{d b}=\beta_{2} s_{d b}+\left(1-\beta_{2}\right)(d b)^{2}}\end{array} $$ d. 修正 $$ v_{d W}^{\text {corrected}}=\frac{v_{d W}}{1-\left(\beta_{1}\right)^{t}}\ \begin{aligned} s_{d W}^{\text {corrected}} &amp;=\frac{s_{d W}}{1-\left(\beta_{2}\right)^{t}} \ v_{d b}^{\text {corrected}} &amp;=\frac{v_{d b}}{1-\left(\beta_{1}\right)^{t}} \ s_{d b}^{\text {corrected}} &amp;=\frac{s_{d b}}{1-\left(\beta_{2}\right)^{t}} \end{aligned} $$ e. 最后更新参数W和b $$ W=W-\alpha \frac{v_{d W}^{\text {corrected}}}{\sqrt{s_{d W}^{\text { corrected }}+\varepsilon}}\ b=b-\alpha \frac{v_{d b}^{\text {corrected}}}{\sqrt{s_{d b}^{\text { corrected }}+\varepsilon}} $$ 超参的选择： α：需要调优 β1: 通常选择为0.9 β2: 通常选择为0.999 ε: 一般不需要调优，选择一个小数，比如10−8 你可以尝试一系列值α，然后看哪个有效 ¶L09 : Learning Rate Decay why 为什么要做learning rate decay？ 较大的learning rate虽然在算法开始阶段会加快收敛速度，但在收敛接近到优化点的时候，算法会在优化点附近震荡，如下图： ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_22.png) 2.如何做learning rate decay？ 思路很简单，就是引入一个函数，让α随着迭代（比如min-batch的epoch）递减。为此可以采用的decay函数有： 倒数： $$ \alpha :=\frac{1}{1+\text { decay rate * epoch num}} \alpha $$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_23.png) ¶L 10: The Problem of local Optima 事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。 但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$，因此更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。所有，担心收敛到local optima，真是人们想多了，实际上并没有想象的那么多local optima。在高维空间，几乎不太可能被困在一个local optima，这是一个好消息。 因此，在高维空间遇到的问题是高原问题（Problem of plateaus） ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_27.png) Adam算法可以加速学习 W3 Hyperparameter tuning ¶L01 Tuning process 到目前为止，我们接触到的hyperparameter有： learning rate: αα momentum 参数: ββ Adam参数: β1β1和 β2β2以及εε 神经网络层数: L 神经网络隐藏层neuron数：n[l]n[l] learning rate decay参数 min-batch size 这些hyperparameter重要性排序： 最重要的： learning rate: αα 比较重要的： momentum 参数: ββ 神经网络层数: L 神经网络隐藏层neuron数：n[l]n[l] 次重要的： 神经网络隐藏层neuron数 learning rate decay参数 基本不需调整的 β1β1和 β2β2以及ε ¶1. Try random values : Don’t use a grid ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_28.png) why: 举个例子，假设超参数1是（学习速率），取一个极端的例子，假设超参数2是Adam算法中，分母中的$\varepsilon$。在这种情况下，a的取值很重要，而$\varepsilon$取值则无关紧要。如果你在网格中取点，接着，你试验了a的5个取值，那你会发现，无论$\varepsilon$取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的值只有5个，我认为这是很重要的。 对比而言，如果你随机取值，你会试验25个独立的a,$\varepsilon$，似乎你更有可能发现效果做好的那个。 ¶2. 由粗糙到精细的策略 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_29.png) ¶L 02: Using an Appropriate Scale to pick hyperparameters $a$取值0.0001,1,如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。 同时在范围内搜索，也不是均匀分布（uniformly random）的，通常有这个参数的scale，比如对数scale。 反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_32.png) ¶L 03 : Hyperparameter tuning i practice 不同的算法和场景，对超参的scale敏感性可能不一样. 根据计算资源和数据量，可以采取两种策略来调参 Panda（熊猫策略）：对一个模型先后修改参数，查看其表现，最终选择最好的参数。就像熊猫一样，一次只抚养一个后代。 Caviar（鱼子酱策略）：计算资源足够，可以同时运行很多模型实例，采用不同的参数，然后最终选择一个好的。类似鱼类，一次下很多卵，自动竞争成活。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_33.png) ¶L 04: Normalizing Activations in a Network ¶1. Implementing Batch Normalizing Batch归一化,Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。 可以normalize $a{[l]},z{[l]}$,选择$z^{[L]}$ 设置 γ 和 β 的原因是，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_34.png) 需要注意的是，β和γ不是超参，而是梯度下降需学习的参数。 ¶L 05 : Fitting Batch Norm Into Neural Networks ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_35.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_36.png) 注意 先前我说过每层的参数是$w{[l]}$和$b{[l]}$，还有$\beta{[l]}$和$b{[l]}$，请注意计算的方式如下，$z{[l]}=w{[l]} a{[l-1]}+b{[l]}$，但Batch归一化做的是，它要看这个mini-batch，先将$z{[l]}$归一化，结果为均值0和标准方差，再由$\beta$和b重缩放，但这意味着，无论$b{[l]}$的值是多少，都是要被减去的，因为在Batch归一化的过程中，你要计算的$z^{[l]}$均值，再减去平均值，在此例中的mini-batch中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消. ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_37.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_38.png) 最后，请记住的维$z{[l]}$，因为在这个例子中，维数会是$\left(n{[l]}, 1\right)$，的尺寸为，如果是l层隐藏单元的数量，那$ \beta^{[l]}$和$ \gamma{[l]}$的维度也是$\left(n{[l]}, 1\right)$，因为这是你隐藏层的数量，你有隐藏单元，所以$\gamma^{[l]}$和$ \beta^{[l]}$用来将每个隐藏层的均值和方差缩放为网络想要的值。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_39.png) ¶L 06 Why Doest Batch Norm Work? 首先，起到了normalization的作用，同对输入数据X的normalization作用类似。 让每一层的学习，一定程度解耦了前层参数和后层参数，让各层更加独立的学习。无论前一层如何变，本层输入的数据总是保持稳定的均值和方差。（主要原因） ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_40.png) 所以使你数据改变分布的这个想法，有个有点怪的名字“Covariate shift”，想法是这样的，如果你已经学习了到 的映射，如果 的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由 到 映射保持不变，正如此例中，因为真实函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。 关于第二点，如果实际应用样本和训练样本的数据分布不同（例如，橘猫图片和黑猫图片），我们称发生了“Covariate Shift”。这种情况下，一般要对模型进行重新训练。Batch Normalization 的作用就是减小 Covariate Shift 所带来的影响，让模型变得更加健壮，鲁棒性（Robustness）更强。 即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_41.png) 另外，Batch Normalization 也起到微弱的正则化（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 z(i)z(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。 因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。 最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_42.png) ¶L 07 : Batch Norm At Test Time 问题：BN算法在训练时是一个批次的数据训练，能算出每一层Z的均值和方差；而在测试时，输入的则是单个数据，单条数据没法做均值和方差的计算，怎么在测试期输入均值和方差呢? 实际应用中一般不使用这种方法，而是使用之前学习过的指数加权平均的方法来预测测试过程单个样本的 μ 和 $σ^2$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_43.png) 计算$z_{\text { norm }}^{(\hat{2})}$，用$\mu$ 和$ \sigma^{2}$的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的和你在神经网络训练过程中得到的$\beta$和$\sigma$参数来计算你那个测试样本的z值。 ¶L 08 : Softmax Regression ¶1. [Multi-class classification] ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_44.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_45.png) 最后一层是概率，之和为1，要用到Softmax层，Softmax激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_46.png) ¶2. Softmax example 没有隐藏层的softmax,代表一些决策边界 ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_47.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_48.png) ¶L 09 Training SoftMax classifier ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_49.png) Softmax这个名称的来源是与所谓hardmax对比,Softmax回归或Softmax激活函数将logistic激活函数推广到类，而不仅仅是两类，结果就是如果C=2，那么C=2的Softmax实际上变回了logistic回归， ¶Loss Function ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_50.png) $$ J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right) $$ ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_51.png) ¶3. Gradient descent with softmax ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_52.png) 最后一层求导，softmax激活函数 $$ J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right) $$ ¶L11 TensorFlow ¶1. 基本流程 使用tensorflow，只要告诉tensorflow forward prop，它自己就会做backprop，因此不用自己实现backprop ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_53.png) 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as npimport tensorflow as tf#导入TensorFlow​w = tf.Variable(0,dtype = tf.float32)#接下来，让我们定义参数w，在TensorFlow中，你要用tf.Variable()来定义参数​#然后我们定义损失函数：​cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)#然后我们定义损失函数J然后我们再写：​train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)#(让我们用0.01的学习率，目标是最小化损失)。​#最后下面的几行是惯用表达式:​init = tf.global_variables_initializer()​session = tf.Session()#这样就开启了一个TensorFlow session。​session.run(init)#来初始化全局变量。​#然后让TensorFlow评估一个变量，我们要用到:​session.run(w)​#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：：​print(session.run(w))​所以如果我们运行这个，它评估等于0，因为我们什么都还没运行。#现在让我们输入：​$session.run(train)，它所做的就是运行一步梯度下降法。#接下来在运行了一步梯度下降法后，让我们评估一下w的值，再print：​print(session.run(w))#在一步梯度下降法之后，w现在是0.1。 ¶2. 如何用训练数据 placeholder 在实际的训练过程中，要用不同的样本反复放到一个待优化函数中的，这个时候就可以用tensorflow的placeholder实现,在run的时候，对应给出feed_dict，表名占位符x的实际值。 123456789101112131415161718192021import numpy as npimport tensorflow as tf # 导入Tensorflowcoefficient = np.array([[2.],[-10.],[25.]])w = tf.Variable(0, dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1]) # 3x1大小的placeholdercost = w**x[0][0] - x[1][0]*w + x[2][0] # 要优化的cost function（即forward prop的形式）train = tf.train.GradientDescentOptimizer(0.01).minimize(cost) init = tf.global_variables_initializer()session = tf.Session()session.run(init)print(session.run(w))session.run(train, feed_dict=&#123;x:coefficient&#125;) # x占位符替换为coefficientprint(session.run(w))for i in range(1000): session.run(train, feed_dict=&#123;x:coefficient&#125;) # # x占位符替换为coefficientprint(session.run(w)) ¶3. 计算流 TensorFlow程序的核心是计算损失函数，然后TensorFlow自动计算出导数，以及如何最小化损失，因此这个等式或者这行代码所做的就是让TensorFlow建立计算图， with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。建立计算流的过程，前向传播的过程，operation ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_56.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_54.png) ![](ImprovingDeep learning.ai_Deep Neural NetworksHyperparameter tuning, Regularization and Optimization\L2_week2_55.png) Summary how to systematically organize the hyper parameter search process and batch normalization and framework http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Improving_Deep_Neural_Networks/深度学习的实用层面 http://www.ai-start.com/dl2017/html/lesson2-week1.html#header-n3 http://dl-notes.imshuai.com/#/c2w1?id=_4-heros-of-deep-learning-yoshua-bengio-interview https://www.youtube.com/watch?v=4Ct3Yujl1dk&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=14]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彩铅DailyLifeStyle]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%BD%A9%E9%93%85DailyLifeStyle%2F</url>
    <content type="text"><![CDATA[Day one ¶1. 工具简单介绍 彩铅 水溶性，油性 彩铅纸 铅笔 B 2B&lt;4B黑的程度 H 4H&lt;8H软度 橡皮 软橡皮 硬橡皮 电动橡皮擦 铅笔刀 可跳档类型 勾线笔 针管笔 （樱花） 笔套 高光笔 可以用修正液替换（三棱) 纸擦笔 玛丽 刷子 画板 速写板 ¶2. 颜色 三原色： 红 黄 蓝 色相 颜色 饱和度 鲜艳程度 明度 明暗程度 邻近色 对比色 红-绿 蓝-橙 紫-黄 暖色和冷色 ¶3. 排线 一个方向 往同一个方向排，无连接 来回 相连接，一条线 不同方向排列 注意：力度和间距 ¶4. 平涂 力度一致 ¶5. 渐变 力度不一致]]></content>
      <categories>
        <category>娱乐生活</category>
      </categories>
      <tags>
        <tag>彩铅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%20test%2F</url>
    <content type="text"><![CDATA[Logistics Regression 如何凸显你是一个对逻辑回归已经非常了解的人呢。那就是用一句话概括它！逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。 ​ 这里面其实包含了5个点 1：逻辑回归的假设，2：逻辑回归的损失函数，3：逻辑回归的求解方法，4：逻辑回归的目的，5:逻辑回归如何分类。这些问题是考核你对逻辑回归的基本了解。 ¶逻辑回归的基本假设 任何的模型都是有自己的假设，在这个假设下模型才是适用的。逻辑回归的 第一个 基本假设是 假设数据服从伯努利分布。 伯努利分布有一个简单的例子是抛硬币，抛中为正面的概率是p,抛中为负面的概率是 1-p,在逻辑回归这个模型里面是假设 $h_θ(x)$为样本为正的概率， $1−h_θ(x)$为样本为负的概率。那么整个模型可以描述为$h_θ(x;θ)=p$ 逻辑回归的第二个假设是假设样本为正的概率是 $p=\frac{1}{1+e{wTx}}$ 所以逻辑回归的最终形式 $h_θ(x;θ)=\frac{1}{1+e{wTx}}$ ¶逻辑回归的损失函数 逻辑回归的损失函数是它的极大似然函数 $Lθ(x)=\pi_{i=1}{m}h_θ(xi;θ)y_i∗(1−h_θ(xi;θ))^{1−y_i}$ ¶逻辑回归的求解方法 由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有随机梯度下降，批梯度下降，small batch 梯度下降三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。 简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。 随机梯度下降是以高方差频繁更新，优点是使得sgd会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。 小批量梯度下降结合了sgd和batch gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。 其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。 第一个是如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。 第二个是如何对参数选择合适的学习率。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。这里我们不展开，有空我会专门出一个专题介绍。 ¶逻辑回归的目的 该函数的目的便是将数据二分类，提高准确率。 逻辑回归如何分类 逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。 ¶3.对逻辑回归的进一步提问 ​ 逻辑回归虽然从形式上非常的简单，但是其内涵是非常的丰富。有很多问题是可以进行思考的 逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？ 损失函数一般有四种，平方损失函数，对数损失函数，HingeLoss0-1损失函数，绝对值损失函数。将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。至于原因大家可以求出这个式子的梯度更新 $w_j=w_j−(yi−h_w(xi;w))∗x_j^i\theta$ 这个式子的更新速度只和$x_j,y_j 相关。和sigmod函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。 为什么不选平方损失函数的呢？其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。 逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？ 先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。 但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。 如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。 为什么我们还是会在训练的过程当中将高度相关的特征去掉？ 去掉高度相关的特征会让模型的可解释性更好 可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。 ¶4.逻辑回归的优缺点总结 ​ 面试的时候，别人也经常会问到，你在使用逻辑回归的时候有哪些感受。觉得它有哪些优缺点。 ​ 在这里我们总结了逻辑回归应用到工业界当中一些优点： 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。 模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。 训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。 资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。 ​ 但是逻辑回归本身也有许多的缺点: 准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。 很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。 ¶模型、策略、算法 ¶Codings]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%2F</url>
    <content type="text"><![CDATA[英伟达:芯片，GPU 开发框架：tensorflow，pytorch caffe ¶监督学习 学习目的是学习一个输入到输出的映射，称为模型。模型的集合就是假设空间。 模型：概率模型；非概率模型； 学习过程：搜索过程]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow]]></title>
    <url>%2F2019%2F04%2F11%2Ftensorflow%2F</url>
    <content type="text"><![CDATA[official definition What is tensorflow flow of tensors “TensorFlow is an open source software library for numerical computation using dataflow graphs. Nodes in the graph represents mathematical operations, while graph edges represent multi-dimensional data arrays (aka tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.”* A major difference between numpy and TensorFlow is that TensorFlow follows a lazy programming paradigm. It first builds a graph of all the operation to be done, and then when a “session” is called, it “runs” the graph. It’s built to be scalable, by changing internal data representation to tensors (aka multi-dimensional arrays). Building a computational graph can be considered as the main ingredient of TensorFlow. It’s easy to classify TensorFlow as a neural network library, but it’s not just that. Yes, it was designed to be a powerful neural network library. But it has the power to do much more than that. You can build other machine learning algorithms on it such as decision trees or k-Nearest Neighbors. You can literally do everything you normally would do in numpy! It’s aptly called “numpy on steroids” The advantages of using TensorFlow are: It has an intuitive construct, because as the name suggests it has “flow of tensors”. You can easily visualize each and every part of the graph. Easily train on cpu/gpu for distributed computing Platform flexibility. You can run the models wherever you want, whether it is on mobile, server or PC. scikit-learn 123456# define hyperparamters of ML algorithmclf = svm.SVC(gamma=0.001, C=100.)# train clf.fit(X, y)# test clf.predict(X_test) The usual workflow of running a program in TensorFlow is as follows: Build a computational graph, this can be any mathematical operation TensorFlow supports. Initialize variables, to compile the variables defined previously Create session(会话）, this is where the magic starts! Run graph in session, the compiled graph is passed to the session, which starts its execution. Close session, shutdown the session. Lets write a small program to add two numbers! 12345678910111213141516171819# import tensorflowimport tensorflow as tf# build computational grapha = tf.placeholder(tf.int16)b = tf.placeholder(tf.int16)addition = tf.add(a, b)# initialize variablesinit = tf.initialize_all_variables()# create session and run the graphwith tf.Session() as sess: sess.run(init) print "Addition: %i" % sess.run(addition, feed_dict=&#123;a: 2, b: 3&#125;)# close sessionsess.close() A typical implementation of Neural Network would be as follows: Define Neural Network architecture to be compiled Transfer data to your model Under the hood, the data is first divided into batches, so that it can be ingested. The batches are first preprocessed, augmented and then fed into Neural Network for training The model then gets trained incrementally Display the accuracy for a specific number of timesteps After training save the model for future use Test the model on a new data and check how it performs ¶三类非常重要的变量 ¶占位符 tensorFlow中接收值的方式为占位符(placeholder)，创建placeholder 123- # b = tf.placeholder(tf.float32, [None, 1], name='b')第二个参数值为[None, 1]，其中None表示不确定，即不确定第一个维度的大小，第一维可以是任意大小。特别对应tensor数量(或者样本数量)，输入的tensor数目可以是32、64… placeholder: A way to feed data into the graphs feed_dict: A dictionary to pass numeric values to computational graph ¶常量 tf.constant()`定义常量 1const = tf.constant(2.0, name='const') ¶变量 ​ 使用tf.Variable()定义变量 1c = tf.Variable(1.0, dtype=tf.float32, name='c') TensorFlow中所有的变量必须经过初始化才能使用，**初始化方式分两步： 定义初始化operation 12# 1. 定义init operationinit_op = tf.global_variables_initializer() 运行初始化operation 12# 2. 运行init operation sess.run(init_op) reference https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/ https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial https://github.com/aymericdamien/TensorFlow-Examples video:https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/ course: https://classroom.udacity.com/courses/ud187 tensorflow: GOOGLE 开源、Deep learning ¶练数成金 ¶C1 tensorboard ：a tool;visual network;debug alter dir of jupyter 顺便改了下新下载的路径（GOOD） CPU or GPU ¶C2 graphs 代表计算任务，节点（op)，一个op可以获得o个或者多个tensor,输出1个或者多个tensor Session(会话)的上下文（context)中执行 tensor表示数据,n维数组 ¶C3 简单的回归神经网络（拟合二次函数），貌似学了理论没有实践，还真是忘得快啊 手写体分类、Softmax函数 softmax函数可以给不同的对象分配概率，softmax($x_i$)=$\frac{exp(x_i)}{\sum_j{exp(x_j)}}$ 如输出[1,2,5] ,$p1=\frac{exp(1)}{exp(1)+exp(2)+exp(5)}$,$p2=\frac{exp(2)}{exp(1)+exp(2)+exp(5)}$,$p1=\frac{exp(5)}{exp(1)+exp(2)+exp(5)}$ ¶Keras 安装 backend 基于什么做运算（tensorflow or theano) import keras 查看 底层搭建 a） /.keras/keras.json 相关的配置信息 b) 终端改，单次 import os os.environ[‘KERAS_BACKEND’]= ‘tensorflow’ import keras For example model :Sequential layer : Dense activation 训练算法：model.compile(参数optimizer=‘梯度下降法的变种’ , loss=‘rms/’) 训练：model. fit (x,y) model.train_on_batch evaluate:model.evaluate prediction: model.predict(x_test, batch_size=128) https://github.com/MorvanZhou/tutorials/blob/master/kerasTUT/5-classifier_example.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 4 - Regressor exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.models import Sequential # 按顺序建立from keras.layers import Dense # 全连接层import matplotlib.pyplot as plt# create some dataX = np.linspace(-1, 1, 200)np.random.shuffle(X) # randomize the dataY = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))# plot dataplt.scatter(X, Y)plt.show()X_train, Y_train = X[:160], Y[:160] # first 160 data pointsX_test, Y_test = X[160:], Y[160:] # last 40 data points# build a neural network from the 1st layer to the last layermodel = Sequential()model.add(Dense(units=1, input_dim=1)) # choose loss function and optimizing methodmodel.compile(loss='mse', optimizer='sgd')# trainingprint('Training -----------')for step in range(301): cost = model.train_on_batch(X_train, Y_train) if step % 100 == 0: print('train cost: ', cost)# testprint('\nTesting ------------')cost = model.evaluate(X_test, Y_test, batch_size=40)print('test cost:', cost)W, b = model.layers[0].get_weights()print('Weights=', W, '\nbiases=', b)# plotting the predictionY_pred = model.predict(X_test)plt.scatter(X_test, Y_test)plt.plot(X_test, Y_pred)plt.show() ¶5 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: 莫烦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 5 - Classifier exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activationfrom keras.optimizers import RMSprop# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# X shape (60,000 28x28), y shape (10,000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(X_train.shape[0], -1) / 255. # normalizeX_test = X_test.reshape(X_test.shape[0], -1) / 255. # normalizey_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your neural netmodel = Sequential([ Dense(32, input_dim=784), Activation('relu'), Dense(10), Activation('softmax'),])# Another way to define your optimizerrmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)# We add metrics to get more results you want to seemodel.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=2, batch_size=32)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('test loss: ', loss)print('test accuracy: ', accuracy) ¶6 CNN卷积神经网络 不是对 https://www.cnblogs.com/skyfsm/p/6790245.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: 莫烦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 6 - CNN example# to try tensorflow, un-comment following two lines# import os# os.environ['KERAS_BACKEND']='tensorflow'import numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flattenfrom keras.optimizers import Adam# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(-1, 1,28, 28)/255.X_test = X_test.reshape(-1, 1,28, 28)/255.y_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your CNNmodel = Sequential()# Conv layer 1 output shape (32, 28, 28)model.add(Convolution2D( batch_input_shape=(None, 1, 28, 28), filters=32, kernel_size=5, strides=1, padding='same', # Padding method data_format='channels_first',))model.add(Activation('relu'))# Pooling layer 1 (max pooling) output shape (32, 14, 14)model.add(MaxPooling2D( pool_size=2, strides=2, padding='same', # Padding method data_format='channels_first',))# Conv layer 2 output shape (64, 14, 14)model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))model.add(Activation('relu'))# Pooling layer 2 (max pooling) output shape (64, 7, 7)model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)model.add(Flatten())model.add(Dense(1024))model.add(Activation('relu'))# Fully connected layer 2 to shape (10) for 10 classesmodel.add(Dense(10))model.add(Activation('softmax'))# Another way to define your optimizeradam = Adam(lr=1e-4)# We add metrics to get more results you want to seemodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=1, batch_size=64,)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('\ntest loss: ', loss)print('\ntest accuracy: ', accuracy)]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>tensorlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning Neural Network and Deep Learning]]></title>
    <url>%2F2019%2F04%2F11%2FDeep%20Learning.ai_Neural%20Networks%20and%20Deep%20Learning%2F</url>
    <content type="text"><![CDATA[Course one : Neural Networks and Deep Learning(Course 1 of the Deep Learning Specialization) C1W1 ¶C1W1L01: Welcome AI is the new Electricity! Course 1: Neural Networks and Deep Learning Course 2: Improving Deep Neural Networks: Hyperparameter tuning,Regularization and Optimization Course 3: Structuring your Machine Learning project Course 4: Convolutional Neural Networks Course 5: Natural Langurge Processing: Building sequence models ¶C1W1L02 : What is Neural Network Deep Learning = training (very large) neural network ¶For example of house prize prediction : the simplest neural network 如果现在有六栋房子的信息，分别是房子的大小(size of house)和对应的价格(prize),绘制出如下的。自然的想法：线性回归，得到拟合的直线。值得注意的是，房价不可能是负数吧！因此下图中蓝色的线，大致就是我们所需要的函数。这个对应一个最简单神经网络（neural network） ![](Deep Learning.ai_Neural Networks and Deep Learning\housr_prize_1.png) 上述是一个tiny little neural network，更大的，更复杂的神经网络是 把很多最简单的single neural堆积(stacking)到一起。 ¶For example of house prize prediction : stacking the neural 上面这个例子，仅仅考虑特征是size,实际情况上，与房屋相关的特征还有number of bedrooms、zip code、wealth, number of bedrooms and size affect family size. The zip code is a feature that tells you you know walkability. The wealth tells you how good is the school quality ![](Deep Learning.ai_Neural Networks and Deep Learning\house_prize_2.png) hidden layer 用输入层计算得到，因此说输入层与中间层紧密连接起来了 ¶The actual application of neural networks hidden layer 与上一层的连接情况并不是手工确定，每一层都是上一层所有的输入函数，所以建立的神经网络如下： ![](Deep Learning.ai_Neural Networks and Deep Learning\house prize 3.png) The remarkable thing about neural network Given enough data about X&amp;Y (x,y) which good at freaking out functions :map x to y Most powerful in supervised learning ¶C2W1CL03 : Supervised Learning with Neural Network ¶常见的监督学习 截止到目前，Neural Network的成功应用基本都在Supervised Learning。比如：Ad，Images vision, Audio to Text, Machine translation, Autonomous Driving ![](Deep Learning.ai_Neural Networks and Deep Learning\supervised-learning-exmples.png) ¶常见的神经网络的设计 ![](Deep Learning.ai_Neural Networks and Deep Learning\NeuralNetworkExamples.png) 卷积神经网络：Convolutional Neural Network (CNN) 通常有用图像数据 递归神经网络： Recurrent Neural Network (RNN) 通常用于time series 对应复杂的应用中，定制一些复杂的混合的神经网络结构 ¶结构化和非结构化数据 ![](Deep Learning.ai_Neural Networks and Deep Learning\datastructure.png) 处理非结构化数据是很难的，与结构化数据比较，让计算机理解非结构化数据很难 ¶C1W1L04: Why is deep learning taking off Answer: scale If you want to hit this very high level of performance ,firstly, you need to be able train a big enough neural network in order to take advantage of the huge amount of data and second you need to be out here on the x axes you do need a lot of data. ![](Deep Learning.ai_Neural Networks and Deep Learning\scale.jpg) If you do not have a lot training data is often up to your skill at hand engineering features that determines the foreman.在这个小的训练集中，各种算法的优先级事实上定义的也不是很明确，所以如果你没有大量的训练集，那效果会取决于你的特征工程能力，那将决定最终的性能。 这个图形区域的左边，各种算法之间的优先级并不是定义的很明确，最终的性能更多的是取决于你在用工程选择特征方面的能力以及算法处理方面的一些细节. 只是在某些大数据规模非常庞大的训练集，也就是在右边这个会非常的大时，我们能更加持续地看到更大的由神经网络控制其它方法. ¶The Reason the scale of data the speed of computation such as GPUS innovation of algorithm 许多算法方面的创新，一直是在尝试着使得神经网络运行的更快 switch sigmoid function to relu function ![](Deep Learning.ai_Neural Networks and Deep Learning\algorithm——rul.jpg) 在这个区域，也就是这个sigmoid函数的梯度会接近零，所以学习的速度会变得非常缓慢，因为当你实现梯度下降以及梯度接近零的时候，参数会更新的很慢，所以学习的速率也会变的很慢，而通过改变这个被叫做激活函数的东西，神经网络换用这一个函数，叫做ReLU的函数（修正线性单元），ReLU它的梯度对于所有输入的负值都是零，因此梯度更加不会趋向逐渐减少到零。 训练你的神经网络的过程，很多时候是凭借直觉的，往往你对神经网络架构有了一个想法，于是你尝试写代码实现你的想法，然后让你运行一个试验环境来告诉你，你的神经网络效果有多好，通过参考这个结果再返回去修改你的神经网络里面的一些细节，然后你不断的重复上面的操作，当你的神经网络需要很长时间去训练，需要很长时间重复这一循环，在这里就有很大的区别，根据你的生产效率去构建更高效的神经网络。当你能够有一个想法，试一试，看效果如何。在10分钟内，或者也许要花上一整天，如果你训练你的神经网络用了一个月的时间，有时候发生这样的事情，也是值得的，因为你很快得到了一个结果。在10分钟内或者一天内，你应该尝试更多的想法，那极有可能使得你的神经网络在你的应用方面工作的更好、更快的计算，在提高速度方面真的有帮助，那样你就能更快地得到你的实验结果。 ![](Deep Learning.ai_Neural Networks and Deep Learning\faster.jpg) ¶Summary 早上花了2h小时学习第一周的视频，先看一遍视频的字幕，逐字逐句的理解，虽然很多时候都是自己乱猜的，大概清楚讲的什么！然后再看大牛的笔记，然后再看一篇结合PPT。下午也看了半个多小时。问题：1. 自己的英文水平不够，这个需要大大的提高讷。2. 其实只要看别人的笔记就可以知道内容，但是还是想听andow ng的讲解。3. 视频都比较短，每个视频设计的知识点或者内容不多，1到3个，分成知识点做笔记还是不错的 这一周的内容，也就是今天我学习的知识简单和容易理解。学习了神经网络的大致结构，神经网络的应用领域，深度学习为什么取得快速的发展的三点原因，尤其是数据scale与其他方法和神经网络规模的大致性能关系 C1W2 ¶C1W2L01: Binary Classification In this week, we’re going to go over the basics of neural network programming. We are going to study handle data without for loop. forward password for propagation backward pass or what’s called a backward propagation step Why the computations in learning in a neural network can be organized in this board propagation and a separate backward propagation by using logistic regression to convey(传达) theses ideas. ¶Binary Classification Input； an image . three separate matrices corresponding red green and blue color channels of this image. 如果你的图片大小为64x64像素，那么你就有三个规模为64x64的矩阵，分别对应图片中红、绿、蓝三种像素的强度值 unroll all of these pixel intensity values into a feature vector pixel intensity values of this image ![](Deep Learning.ai_Neural Networks and Deep Learning\w_piexl.jpg) ![](Deep Learning.ai_Neural Networks and Deep Learning\2_blue_green_read.jpg) notation (x,y)： a pair X comma Y $M_{train}$: M subscript train 每条测试集在矩阵中都是以列向量的形式存在 ![](Deep Learning.ai_Neural Networks and Deep Learning\2_noation.png) Matrix capital ![](Deep Learning.ai_Neural Networks and Deep Learning\2_nation_2.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\2_all_nation.jpg) ![](Deep Learning.ai_Neural Networks and Deep Learning\2_all_nation_1.jpg) ¶Model : hypothesis Function :Logistic Regression So given an input X and the parameters W and b, how do we generate the output Y hat? Well, one thing you could try, that doesn’t work, would be to have Y hat be w transpose X plus B, kind of a linear function of the input X. And in fact, this is what you use if you were doing linear regression. But this isn’t a very good algorithm for binary classification because you want Y hat to be the chance that Y is equal to one. So,Y hat should really be between zero and one. This is what the sigmoid function looks like. ![](Deep Learning.ai_Neural Networks and Deep Learning\log_1.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\log_3.jpg) ¶sigmoid function $$ \sigma(z) = \frac{1}{1+e^{-z}} $$ 因为你想让$\hat{y}$表示实际值$y$等于1的机率的话， 应该在0到1之间。这是一个需要解决的问题，因为可能比1要大得多，或者甚至为一个负值。对于你想要的在0和1之间的概率来说它是没有意义的，因此在逻辑回归中，我们的输出应该是等于由上面得到的线性函数式子作为自变量的sigmoid函数中，公式如上图最下面所示，将线性函数转换为非线性函数。 ![](Deep Learning.ai_Neural Networks and Deep Learning\log_2.jpg) 注意：原来$w,b$是分开在，这里就合并，引入变量$x_0=1$,对应偏置$b$, ![](Deep Learning.ai_Neural Networks and Deep Learning\log_3.png) ¶Strategy：Cost function Firstly : Loss function $$ L(\hat{y},y)=\frac{1}{2}\sum{(y_i-\hat{y_i})^2} $$ 这个优化问题不是凸优化问题(non-convex)，因此不选用这个 Secondly， $$ L(y,\hat{y})=-(ylog{\hat{y}}+(1-y)log{1-\hat{y}}) $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\log_cost_1.jpg) ![](Deep Learning.ai_Neural Networks and Deep Learning\log__cost_2.jpg) ¶Algorithm: Gradient Descent ![](Deep Learning.ai_Neural Networks and Deep Learning\GD1.jpg) Gradient Descent算法步骤： Initialize $w$, $b$ to zero repeat： $w :=w−\alpha \frac{∂J(w,b)}{∂w}$ $b :=b-\alpha \frac{∂J(w,b)}{∂b}$ ¶C1W2L05 &amp; C1W2L06 Derivatives 求导，这个是微积分的内容，不用写了！ ¶C1W2L07： Computation Graph ¶C1W2L08 : Derivatives with compution graphs 链式法则 $$ \frac{\partial L}{\partial v}=\frac{\partial L}{\partial u}\frac{\partial u}{\partial v} $$ ¶C1W2L09 : Logistic Regression Gradient Descent ¶single training example You’ve seen the loss function that measures how well you’re doing on the single training example. You’ve also seen the cost function that measures how well your parameters w and b are doing on your entire training set. You’ve heard me say that the computations of a neural network are organized in terms of a forward pass or a forward propagation step, in which we compute the output of the neural network, followed by a backward pass or back propagation step, which we use to compute gradients or compute derivatives. ![](Deep Learning.ai_Neural Networks and Deep Learning\gd_1.jpg) ![](Deep Learning.ai_Neural Networks and Deep Learning\gd_2.png) $$ \frac{\partial L}{\partial w}=\frac{\partial L}{\partial \alpha }\frac{\partial \alpha }{\partial z}\frac{\partial z}{\partial w} \=-(\frac{y}{a}+\frac{1-y}{1-a})a(1-a)x=(a-y)x $$ ¶C1W2L10 Gradient Descent on m example $$ \min L(w,b)=\sum_{i=1}^{m}L(\alpha_i,y_i)/m\ \frac{\partial L }{\partial w}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial w})/m=(\sum_{i=1}^{m}(a-y_i)x_i)/m\ \frac{\partial L }{\partial b}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial b})/m=(\sum_{i=1}^{m}(a-1)x_i)/m $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\gd_3jpg.jpg) ![](Deep Learning.ai_Neural Networks and Deep Learning\cost_3.png) 上面的伪代码告诉我们，需要多次for loop完成代码，但是这会造成运算速度下降！因为我们越来越多地训练非常大的数据集，因此你真的需要你的代码变得非常高效。所以在接下来的几个视频中，我们会谈到向量化，以及如何应用向量化而连一个for循环都不使用。所以学习了这些，我希望你有关于如何应用逻辑回归，或是用于逻辑回归的梯度下降，事情会变得更加清晰 ¶summary 今天主要学习了以logistics regression 为例，如何通过链式求导的过程，简单的练习一下，以及再次了解什么是梯度下降法，以及训练学习算法的需要一个损失函数，训练的过程就是求损失函数最优值的过程 ¶C1W2L11: Vectorization ¶1. 什么是Vectorization：将 for loop 尽可能转换为矩阵运算 通过numpy内置函数和避开显式的循环(loop)的方式进行向量化，从而有效提高代码速度。 ![](Deep Learning.ai_Neural Networks and Deep Learning\v_1.jpg) 123np.dot(a,b)如果a,b是一维数组，则计算点积如果a,b是多维数据，则矩阵乘法 ¶2. An example of vectorization vectorization的好处：conciser code, but faster execution 一个简单的对比实验：1,000,000大小的两个向量内积计算，for loop要比Vectorization快300倍。 在Deep Learning时代，vectorization是一项重要的技能。 123456789101112131415161718192021import numpy as np #导入numpy库a = np.array([1,2,3,4]) #创建一个数据aprint(a)# [1 2 3 4]import time #导入时间库a = np.random.rand(1000000)b = np.random.rand(1000000) #通过round随机得到两个一百万维度的数组tic = time.time() #现在测量一下当前时间#向量化的版本c = np.dot(a,b)toc = time.time()print(“Vectorized version:” + str(1000*(toc-tic)) +”ms”) #打印一下向量化的版本的时间​#继续增加非向量化的版本c = 0tic = time.time()for i in range(1000000): c += a[i]*b[i]toc = time.time()print(c)print(“For loop:” + str(1000*(toc-tic)) + “ms”)#打印for循环的版本的时间 ¶3. GPU or CPU 大规模的深度学习再GPU或者图像处理单元运行”，CPU和GPU都有并行化的指令，他们有时候会叫做SIMD指令，这个代表了一个单独指令多维数据，这个的基础意义是，如果你使用了built-in函数,像np.function或者并不要求你实现循环的函数，它可以让python的充分利用并行化计算。 只是在GPU和CPU上面计算，GPU更加擅长SIMD计算，但是CPU事实上也不是太差，可能没有GPU那么擅长吧。SIMD Both CPU and GPU have parallelization instructions(i.e. SIMD, Signle Instruction Multiple Data) ¶C12L12 ： More Vectorization Example ¶矩阵和向量乘法 ![](Deep Learning.ai_Neural Networks and Deep Learning\v_2.png) ¶向量函数 ![](Deep Learning.ai_Neural Networks and Deep Learning\v_3.png) 原则：whenever possible, avoid explict for-loops 使用Element wised的矩阵运算，将函数作用在每个矩阵元素上，比如： np.exp() np.log() np.abs() np.maxium() 1/v v**2 ¶C1W2L13: Vectorizing Logistic Regression ¶1. 前向传播 ![](Deep Learning.ai_Neural Networks and Deep Learning\v_3.jpg) $$ \hat{y}=σ(w^TX+b)=(a(1),a(2),…,a(m−1),a(m))=\ (\alpha(z_1),\alpha(z_m),…,\alpha(z_m))=\ (\alpha(wTx_1+b),\alpha(wTx_2+b),…,\alpha(w^Tx_m+b))= $$ 1234import numpy as npz=np.dot(W^T,X)+b# z这里就是python 巧妙的地方，b是实数，但是向量加上实数后，b扩展成向量，被称为广播（brosdcasting） 个人经验： 首先，熟悉每个变量的记号和维度，必要的话，可以画出来，更直观。 先从一个样本做向量化，再把m个样本的操作向量化。 for-loop里面是循环乘法，则向量化一定是一个乘法形式，若对于不确定乘法的左右关系，是否需转置，可以根据目标变量的维度推测。或者先乘起来，再根据目标变量看是否要转置。 ¶C1W2L14 : Vectorzing Logistic Regression’s Gradient Compution backforwd $$ \frac{∂J}{∂w}=\frac{1}{m}X(A−Y)T\ \frac{∂J}{∂b}=\frac{1}{m}(a(i)−y(i)) $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\v-4.jpg) 重要的是弄清楚，里面的行列关系，代表的意思，运算时候，先自己理清楚。还有点积、等等运算性质对应的操作，或者对应的内置函数 ¶C1W2L15: Broadcasting in Python ¶One Example ![](Deep Learning.ai_Neural Networks and Deep Learning\bordacasing_4.png) A.sum(axis = 0)中的参数axis。axis用来指明将要进行的运算是沿着哪个轴执行，在numpy中，0轴是垂直的，也就是列，而1轴是水平的，也就是行。 ![](Deep Learning.ai_Neural Networks and Deep Learning\boradcasing_5.png) 第二个A/cal.reshape(1,4)指令则调用了numpy中的广播机制。这里使用 3 by 4的矩阵除以1 by 4 的矩阵。技术上来讲，其实并不需要再将矩阵 reshape(重塑)成 ，因为矩阵本身已经是 了。但是当我们写代码时不确定矩阵维度的时候，通常会对矩阵进行重塑来确保得到我们想要的列向量或行向量。重塑操作reshape是一个常量时间的操作，时间复杂度是，它的调用代价极低。 ![](Deep Learning.ai_Neural Networks and Deep Learning\boradcasing_6.png) ¶Secondly Example ![](Deep Learning.ai_Neural Networks and Deep Learning\bordacasing_2.png) python的广播机制会将常数扩展成4by 1的列向量 ![](Deep Learning.ai_Neural Networks and Deep Learning\boradcasing_3.png) 其实是将1by*n 的矩阵复制成为mbyn的矩阵 ¶广播机制的举例 ![](Deep Learning.ai_Neural Networks and Deep Learning\bordcasing_1.png) ¶axis 补充：numpy中，类似sum的函数，经常涉及axis参数，可以取值为0或1，甚至其他。经常记不住，这里我查了了一下，是这样的（原文）： axis的数字，和数组的shape参数的索引是对应的。比如一个数组的shape是(5,6)，则代表5个row，6个column。即在shape中，row和column的个数的索引是0和1。也就第1个坐标，在shape中的第一个元素，索引是0，代表row的方向；第2个坐标，在shape中的第2个元素，索引是1，代表row的方向。 对于sum函数，axis指的是sum“沿着”的方向，经过计算，这个方向的维度因为求和后就消失了，比如sum(axis=0)代表是沿着“row”方向进行求和， 当然axis可以是一个tupe，那就相当于沿着多个多个方向求和。 sum如果不传入axis参数，默认是对所有维度求和。 ¶broadcasting 当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作，这种机制叫做广播（broadcasting）。 三种广播情况 ![](Deep Learning.ai_Neural Networks and Deep Learning\bordacasing.png) ¶C1W2L16 A Note on Python/numpy vectors 本节主要讲Python中的numpy一维数组的特性，以及与行向量或列向量的区别 ¶1. 一维数组的特性 首先设置a = np.array.random.randn(5)，这样会生成存储在数组a中的5个高斯随机数变量。之后输出 ，从屏幕上可以得知，此时a 的shape（形状）是一个的结构。这在Python中被称作一个一维数组。它既不是一个行向量也不是一个列向量，这也导致它有一些不是很直观的效果。举个例子，如果我输出一个转置阵，最终结果它会和看起来一样，所以和的转置阵最终结果看起来一样。而如果我输出和的转置阵的内积，你可能会想：乘以的转置返回给你的可能会是一个矩阵。但是如果我这样做，你只会得到一个数。 所以我建议当你编写神经网络时，不要在使用的shape(5,1)是还是(n,)或者一维数组。相反，如果你设置(5,1)，那么这就是5行1列向量。在先前的操作里a和a的转置看起来一样，而现在这样的 a变成一个新的a 的转置，并且它是一个行向量。请注意一个细微的差别，在这种数据结构中，当我们输出a 的转置时有两对方括号，而之前只有一对方括号，所以这就是1行5列的矩阵和一维数组的差别。 ¶2. 行向量和列向量 rank 1 array问题：shape是(x,)的数组，既不是行向量，也不是列向量，没法参与正常的矩阵运算，应该总是使用(x,1)或(1,x)的shape来表示向量。但可以通过reshape方法将rank 1 array转换为行向量或列向量。（什么是rank，就是一个数组的维度）一维的数组既不是行向量也不是列向量，转置后，依然是本身。 ![](Deep Learning.ai_Neural Networks and Deep Learning\note_1.jpg) ¶3. 解决方法 12assert(a.shape=（5，1)）# 为了确保你的矩阵或向量所需要的维数时，不要羞于 reshape 操作 ¶C1W2L18 ：Quick Tour of Jupyter/iPython Notebooks ¶C1W2L18: Explanation of Logistic Regression Cost Function 对应logistic regression，输出$\hat{y}=p(y=1|x)$,那么$p(y=0|x)=1-\hat{y}$ ![](Deep Learning.ai_Neural Networks and Deep Learning\cost_2png.png) 综合上面 $$ p(y|x)= \hat{y}y*(1-\hat{y}){1-y} $$ 对于整个训练集， ![](Deep Learning.ai_Neural Networks and Deep Learning\cost_1png.png) 假设所有的训练样本服从同一分布且相互独立，也即独立同分布的，所有这些样本的联合概率就是每个样本概率的乘积: $$ p(labels \ in\ training\ set)=\Pi_{i=1}^mp(y_i|x_i) $$ 如果利用极大似然法做，找到一组参数，使得样本观测值概率最大 $$ \max log p(label \ in \ training \ set)=log \Pi_{i=1}^mp(y_i|x_i)=\sum -L(\hat{yi},yi) $$ $$ \min cost J(w,b)=\frac{1}{m}L(\hat{yi},yi) $$ 总结一下，为了最小化成本函数，我们从logistic回归模型的最大似然估计的角度出发，假设训练集中的样本都是独立同分布的条件下 ¶Day3 : summary 主要学习了python编程的如何才能高效率，内置函数的具有并行性，simd指令，以及一维数组的使用注意事项，logistic regression的lost function的原理证明 C1W3 ¶C1W3L01 : Neural Network Overview ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_2.png) 许多sigmoid单元堆叠起来形成一个神经网络。 正向传播：输入层到layer one $$ \left.\begin{array}{c}{x} \ {W^{[1]}} \ {b^{[1]}}\end{array}\right} \Longrightarrow z{[1]}=W{[1]} x+b^{[1]} \Longrightarrow a{[1]}=\sigma\left(z{[1)}\right) $$ layer one 到layer two $$ \left.\begin{array}{r}{a{(1]}=\sigma\left(z{[1]}\right)} \ {W^{[2]}} \ {b^{[2]}}\end{array}\right}\begin{array}{l}{\Longrightarrow z{[2]}=W{[2]} a{[1]}+b{[2]} \Longrightarrow a{[2]}=\sigma\left(z{[2]}\right)} \ {\Longrightarrow L\left(a^{[2]}, y\right)}\end{array} $$ 反向传播 $$ \left.\begin{array}{r}{d a^{[1]}=d \sigma\left(z^{[1]}\right)} \ {d W^{[2]}} \ {d b^{[2]}}\end{array}\right}\begin{array}{l}{\Longleftarrow d z{[2]}=d\left(W{[2]} \alpha{[1]}+b{[2]}\right) \Longleftarrow d a^{[2]}=d \sigma\left(z^{[2]}\right)} \ {\Longleftarrow d L\left(a^{[2]}, y\right)}\end{array} $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_3.png) $W$的行数是本次结点个数，列数是上层节点个数 ¶C1W3L02 : Nerual Network Representations 符号说明 ¶C1W3L03： Computation Neural Network Output ¶A simple training examples ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_5.png) 其中，x表示输入特征，a表示每个神经元的输出，W表示特征的权重，上标表示神经网络的层数（隐藏层为1），下标表示该层的第几个神经元。这是神经网络的符号惯例，下同。 神经网络的计算 关于神经网络是怎么计算的，从我们之前提及的逻辑回归开始，如下图所示。用圆圈表示神经网络的计算单元，逻辑回归的计算有两个步骤，首先你按步骤计算出，然后在第二步中你以sigmoid函数为激活函数计算（得出），一个神经网络只是这样子做了好多次重复计算。 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_6.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_4.png) 说明：$w_i{[1]}$和$W{[1]}$的关系，一个按照logistic regression ，一个是矩阵表示。 向量化计算 如果你执行神经网络的程序，用for循环来做这些看起来真的很低效。所以接下来我们要做的就是把这四个等式向量化。向量化的过程是将神经网络中的一层神经元参数纵向堆积起来，例如隐藏层中的纵向堆积起来变成一个(4,3)的矩阵，用符号$W^{[1]}$表示。另一个看待这个的方法是我们有四个逻辑回归单元，且每一个逻辑回归单元都有相对应的参数——向量，把这四个向量堆积在一起，你会得出这4×3的矩阵。 $$ z{[n]}=W{[n]}X+b^{[n]} $$ $$ a^{[1]}=\left[ \begin{array}{c}{a_{1}^{[1]}} \ {a_{2}^{[1]}} \ {a_{3}^{[1]}} \ {a_{4}{[1]}}\end{array}\right]=\sigma\left(z{[1]}\right) $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_7.png) Given input X（a single training set) $$ \begin{array}{c}{z{[1]}=W{[1]} a{[0]}+b{[1]}} \ {a{[1]}=\sigma\left(z{[1]}\right)} \ {z{[2]}=W{[2]} a{[1]}+b{[2]}} \ {a{[2]}=\sigma\left(z{[2]}\right)}\end{array} $$ 说明： $W$的第$i$行表示，当前层到上一层的权重行向量，再计算单个的时候，由于是按照logristics regression的方式，所以认为$w_i$是列向量，所以转置成行向量。上面的图也说明了：如何从单个操作到矩阵操作，权重矩阵是怎么构造，怎么表示的。 b是列向量。 ¶C1W3L04: Vectorizing Across Mutilple Example Different training examples in different columns of the matrix for loop ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_8.png) vectorizing : stacking training set in columns $$ x=\left[ \begin{array}{cccc}{\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \ {x^{(1)}} &amp; {x^{(2)}} &amp; {\dots} &amp; {x} \ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots}\end{array}\right] $$ 就有 $$ \left{\begin{array}{l}{A{[1]}=\sigma\left(z{[1]}\right)} \ {z{[2]}=W{[2]} A{[1]}+b{[2]}} \ {A{[2]}=\sigma\left(z{[2]}\right)}\end{array}\right. $$ ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_9.png) 当垂直扫描，是索引到隐藏单位的数字。当水平扫描，将从第一个训练示例中从第一个隐藏的单元到第二个训练样本，第三个训练样本……直到节点对应于第一个隐藏单元的激活值，且这个隐藏单元是位于这个训练样本中的最终训练样本。 从水平上看，矩阵代表了各个训练样本。从竖直上看，矩阵的不同的索引对应于不同的隐藏单元。 ¶C1W3L05 : Explanation for vectorized implement ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_10.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_11.png) ¶C1W3L06 : Activation Function 在讨论优化算法时，有一点要说明：基本已经不用sigmoid激活函数了，tanh函数在所有场合都优于sigmoid函数。 sigmoid函数和tanh函数两者共同的缺点是，在z特别大或者特别小的情况下，导数的梯度或者函数的斜率会变得特别小，最后就会接近于0，导致降低梯度下降的速度。 在机器学习另一个很流行的函数是：修正线性单元的函数（ReLu），ReLu函数图像是如下图。$ a = max(0,z)$： 所以，只要是正值的情况下，导数恒等于1，当是负值的时候，导数恒等于0。从实际上来说，当使用的导数时，=0的导数是没有定义的。但是当编程实现的时候，的取值刚好等于0.00000001，这个值相当小，所以，在实践中，不需要担心这个值，是等于0的时候，假设一个导数是1或者0效果都可以。 如果输出是0、1值（二分类问题），则输出层选择sigmoid函数，然后其它的所有单元都选择Relu函数。 这是很多激活函数的默认选择，如果在隐藏层上不确定使用哪个激活函数，那么通常会使用Relu激活函数。有时，也会使用tanh激活函数，但Relu的一个缺点是：当z是负值的时候，导数等于0。 这里也有另一个版本的Relu被称为Leaky Relu。 当是负值时，这个函数的值不是等于0，而是轻微的倾斜。 两者的优点是： 第一，在的区间变动很大的情况下，激活函数的导数或者激活函数的斜率都会远大于0，在程序实现就是一个if-else语句，而sigmoid函数需要进行浮点四则运算，在实践中，使用ReLu激活函数神经网络通常会比使用sigmoid或者tanh激活函数学习的更快。 第二，sigmoid和tanh函数的导数在正负饱和区的梯度都会接近于0，这会造成梯度弥散，而Relu和Leaky ReLu函数大于0部分都为常数，不会产生梯度弥散现象。(同时应该注意到的是，Relu进入负半区的时候，梯度为0，神经元此时不会训练，产生所谓的稀疏性，而Leaky ReLu不会有这问题) 在ReLu的梯度一半都是0，但是，有足够的隐藏层使得z值大于0，所以对大多数的训练数据来说学习过程仍然可以很快。 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_12.png) sigmoid激活函数：除了输出层是一个二分类问题基本不会用它。 tanh激活函数：tanh是非常优秀的，几乎适合所有场合。 ReLu激活函数：最常用的默认函数，，如果不确定用哪个激活函数，就使用ReLu或者Leaky ReLu。 通常的建议是：如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者发展集上进行评价。然后看哪一种表现的更好，就去使用它。 ¶C1W3L07 : Why non-linear activation Functions ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_13.png) 通过推导可以得出，如果使用线性激活函数，相当于没有隐藏层。无论你的神经网络有多少层一直在做的只是计算线性函数，所以不如直接去掉全部隐藏层。当当然，在output layer是可以不用activation function，或者用linear activation function；这种情况一般是要求输出实数集结果（比如预测房价）。即便如此，在hidden layer还是要用non-linear activation function。 ¶sigmoid activation function ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_14.png) $$ \frac{d}{d z} g(z)=\frac{1}{1+e{-z}}\left(1-\frac{1}{1+e{-z}}\right)=g(z)(1-g(z)) $$ ¶tanh activation function ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_15.png) $$ g(z)=\tanh (z)=\frac{e{z}-e{-z}}{e{x}+e{-z}} $$ $$ \frac{d}{d z} g(z)=1-(\tanh (z))^{2} $$ ¶Rectified linear unit(RelU) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_16.png) $$ g(z)^{\prime}=\left{\begin{array}{ll}{0} &amp; {\text { if } z&lt;0} \ {1} &amp; {\text { if } z&gt;0} \ {\text {undefined}} &amp; {\text { if } z=0}\end{array}\right. $$ 注：通常在z= 0的时候给定其导数1,0；当然=0的情况很少 ¶Leaky linear unit (Leaky ReLU) $$ g(z)=\max (0.01 z, z) $$ $$ g(z)^{\prime}=\left{\begin{array}{ll}{0.01} &amp; {\text { if } z&lt;0} \ {1} &amp; {\text { if } z&gt;0} \ {\text {undefined}} &amp; {\text { if } z=0}\end{array}\right. $$ 注：通常在的z=0时候给定其导数1,0.01；当然的情况很少。 ¶C1W3L09 : Gradient Descent For Neural Networks gradient descent的关键是求cost function对参数的偏导数 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_17.png) 求导过程使用的是Backpropagation 首先做forward propagation，求解出每一层的输出A $$ (1) z{[1]}=W{[1]} x+b^{[1]}\ (2) a{[1]}=\sigma\left(z{[1]}\right)\(3) z{[2]}=W{[2]}=W^{[2]} a{[1]}+b{[2]}\(4) a{[2]}=g{[2]}\left(z{[z]}\right)=\sigma\left(z{[2]}\right) $$ 然后向后，逐层求解对每一层参数的偏导数 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_18.png) sum，keepdims是防止python输出那些古怪的秩数(n,)，加上这个确保阵矩阵这个向量输出的维度为(n,1）这样标准的形式。 ¶C1WL10: Backpropagation intuition (optional) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_19.png) 实现后向传播有个技巧，就是要保证矩阵的维度相互匹配 其实，对于一个神经元，输入部分：是权重和上一层输出的线性组合；输出：激活函数作用于输入，因此对$W$求偏导时，对激活函数求一次，再对线性组合求一次。对$b$求偏导是，对线性部分求偏导是1,这里用求和。 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_20.png) ¶C1W3L11: Random Initialization ` 与logistic regression不同，初始化参数不可固定为0，而是每个参数都要随机初始化。 主要原因是：如果每个参数w和b都是0，则同一层的每个neuron计算结果完全一样（输入一样a，参数一样w，则z一样,symmetry breaking problem）；接下来反向传播时的偏导数也一样，下一轮迭代同一层的每个neuron的w又是一样的。这样整个neural Network上每一层的neuron是同质的，自然不会有好的performance。 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week3_13 (1).png) 不过，对b参数，可以都初始化为0。 另外需要注意，虽然w是随机初始化，但最好使用较小的随机数。主要是避免让z的计算值过大，导致activation function对z的偏导数趋于0，导致Gradient descent下降较慢。 通常的做法是对random的值乘以一个比率，比如0.01（但具体怎么选这个比率，也要根据情况而定，这应该又是一个超参了）： $W[1]=np.random.randn((2,2))∗0.01$ 因为如果你用tanh或者sigmoid激活函数，或者说只在输出层有一个Sigmoid，如果（数值）波动太大，当你计算激活值时如果很大，就会很大或者很小，因此这种情况下你很可能停在tanh/sigmoid函数的平坦的地方，这些地方梯度很小也就意味着梯度下降会很慢，因此学习也就很慢。 事实上有时有比0.01更好的常数，当你训练一个只有一层隐藏层的网络时（这是相对浅的神经网络，没有太多的隐藏层），设为0.01可能也可以。但当你训练一个非常非常深的神经网络，你可能要试试0.01以外的常数。 ¶summary 如何建立一个一层的神经网络了，初始化参数，用前向传播预测，还有计算导数，结合反向传播用在梯度下降中。 Define the neural network structure ( # of input units, # of hidden units, etc). Initialize the model’s parameters Loop: Implement forward propagation Compute loss Implement backward propagation to get the gradients Update parameters (gradient descent) C1W4 ¶C1W4L01 Deep-layer neural network ¶1. logistics regression and shallow neural network and deep-layer neural network ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_1.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_2.png) ¶2. notation 神经网络模型 $$ \begin{array}{l}{X \in \mathbb{R}^{n_{x} \times m}} 代表输入的矩阵\{x^{(i)} \in \mathbb{R}^{n_{x}}} 代表第 i 个样本的列向量\ {Y \in \mathbb{R}^{n_{y} \times n}} 标记矩阵\ {y^{(i)} \in \mathbb{R}^{n_{v}}}是第i样本的输出标签\ W^{[l]} \in \mathbb{R}^{l \times(l-1)}代表第[l]层的权重矩阵\ b^{[l]} \in \mathbb{R}^{l}代表第[l]层的偏差矩阵\ {\hat{y}^{(i)} \in \mathbb{R}^{n_{v}}}是预测输出向量\end{array} $$ $$ 通用激活公式： a_{j}{[l]}=g{[l]}\left(z_{j}{[l]}\right)=g{ | l ]}\left(\sum_{k} w_{j k}^{[l]} a_{k}{[l-1]}+b_{j}{[l]}\right) $$ ¶C1W4L02： Forward and Backward propagation ¶1. forward propagation ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_3.png) ¶2. backward propagation $$ \begin{array}{l}{d z^{[l]}=d a^{[l]} * g{[l]}\left(z{l l}\right)} \ {d w^{[l]}=d z^{[l]} \cdot a^{[l-1]}}\d b^{[l]}=d z^{[l]}\ d a{[l-1]}=w{[l]} \cdot d z^{[l]}\ d z{[l]}=w{[l+1] T} d z^{[l+1]} \cdot g{[l]{\prime}}\left(z^{[l]}\right)\end{array} $$ 向量化 $$ \begin{array}{l}{d Z^{[l]}=d A^{[l]} * g{[l]}\left(Z{[l]}\right)} \ {d W^{[l]}=\frac{1}{m} d Z^{[l]} \cdot A^{[l-1] T}}\ \begin{array}{l}{d b^{[l]}=\frac{1}{m} n p \cdot \operatorname{sum}\left(d z^{[l]}, \text { axis }=1, \text {keepdims}=\text {True}\right)} \ {d A{[l-1]}=W{[l] T} \cdot d Z^{[l]}}\end{array}\end{array} $$ summary ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_5.png) ¶C1W4L03 : Forward Propagation in d deep network ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_6.png) 这里只能用一个显式for循环，从1到，然后一层接着一层去计算。 ¶C1W4L04 Getting matrix dimension right 当实现深度神经网络的时候，其中一个常用的检查代码是否有错的方法就是拿出一张纸过一遍算法中矩阵的维数。 $d_w{[l]}$和$w{[l]}$维度相同，$db{[l]}$和$b{[l]}$维度相同，且w和b向量化维度不变，但z,a以及x的维度会向量化后发生变化。 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_8.png) 反向传播的维数检查 ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_7.png) 在你做深度神经网络的反向传播时，一定要确认所有的矩阵维数是前后一致的，可以大大提高代码通过率。 ¶C1W4L05 Why deep representations? 神经网络不需要很大，但是得有深度，也就是隐藏层需要很多， ¶1. for example of face detector ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_9.png) ¶C1W4L06 :Building blocks of a deep neural network ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_10.png) ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_11.png) 可以看得出，再反向传播的时候，需要用到$Z{[L]},W{[L]},b^{[L]}$,因此cash them 正向传播：$Z{[1]},A{[1]}…$,反向传播：$dA{[L]},dZ{[L]},dW{[L]}dB{[L]},dA{[L-1]}$ ¶C1W4L07：Parameters vs Hyperparameters ¶1 What ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_12.png) ¶2 How ![](Deep Learning.ai_Neural Networks and Deep Learning\L1_week4_13.png) Idea—Code—Experiment—Idea这个循环，尝试各种不同的参数，实现模型并观察是否成功，然后再迭代 今天的深度学习应用领域，还是很经验性的过程，通常你有个想法，比如你可能大致知道一个最好的学习率值，可能说最好，我会想先试试看，然后你可以实际试一下，训练一下看看效果如何。然后基于尝试的结果你会发现，你觉得学习率设定再提高到0.05会比较好。如果你不确定什么值是最好的，你大可以先试试一个学习率，再看看损失函数J的值有没有下降。然后你可以试一试大一些的值，然后发现损失函数的值增加并发散了。然后可能试试其他数，看结果是否下降的很快或者收敛到在更高的位置。你可能尝试不同的并观察损失函数这么变了，试试一组值，然后可能损失函数变成这样，这个值会加快学习过程，并且收敛在更低的损失函数值上（箭头标识），我就用这个值了。 在前面几页中，还有很多不同的超参数。然而，当你开始开发新应用时，预先很难确切知道，究竟超参数的最优值应该是什么。所以通常，你必须尝试很多不同的值，并走这个循环，试试各种参数。试试看5个隐藏层，这个数目的隐藏单元，实现模型并观察是否成功，然后再迭代。这页的标题是，应用深度学习领域，一个很大程度基于经验的过程，凭经验的过程通俗来说，就是试直到你找到合适的数值。 所以我经常建议人们，特别是刚开始应用于新问题的人们，去试一定范围的值看看结果如何。然后下一门课程，我们会用更系统的方法，用系统性的尝试各种超参数取值。然后其次，甚至是你已经用了很久的模型，可能你在做网络广告应用，在你开发途中，很有可能学习率的最优数值或是其他超参数的最优值是会变的，所以即使你每天都在用当前最优的参数调试你的系统，你还是会发现，最优值过一年就会变化，因为电脑的基础设施，CPU或是GPU可能会变化很大。所以有一条经验规律可能每几个月就会变。如果你所解决的问题需要很多年时间，只要经常试试不同的超参数，勤于检验结果，看看有没有更好的超参数数值，相信你慢慢会得到设定超参数的直觉，知道你的问题最好用什么数值。 有一条经验规律：经常试试不同的超参数，勤于检查结果，看看有没有更好的超参数取值，你将会得到设定超参数的直觉。 总结：超参数的设定，靠经验，尝试，并调，根据结果调， ¶C1W4L08 : What does this have to do with the brain? # summary : forward prop and back prop ¶1. logistics regression,shallow neural network and deep neural network logistics regression $$ Z = W^TX+B\ A = \frac{1}{1+e^{-Z}}\ L(A,Y)=-\frac{1}{m}(YlogA+(1-Y)log{1-A}\ \frac{\partial L}{\partial Z}=(A-Y)\ \frac{\partial L}{\partial W}=X(A-Y)\ $$ 说明：X是样本按列堆积，W是列向量 shallow neural network 以二分问题为例 $$ Z{[1]}=W{[1]}A{[0]}+b{[1]}\ A{[1]}=g{[1]}(Z^{[1]})\ \ \ Z{[2]}=W{[2]}A{[1]}+b{[2]}\ A{[2]}=g{[2]}(Z^{[2]})\ \ \ \ \ \ L(A{[2]},Y)=-\frac{1}{m}(Ylog{A}+(1-Y)log^{1-A})\ \frac{\partial L}{\partial Z{[2]}}=(A{[2]}-Y)\ \frac{\partial L}{\partial W{[2]}}=(A{[2]}-Y)A{[1]T}\ \frac{\partial L}{\partial b{[2]}}=(A{[2]}-Y)1_{1m}^T\ \frac{\partial L}{\partial a{[1]}}=W{[2]T}(A{[2]}-Y)\ \ \ \frac{\partial L}{\partial Z{[1]}}=W{[2]T}(A{[2]}-Y) g{’[1]}(Z{[1]})\ $$ 说明：W是按列排$W{[L]}$是$n{[L]}*n^{[L-1]}$矩阵，A,Z是按列堆积，记得检查矩阵维数就好了 ¶deep neural network $$ Z{[l]}=W{[l]}A{[l-1]}+b{[l]}\ A{[l]}=g{[l]}(Z^{[l]})\ \ \ \ \ \ \frac{\partial L}{\partial Z^{[l]}}=\partial A&lt;!–￼0–&gt;*g{’[l]}(Z^{l})\ \frac{\partial L}{\partial W^{[l]}}=\partial Z^{[l]} A{[1-1]T}\ \frac{\partial L}{\partial b^{[l]}}=\partial Z^{[l]}\ \frac{\partial L}{\partial a{[l-1]}}=W{[l]^T}\partial Z^{[l]}\ \ \ \frac{\partial L}{\partial Z{[l-1]}}=W{[l]^T}\partial Z^{[l]}* g{’[l-1]}(Z{[l-1]})\ $$ ¶2. vectorization 推导的时候要向量化，注意矩阵维数表示，可以从单个推导到mutli 充分利用python的广播属性，和内置函数的并行化 python一维，二维数组的特性 ¶3. 知识结构 ![](Deep Learning.ai_Neural Networks and Deep Learning\C1.png)]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep_learning.ai深度学习笔记]]></title>
    <url>%2F2019%2F04%2F11%2Fdeep-learning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[C5: Sequence Models ¶W1 : Recurrent Neural Networks (循环序列模型) ¶L1 ： Why Sequence Models? 循环神经网络（RNN）之类的模型在语音识别、自然语言处理和其他领域中引起变革。 序列模型的列子 ¶L2 : Notation 数学符号 NLP 我们用$X{(i)}$来表示第个i训练样本，所以为了指代第个t元素，或者说是训练样本i的序列中第t个元素用$X{(i)}$这个符号来表示。如果是序列长度$T_x$，那么你的训练集里不同的训练样本就会有不同的长度，所以$T_x{(i)}$就代表第个训练样本的输入序列长度。同样$y{(i)}$代表第i个训练样本中第t个元素，$T_y^{(i)}$就是第i个训练样本的输出序列的长度。 预先有一个词典 ¶L3 : Recurrent Neural Network Model (循环神经网络模型) 现在我们讨论一下怎样才能建立一个模型，建立一个神经网络来学习X到Y的映射 $a^{&lt;0&gt;}$通常 是零向量 N模型包含三类权重系数，分别是Wax，Waa，Wya。且不同元素之间同一位置共享同一权重系数。 RNN的正向传播（Forward Propagation）过程为： 循环神经网络用的激活函数经常是tanh，不过有时候也会用ReLU，但是tanh是更通常的选择，我们有其他方法来避免梯度消失问题，我们将在之后进行讲述。选用哪个激活函数是取决于你的输出y，如果它是一个二分问题，那么我猜你会用sigmoid函数作为激活函数，如果是k类别分类问题的话，那么可以选用softmax作为激活函数。不过这里激活函数的类型取决于你有什么样类型的输出y，对于命名实体识别来说y只可能是0或者1，那我猜这里第二个激活函数g可以是sigmoid激活函数。 ¶c4: Backpropagation through time ( 通过时间的反向传播) 参数的关系* 单个元素的Loss function: 该样本所有元素的Loss function为： 然后，反向传播（Backpropagation）过程就是从右到左分别计算L(y^,y)对参数Wa，Wy，ba，by的偏导数。思路与做法与标准的神经网络是一样的。一般可以通过成熟的深度学习框架自动求导，例如PyTorch、Tensorflow等。这种从右到左的求导过程被称为Backpropagation through time ¶L5: Different types of RNNs (不同类型的循环神经网络) ¶L6 : Language model and sequence generation (语言模型和序列生成) ¶L7 : Sampling novel sequences (对新序列采样) ¶Vanishing gradients with RNNs (循环神经网络的梯度消失) 首先从左到右前向传播，然后反向传播。但是反向传播会很困难，因为同样的梯度消失的问题，后面层的输出误差（上图编号6所示）很难影响前面层（上图编号7所示的层）的计算。这就意味着，实际上很难让一个神经网络能够意识到它要记住看到的是单数名词还是复数名词，然后在序列后面生成依赖单复数形式的was或者were。而且在英语里面，这中间的内容（上图编号8所示）可以任意长，对吧？所以你需要长时间记住单词是单数还是复数，这样后面的句子才能用到这些信息。也正是这个原因，所以基本的RNN模型会有很多局部影响 http://www.ai-start.com/dl2017/html/lesson5-week1.html https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&amp;mid=2247484029&amp;idx=1&amp;sn=c93b5eddec33dc29dc172a5ea0d76822&amp;chksm=976fa7e0a0182ef61e36d1c32aa0706c4e81e1762a7ee2554165beecde929b72cf026c5b7a64&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>学习の历程(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>我的读书笔记</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F07%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[^]: [TOC] 利用听力材料学英语最高效 有效输出应该是稍高于现有水平的、更准确、更得体的表达输出 先记住以下两点，下面我们再一一解析应该要怎么做到。 1. 学习需要反馈，来告诉我们这输出是正确的，可以继续；或者是错误的，需要修正。 2. 将输入内化，变成自己的知识。 我一般会听四遍，但不是全听原文。 **第一遍：泛听原文，不要看字幕或脚本，清楚录音的内容。**听第一遍的时候我通常连笔记都不做，目的是为了让自己流畅的听完，对听力的内容有一个整体的掌握。 第二遍：先听原文，根据内容段落，开始复述内容，并录音。这一步的目的是强迫自己调用已经学过的知识，组织语言和进行练习。 **第三遍，听自己的录音，然后做出修正。**这一步很重要，可以让你了解自己的发音问题和语法问题，并把可听出来的语法问题进行修改。通过这一步，我们就可以把简单重复输入的语言材料，转化为有效输出。 第四遍，听原文看字幕和脚本，看把听不懂的地方标注，说明为什么听不懂（比如是因为自己发音不准导致的听不出，或者就是因为这个词没背过、不熟悉）。不熟悉的用法和自己用错的地方总结，背下来，下次试着用。 Tips： 不要选择太难的材料，太难的材料容易使自己丧失学习兴趣。 一开始，不要选择太长的听力材料。10分钟左右最佳。在这里推荐ted，可以选择有字幕或关闭字幕。 在一个相近的时间段内，选择相近题材的材料。比如我会在两个星期内选择“心理”题材的录音。这样我就会有更大的几率用上刚学过的结构和词汇。 及时总结，及时复习已背过的材料，复习的重要性大家都懂，这里就不多说了。 真题听写 材料选择 能够听得懂 70%的材料 2 具体执行方法 先泛听一篇 再循环听几遍 再逐句逐句的听 ¶美剧精听 先看中文听 英文，查 听找 台词，跟读 重复三四 至少10]]></content>
  </entry>
  <entry>
    <title><![CDATA[deeplearningvideo]]></title>
    <url>%2F2019%2F04%2F03%2Fdeeplearningvideo%2F</url>
    <content type="text"><![CDATA[Coursera深度学习教程中文笔记 课程概述 https://mooc.study.163.com/university/deeplearning_ai#/c 这些课程专为已有一定基础（基本的编程知识，熟悉Python、对机器学习有基本了解），想要尝试进入人工智能领域的计算机专业人士准备。介绍显示：“深度学习是科技业最热门的技能之一，本课程将帮你掌握深度学习。” 在这5堂课中，学生将可以学习到深度学习的基础，学会构建神经网络，并用在包括吴恩达本人在内的多位业界顶尖专家指导下创建自己的机器学习项目。Deep Learning Specialization对卷积神经网络 (CNN)、递归神经网络 (RNN)、长短期记忆 (LSTM) 等深度学习常用的网络结构、工具和知识都有涉及。 笔记是根据视频和字幕写的，没有技术含量，只需要专注和严谨。 2018-04-14 本课程视频教程地址：https://mooc.study.163.com/university/deeplearning_ai#/c （该视频从www.deeplearning.ai 网站下载，因众所周知的原因，国内用户观看某些在线视频非常不容易，故一些学者一起制作了离线视频，旨在方便国内用户个人学习使用，请勿用于商业用途。视频内嵌中英文字幕，推荐使用potplayer播放。版权属于吴恩达老师所有，若在线视频流畅，请到官方网站观看。） 笔记网站(适合手机阅读) 吴恩达老师的机器学习课程笔记和视频：https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes 深度学习笔记目录 ¶第一门课 神经网络和深度学习(Neural Networks and Deep Learning) 第一周：深度学习引言(Introduction to Deep Learning) 1.1 欢迎(Welcome) 1.2 什么是神经网络？(What is a Neural Network) 1.3 神经网络的监督学习(Supervised Learning with Neural Networks) 1.4 为什么神经网络会流行？(Why is Deep Learning taking off?) 1.5 关于本课程(About this Course) 1.6 课程资源(Course Resources) 1.7 Geoffery Hinton 专访(Geoffery Hinton interview) 第二周：神经网络的编程基础(Basics of Neural Network programming) 2.1 二分类(Binary Classification) 2.2 逻辑回归(Logistic Regression) 2.3 逻辑回归的代价函数（Logistic Regression Cost Function） 2.4 梯度下降（Gradient Descent） 2.5 导数（Derivatives） 2.6 更多的导数例子（More Derivative Examples） 2.7 计算图（Computation Graph） 2.8 计算图导数（Derivatives with a Computation Graph） 2.9 逻辑回归的梯度下降（Logistic Regression Gradient Descent） 2.10 梯度下降的例子(Gradient Descent on m Examples) 2.11 向量化(Vectorization) 2.12 更多的向量化例子（More Examples of Vectorization） 2.13 向量化逻辑回归(Vectorizing Logistic Regression) 2.14 向量化逻辑回归的梯度计算（Vectorizing Logistic Regression’s Gradient） 2.15 Python中的广播机制（Broadcasting in Python） 2.16 关于 Python与numpy向量的使用（A note on python or numpy vectors） 2.17 Jupyter/iPython Notebooks快速入门（Quick tour of Jupyter/iPython Notebooks） 2.18 逻辑回归损失函数详解（Explanation of logistic regression cost function） 第三周：浅层神经网络(Shallow neural networks) 3.1 神经网络概述（Neural Network Overview） 3.2 神经网络的表示（Neural Network Representation） 3.3 计算一个神经网络的输出（Computing a Neural Network’s output） 3.4 多样本向量化（Vectorizing across multiple examples） 3.5 向量化实现的解释（Justification for vectorized implementation） 3.6 激活函数（Activation functions） 3.7 为什么需要非线性激活函数？（why need a nonlinear activation function?） 3.8 激活函数的导数（Derivatives of activation functions） 3.9 神经网络的梯度下降（Gradient descent for neural networks） 3.10（选修）直观理解反向传播（Backpropagation intuition） 3.11 随机初始化（Random+Initialization） 第四周：深层神经网络(Deep Neural Networks) 4.1 深层神经网络（Deep L-layer neural network） 4.2 前向传播和反向传播（Forward and backward propagation） 4.3 深层网络中的前向和反向传播（Forward propagation in a Deep Network） 4.4 核对矩阵的维数（Getting your matrix dimensions right） 4.5 为什么使用深层表示？（Why deep representations?） 4.6 搭建神经网络块（Building blocks of deep neural networks） 4.7 参数VS超参数（Parameters vs Hyperparameters） 4.8 深度学习和大脑的关联性（What does this have to do with the brain?） ¶第二门课 改善深层神经网络：超参数调试、正则化以及优化(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization) 第一周：深度学习的实用层面(Practical aspects of Deep Learning) 1.1 训练，验证，测试集（Train / Dev / Test sets） 1.2 偏差，方差（Bias /Variance） 1.3 机器学习基础（Basic Recipe for Machine Learning） 1.4 正则化（Regularization） 1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?） 1.6 dropout 正则化（Dropout Regularization） 1.7 理解 dropout（Understanding Dropout） 1.8 其他正则化方法（Other regularization methods） 1.9 标准化输入（Normalizing inputs） 1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients） 1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing /Exploding gradients） 1.12 梯度的数值逼近（Numerical approximation of gradients） 1.13 梯度检验（Gradient checking） 1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes） 第二周：优化算法 (Optimization algorithms) 2.1 Mini-batch 梯度下降（Mini-batch gradient descent） 2.2 理解Mini-batch 梯度下降（Understanding Mini-batch gradient descent） 2.3 指数加权平均（Exponentially weighted averages） 2.4 理解指数加权平均（Understanding Exponentially weighted averages） 2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages） 2.6 momentum梯度下降（Gradient descent with momentum） 2.7 RMSprop——root mean square prop（RMSprop） 2.8 Adam优化算法（Adam optimization algorithm） 2.9 学习率衰减（Learning rate decay） 2.10 局部最优问题（The problem of local optima） 第三周超参数调试，batch正则化和程序框架（Hyperparameter tuning, Batch Normalization and Programming Frameworks) 3.1 调试处理（Tuning process） 3.2 为超参数选择和适合范围（Using an appropriate scale to pick hyperparameters） 3.3 超参数训练的实践：Pandas vs. Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar） 3.4 网络中的正则化激活函数（Normalizing activations in a network） 3.5 将 Batch Norm拟合进神经网络（Fitting Batch Norm into a neural network） 3.6 为什么Batch Norm奏效？（Why does Batch Norm work?） 3.7 测试时的Batch Norm（Batch Norm at test time） 3.8 Softmax 回归（Softmax Regression） 3.9 训练一个Softmax 分类器（Training a softmax classifier） 3.10 深度学习框架（Deep learning frameworks） 3.11 TensorFlow（TensorFlow） ¶第三门课 结构化机器学习项目 (Structuring Machine Learning Projects) 第一周：机器学习策略（1）(ML Strategy (1)) 1.1 为什么是ML策略？ (Why ML Strategy) 1.2 正交化(Orthogonalization) 1.3 单一数字评估指标(Single number evaluation metric) 1.4 满足和优化指标 (Satisficing and Optimizing metric) 1.5 训练集、开发集、测试集的划分(Train/dev/test distributions) 1.6 开发集和测试集的大小 (Size of the dev and test sets) 1.7 什么时候改变开发集/测试集和评估指标(When to change dev/test sets and metrics) 1.8 为什么是人的表现 (Why human-level performance?) 1.9 可避免偏差(Avoidable bias) 1.10 理解人类的表现 (Understanding human-level performance) 1.11 超过人类的表现(Surpassing human-level performance) 1.12 改善你的模型表现 (Improving your model performance) 第二周：机器学习策略（2）(ML Strategy (2)) 2.1 误差分析 (Carrying out error analysis) 2.2 清除标注错误的数据(Cleaning up incorrectly labeled data) 2.3 快速搭建你的第一个系统，并进行迭代(Build your first system quickly, then iterate) 2.4 在不同的分布上的训练集和测试集 (Training and testing on different distributions) 2.5 数据分布不匹配的偏差与方差分析 (Bias and Variance with mismatched data distributions) 2.6 处理数据不匹配问题(Addressing data mismatch) 2.7 迁移学习 (Transfer learning) 2.8 多任务学习(Multi-task learning) 2.9 什么是端到端的深度学习？ (What is end-to-end deep learning?) 2.10 是否使用端到端的深度学习方法 (Whether to use end-to-end deep learning) ¶第四门课 卷积神经网络（Convolutional Neural Networks） 第一周 卷积神经网络(Foundations of Convolutional Neural Networks) 1.1 计算机视觉（Computer vision） 1.2 边缘检测示例（Edge detection example） 1.3 更多边缘检测内容（More edge detection） 1.4 Padding 1.5 卷积步长（Strided convolutions） 1.6 三维卷积（Convolutions over volumes） 1.7 单层卷积网络（One layer of a convolutional network） 1.8 简单卷积网络示例（A simple convolution network example） 1.9 池化层（Pooling layers） 1.10 卷积神经网络示例（Convolutional neural network example） 1.11 为什么使用卷积？（Why convolutions?） 第二周 深度卷积网络：实例探究(Deep convolutional models: case studies) 2.1 为什么要进行实例探究？（Why look at case studies?） 2.2 经典网络（Classic networks） 2.3 残差网络（Residual Networks (ResNets)） 2.4 残差网络为什么有用？（Why ResNets work?） 2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions） 2.6 谷歌 Inception 网络简介（Inception network motivation） 2.7 Inception 网络（Inception network） 2.8 使用开源的实现方案（Using open-source implementations） 2.9 迁移学习（Transfer Learning） 2.10 数据扩充（Data augmentation） 2.11 计算机视觉现状（The state of computer vision） 第三周 目标检测（Object detection） 3.1 目标定位（Object localization） 3.2 特征点检测（Landmark detection） 3.3 目标检测（Object detection） 3.4 卷积的滑动窗口实现（Convolutional implementation of sliding windows） 3.5 Bounding Box预测（Bounding box predictions） 3.6 交并比（Intersection over union） 3.7 非极大值抑制（Non-max suppression） 3.8 Anchor Boxes 3.9 YOLO 算法（Putting it together: YOLO algorithm） 3.10 候选区域（选修）（Region proposals (Optional)） 第四周 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition &amp;Neural style transfer） 4.1 什么是人脸识别？(What is face recognition?) 4.2 One-Shot学习（One-shot learning） 4.3 Siamese 网络（Siamese network） 4.4 Triplet 损失（Triplet 损失） 4.5 面部验证与二分类（Face verification and binary classification） 4.6 什么是神经风格转换？（What is neural style transfer?） 4.7 什么是深度卷积网络？（What are deep ConvNets learning?） 4.8 代价函数（Cost function） 4.9 内容代价函数（Content cost function） 4.10 风格代价函数（Style cost function） 4.11 一维到三维推广（1D and 3D generalizations of models） 第五门课 序列模型(Sequence Models) 第一周 循环序列模型（Recurrent Neural Networks） 1.1 为什么选择序列模型？（Why Sequence Models?） 1.2 数学符号（Notation） 1.3 循环神经网络模型（Recurrent Neural Network Model） 1.4 通过时间的反向传播（Backpropagation through time） 1.5 不同类型的循环神经网络（Different types of RNNs） 1.6 语言模型和序列生成（Language model and sequence generation） 1.7 对新序列采样（Sampling novel sequences） 1.8 循环神经网络的梯度消失（Vanishing gradients with RNNs） 1.9 GRU单元（Gated Recurrent Unit（GRU）） 1.10 长短期记忆（LSTM（long short term memory）unit） 1.11 双向循环神经网络（Bidirectional RNN） 1.12 深层循环神经网络（Deep RNNs） 第二周 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings） 2.1 词汇表征（Word Representation） 2.2 使用词嵌入（Using Word Embeddings） 2.3 词嵌入的特性（Properties of Word Embeddings） 2.4 嵌入矩阵（Embedding Matrix） 2.5 学习词嵌入（Learning Word Embeddings） 2.6 Word2Vec 2.7 负采样（Negative Sampling） 2.8 GloVe 词向量（GloVe Word Vectors） 2.9 情绪分类（Sentiment Classification） 2.10 词嵌入除偏（Debiasing Word Embeddings） 第三周 序列模型和注意力机制（Sequence models &amp; Attention mechanism） 3.1 基础模型（Basic Models） 3.2 选择最可能的句子（Picking the most likely sentence） 3.3 集束搜索（Beam Search） 3.4 改进集束搜索（Refinements to Beam Search） 3.5 集束搜索的误差分析（Error analysis in beam search） 3.6 Bleu 得分（选修）（Bleu Score (optional)） 3.7 注意力模型直观理解（Attention Model Intuition） 3.8注意力模型（Attention Model） 3.9语音识别（Speech recognition） 3.10触发字检测（Trigger Word Detection） 3.11结论和致谢（Conclusion and thank you） 人工智能大师访谈 吴恩达采访 Geoffery Hinton 吴恩达采访 Ian Goodfellow 吴恩达采访 Ruslan Salakhutdinov 吴恩达采访 Yoshua Bengio 吴恩达采访 林元庆 吴恩达采访 Pieter Abbeel 吴恩达采访 Andrej Karpathy 附件 深度学习符号指南（原课程翻译）]]></content>
      <categories>
        <category>视频学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯分类器]]></title>
    <url>%2F2019%2F03%2F28%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[[TOC] 概率论的知识 ¶条件概率 $$ P(A|B)=P(A\cap B)/P(B) $$ 已知B发生的概率，求A发生的概率 ¶全概率 $$ P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i) $$ ¶贝叶斯推断 $$ P(A|B)=P(A)\frac{P(B|A)}{P(B)} $$ $$ P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)} $$ $P(A)$：Prior probability 先验概率，在B事件发生之前，对A事件做一个判断 $P(A|B)$:Posterior probability 后验概率，在B事件发生之后，对A事件的概率重新评估 $P(B|A)/P(B)$:称为可能性函数，一个调整因子 后验概率=先验概率*调整因子 （可知，调整因此&gt;1,发生概率增大了， 贝叶斯决策论 英文：Bayesian decision theory 设有$N$种可能的类别, 即γ=${c_1,c_2,…,c_N}$. $λ_ij$是将一个真实类别为$c_j$的样本判为$c_x$的损失。 基于后验概率可得将样本分类所产生的期望损失, 或者成为条件风险(Conditional Risk) $$ R(C_i|x)=∑_{j=1}^Nλ_{ij}P(c_j|x) $$ 于是， 我们的任务就是寻找判定准则h， 令$χ→γ$ 使得最小化总体风险，$R(h)=E_x[R(h(x)|x]$最小. 对于每一个$x$，若$h$都能最小化条件风险，那么总体也被最小化了。 可以简化为对每个样本选择其条件风险最小的分类, 即: $$ h(x)=arg \min_{c⊂λ}R(c|x) $$ 此$h(x)$就是贝叶斯最优分类器。 $R(h)$为贝叶斯风险(Bayes Risk), $1−R(h)$反映了分类器的最优性能. 具体来说，如果目标是最小化分类错误率， $$\lambda_{ij}=\begin{cases} 0\ \ i==j\1 \ \ \ i!=j \end{cases}$$ 则$R(c|x)=1-p(c|x)$，因此可知，$h(x)=\max_{c\in C} p(c|x)$ 对于样本$x$,选择后验概率$P(c|X)$最大的类别为标记。 问题转换为 $$ P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)} $$ 求先验概率和似然($P(x|c)$) 其中 $P©$表达了样本空间种各类样本所占的比列，根据大数定律，当样本足够充分的独立同分布样本是，可以频率估计 $P(x|c)$,涉及关于x所以属性的联合概率，用频率估计概率可能不太好，对于估计类条件概率的一种宠用策略是先假设具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。 $P(x|c)$是类条件概率，由某个分布决定，$P(x|\theta_c)$来表示了 频率注意派认为可以通过优化似然函数估计参数。$D_c$类别c的样本集合，独立同分布 $$ P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c) $$ $$ LL(\theta_c)=log P(D_c|\theta_c) $$ 朴素贝叶斯分类器 英文：naive Bayes classifier 假设：属性条件独立性假设，每个属性独立性对分类结果发生影响 $$ P(c|x)=\frac{P©P(x|c)}{P(x)}=\frac{P©\Pi_{i=1}^{d}P(x_i|c)}{P(x)} $$ 对于一个$x$，$P(x)$都是相同的，因此贝叶斯模型可写为 $$ h_{nb}(x)=arg max_{c\in y}P©\Pi_{i=1}^{d}P(x_i|c) $$ ¶计算过程 假设$D_{c_i}$表示第i类的样本集合， $P(c_i)=\frac{|D_{c_i}|}{|D|}$ 如果是离散属性 $$ P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|} $$ 如果是连续属性，$P(x_i|c_i)$服从$N(u_{c,i},\theta_{c,i}^2)$的分布 $$ P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)2}{2\theta_{c,i}2}) $$ $P(c_i)\Pi_{i=1}^{N}P(x_i|c_i)$ 注意为了避免其他属性携带的信息被训练集中未出现的属性值抹去，因此用拉普拉斯修正（Laplacian correction) $$ P©=\frac{|D_{c_i}|+1}{|D|+N}\ P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i} $$ $N$:训练集可能出现的类别数 $N_i$:第i个属性可能的取值数 显然，拉普拉斯修正避免因训练集不充分导出的概率估值为0的情况 朴素贝叶斯的种类 再scikit-learn中，一共有三个朴素贝叶斯，分别是 ¶GaussianNB $$ P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)2}{2\theta_{c,i}2}) $$ 12345678910111213141516171819202122#导入包import pandas as pdfrom sklearn.naive_bayes import GaussianNBfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_score#导入数据集from sklearn import datasetsiris=datasets.load_iris()#切分数据集Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=42)#建模clf = GaussianNB()clf.fit(Xtrain, ytrain)#在测试集上执行预测，proba导出的是每个样本属于某类的概率clf.predict(Xtest)clf.predict_proba(Xtest) #每一类计算结果都输出#测试准确率accuracy_score(ytest, clf.predict(Xtest)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npimport pandas as pdimport randomdataSet =pd.read_csv('iris.txt',header = None)dataSet.head()def randSplit(dataSet, rate): l = list(dataSet.index) #提取出索引 random.shuffle(l) #随机打乱索引 dataSet.index = l #将打乱后的索引重新赋值给原数据集 n = dataSet.shape[0] #总行数 m = int(n * rate) #训练集的数量 train = dataSet.loc[range(m), :] #提取前m个记录作为训练集 test = dataSet.loc[range(m, n), :] #剩下的作为测试集 dataSet.index = range(dataSet.shape[0]) #更新原数据集的索引 test.index = range(test.shape[0]) #更新测试集的索引train,test=randSplit(dataSet, 0.8)def gnb_classify(train,test): labels = train.iloc[:,-1].value_counts().index #提取训练集的标签种类 mean =[] #存放每个类别的均值 std =[] #存放每个类别的方差 result = [] #存放测试集的预测结果 for i in labels: item = train.loc[train.iloc[:,-1]==i,:] #分别提取出每一种类别 m = item.iloc[:,:-1].mean() #当前类别的平均值 s = np.sum((item.iloc[:,:-1]-m)**2)/(item.shape[0]) #当前类别的方差 mean.append(m) #将当前类别的平均值追加至列表 std.append(s) #将当前类别的方差追加至列表 means = pd.DataFrame(mean,index=labels) #变成DF格式，索引为类标签 stds = pd.DataFrame(std,index=labels) #变成DF格式，索引为类标签 for j in range(test.shape[0]): iset = test.iloc[j,:-1].tolist() #当前测试实例 iprob = np.exp(-1*(iset-means)**2/(stds*2))/(np.sqrt(2*np.pi*stds)) #正态分布公式 prob = train.iloc[:,-1].value_counts()/len(train.iloc[:,-1]) #初始化当前实例总概率 for k in range(test.shape[1]-1): #遍历每个特征 prob *= iprob[k] #特征概率之积即为当前实例概率 cla = prob.index[np.argmax(prob.values)] #返回最大概率的类别 result.append(cla) test['predict']=result acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean() #计算预测准确率 print(f'模型预测准确率为&#123;acc&#125;') return testgnb_classify(train,test)for i in range(20): train,test= randSplit(dataSet, 0.8) gnb_classify(train,test) ¶MultinomialNB 先验概率多项式分布的朴素贝叶斯，假设特征是由一共简单多项式分布生成，多项分布可以描述各种类型样本出现的频率，该模型常用于文本分类，特别表示次数。$\lambda$常取值1 $$ P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda} $$ 12345678910def loadDataSet(): dataSet=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] #切分好的词条 classVec = [0,1,0,1,0,1] #类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇 return dataSet,classVecdataSet,classVec = loadDataSet() 12345678def createVocabList(dataSet): vocabSet = set() #创建一个空的集合 for doc in dataSet: #遍历dataSet中的每一条言论 vocabSet = vocabSet | set(doc) #取并集 vocabList = list(vocabSet) return vocabListvocabList = createVocabList(dataSet) 12345678def setOfWords2Vec(vocabList, inputSet): returnVec = [0] * len(vocabList) #创建一个其中所含元素都为0的向量 for word in inputSet: #遍历每个词条 if word in vocabList: #如果词条存在于词汇表中，则变为1 returnVec[vocabList.index(word)] = 1 else: print(f" &#123;word&#125; is not in my Vocabulary!" ) return returnVec #返回文档向量 12345678def get_trainMat(dataSet): trainMat = [] #初始化向量列表 vocabList = createVocabList(dataSet) #生成词汇表 for inputSet in dataSet: #遍历样本词条中的每一条样本 returnVec=setOfWords2Vec(vocabList, inputSet) #将当前词条向量化 trainMat.append(returnVec) #追加到向量列表中 return trainMattrainMat = get_trainMat(dataSet) 1234567891011121314151617181920def trainNB(trainMat,classVec): n = len(trainMat) #计算训练的文档数目 m = len(trainMat[0]) #计算每篇文档的词条数 pAb = sum(classVec)/n #文档属于侮辱类的概率 p0Num = np.zeros(m) #词条出现数初始化为0 p1Num = np.zeros(m) #词条出现数初始化为0 p0Denom = 0 #分母初始化为0 p1Denom = 0 #分母初始化为0 for i in range(n): #遍历每一个文档 if classVec[i] == 1: #统计属于侮辱类的条件概率所需的数据 p1Num += trainMat[i] p1Denom += sum(trainMat[i]) else: #统计属于非侮辱类的条件概率所需的数据 p0Num += trainMat[i] p0Denom += sum(trainMat[i]) p1V = p1Num/p1Denom p0V = p0Num/p0Denom return p0V,p1V,pAb #返回属于非侮辱类,侮辱类和文档属于侮辱类的概率p0V,p1V,pAb=trainNB(trainMat,classVec) 1234567891011121314151617181920212223from functools import reducedef classifyNB(vec2Classify, p0V, p1V, pAb): p1 = reduce(lambda x,y:x*y, vec2Classify * p1V) * pAb #对应元素相乘 p0 = reduce(lambda x,y:x*y, vec2Classify * p0V) * (1 - pAb) print('p0:',p0) print('p1:',p1) if p1 &gt; p0: return 1 else: return 0def testingNB(testVec): dataSet,classVec = loadDataSet() #创建实验样本 vocabList = createVocabList(dataSet) #创建词汇表 trainMat= get_trainMat(dataSet) #将实验样本向量化 p0V,p1V,pAb = trainNB(trainMat,classVec) #训练朴素贝叶斯分类器 thisone = setOfWords2Vec(vocabList, testVec) #测试样本向量化 if classifyNB(thisone,p0V,p1V,pAb): print(testVec,'属于侮辱类') #执行分类并打印分类结果 else: print(testVec,'属于非侮辱类') #执行分类并打印分类结果 testVec1 = ['love', 'my', 'dalmation']testingNB(testVec1) ¶BernoulliNB 伯努利分布，如果是二元伯努利分布 $$ P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il}) $$ 如果样本属性大多数属于连续，GaussionNB 如果是离散值，使用MultinomialNB 如果样本特征是二元离散值或者稀疏离散值，BernoulliNB 半朴素贝叶斯 ¶信息量、熵、联合熵、条件熵、互信息 ¶信息量 反应了随机变量取某个值含的可能性大小，或者是含有的信息多少 $$ I(X=x)=-log_2^{p(x）} $$ ¶熵(entropy) 反应了信源平均每个符号的信息量,或者是随机变量不确定性的衡量 $$ H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)}) $$ ¶联合熵 反应了多个随机变量的平均信息量 $$ H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)}) $$ ¶条件熵（Conditional entropy） 反应了已知一个随机变量下，另一个随机变量的不确定性 $$ H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)} $$ ¶互信息(mutual information) 反应了已知一个随机变量的情况下，另外一个随机变量不确定性减少了多少,可以把互信息看成由于知道 y 值而造成的 x 的不确定性的减小 $$ I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\ =H(X)-H(X|Y)=H(Y)-H(Y|X) $$ 如果两个随机变量独立，则互信息为0,因此，互信息可以衡量两个随机变量的相关程度 ¶条件互信息 在条件z发生时的条件互信息 $$ I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}} $$ ¶半朴素贝叶斯 适当的考虑一部分属性间的相互依赖关系，这个关系可以用互信息描述 ¶独依赖 假设每个属性只有一个其他 的属性.则计算公式改下如下 $$ p©\Pi_{i=1}^{d} P(x_i|C_i,pa_i) $$ $pa_i$是属性$x_i$所依赖的属性，被称为$x_i$的父属性 **SPODE **最简单的方法是：都选一个属性作为父属性 可以通过交叉验证的方法 TAN :最大带权生成树 权重：当y划分为$c_k$类时条件熵 $$ I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}} $$ step 1: 计算任意两个属性之间条件互信息 $$ I(X;Y|Y)=\sum_{i}I(X;Y|c_i) $$ step 2: 以属性为结点构建完全图 step 3: 最大带权生成树，挑选根变量 step 4: 加入类别结点y,增加到每个属性的有向边 条件互信息反应了属性在已知类别下的相关性大小 ¶集成学习 AODE选择模型尝试将每个属性作为超父构建SPODE $$ P(c_i|X)正比于 \sum_{i=1,|D_{x_i}&gt;=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i) $$ $m$通常取30, $$ P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\ P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j} $$ 贝叶斯网(Bayesian network) 借助有向无环图来刻画属性之间的依赖关系，条件概率表来描述属性的联合概率分布。 一个贝叶斯网络$B$,包括结构$G$和参数$\Theta$ ,$B(G,\Theta)$,如果两个属性有直接依赖关系，用边连接，对于属性$x_i$,其父节点集合$G_i$,则$\Theta$包括每个属性条件概率$\Theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$ ¶结构 $$ p(x_1,x_2,…,x_n)=\Pi_{i=1}{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}{d}\Theta_{xi|\pi_i}\ =\Pi_{i=1}^{d}P(x_i|Parents(x_i)) $$ ¶推断 一旦训练好贝叶斯网后，就能回答query,通过一些属性的观测者来推断其他属性变量的取值，其中，已知变量的值观测推测待查询的过程“推断&quot;,已知变量的观测者”证据“]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>贝叶斯分类器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二次规划]]></title>
    <url>%2F2019%2F03%2F25%2F%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[[TOC] KKT(Karush-Kuhn-Tucher)条件 给定优化问题 $$ \min f(x)\ subject\ to \begin{cases} g_i(x) = 0 (i=1,m\ h_i(x) &lt;= 0 (i=m+1,…,n) \end{cases} $$ 构造lagrange函数 $$ L(x,\lambda) = f(x)+\sum_{i=1}{m}\lambda_ig_i(x)+\sum_{i=m+1}{n}\lambda_ih_i(x) $$ KKT条件 $$ \frac{\partial L}{\partial x}=0\ g_i(x)=0\ \lambda_i&gt;=0 (i=m+1,…,n)\ \lambda_i h_i(x)=0(i=m+1,…,n) $$ 二次规划问题 问题的数学表达 $$ \min Q(x) = \frac{1}{2}xTHx+gTx\ s.t. a_i^Tx = b_i (i=1,…,m)\ \ \ \ \ \ \ \ a_i^Tx &lt;= b_i(i=m+1,…n) $$ KKT条件 $$ \bigtriangledown f(x)-A^T\lambda =0\ A_{E}x - b_{E}=0\ A_{L}x-b_L&lt;=0\ \lambda_L&gt;=0\ \lambda_L^T(A_LX_L-b_L)=0 $$ 如果$H$半正定，二次规划问题的全局极小值的充要条件，$x^{*}$是一个K-T条件 证明： 必要性：KKT 充分性： $$ f(x)-f(x{*})=\frac{1}{2}xTHx+gTx-\frac{1}{2}x{T}Hx{*}-gTx^{}\ =\frac{1}{2}(x-x{*})TH(x-x{*})+x{T}H(x-x{*})+gT(x-x^{})\ =x{*T}H(x-x{})+gT(x-x{})=\lambdaTA(x-x{*}) $$ http://www.hankcs.com/ml/lagrange-duality.html#h3-7 SMO ：Sequential minimal optimization 支持向量机的对偶问题 $$ \min \frac{1}{2}\sum_{i=1}{m}\sum_{j=1}{m}\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^{m}\alpha_i\ s.t. \sum_{i=1}^{m}\alpha_iy_i=0\ 0&lt;=\alpha_i&lt;=C $$ 这个优化问题，可以根据二次规划求解，但是如果样本 过多，特别慢 Platt提出了一种更快的方法 SMO算法是一种启发式算法，其基本思路是： 如果所有变量的解都满足此最优化问题的KKT条件（Karush-Kuhn-Tuckerconditions)，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。 否则，选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题。这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小。重要的是，这时子问题可以通过解析方法求解，这样就可以大大提高整个算法的计算速度。子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定。如此，SMO算法将原问题不断分解为子问题并对子问题求解，进而达到求解原问题的目的。 假设$\alpha_i,\alpha_j$为选择的两个优化变量，则优化问题 $$ \min W(\alpha_i,\alpha_j)=\frac{1}{2}\alpha_i\alpha_iy_iy_iK(x_i,x_i)+\frac{1}{2}\alpha_j\alpha_jy_jy_jK(x_j,x_j)+\alpha_i\alpha_jy_iy_jK(x_i,x_j)\ +\sum_{k_1,k_2!=i,j}^{m}\alpha_{k_1}\alpha_{k_2}y_{k_1}y_{k_2}K(x_{k_1},x_{k_2})-(\alpha_i+\alpha_j)\ s.t\ \ \ \alpha_iy_i+\alpha_jy_j=-\sum_{k!=i,j}^{m}\alpha_ky_k=\xi\ 0&lt;=\alpha_i&lt;=C $$ 上述问题就是关于]]></content>
      <categories>
        <category>机器学习</category>
        <category>数学</category>
      </categories>
      <tags>
        <tag>二次规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle]]></title>
    <url>%2F2019%2F03%2F24%2Fkaggle%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scikit-learn]]></title>
    <url>%2F2019%2F03%2F23%2Fscikit-learn%2F</url>
    <content type="text"><![CDATA[Cross-validation: evaluating estimator performance¶ 12345import numpy as npfrom sklearn.model_selection import train_test_split# 调用train_test_split函数 自动划分数据集 40%for testingX_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, test_size=0.4, random_state=0) ¶corss validation 1234567from sklearn.model_selection import cross_validatefrom sklearn.metrics import recall_scorescoring = [&apos;precision_macro&apos;, &apos;recall_macro&apos;]clf = svm.SVC(kernel=&apos;linear&apos;, C=1, random_state=0)scores = cross_validate(clf, iris.data, iris.target, scoring=scoring, cv=5, return_train_score=False)sorted(scores.keys()) ¶Cross validation of time series data Tuning the hyper-parameters of an estimator A search consists of: an estimator (regressor or classifier such as sklearn.svm.SVC()); a parameter space; a method for searching or sampling candidates; a cross-validation scheme; and a score function. ¶Grid Search 1234param_grid = [ &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;kernel&apos;: [&apos;linear&apos;]&#125;, &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;gamma&apos;: [0.001, 0.0001], &apos;kernel&apos;: [&apos;rbf&apos;]&#125;, ] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from __future__ import print_functionfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.model_selection import GridSearchCVfrom sklearn.metrics import classification_reportfrom sklearn.svm import SVCprint(__doc__)# Loading the Digits datasetdigits = datasets.load_digits()# To apply an classifier on this data, we need to flatten the image, to# turn the data in a (samples, feature) matrix:n_samples = len(digits.images)X = digits.images.reshape((n_samples, -1))y = digits.target# Split the dataset in two equal partsX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=0)# Set the parameters by cross-validationtuned_parameters = [&#123;'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]&#125;, &#123;'kernel': ['linear'], 'C': [1, 10, 100, 1000]&#125;]scores = ['precision', 'recall']for score in scores: print("# Tuning hyper-parameters for %s" % score) print() clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score) clf.fit(X_train, y_train) print("Best parameters set found on development set:") print() print(clf.best_params_) print() print("Grid scores on development set:") print() means = clf.cv_results_['mean_test_score'] stds = clf.cv_results_['std_test_score'] for mean, std, params in zip(means, stds, clf.cv_results_['params']): print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params)) print() print("Detailed classification report:") print() print("The model is trained on the full development set.") print("The scores are computed on the full evaluation set.") print() y_true, y_pred = y_test, clf.predict(X_test) print(classification_report(y_true, y_pred)) print()# Note the problem is too easy: the hyperparameter plateau is too flat and the# output model is the same for precision and recall with ties in quality. ¶Randomized Parameter Optimization 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566print(__doc__)import numpy as npfrom time import timefrom scipy.stats import randint as sp_randintfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.datasets import load_digitsfrom sklearn.ensemble import RandomForestClassifier# get some datadigits = load_digits()X, y = digits.data, digits.target# build a classifierclf = RandomForestClassifier(n_estimators=20)# Utility function to report best scoresdef report(results, n_top=3): for i in range(1, n_top + 1): candidates = np.flatnonzero(results['rank_test_score'] == i) for candidate in candidates: print("Model with rank: &#123;0&#125;".format(i)) print("Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)".format( results['mean_test_score'][candidate], results['std_test_score'][candidate])) print("Parameters: &#123;0&#125;".format(results['params'][candidate])) print("")# specify parameters and distributions to sample fromparam_dist = &#123;"max_depth": [3, None], "max_features": sp_randint(1, 11), "min_samples_split": sp_randint(2, 11), "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run randomized searchn_iter_search = 20random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, cv=5)start = time()random_search.fit(X, y)print("RandomizedSearchCV took %.2f seconds for %d candidates" " parameter settings." % ((time() - start), n_iter_search))report(random_search.cv_results_)# use a full grid over all parametersparam_grid = &#123;"max_depth": [3, None], "max_features": [1, 3, 10], "min_samples_split": [2, 3, 10], "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run grid searchgrid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)start = time()grid_search.fit(X, y)print("GridSearchCV took %.2f seconds for %d candidate parameter settings." % (time() - start, len(grid_search.cv_results_['params'])))report(grid_search.cv_results_) step1： 交叉验证（评价模型） step2: 超参数选择，每一组参数：对应一次交叉验证 step 3: 集成学习 也可进行参数的调解 12345678from sklearn.model_selection import cross_val_scorefrom sklearn.datasets import load_irisfrom sklearn.ensemble import AdaBoostClassifieriris = load_iris()clf = AdaBoostClassifier(n_estimators=100)scores = cross_val_score(clf, iris.data, iris.target, cv=5)scores.mean() 1234567891011121314151617181920212223from sklearn import datasetsfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCfrom itertools import productfrom sklearn.ensemble import VotingClassifier# Loading some example datairis = datasets.load_iris()X = iris.data[:, [0, 2]]y = iris.target# Training classifiersclf1 = DecisionTreeClassifier(max_depth=4)clf2 = KNeighborsClassifier(n_neighbors=7)clf3 = SVC(gamma=&apos;scale&apos;, kernel=&apos;rbf&apos;, probability=True)eclf = VotingClassifier(estimators=[(&apos;dt&apos;, clf1), (&apos;knn&apos;, clf2), (&apos;svc&apos;, clf3)], voting=&apos;soft&apos;, weights=[2, 1, 2])clf1 = clf1.fit(X, y)clf2 = clf2.fit(X, y)clf3 = clf3.fit(X, y)eclf = eclf.fit(X, y)]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boosting]]></title>
    <url>%2F2019%2F03%2F22%2FBoosting%2F</url>
    <content type="text"><![CDATA[[TOC] Boosting ¶原理 Boosting算法是将“弱学习算法“提升为“强学习算法”的过程。 加法模型 $$ F_n(x;P) = \sum_{t=1}^{n}\alpha_th_t(x;a_t) $$ 前向分步 $$ F_m(x) = F_{m-1}(x)+\alpha_mh_m(x,a_m) $$ 如果选取不同损失函数，则产生不同的类型 AdaBoost AdaBoost就是损失函数为指数损失的Boosting算法。 每一次迭代的弱学习$h(x;a_m)$有何不一样，如何学习？ AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。 弱分类器权值$β_m$如何确定？ AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。 ¶原理理解 基于Boosting的理解，对于AdaBoost，我们要搞清楚两点： 每一次迭代的弱学习h(x;am)有何不一样，如何学习？ 弱分类器权值βm如何确定？ 对于第一个问题，AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。然后，再根据所采用的一些基本机器学习算法进行学习，比如逻辑回归。 对于第二个问题，AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。 ¶公式推导 指数损失函数 $$ L(Y,f(x))=exp(-Yf(x)) $$ 权重更新公式: 采用的指数误差函数 $$ l_{exp}(a_th_t|D_t)=E(exp(-f(x)a_th_t(x)))\ =p(f(x)=h_t(x))e{-at}+p(f(x)!=h_t(x))e{at}\ =e{-at}(1-\xi)+e{at}\xi $$ $$ a_t=\frac{1}{2}ln \frac{1-\xi}{\xi} $$ 分布更新公式 $$ \begin{aligned} l\left(H_{t-1}(x)+\alpha h_{t}(x) | D\right) &amp;=E_{X \sim D}\left(\exp \left(-y(x)\left(H_{t-1}(x)+\alpha h_{t}(x)\right)\right)\right) \ &amp;=E_{x \sim D}\left(\exp \left(-y(x) H_{t-1}(x)\right) \exp \left(-y(x) \alpha h_{t}(x)\right)\right) \end{aligned} $$ 在泰勒展开$exp(-y(x)h_t(x))$ $$ \begin{aligned} l\left(H_{t-1}(x)+h_{t}(x) | D\right) &amp; \approx E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-\alpha y(x) h_{t}(x)+\frac{\alpha^{2} y^{2}(x) h_{t}^{2}(x)}{2}\right)\right] \ &amp;=E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-y(x) h_{t}(x)+0.5 \alpha^{2}\right)\right] \end{aligned} $$ $$ \begin{aligned} h(x) &amp;=\arg \min {h} l\left(H{t-1}(x)+\alpha h_{t} | D\right) \ &amp;=\arg \max {h} E{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right) \alpha y(x) h_{t}(x)\right] \ &amp;=\arg \max {h}\left[\frac{\exp \left(-y(x) H{t-1}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} y(x) h(x)\right] \end{aligned} $$ $$ $$ 令一个新分布,注意分子是常数 $$ D_{t}(x)=\frac{D(x) \exp \left(-y(x) H_{t-1}(x)\right)^{L}}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} $$ $$ \begin{aligned} h(x) &amp;=\arg \max {h} E{x \sim D,}(y(x) h(x)) \ &amp;=\arg \max {h} E{x \sim D_{t}}(1-2 \mathcal{I}(y(x) \neq h(x))) \ &amp;=\arg \min {h} E{x \sim D_{i}}(\mathcal{I}(y(x) \neq h(x))) \end{aligned} $$ 同理可得 $$ \begin{aligned} D_{t+1} &amp;=\frac{D(x) \exp \left(-y(x) H_{t}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \ &amp;=\frac{D_{t}(x) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right] \cdot \exp \left(-y(x) H_{t}(x)\right)}{\exp \left(-y(x) H_{t-1}(x)\right) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \ &amp;=D_{t}(x) \exp \left(-y(x) \alpha h_{t}(x)\right) \cdot C . \quad(C i s a \text {constant}) \end{aligned} $$ $$ Z_{t}=\sum_{i}^{m} D_{t}(x) \exp \left(-y(x) \alpha_{t} h_{y}(x)\right) $$ 指数误差函数 $$ \begin{aligned} l(H(x) | D) &amp;=\frac{1}{m} \sum_{i}^{m} \exp \left(-y_{i} H\left(x_{i}\right)\right) \ &amp;=\frac{1}{m} \sum_{i}^{m} \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \ &amp;=\sum_{i}^{m} D_{1}\left(x_{i}\right) \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \ &amp;=Z_{1} Z_{2}\left(x_{i}\right) \exp \left(-\sum_{j=2}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \ &amp; \vdots \ &amp;=\prod_{i=1}^{T} Z_{i} \end{aligned} $$ ¶算法描述 总结一下，得到AdaBoost的算法流程： 输入：训练数据集$T={(x1,y1),(x2,y2),(xN,yN)}T={(x1,y1),(x2,y2),(xN,yN)}$，其中，$xi∈X⊆Rnxi∈X⊆Rn，yi∈Y=−1,1yi∈Y=−1,1，$迭代次数M 初始化训练样本的权值分布：$D1=(w1,1,w1,2,…,w1,i),w,i=1,2,…,N$。 对于$m=1,2,…,M$ (a) 使用具有权值分布$D_m$的训练数据集进行学习，得到弱分类器$h_m(x)$ (b) 计算$h_m(x)$在训练数据集上的分类误差率： $e_m=∑_{i=1}^{N}w_m,iI(h_m(xi)≠y_i)$ © 计算$h_m(x)$在强分类器中所占的权重： $\alpha_m=\frac{1}{2}log(\frac{1−e_m}{e_m})$ (d) 更新训练数据集的权值分布（这里，$z_m是归一化因子，为了使样本的概率分布和为1）： $$w_{m+1,i}=\frac{w_{m,i}}exp(−α_my_ih_m(xi))，i=1,2,…,10$$ $$z_m=∑_{i=1}^{N}w_{m,i}exp(−α_my_ih_m(xi))$$ 得到最终分类器： $$F(x)=sign(∑_{i=1}^{N}α_mh_m(x))$$ ¶面经 今年8月开始找工作，参加大厂面试问到的相关问题有如下几点： 手推AdaBoost 与GBDT比较 AdaBoost几种基本机器学习算法哪个抗噪能力最强，哪个对重采样不敏感？ ¶算法流程 ¶实例计算 ¶Python实现 https://www.cnblogs.com/davidwang456/articles/8927029.html 集成学习]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Boosting, AdaBoost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持向量回归]]></title>
    <url>%2F2019%2F03%2F19%2FSVR%2F</url>
    <content type="text"><![CDATA[[TOC] 支持向量机用于分类:硬间隔和软件间隔支持向量机。尽可能分对 支持向量机回归： 希望$f(x)$与$y$尽可能的接近。 支持向量机基本思想 英文名:support vector regression 简记：SVR ¶标准的线性支持向量回归模型 学习的模型: $$f(x)=w^Tx+b$$ 假设能容忍$f(x)$与$y$之间差别绝对值$\xi$,这就以$f(x)=w^Tx+b$形成了一个$2\xi$的间隔带，因此模型 $$ \min \frac{1}{2}w^Tw\ s.t -\xi&lt;=f(x_i)-y_i&lt;=\xi $$ 但是上述条件太过严苛，因此增加惩罚项， $$ \min \frac{1}{2}w^Tw+C\sum(\epsilon_i+\hat{\epsilon}i)\ s.t. \begin{cases}f(x_i)-y_i&lt;=\xi+\epsilon_i\ y_i-f(x_i)&lt;=\xi+\hat{\epsilon}i\ \hat{\epsilon}i&gt;=0,\epsilon_i&gt;=0 \end{cases} $$ 构造Lagrange函数 $$ \begin{aligned} L :=\frac{1}{2}|\omega|^{2} &amp;+C \sum\left(\xi_i+\xi{\prime}_i\right)-\sum_{i=1}{N}\left(\eta{i} \xi{i}+\eta{i}^{’} \xi_{i}6{’}\right) \ &amp;+\sum \alpha_{i}\left(y_{i}-\omega^{T} x_{i}-b-\varepsilon-\xi_{i}\right) \ &amp;+\sum \alpha_{i}{’}\left(\omega{T} x_{i}+b-y_{i}-\varepsilon-\xi_{i}^{\prime}\right) \end{aligned}\tag{1} $$ 求偏导 $$ \frac{\partial L}{\partial \omega}=\omega-\sum\left(\alpha_{i}-\alpha_{i}\right) x_{i}=0 \Rightarrow \omega=\sum\left(\alpha_{i}-\alpha_{i}^{\prime}\right) x_{i}\tag{2} $$ $$ \frac{\partial L}{\partial b}=\sum_{i=1}{N}\left(\alpha_{i}-\alpha_{i}{\prime}\right)=0 \tag{3} $$ $$ \frac{\partial L}{\partial \xi_{i}{\prime}}=C-\alpha_{i}{’}-\eta_{i}^{\prime}=0 \tag{4} $$ $$ \frac{\partial L}{\partial \xi_{i}}=C-\alpha_{i}-\eta_{i}=0 \tag{5} $$ 将(2)-(4)带回(1),可得对偶问题 $$ \begin{aligned} \min L(\boldsymbol{\alpha})=&amp; \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}{N}\left(\alpha_{i}-\alpha_{i}{}\right)\left(\alpha_{j}-\alpha_{j}^{}\right)\left\langle x_{i}, x_{j}\right\rangle \ &amp;+\varepsilon \sum_{i=1}{N}\left(\alpha_{i}+\alpha_{i}{}\right)-\sum_{i=1}^{N} y_{i}\left(\alpha_{i}-\alpha_{i}^{}\right) \ \text { s.t. } &amp; \sum_{n=1}{N}\left(\alpha_{n}-\alpha_{n}{}\right)=0 \end{aligned} $$ 再将(2)带回$Y=w^Tx+b$,可得线性回归模型 $$ y(x)=\sum_{i=1}{N}\left(\alpha_{i}-\alpha_{i}{}\right) x_{i}^{T} x+b $$ ¶非线性支持向量机 考虑模型 $$ y=f(x)+b $$ $f(x)$是非线性函数，存在一个由$X$所在空间到希尔伯特空间的映射，使得 $$ f(x)=w^T\varphi(x) $$ 因此，建立如下的优化问题 $$ \min \frac{1}{2}|\omega|^{T}+C \sum_{i}\left(\xi_{i}+\xi_{i}^{\prime}\right)\ \begin{cases} y\left(x_{i}\right)-\omega^{T} \varphi\left(x_{i}\right)-b \leq \xi_{i} \ \omega^{T} \varphi\left(x_{i}\right)+b-y\left(x_{i}\right) &amp; \leq \xi_{i} \ \xi_{i} &amp; \geq 0 \ \xi_{i} &amp; \geq 0 \end{cases} $$ 构造lagrange函数 $$ \begin{aligned} L :=\frac{1}{2}|\omega|^{2} &amp;+C \sum\left(\xi+\xi^{\prime}\right)-\sum\left(\eta_{i} \xi_{i}+\eta_{i} \xi_{i}^{\prime}\right) \ &amp;+\sum \alpha_{i}\left(y_{i}-w^{T} \varphi\left(x_{i}\right)-b-\varepsilon_{i}-\xi_{i}\right) \ &amp;+\sum \alpha_{\mathrm{i}}{\prime}\left(w{T} \varphi\left(x_{i}\right)+b-y_{i}-\varepsilon_{i}{’}-\xi_{i}{\prime}\right) \end{aligned} $$ 求偏导 $$ \begin{cases}\frac{\partial L}{\partial w}=w-\sum\left(\alpha_{i}-\alpha_{i}\right) \varphi\left(x_{i}\right)=0\ \frac{\partial L}{\partial b} =\sum\left(\alpha_{i}-\alpha_{i}^{\prime}\right)=0 \ \frac{\partial L}{\partial \xi_{i}^{\prime}} =C-\alpha_{i}{’}-\eta_{i}{\prime}=0 \ \frac{\partial L}{\partial \xi_{i}} =C-\alpha_{i}-\eta_{i}=0 \end{cases} $$ 再带回优化问题可得 $$\min {t}-\frac{1}{2} \sum\left(\alpha{i}-\alpha_{i}{\prime}\right)\left(\alpha_{j}-\alpha_{j}{\prime}\right) \varphi\left(x_{i}\right)^{T} \varphi\left(x_{j}\right)-\varepsilon \sum\left(\alpha_{i}+\alpha_{i}^{\prime}\right)+\sum y_{i}\left(\alpha_{i}-\alpha_{i}^{’}\right)\s t . \sum\left(\alpha_{i}-\alpha_{i}^{\prime}\right)=0$$ 再次将$w$带回模型 $$ y=\sum\left(\alpha_{i}-\alpha_{i}^{’}\right) \varphi\left(x_{i}\right)^{T} \varphi(x)+b $$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>支持向量机回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持向量机(SVM) ----- 分类器]]></title>
    <url>%2F2019%2F03%2F17%2FSVMClassifiar%2F</url>
    <content type="text"><![CDATA[[TOC] 预备的数学知识 ¶约束优化问题 原问题,带等式约束，也带不等式约束的一般约束问题 $$ \begin{cases} \min_{x}f(x)\ s.t \begin{cases} m_i(x)&gt;=0, i=1,…,m\ n_j(x)=0，j=1,…,m\ \end{cases} \end{cases}\tag{1} $$ 构造lagrange乘子法 $$ L(x,\lambda_i,\eta_j)= f(x)-\sum_{i=1}{m}\lambda_im_i(x)-\sum_{j=1}{n}\eta_j \tag{2} $$ $$ \begin{cases} \min_{x} max_{\lambda_i,\eta_j} L(R^p)\ s.t \lambda_i&gt;=0 \end{cases} $$ 上述两个问题的等价性证明 如果x不满足约束$m_i(x)$,则$\lambda_i&gt;=0$,同时$m_i(x)&lt;$,则$L(R^{p},\lambda,\eta)$趋近无穷，反之，则存在最大值 $$ min_{x} max_{\lambda,\eta}=min_{x}(max f满足条件,max f不满足约束)\=min_{x} max_{\lambda,\eta}{f满足条件} $$ 对偶问题: 关于$\lambda,\eta$的最大化问题 $$max min L(x,\lambda,\eta)\ s.t \lambda_i&gt;=0$$ 弱对偶问题：对偶问题&lt;=原问题 证明: $max_{x} min(\lambda \eta ) L&lt;=min_{\eta,\lambda } max_{x} L$ $$ \underbrace{\min_{x}L(x,\lambda,\eta)}{A(\lambda,\eta)}&lt;=L(x,\lambda,\eta)&lt;=\underbrace{\max{\lambda,\eta} L(x,\lambda,\eta)}_{B(x)} $$ 分类 hard-margin SVM、 soft-margin SVM 、kernel SVM 线性可分支持向量机 对于A子图，可以用一个超平面($w^Tx+b$)去分类两类数据，建立如下的数学模型 $$ f(w,b)=sign(w^Tx+b)$$ B,C,D子图提供了超平面都可以分类，显然B,C图的超平面的鲁棒性不如D图。SVM就是找到最好的一个超平面，怎么衡量好呢？找到平面离样本点的距离最大 ¶hard-margin SVM： 最大间隔SVM ¶第一宝 间隔 首先，看下margin的定义 $$ margin(w,b) = min(\frac{|w^Tx_i+b|}{||w||})$$ 接下来 数学模型： $$\begin{cases} \max margin(w,b)\ st. y_i(w^Tx_i+b)&gt;0\end{cases}$$ $$\Longrightarrow\begin{cases} max \frac{1}{||w||}min(y_i(w^Tx_i+b))\ st. y_i(w^Tx_i+b)&gt;0\end{cases}$$ 注意，$y_i(w^Tx_i+b)&gt;0$,所以$\exists r&gt;0, min(y_i(wTx_i+b))=r$,可令$r=1$,这是对超平面范数的固定作用，因为$y=wTx+b$和$y=2w^T+2b$是同一个超平面，总能找到缩放$w,b$使得，可以将$r$缩放到1 $$\Longrightarrow\begin{cases} max \frac{1}{||w||}\ st. y_i(w^Tx_i+b)&gt;=1\end{cases}$$ $$\Longrightarrow\begin{cases} \min \frac{1}{2}w^Tw\ st. y_i(w^Tx_i+b)&gt;=1\end{cases}$$ 这是一个土二次规划问题 ¶第二宝 对偶 利用lagrange乘子法得出对偶问题 带约束 $$\begin{cases} \min \frac{1}{2}w^Tw\ st. y_i(w^Tx_i+b)-1&gt;=0\end{cases}$$ $$ \Longrightarrow L(w,b,\lambda）=\frac{1}{2}wTw-\sum_{i=1}{N}\lambda_i(1-y_i(w^Tx_i+b)$$ 无约束 $$ \begin{cases}min_{w,b} max_{\lambda}L(w,b,\lambda) \ s.t \lambda_i&gt;=0\end{cases}$$ 此时关于$w,b$无约束的。 对$(L(w,b,\lambda))$ 对$w$,$b$求偏导 $$ \frac{\partial L}{\partial w}=w+\sum_{i=1}^{N}y_ix_i\lambda_i=0 \Longrightarrow w=-\sum_{i=1}^{N}y_ix_i\lambda_i\ \frac{\partial L}{\partial b}=-\sum_{i=1}^{N}\lambda_iy_i=0 $$ 带回$L(w,b,\lambda)$,可得对偶问题 $$ \begin{cases} max_{\lambda}L(w,b,\lambda ) =-\frac{1}{2}\sum_iN\sum_jN\lambda_i \lambda_jy_iy_jx_i^Tx_j +\sum_i^N\lambda_i \ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i&gt;=0\end{cases} \Longrightarrow\\begin{cases} min_{\lambda}L(w,b,\lambda ) =\frac{1}{2}\sum_iN\sum_jN\lambda_i \lambda_jy_iy_jx_i^Tx_j -\sum_i^N\lambda_i \ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i&gt;=0\end{cases}$$ ¶原问题和对偶问题有相同解的充要条件 满足 KKT $$ \begin{cases} \frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0,\frac{\partial L}{\partial \lambda}=0\ \lambda_i(y_i(w^Tx_i+b)-1)=0\ \lambda_i&gt;=0\ y_i(w^Tx_i+b)-1&gt;=0 \end{cases} $$ 如果存在$(x_k,y_k)=+1or -1$使得$y_i(wTx_i+b)-1=0$即可求解$b=y_k-\sum_{i=0}{N}\lambda_ix_i^Tx_k$ 代入模型 $$ f(x)=sign(\sum_iNa_iy_ix_iTx+y_k-\sum_{i=0}{N}\lambda_ix_iTx_k)$$ 注意，对于任意的训练样本，总有$\lambda_i=0$或者$y_if(x_i)=1$,如果$\lambda_i&gt;0$,说明样本点落在最大间隔的边界上，这些点就是支持向量，这条边界$w^Tx+b=1or-1$ soft-marign 软间隔 想法：允许一部分样本可以不被正确分类 ¶优化目标 $$ \min_{w,b} \frac{1}{2}w^Tw+loss $$ ¶一些损失函数 0-1损失 个数 $$loss=\sum_{i=1}NI{y_i(wTx+b)&lt;1}$$ 数学性质不好，不连续 0-1损失 距离 hinge loss $$ loss = \begin{cases} 0 , y_i(w^Tx_i+b)&gt;=0,\ 1-y_i(w^tx_i+b), y_i(w^Tx_i+b)&lt;1\ \end{cases} $$ $$ loss_{max} = max(0,1-y_i(w^Tx_i+b)=1-z) $$ 此时优化问题，令$\xi_i=1-y_i(w^Tx_i+b)$ $$ \min \frac{1}{2}wTw+\sum_{i=1}{N}\xi_i\ s.t \begin{cases} y_i(w^Tx_i+b)&gt;=1-\xi_i\ \xi_i&gt;=0 \end{cases} $$ 指数损失（**exponential loss **) $$ l_{exp}(z)=exp(-z) $$ 对率损失logistic loss $$ l_{log}(z)=log(1+exp(-z)） $$ 核方法 ¶核函数的定义 设 $\chi$为输入空间（Input Space）， $\mathrm{H}$为特征空间(Feature Space,一定是希尔伯特空间），存在一个映射 $$ \varphi : \chi \rightarrow \mathrm{H} $$ 对任意的 $x, y \in \mathrm{X}$，函数 $K(x, y)$，满足 $$ K(x, y)=&lt;\varphi(x), \varphi(y)&gt; $$ 则称 $K(x, y)$为核函数。可以看出，我们并不需要知道输入空间和特征空间满足的映射关系 ，只需要知道核函数就可以算出，输入空间中任意两点映射到特征空间的内积。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归树]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%9B%9E%E5%BD%92%E6%A0%91%2F</url>
    <content type="text"><![CDATA[[TOC] 分类树与回归树 分类树用于分类问题。分类决策树在选取划分点，用信息熵、信息增益、或者信息增益率、或者基尼系数为标准。 Classification tree analysis is when the predicted outcome is the class to which the data belongs. 回归决策树用于处理输出为连续型的数据。回归决策树在选取划分点，就希望划分的两个分支的误差越小越好。 Regression tree analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient’s length of stay in a hospital)。 回归树 英文名字：Regression Tree ¶原理介绍 决策树最直观的理解其实就是，输入特征空间($R^n$)，然后对特征空间做划分，每一个划分属于同一类或者对于一个输出的预测值。那么这个算法需要解决的问题是1. 如何决策边界(划分点)？2. 尽可能少的比较次数(决策树的形状) 如上图，每一个非叶子对于某个特征的划分。 ¶最小二乘回归树生成算法 Q1: 选择划分点？遍历所有的特征($n$),对于每一个特征对应$s_i$个取值，尝试完所有特征，以及特征所以有划分，选择使得损失函数最小的那组特征以及特征的划分取值。 Q2: 叶节点的输出？取每个区域所以结果的平均数作为输出 节点的损失函数的形式 $$ \min _{j, s}\left[\min {c{1}} Loss(y_i,c_1)+\min {c{2}} Loss(y_i,c_2)\right] $$ 节点有两条分支，$c1$是左节点的平均值，$c2$是右节点的平均值，换句话说，分一次划分都是使得划分出的两个分支的误差和最小。最终得到函数是分段函数 ¶CART算法 输入： 训练数据集 输出：回归树$f(x)$ 选择最优的特征$j$和分切点$s$ $$ \min {j, s}\left[\min {c{1}} \sum{x_{i} \in R_{1}(j, s)}\left(y_{i}-c_{1}\right)^{2}+\min {c{2}} \sum_{x_{i} \in R_{2}(j, s)}\left(y_{i}-c_{2}\right)^{2}\right] $$ 对于选定的$(j,s)$划分区域，并确定该区域的预测值 对两个区域递归1. 2. 直到满足停止条件 返回生成树 注：分切点选择：先排序，二分。 Python代码 ¶节点类 属性：左右节点、loss、特征编号或者特征、分割点 12345678class Node(object): def __init__(self, score=None): # 构造函数 self.score = score self.left = None self.right = None self.feature = None self.split = None ¶回归树类 构造方法 1234class RegressionTree(object): def __init__(self): self.root = Node() self.height = 0 给定特征、划分点，返回计算MAPE 12345678910111213141516def _get_split_mse(self, X, y, idx, feature, split): ''' X:训练样本输入 y:训练样本输出 idx:该分支对应的样本编号 feaure: 特征 split: 划分点 ''' split_x1=X[X[idex,feature]&lt;split] split_y1=y[X[idex,feature]&lt;split] split_x2=X[X[idex,feature]&gt;=split] split_y2=y[X[idex,feature]&gt;=split] split_avg = [np.mean(split_y1), np.mean(split_y2)] split_mape = [np.sum((split_y1-split_avg[0])**2),np.sum((split_y2-split_avg[1])**2)] return split_mse, split, split_avg 计算给定特征的最佳分割点 遍历特征某一列的所有的不重复的点，找出MAPE最小的点作为最佳分割点。如果特征中没有不重复的元素则返回None。 12345678910def _choose_split_point(self, X, y, idx, feature): feature_x = X[idx,feature] uniques = np.unique(feature_x) if len(uniques)==1: return Noe mape, split, split_avg = min( (self._get_split_mse(X, y, idx, feature, split) for split in unique[1:]), key=lambda x: x[0]) return mape, feature, split, split_avg 选择特征 遍历全部特征，计算mape,然后确定特征和对应的切割点，注意如果某个特征的值是一样的，则返回None 12345678910111213141516171819def _choose_feature(self, X, y, idx): m = len(X[0]) split_rets = [x for x in map(lambda x: self._choose_split_point( X, y, idx, x), range(m)) if x is not None] if split_rets == []: return None _, feature, split, split_avg = min( split_rets, key=lambda x: x[0]) idx_split = [[], []] while idx: i = idx.pop() xi = X[i][feature] if xi &lt; split: idx_split[0].append(i) else: idx_split[1].append(i) return feature, split, split_avg, idx_split 对应叶子节点，打印相关的信息 1234def _expr2literal(self, expr): feature, op, split = expr op = "&gt;=" if op == 1 else "&lt;" return "Feature%d %s %.4f" % (feature, op, split) 建立好二叉树以后，遍历操作 12345678910111213141516171819def _get_rules(self): que = [[self.root, []]] self.rules = [] while que: nd, exprs = que.pop(0) if not(nd.left or nd.right): literals = list(map(self._expr2literal, exprs)) self.rules.append([literals, nd.score]) if nd.left: rule_left = [] rule_left.append([nd.feature, -1, nd.split]) que.append([nd.left, rule_left]) if nd.right: rule_right =[] rule_right.append([nd.feature, 1, nd.split]) que.append([nd.right, rule_right]) 建立二叉树的过程，也就是训练的过程 控制深度 控制节叶子节点的最少样本数量 至少有一个特征是不重复的 12345678910111213141516171819202122232425def fit(self, X, y, max_depth=5, min_samples_split=2): self.root = Node() que = [[0, self.root, list(range(len(y)))]] while que: depth, nd, idx = que.pop(0) if depth == max_depth: break if len(idx) &lt; min_samples_split or set(map(lambda i: y[i,0], idx)) == 1: continue feature_rets = self._choose_feature(X, y, idx) if feature_rets is None: continue nd.feature, nd.split, split_avg, idx_split = feature_rets nd.left = Node(split_avg[0]) nd.right = Node(split_avg[1]) que.append([depth+1, nd.left, idx_split[0]]) que.append([depth+1, nd.right, idx_split[1]]) self.height = depth self._get_rules() 打印叶子节点 12345def print_rules(self): for i, rule in enumerate(self.rules): literals, score = rule print("Rule %d: " % i, ' | '.join( literals) + ' =&gt; split_hat %.4f' % score) 预测单样本 123456789101112def _predict(self, row): nd = self.root while nd.left and nd.right: if row[nd.feature] &lt; nd.split: nd = nd.left else: nd = nd.right return nd.score # 预测多条样本def predict(self, X): return [self._predict(Xi) for Xi in X] 1234567891011121314 def main(): print("Tesing the accuracy of RegressionTree...") X_train=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]) y_train=np.array([[5.56 ],[5.7],[5.91],[6.4 ],[6.8],[7.05],[8.9],[8.7 ],[9 ],[9.05]]) reg = RegressionTree() print(reg) reg.fit(X=X_train, y=y_train, max_depth=3) reg.print_rules()main() 简单的例子 训练数据 x 1 2 3 4 5 6 7 8 9 10 y 5.56 5.7 5.91 6.4 6.8 7.05 8.9 8.7 9 9.05 根据上表，只有一个特征$x$. 选择最优的特征$j$和分切点$s$ 分切点(s) 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 $c_1$ 5.56 5.63 5.72 5.89 6.07 6.24 6.62 6.88 7.11 $c_2$ 7.5 7.73 7.99 8.25 8.54 8.91 8.92 9.03 9.05 loss 15.72 12.07 8.36 5.78 3.91 1.93 8.01 11.73 15.74 当分切点取$s=6.5$,损失最小$l(s=6.5)=1.93$,此时划分出两个分支，分别是$R_1={1,2,3,4,5,6}$,$c_1=6.42$,$R_2={7,8,9,10}$,$c_2=8.91$ a) 对R1继续划分 x 1 2 3 4 5 6 y 5.56 5.7 5.91 6.4 6.8 7.05 分切点(s) 1.5 2.5 3.5 4.5 5.5 $c_1$ 5.56 5.63 5.72 5.89 6.07 $c_2$ 6.37 6.54 6.75 6.93 7.05 loss 1.3087 0.754 0.2771 0.4368 1.0644 当分切点取$s=3.5$,损失函数$l(s=3.6)=0.2771$(假设此时满足停止条件）,此时得到两个分支，分别是$R_1={1,2,3}$，$c_1=5.72$,$R_2={4,5,6}$,$c_2=6.75$ b) 对R2继续划分 x 7 8 9 10 y 8.9 8.7 9 9.05 分切点(s) 7.5 8.5 9.5 $c_1$ 8.9 8.8 8.87 $c_2$ 8.92 9.03 9.05 loss 0.0717 0.0213 0.0467 当分切点取$s=8.5$,损失函数$l(s=8,5)=0.0213$(假设此时满足停止条件）,此时得到两个分支，分别是$R_1={7,8}$，$c_1=8.8$,$R_2={9,10}$,$c_2=9.03$ 函数表达式 $$ \begin{equation} f(x)=\left\{ \begin{aligned} 5.72 &amp; &amp; x&lt;3.5\\ 6.7 5&amp; &amp;3.5&lt;=x&lt;6.5\\ 8.8&amp; &amp;6.5&lt;=x&lt;8.5\\ 9.03&amp; &amp;8.5&lt;=x&lt;10\\ \end{aligned} \right. \end{equation} $$ Python库 1class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False) 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-"""Created on Wed Mar 13 19:59:53 2019@author: 23230"""import numpy as npfrom sklearn.tree import DecisionTreeRegressorimport matplotlib.pyplot as pltX=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])y=np.array([[5.56 ],[5.7],[5.91],[6.4],[6.8],[7.05],[8.9],[8.7],[9 ],[9.05]])# Fit regression modelregr_1 = DecisionTreeRegressor(max_depth=2)regr_2 = DecisionTreeRegressor(max_depth=3)regr_3 = DecisionTreeRegressor(max_depth=4)regr_1.fit(X, y)regr_2.fit(X, y)regr_3.fit(X, y)X_test = np.copy(X)y_1 = regr_1.predict(X_test)y_2 = regr_2.predict(X_test)y_3 = regr_3.predict(X_test) # Plot the resultsplt.figure()plt.scatter(X, y, s=20, edgecolor="black",c="darkorange", label="data")plt.plot(X_test, y_1, color="cornflowerblue",label="max_depth=2", linewidth=2)plt.plot(X_test, y_2, color="yellowgreen", label="max_depth=4", linewidth=2)plt.plot(X_test, y_3, color="r", label="max_depth=8", linewidth=2)plt.xlabel("data")plt.ylabel("target")plt.title("Decision Tree Regression")plt.legend()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP算法]]></title>
    <url>%2F2019%2F03%2F05%2FBP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[TOC] 1. 需要的微积分知识 ¶1.1 导数 对于一元函数，在导数存在的情况下，在某一点的导数，也就是该点的斜率。 对于多元函数，对于某一点求导，则需要指明方向，两个特殊的方向，1. 偏导：在坐标轴方向的导数 2. 梯度的方向:总有一个方向是变化最快的。 ¶1.2 求导的链式法则 $x \in R$, $z=g(f(x))$, $y=f(x)$ $$ \frac{\partial z}{\partial x}=\frac{\partial z}{\partial y} \frac{\partial y}{\partial x}$$ $ x \in R^m $, $f(x)$是$RM$到$Rn$的映射，$g(f)$是$R^n$到R的映射 $$ \frac{\partial g}{\partial x_i}=\sum_j^n \frac{\partial g}{\partial f_i} \frac{\partial f_i}{\partial x_i}$$ 如果使用向量表示 $$ \nabla_x^z=(\frac{\partial f}{\partial x})^T \nabla_y^z$$ 2. 梯度下降法 ¶2.1 梯度 梯度其实本质也是一个向量，对于函数$f(X,y)$ 在$(W,y)$这一点的梯度 $(\frac{\partial f}{\partial X},\frac{\partial f}{\partial y})$ 梯度的几何意义：在该店变化增加最快的地方 ¶2.2 梯度算法的解释 图来自吴恩达的机器学习课程 颜色偏红(A)的地方开始，根据梯度的负方向通过9次更新，达到了最小值(B)。 现在给定一个点$A(\theta_0,\theta_1)$,干嘛呢，我们想从A到B点（最小值点),类似人类下山，需要知道往那个方向吧、走大多一步呢？ 方向：梯度的负方向 $ \delta=(\frac{\partial L}{\partial \theta_0},\frac{\partial L}{\partial \theta_1})$) 步长：学习率（$\alpha$) 因此，计算一次里目标更近了 $(\theta_0,\theta_1)=(\theta_0,\theta_1)-\alpha \dot (\delta)$ 在重复上两步，直到满意为止。 3.误差反向传播算法 ¶3.1 理论推导 ¶3.1.1 符号说明 上图是一个L层的神经网络，输入层为第一层，隐藏层：2至$L-1$层，输出层L 令 输入向量 $\vec{X}$ $$ \vec{X} = (x_1,x_2,…,x_{m-1},x_m)$$ 输出向量 $\vec{Y}$ $$ \vec{Y}=(y_1,y_2,…,y_{n-1},y_n)$$a 第j层隐藏层的输出向量 $\vec{h^{(j)}}$ $$\vec{h{(j)}}=(h_1{(j)},h_2&lt;!–￼0–&gt;,…,h_{t-1}{(j)},h_tj^{(j)})$$ 其中，$tj$:表示第j的隐藏层个数 第$(l-1)$层的第i个神经元到第$l$层的第j个神经元的连接权重：$w_{ij}^{(l)}$，则第$(l-1)$层神经元到第$l$层神经元的连接权重矩阵 $$W^{(l)}=\left( \begin{matrix}w_{11}^{(l)}&amp; \cdots &amp; w_{1(tj)}\ &amp; \dots &amp;\ w_{s(l-1)}{l}&amp;\cdots&amp;w_{s(l-1)s(l)}{l} \end{matrix}\right)$$ ¶3.1.2 推导过程 ¶3.1.2.1 误差 定义的误差函数,常见的衡量性指标见 戳我,这里选择的误差平方和最小 第$i$个输出的误差,假设实际输出$(d(1),d(2),…,d(n))$：,一个输入样本对应的误差 $$E(i)=\frac{1}{2}\sum_{k=1}n(y(i)-d(i))2=\frac{1}{2}||y-d||^2$$ 所有训练样本($N$)的误差： $$E(i)=\frac{1}{2}\sum_{j=1}{N}(\sum_{k=1}n(y(i)-d(i))2)=\frac{1}{2N}\sum_{j=1}{N}(||y(i)-d(i)||^2)$$ 因此， $$ E = \frac{1}{2N}\sum_{i=1}N(||y(i)-d(i)||2)$$ 其实，神经网络的输出是关于节点的复合函数。代价函数是关于$W$和$b$的函数。 ¶3.1.2.2 正向传播 输入层$\hat{X}$： $$ X =(x_1,x_2,x_3,…,x_m)$$ 当有$N$个训练样本时，可用矩阵表示 $$ X=\left( \begin{matrix} x_{11} &amp;x_{12}&amp;…&amp;x_{1m}\ x_{21} &amp; x_{22}&amp;…&amp;x_{2m}\ \vdots &amp; \vdots&amp;\dots&amp;\vdots\ x_{N1} &amp; \vdots&amp;\vdots&amp;x_{Nm}\ \end{matrix} \right)$$ 第二层 $h^{(2)}$,一共$s2$个节点: 第i个节点的计算 $$h{(2)}(i)=f(\sum_{j=1}{s2}x(j)w_{ji}^{(l)}+b_i)=f(xw(:,i)+b_i)$$ 矩阵表示 $$ h{(2)}=f(x*W{(l)}+b^{(2)})$$ 第i层 矩阵形式 $$ h{(l)}=f(h{(l-1)}*W^{(l)}+b)$$ ¶3.1.2.3 反向传播 梯度下降法更新权重，不断迭代到最优解。 对$w_{ij}$求导数可得,可更新$w_{ij}$更新公式： $$ w_{ij}=w_{ij}-\alpha \frac{\partial E}{\partial w_{ij}}$$ 当然简单的情况下，可直接写出公式，当太复杂的时候，引入BP简化求导 方便书写公式，对于第i的输入$h{(i-1)}*W{(i)}+b{(i)}$记作$net{(i)}$,其中，第$i$的输入和输出的关系，$输入=f(输出)$ 下面开始推导 首先，对于$L$层， 对于$W{(L)}$，先看对$W_{ij}{(L)}$求导， $$ \frac{\partial E}{\partial W_{ij}^{(L)}} =\frac{\partial E}{\partial y(j)} * \frac{\partial y(i)}{\partial net_{j}^{L}} * \frac{\partial net_{j}^{L}}{\partial W_{ij}^{(L)}}\ =(y(j)-d(j))*f(x){’}|_{x=net_j{(L)}}h_i^{(L-1)}$$ 令$\delta_i^{(L)}=y(i)-d(i)$ 上述给出了单个分量的求偏导的结果，对于$W^{(L)}$ $$ \frac{\partial E}{\partial W^{(L)}} =\left[\begin{matrix} \frac{\partial E}{\partial W_{11}^{(L)}} &amp; \frac{\partial E}{\partial W_{12}^{(L)}}&amp;\dots &amp; \frac{\partial E}{\partial W_{1n}^{(L)}}\ \frac{\partial E}{\partial W_{21}^{(L)}} &amp; \frac{\partial E}{\partial W_{22}^{(L)}}&amp;\dots&amp; \frac{\partial E}{\partial W_{2n}^{(L)}}\ \vdots&amp; \dots&amp; \dots&amp; \dots\ \frac{\partial E}{\partial W_{sL,1}^{(L)}} &amp; \frac{\partial E}{\partial W_{sL,2}^{(L)}}&amp;\dots&amp; \frac{\partial E}{\partial W_{sL,n}^{(L)}} \end{matrix}\right] \= \left[ \begin{matrix} h{(L-1)}_1\h{(L-1)}2\ \dots\h^{(L-1)}n \end{matrix} \right] *\left[\begin{matrix} \delta_1{(L)}f(x){’}|{x=net_1^{(L)}}\ \delta_2{(L)}f(x){’}|{x=net_2^{(L)}}\ \dots\ \delta_n{(L)}f(x){’}|_{x=net_n^{(L)}} \end{matrix}\right] ^T =h{(L-1)}S{(L)} $$ 其中， $$ S^{(L)}=\left[\begin{matrix} \delta_1{(L)}f(x){’}|{x=net_1^{(L)}}\ \delta_2{(L)}f(x){’}|{x=net_2^{(L)}}\ \dots\ \delta_n{(L)}f(x){’}|{x=net_n^{(L)}} \end{matrix}\right]^T $$ 同理可得， $$ \frac{\partial E}{\partial b_k{(L)}}=(y(j)-d(j))*f(x){’}|{x=net_j^{(L)}} $$ 其次，对于隐含层$L-1$层，对$W_{ij}^{(L)}$求导 $$ \frac{\partial E}{\partial W_{ij}^{(L-1)}} =\sum_{k=1}^{n}\frac{\partial E}{\partial y(k)} * \frac{\partial y(k)}{\partial net_{k}^{L}} * \frac{\partial net_{k}^{L}}{\partial f(net_j^{(L-1)})}\frac{\partial f(net_j^{(L-1)})}{\partial net_j^{(L-1)}}\frac{\partial net_j^{(L-1)}}{\partial W_{ij}^{(L-1)}}\ =\sum_{k=1}^{n} (y(j)-d(j))*f(x){’}|_{x=net_j{(L)}}W_{kj}{(L)}f(x){’}|{x=net_j{L-1}}h_i{L-2}\ =\sum{k=1}{n}S_i{(L)}W_{kj}{(L)}f(x){’}|_{x=net_j{L-1}}h_i{L-2}\ $$ 写出矩阵形式,对$W^{(L-1)}$ $$ \frac{\partial E}{\partial W^{(L-1)}}=\left[\begin{matrix} h{(L-2)}_1\h{(L-2)}2\\vdots\h^{(L-2)}{s(L-2)}\end{matrix}\right] \left[\begin{matrix} \delta_1{(L)}f(x){’}|{x=net_1^{(L)}}\ \delta_2{(L)}f(x){’}|{x=net_2^{(L)}}\ \dots\ \delta_n{(L)}f(x){’}|{x=net_n^{(L)}} \end{matrix}\right]^T \left[\begin{matrix} W{11}^{(L)} &amp; W_{12}^{(L)}&amp;\dots &amp; W_{1n}^{(L)}\ W_{21}^{(L)} &amp; W_{22}^{(L)}&amp;\dots&amp; W_{2n}^{(L)}\ \vdots&amp; \dots&amp; \dots&amp; \dots\ W_{s(L-1),1}^{(L)} &amp; W_{s(L-1),2}^{(L)}&amp;\dots&amp; W_{s(L-1),n}^{(L)} \end{matrix}\right]^T \ \left[ \begin{array}{ccc}{f{’(L-1)}\left(net{(L-1)}{(1)}\right)} &amp; {0} &amp; {0}&amp;{0} \ {0} &amp; {f{’(L-1)}\left(net{(L-1)}{(2)}\right)} &amp; {0} &amp;{0}\ 0 &amp; \dots &amp; \vdots &amp; 0\{0} &amp; {0} &amp; {0}&amp;{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\ =h{(L-2)}S{(L-1)} $$ $$ S^{(L-1)}=\left(\left[\begin{matrix} f(x){’(L)}|_{x=net_1{(L)}}&amp;0&amp; \dots&amp; 0\ 0&amp;f(x){’}|_{x=net_2{(L)}}0&amp; \dots&amp; 0\ 0&amp;\dots&amp;\dots&amp;0\ 0&amp;0&amp;0&amp;f(x){’(L)}|_{x=net_n{(L)}} \end{matrix}\right]\left[\begin{matrix} \delta_1{(L)}\\delta_2{(L)}\\vdots\\delta_n^{(L)}\end{matrix}\right] \right)^T\ \left[\begin{matrix} W_{11}^{(L)} &amp; W_{12}^{(L)}&amp;\dots &amp; W_{1n}^{(L)}\ W_{21}^{(L)} &amp; W_{22}^{(L)}&amp;\dots&amp; W_{2n}^{(L)}\ \vdots&amp; \dots&amp; \dots&amp; \dots\ W_{s(L-1),1}^{(L)} &amp; W_{s(L-1),2}^{(L)}&amp;\dots&amp; W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T \left[ \begin{array}{ccc}{f{’(L-1)}\left(net{(L-1)}{(1)}\right)} &amp; {0} &amp; {0}&amp;{0} \ {0} &amp; {f{’(L-1)}\left(net{(L-1)}{(2)}\right)} &amp; {0} &amp;{0}\ 0 &amp; \dots &amp; \vdots &amp; 0\{0} &amp; {0} &amp; {0}&amp;{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\ =S^{(L)}\left[\begin{matrix} W_{11}^{(L)} &amp; W_{12}^{(L)}&amp;\dots &amp; W_{1n}^{(L)}\ W_{21}^{(L)} &amp; W_{22}^{(L)}&amp;\dots&amp; W_{2n}^{(L)}\ \vdots&amp; \dots&amp; \dots&amp; \dots\ W_{s(L-1),1}^{(L)} &amp; W_{s(L-1),2}^{(L)}&amp;\dots&amp; W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T\left[ \begin{array}{ccc}{f{’(L-1)}\left(net{(L-1)}{(1)}\right)} &amp; {0} &amp; {0}&amp;{0} \ {0} &amp; {f{’(L-1)}\left(net{(L-1)}{(2)}\right)} &amp; {0} &amp;{0}\ 0 &amp; \dots &amp; \vdots &amp; 0\{0} &amp; {0} &amp; {0}&amp;{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]*\ $$ 对$1&lt;l&lt;L$,求$W^{(l)}$的偏导, 最后，根据上述的推导喔，很容易得出$S{(l)}$和$S{(l+1)}$, $$ S{(l)}=S{(l+1)}W{(l+1)T}F{’(l)}(net{(l)})\ S{(L)}=(Y-\hat{Y})F{’(L)}(net^{(L)}) $$ $$ \frac{\partial E}{\part W{(l)}}=\left[\begin{matrix}h{(l-1)}1\h^{(l-1)}2 \\dots \h{(l-1)}_{sl}\end{matrix}\right]S{(l+1)} \left[\begin{matrix}W{11}{(l+1)}&amp;W_{12}{(l+1)} &amp;\dots&amp; W{2(sl+1)}^{(l+1)}\ W_{21}{(l+1)}&amp;W_{22}{(l+1)} &amp;\dots&amp; W_{2(sl+1)}^{(l+1)}\ \dots&amp;\dots&amp;\dots&amp;\dots\ W_{sl1}{(l+1)}&amp;W_{sl2}{(l+1)} &amp;\dots&amp; W_{sl(sl+1)}^{(l+1)}\ \end{matrix} \right]^T\left[\begin{matrix} \part f{’(l)}(net_1{l})&amp;0&amp;\dots &amp; 0\ 0\0 &amp;\part f{’(l)}(net_2{l})&amp;\dots&amp;0\ 0 &amp; 0&amp;\dots&amp;0\ 0&amp;0&amp;\dots&amp;\part f{’(l)}(net_l{l})\end{matrix}\right] $$ ¶3.2 BP算法的小结 算法分为两个阶段：前向阶段和后向传播阶段 后向阶段算法： Step 1: 计算$\hat{y}^{(L)}$ Step 2: for l =L:2 ​ 计算$S{(l)}=S{(l+1)}W{(l+1)}F’(net{(l)})$ ​ 计算 $\Delta W{(l)}=h{(l-1)}S^{(l)} $ ​ 计算$W{(l)}=W{(l)}-\delta \Delta W^{(l)}$ ¶3.3 Python实现 ¶3.3.1 最简单三层网络 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071'''不用任何框架，自己写一个三层的神经网络# input-3,hidden-4 output-1'''import numpy as npnp.random.seed(1)# Input MatrixX = np.array([[0, 0, 1], [0, 1, 1], [1, 0 ,1], [1, 1, 1],])# Output Matrixy = np.array([[0], [1], [1], [0]])# Nonlinear functiondef sigmoid(X,derive=False): if not derive: return 1 / (1 + np.exp(-X)) else: return X*(1-X)# reludef relu(X,derive = False): if not derive: return np.maximum(0,X) else: return (X&gt;0).astype(float) # Weight biasW1 = 2 * np.random.random((3, 4))-1b1 = 0.1 * np.ones((4,)) W2 = 2 * np.random.random((4,1))-1b2 = 0.1 * np.ones((1,)) rate = 0.1noline = relu# Trainingtrain_times = 200 for time in range(train_times): # Layer one A1 = np.dot(X,W1)+b1 Z1 = noline(A1) # Layer two A2 = np.dot(Z1, W2)+b2 Z2 = noline(A2) cost = -y+Z2 # Calc deltas S2= cost*noline(A2,True) delta_W2 = np.dot(Z1.T,S2) bias2 = S2.sum(axis=0) S1 = np.dot(S2, W2.T)*noline(A1,True) delta_W1= np.dot(X.T, S1) bias1 = S1.sum(axis=0) # update W1 = W1-rate*delta_W1 b1 = b1-rate*bias1 W2 = W2-rate*delta_W2 b2 = b2-rate*bias2 print('error',np.mean(((y-Z2)*(y-Z2))**2))print("prediction",Z2) ¶3.4 附录： Name Abbreviation Mean absolute percentage error MAPE Root mean squares percentage error RMSPE Mean absolute percentage error MAE Mean squares error MSE Index of agreement IA Theil U statistic 1 U1 Theil U statistic 2 U2 Correlation coefficient R MAPE = $\frac{1}{n} \sum_{k=1}{n}\left|\frac{x{(0)}(k)-\hat{x}{(0)}(k)}{x{(0)}(k)}\right| \times 100$ RMSPE = $\sqrt{\frac{1}{n} \sum_{k=1}{n}\left(\frac{\hat{x}{(0)}(k)-x{(0)}(k)}{x{(0)}(k)}\right)^{2}} \times 100$ MAE = $\frac{1}{n} \sum_{k=1}{n}\left|\hat{x}{(0)}(k)-x^{(0)}(k)\right|$ MSE = $\frac{1}{n} \sum_{k=1}{n}\left(\hat{x}{(0)}(k)-x{(0)}(k)\right){2}$ IA = $1-\frac{\sum_{k=1}{n}\left(\hat{x}{(0)}(k)-x{(0)}(k)\right){2}}{\sum_{k=1}^{n} \left( \left| \hat{x}^{(0)}(k)-\overline{x} \right|+\left| x^{(0)}(k)-\overline{x}\right| \right)^{2}}$ U1 = $\frac{\sqrt{\frac{1}{n} \sum_{k=1}{n}\left(x{(0)}(k)-x{(0)}(k)\right){2}}}{\sqrt{\frac{1}{n} \sum_{k=1}^{n} x{(0)}(k){2}}+\sqrt{\frac{1}{n} \sum_{k=1}^{n} x{(0)}(k){2}}}$ U2 = $\frac{\left[\sum_{k=1}{n}\left(\hat{x}{(0)}(k)-x{(0)}(k)\right){2}\right]^{1 / 2}}{\left[\sum_{k=1}^{n} x{(0)}(k){2}\right]^{1 / 2}}$ R = $\frac{\operatorname{Cov}(\hat{x}^{(0)}, x{(0)})}{\sqrt{\operatorname{Var}[\hat{x}{(0)}] \operatorname{Var}[x^{(0)}]}}$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>BP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希腊字母]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D%2F</url>
    <content type="text"><![CDATA[$\alpha$ $\beta$ $\gamma$ $\Gamma$ $\delta$ $\Delta$ $\epsilon$ $\varepsilon$ $\zeta$ $\eta$ $\theta$ $\Theta$ $\vartheta$ $\iota$ $\kappa$ $\lambda$ $\Lambda$ $\mu$ $\nu$ $\xi$ $\Xi$ $\pi$ $\Pi$ $\varpi$ $\rho$ $\varrho$ $\sigma$ $\Sigma$ $\varsigma$ $\tau$ $\upsilon$ $\Upsilon$ $\phi$ $\Phi$ $\varphi$ $\chi$ $\psi$ $\Psi$ $\Omega$ $\omega$ alpha beta gamma delta epsilon theta]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>希腊字母</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%90%B4%E6%81%A9%E8%BE%BE%2F</url>
    <content type="text"><![CDATA[Neural Networks and Deep Learning 4 周]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2019%2F03%2F03%2F%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[主要是分享决策的基本知识点，重点在分类决策树上，对于回归的决策树后面在给出。希望大家和我一起做知识的传播者啦！😄 😃 😁 😮 [TOC] 决策树 英文名字：Descision Tree ¶什么是决策树 举个校园相亲的例子，今天校园的小猫(女)和小狗(男)准备配对，小猫如何才能在众多的优质🐶的心仪的狗呢？于是呢？有一只特乖巧的小猫找到了你，你正在学习机器学习，刚好学习了决策树，准备给这只猫猫挑选优质狗，当然，你不仅仅是直接告诉猫哪些狗是合适你的？你更应该详细的给猫讲解决策树是如何根据它提出的标准选出的符合要求的狗呢？ 猫给出如下信息： 年龄&lt;0.5 不心仪；年龄大于&gt;=0.5 6.5&lt;=体重&lt;=8.5;心仪; 年龄&gt;=0.5 体重&gt;8.5 长相好 心仪;其余情况不心仪; 根据上述条件可以构造一颗树： 上面的图就是决策树，最终的结果是心仪或者不心仪。决策树算法以树形结构表示数据分类的结果 ¶基本概念 决策树属于也只能非参数学习算法、可以用于解决(多)分类问题，回归问题。 回归问题的结果，叶子结点的平均值是回归问题的解。 根节点：决策树具有数据结构里面的二叉树、树的全部属性 非叶子节点 ：（决策点） 代表测试的条件，数据的属性的测试 叶子节点 ：分类后获得分类标记 分支： 测试的结果 ¶数学问题-熵-Gini系数 什么是熵：熵的概念源于物理学，用于度量一个热力学系统的无序程度。 信息熵：不得不提香农这个大写的人啦！信息论里面的知识。在信息论里面，信息熵衡量信息量的大小，也就是对随机变量不确定度的一个衡量。熵越大，不确定性越大；样本纯度越大越好。 对于某个单符号无记忆信源，发出符号($x_i$)的概率是$p_i$,概率越大，符号的信息量就越小，香农公式 $I(x_i)=-log_{p_i}$。信源所含的信息熵就是信息量的期望] $H(x)=-\sum p_i*log_{p_i}$ Gini系数： $Gimi§ = 1-\sum_{k=1}{K}p_k2$ ¶决策树如何构建的问题 自我提问阶段： 每个节点的位置如何确定？ 特征的选择：每次选入的特征作为分裂的标准，都是使得决策树在这个节点的根据你自己选择的标准（信息熵最小、信息增益最大、gini系数最小）. 选取的标准：尽快能的划分出结果，使得分的结果最好。 每个节点在哪个值上做划分，确定分支结构呢？ 遍历划分的节点的分界值操作来解决这个问题 可以想象，我们构造的决策树足够庞大，决策树可以把每一个样本都分对，那么决策树的泛化能力就可以很差了 为了解决这个问题，就需要剪枝操作了 ¶训练算法 ¶基于信息熵的构造 当选择某个特征作为节点时，我们就希望这个特征的使得分类结果信息熵越小越好，那么不确定性越小。 计算特征的信息熵公式如下： $$ H(x) = -p_i(x)log^{p_i(x)} = -\frac{n_j}{S}log^{\frac{n_j}{S}}$$ $n_j$: 第j个类别，在样本中出现的频数 $S$: 样本个数 对于离散属性，直接计算信息熵，连续属性，就需要划分区间，按区间计算信息熵。 基于某一层的数据集 a. 遍历计算所有属性，遍历相应属性以不同值为分截点的信息熵 b. 选择信息熵最小的作为节点 如果到达终止条件，返回相应信息，否则，按照分支重复步骤1 ¶ID3 算法： 信息增益最大化 建立在奥卡姆剃刀的基础上。 思想 集合C的信息熵 $$H©=-\sum_{i=1}^{m}p_i log 2^{p_i}$$ 按照D组划分C，数据集C的条件熵， $$H(C/D)=\sum{i=1}^{v}\frac{|C_i|}{|C|}H(C_i) = \sum_{i=1}^{v}\frac{|C_i|}{|C|}\sum_{j = 1}^{m}\frac{|C_{ik}|}{|C_i|}log_2\frac{|C_{ik}|}{|C_2|}$$ 信息增益 = 信息熵-条件熵 $$ gain(C,D) = gain©-H(C/D)$$ 这里我就以网上给出的数据为例，给出根据信息熵构成决策树的计算过程。 确定特征，统计属性值和分解结果，总共四个特征，四种特征的统计结果如下图： 根据历史数据，在不知到任何情况下，计算数据本身的熵为 $$ - \frac{9}{14}log_2 \frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940$$ 计算每个特征做为节点的信息熵 以天气为例，天气三种属性，当Outlook = sunny时，H(x) = $-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}$; 当Outlook= overcast,$H(x)=0$,当Outlook = rainy ,$H(x) = 0.971$ 所以，当选天气作为节点时，此时$H(x)=\frac{5}{14}*0.971+\frac{4}{14}*0+\frac{5}{14}*0.971 = 0.693$,gain(天气) = 0.247 同理，可得gain(温度) =0.029 gain(湿度)=0.152，gain(风)=0.048 因此选择天气节点，在递归实现其他节点的选择。 信息增益的方法偏向选择具有大量值的属性，也就是说某个属性特征索取的不同值越多，那么越有可能作为分裂属性，这样是不合理的； 缺点 没有剪纸策略，容易过拟合 信息增益准则表现出对取值较多的特征，列如编号，生日这种 没有考虑缺失值 ¶C4.5: 信息增益率 C4.5 相对于ID3的缺点改进如下： 引入了剪纸策略 对于具有缺失值特征，用没有缺失的样本子集所占比重来折算； 引入信息增益率作为划分标准 连续特征离散化 缺失值处理。 以不同概率划分到不同节点中 如果这里考虑了一列ID,每个ID出现一次，所以算出的信息增益大。 $ H(x) = 0$,信息增益最大化了，可以引入信息增益率 $$C(T) = \frac{信息增益}{H(T)} =\frac{H©-H(C/T)}{H(T)}$$ ¶CART:基尼(Gini)系数 $$G = 1-\sum_{i=l_k}{k}p_i2$$,也是对随机变量不确定性的一个衡量，gini越大，不确定性越大 ¶连续属性的处理方法 选取分解点的问题： 分成不同的区间（二分、三分…)，分别计算增益值，然后比较选择。 将需要处理的样本（对应根节点）或样本子集（对应子树）按照连续变量的大小从小到大进行排序 假设该属性对应不同的属性值共N个，那么总共有N-1个可能的候选分割值点，每个候选的分割阈值点的值为上述排序后的属性值中两两前后连续元素的中点。 阙值：threshold ¶评价 评价函数： $$C(T) = \sum_{releaf} N_t*H(T)$$ $ N_t$：每个叶子节点里面含有的样本个数 $H(T)$:叶子节点含有的信息熵 ¶过拟合 如果决策树过于庞大，分支太多，可能造成过拟合。对应训练样本都尽可能的分对，也许样本本身就存在异常点呢？ I. 预剪枝：边构建，边剪枝 指定深度d 节点的min_sample 节点熵值或者gini值小于阙值 熵和基尼值的大小表示数据的复杂程度，当熵或者基尼值过小时，表示数据的纯度比较大，如果熵或者基尼值小于一定程度数，节点停止分裂。 当所有7特征都用完了 指定节点个数 当节点的数据量小于一个指定的数量时，不继续分裂。两个原因：一是数据量较少时，再做分裂容易强化噪声数据的作用；二是降低树生长的复杂性。提前结束分裂一定程度上有利于降低过拟合的影响。 II. 后剪枝： 构建好后，然后才开始裁剪 $$ C_\alpha(T) = C(T)+\alpha|T_{leaf}|$$ 在构造含一棵树后，选一些节点做计算，看是否需要剪枝。 后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多 ¶熵 bias 生日这种属性，把属性分的太多了，分的越细，往往熵越大。 ¶决策树单个节点选择的代码实现 ¶简单实现了单个节点决策构造过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def split(X,y,d,value):'''在d纬度上，按照value进行划分''' index_a =(X[:,d]&lt;=value) index_b =(X[:,d]&gt;value) return X[index_a],X[index_b],y[index_a],y[index_b]from collections import Counterfrom math import log from numpy as npdef entropy(y): counter = Counter(y) # 字典 res = 0.0 for num in counter.values(): p = num/len(y) res+=-p*log(p) return resdef gain(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) e = len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return (entropy(y)-e)def gainratio(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) gain =entropy(y) - len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return gain/(entropy(y_l)+entropy(y_r))def gini(y): counter = Counter(y) res = 1.0 for num in counter.values(): p = num / len(y) res += -p**2 return res #X_l,X_r,y_l,y_r = split(X,y,d,v) #return 1-(len(y_l)/len(y))**2-(len(y_r)/len(y))**2def try_split(X,y): best_entropy = float('inf') best_d,best_v=-1,-1 for d in range(X.shape[1]): sorted_index = np.argsort(X[:,d]) for i in range(1, len(X)): if (X[sorted_index[i],d] != X[sorted_index[i-1],d]): v = (X[sorted_index[i-1],d]+X[sorted_index[i],d])/2 X_l,X_r,y_l,y_r = split(X,y,d,v) # 信息熵 e = entropy(y_l)+entropy(y_r) #gini e = gini(y_l) + gini(y_r) # 信息增益 e = -gain(X,y,d,v) if e &lt; best_entropy: best_entropy, best_d,best_v = e,d,v return best_entropy, best_d, best_v# 手动来划分data =np.array([[ 0.3 , 5 , 2 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.5 , 6.5 , 1 , 1 ],[ 0.6 , 6 , 0 , 0 ],[ 0.7 , 9 , 2 , 1 ],[ 0.5 , 7 , 1 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.6 , 8.5 , 0 , 1 ],[ 0.3 , 5.5 , 2 , 0 ],[ 0.9 , 10 , 0 , 1 ],[ 1 , 12 , 1 , 0 ],[ 0.6 , 9 , 1 , 0 ],])X =data[:,0:3]y = data[:,-1]# 手动来划分best_entropy, best_d, best_v = try_split(X, y)print(best_entropy, best_d, best_v)X1_l, X1_r, y1_l, y1_r = split(X,y,best_d,best_v)print(X1_l, X1_r, y1_l, y1_r)best_entropy2, best_d2, best_v2 = try_split(X1_r, y1_r)X2_l, X2_r, y2_l, y2_r = split(X1_r,y1_r,best_d2,best_v2)entropy(y2_l) ¶Python sklean里面tree模块里面的DecisionTreeClassifier 1234from sklearn import treeclf =tree.DecisionTreeClassifier(max_depth=1,criterion ='gini') # criterion='entropy|gini'clf = clf.fit(X,y) 训练好一颗决策树之后，我们可以使用export_graphviz导出器以Graphviz格式导出树。 1234import graphviz dot_data = tree.export_graphviz(clf, out_file=None,) graph = graphviz.Source(dot_data) graph.render("data") 在运行时可以出错： ExecutableNotFound: failed to execute [‘dot’, ‘-Tpdf’, ‘-O’, ‘data’], make sure the Graphviz executables are on your systems’ PATH 原因：graphviz本身是一个软件，需要额外下载，并将其bin加入环境变量之中。下载]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[主要是分享决策的基本知识点，重点在分类决策树上，对于回归的决策树后面在给出。希望大家和我一起做知识的传播者啦！😄 😃 😁 😮 [TOC] 决策树 英文名字：Descision Tree ¶什么是决策树 举个校园相亲的例子，今天校园的小猫(女)和小狗(男)准备配对，小猫如何才能在众多的优质🐶的心仪的狗呢？于是呢？有一只特乖巧的小猫找到了你，你正在学习机器学习，刚好学习了决策树，准备给这只猫猫挑选优质狗，当然，你不仅仅是直接告诉猫哪些狗是合适你的？你更应该详细的给猫讲解决策树是如何根据它提出的标准选出的符合要求的狗呢？ 猫给出如下信息： 年龄&lt;0.5 不心仪；年龄大于&gt;=0.5 6.5&lt;=体重&lt;=8.5;心仪; 年龄&gt;=0.5 体重&gt;8.5 长相好 心仪;其余情况不心仪; 根据上述条件可以构造一颗树： 上面的图就是决策树，最终的结果是心仪或者不心仪。决策树算法以树形结构表示数据分类的结果 ¶基本概念 决策树属于也只能非参数学习算法、可以用于解决(多)分类问题，回归问题。 回归问题的结果，叶子结点的平均值是回归问题的解。 根节点：决策树具有数据结构里面的二叉树、树的全部属性 非叶子节点 ：（决策点） 代表测试的条件，数据的属性的测试 叶子节点 ：分类后获得分类标记 分支： 测试的结果 ¶数学问题-熵-Gini系数 什么是熵：熵的概念源于物理学，用于度量一个热力学系统的无序程度。 信息熵：不得不提香农这个大写的人啦！信息论里面的知识。在信息论里面，信息熵衡量信息量的大小，也就是对随机变量不确定度的一个衡量。熵越大，不确定性越大； 对于某个单符号无记忆信源，发出符号($x_i$)的概率是$p_i$,概率越大，符号的信息量就越小，香农公式 $I(x_i)=-log_{p_i}$。信源所含的信息熵就是信息量的期望] $H(x)=-\sum p_i*log_{p_i}$ Gini系数： $Gimi§ = 1-\sum_{k=1}{K}p_k2$ ¶决策树如何构建的问题 自我提问阶段： 每个节点的位置如何确定？ 特征的选择：每次选入的特征作为分裂的标准，都是使得决策树在这个节点的根据你自己选择的标准（信息熵最小、信息增益最大、gini系数最小）. 每个节点在哪个值上做划分，确定分支结构呢？ 遍历划分的节点的分界值操作来解决这个问题 可以想象，我们构造的决策树足够庞大，决策树可以把每一个样本都分对，那么决策树的泛化能力就可以很差了 为了解决这个问题，就需要剪枝操作了 ¶训练算法 ¶基于信息熵的构造 当选择某个特征作为节点时，我们就希望这个特征的信息熵越小越好，那么不确定性越小。 计算特征的信息熵公式如下： $$ H(x) = -p_i(x)log^{p_i(x)} = -\frac{n_j}{S}log^{\frac{n_j}{S}}$$ $n_j$: 第j个类别，在样本中出现的频数 $S$: 样本个数 对于离散属性，直接计算信息熵，连续属性，就需要划分区间，按区间计算信息熵。 基于某一层的数据集 a. 遍历计算所有属性，遍历相应属性以不同值为分截点的信息熵 b. 选择信息熵最小的作为节点 如果到达终止条件，返回相应信息，否则，按照分支重复步骤1 ¶ID3算法： 信息增益最大化 C:类别 $$H©=-\sum_{i=1}^{m}p_i log 2^{p_i}$$ 按照D组划分C $$H(C/D)=\sum{i=1}^{v}\frac{|C_i|}{|C|}H(C_i)$$ 信息增益 $$ gain(D) = gain©-H(C/D)$$ 这里我就以网上给出的数据为例，给出根据信息熵构成决策树的计算过程。 确定特征，统计属性值和分解结果，总共四个特征，四种特征的统计结果如下图： 根据历史数据，在不知到任何情况下，计算数据本身的熵为 $$ - \frac{9}{14}log_2 \frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940$$ 计算每个特征做为节点的信息熵 以天气为例，天气三种属性，当Outlook = sunny时，H(x) = $-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}$; 当Outlook= overcast,$H(x)=0$,当Outlook = rainy ,$H(x) = 0.971$ 所以，当选天气作为节点时，此时$H(x)=\frac{5}{14}*0.971+\frac{4}{14}*0+\frac{5}{14}*0.971 = 0.693$,gain(天气) = 0.247 同理，可得gain(温度) =0.029 gain(湿度)=0.152，gain(风)=0.048 因此选择天气节点，在递归实现其他节点的选择。 信息增益的方法偏向选择具有大量值的属性，也就是说某个属性特征索取的不同值越多，那么越有可能作为分裂属性，这样是不合理的； ¶C4.5: 信息增益率 如果这里考虑了一列ID,每个ID出现一次，所以算出的信息增益大。 $ H(x) = 0$,信息增益最大化了，可以引入信息增益率 $$C(T) = \frac{信息增益}{H(T)} =\frac{H©-H(C/T)}{H(T)}$$ ¶CART:基尼(Gini)系数 $$G = 1-\sum_{i=l_k}{k}p_i2$$,也是对随机变量不确定性的一个衡量，gini越大，不确定性越大 ¶连续属性的处理方法 选取分解点的问题： 分成不同的区间（二分、三分…)，分别计算增益值，然后比较选择。 将需要处理的样本（对应根节点）或样本子集（对应子树）按照连续变量的大小从小到大进行排序 假设该属性对应不同的属性值共N个，那么总共有N-1个可能的候选分割值点，每个候选的分割阈值点的值为上述排序后的属性值中两两前后连续元素的中点 ¶评价 评价函数： $$C(T) = \sum_{releaf} N_t*H(T)$$ $ N_t$：每个叶子节点里面含有的样本个数 $H(T)$:叶子节点含有的信息熵 ¶过拟合 如果决策树过于庞大，分支太多，可能造成过拟合。对应训练样本都尽可能的分对，也许样本本身就存在异常点呢？ I. 预剪枝：边构建，边剪枝 指定深度d 节点的min_sample 节点熵值或者gini值小于阙值 熵和基尼值的大小表示数据的复杂程度，当熵或者基尼值过小时，表示数据的纯度比较大，如果熵或者基尼值小于一定程度数，节点停止分裂。 当所以特征都用完了 指定节点个数 当节点的数据量小于一个指定的数量时，不继续分裂。两个原因：一是数据量较少时，再做分裂容易强化噪声数据的作用；二是降低树生长的复杂性。提前结束分裂一定程度上有利于降低过拟合的影响。 II. 后剪枝： 构建好后，然后才开始裁剪 $$ C_\alpha(T) = C(T)+\alpha|T_{leaf}|$$ 在构造含一棵树后，选一些节点做计算，看是否需要剪枝 ¶决策树单个节点选择的代码实现 ¶简单实现了单个节点决策构造过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def split(X,y,d,value):'''在d纬度上，按照value进行划分''' index_a =(X[:,d]&lt;=value) index_b =(X[:,d]&gt;value) return X[index_a],X[index_b],y[index_a],y[index_b]from collections import Counterfrom math import log from numpy as npdef entropy(y): counter = Counter(y) # 字典 res = 0.0 for num in counter.values(): p = num/len(y) res+=-p*log(p) return resdef gain(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) e = len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return (entropy(y)-e)def gainratio(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) gain =entropy(y) - len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return gain/(entropy(y_l)+entropy(y_r))def gini(y): counter = Counter(y) res = 1.0 for num in counter.values(): p = num / len(y) res += -p**2 return res #X_l,X_r,y_l,y_r = split(X,y,d,v) #return 1-(len(y_l)/len(y))**2-(len(y_r)/len(y))**2def try_split(X,y): best_entropy = float('inf') best_d,best_v=-1,-1 for d in range(X.shape[1]): sorted_index = np.argsort(X[:,d]) for i in range(1, len(X)): if (X[sorted_index[i],d] != X[sorted_index[i-1],d]): v = (X[sorted_index[i-1],d]+X[sorted_index[i],d])/2 X_l,X_r,y_l,y_r = split(X,y,d,v) # 信息熵 e = entropy(y_l)+entropy(y_r) #gini e = gini(y_l) + gini(y_r) # 信息增益 e = -gain(X,y,d,v) if e &lt; best_entropy: best_entropy, best_d,best_v = e,d,v return best_entropy, best_d, best_v# 手动来划分data =np.array([[ 0.3 , 5 , 2 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.5 , 6.5 , 1 , 1 ],[ 0.6 , 6 , 0 , 0 ],[ 0.7 , 9 , 2 , 1 ],[ 0.5 , 7 , 1 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.6 , 8.5 , 0 , 1 ],[ 0.3 , 5.5 , 2 , 0 ],[ 0.9 , 10 , 0 , 1 ],[ 1 , 12 , 1 , 0 ],[ 0.6 , 9 , 1 , 0 ],])X =data[:,0:3]y = data[:,-1]# 手动来划分best_entropy, best_d, best_v = try_split(X, y)print(best_entropy, best_d, best_v)X1_l, X1_r, y1_l, y1_r = split(X,y,best_d,best_v)print(X1_l, X1_r, y1_l, y1_r)best_entropy2, best_d2, best_v2 = try_split(X1_r, y1_r)X2_l, X2_r, y2_l, y2_r = split(X1_r,y1_r,best_d2,best_v2)entropy(y2_l) ¶Python sklean里面tree模块里面的DecisionTreeClassifier 1234from sklearn import treeclf =tree.DecisionTreeClassifier(max_depth=1,criterion ='gini') # criterion='entropy|gini'clf = clf.fit(X,y) 训练好一颗决策树之后，我们可以使用export_graphviz导出器以Graphviz格式导出树。 1234import graphviz dot_data = tree.export_graphviz(clf, out_file=None,) graph = graphviz.Source(dot_data) graph.render("data") 在运行时可以出错： ExecutableNotFound: failed to execute [‘dot’, ‘-Tpdf’, ‘-O’, ‘data’], make sure the Graphviz executables are on your systems’ PATH 原因：graphviz本身是一个软件，需要额外下载，并将其bin加入环境变量之中。下载]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的读书笔记]]></title>
    <url>%2F2019%2F02%2F28%2FSVD%2F</url>
    <content type="text"><![CDATA[目录 😄 1️⃣ 简单说一下特征值、特征向量与特征分解 I. 特征值、特征向量与特征分解 II. 几何意义 III. 如何实现通过Matlab、Python实现 2️⃣详细解说SVD I. 几何意义 I. 奇异值分解的推导过程 I. SVD算例 I. 如何通过Matlab和Python 3️⃣应用举例 I. 特征值、特征向量与特征分解 4️⃣特征分解、奇异值分解的区别 I. 特征分解、奇异值分解的区别 简单说一下特征值、特征向量与特征分解 ¶特征值、特征向量与特征分解 Theory: 对于一个正阵$M$，满足如下： $$Mx=\lambda x $$ 其中$\lambda$被成为特征值，满足$||M-\lambda E||=0$再有$(M-\lambda E)x=0$，可计算其特征向量。 如果有了特征值和特征向量后呢，则可以将矩阵$M$用特征分解： $$ M=W\sum W^{-1}$$ $W={w_1,w_2,…,w_n}$分别是特征值$\lambda_1,\lambda_2,…,\lambda_n$对应的特征向量构成的方阵 ¶ 几何意义 对应矩阵M,其对应的线性变化 $$Mx = x’$$ 上面这个式子，$Mx，x’$是一个向量，$x,x’$可能是不共线的(如图(b))，如果向量$Mx,x’$满足$Mx=x’=\lambda x$,则如图(b)，这说明了这个变换就是对向量x做一个拉伸或者压缩。 ¶如何实现通过Matlab、Python实现 数学推导： $$ Mx = \lambda x$$ $$ Mx-\lambda x=(M-\lambda E)x=0$$ 齐次线性方程组有非零解，则$||M-\lambda E||=0$可求得特征向量 再带回，可得特征向量。 Matlab: 123d = eig(M) % 求取矩阵M的特征值，向量形式存储[V,D] = eig(M) % 计算M的特征值对角阵D和特征向量V，使得MV = VD成立[V,D] = eig(M,'nobalance') %当矩阵M中有与截断误差数量级相差不远的值时，该指令可能更精确。'nobalance'起误差调节作用 Python numpy科学计算库提供相应的方法 1234import numpy as npx = np.diag((1,2,3)) # 这是你想要求取特征值的数组a,b = numpy.linalg.elg(x) # 特征值赋值给a,对应的特征向量赋值给b 详细解说SVD SVD的英文全称： Singular Value Decomposition，中文名字：奇异值分解 ¶几何意义 图来源 以二维空间为例 几何意义就是把一个单位正交的网格，转换为另外一个单位正交的网格 假如选取了一组单位正交基{$\vec{v}1$,$\vec{v}2$},刚好矩阵$M$的线性变化$M\vec{v}1 $,$M\vec{v}2 $ 也正交，用$\vec{u}1,\vec{u}2 $分别表示$M\vec{v}1 $,$M\vec{v}2 $ 的单位向量，用$\lambda_1,\lambda_2 $表示$M\vec{v}1 $,$M\vec{v}2$的长度，描述网格在这些特定方向上的拉伸量，也被称作矩阵M的奇异值。 $M\vec{v}1 =\lambda_1\vec{u}1 $ $M\vec{v}2 =\lambda_2\vec{u}2 $ 对任意给定的向量 $\vec{x}$ ,则有 $$ \mathbf{x}=\left(\mathbf{v}{1} \cdot \mathbf{x}\right) \mathbf{v}{1}+\left(\mathbf{v}{2} \cdot \mathbf{x}\right) \mathbf{v}{2} $$ 再将M的线性变换 $$ \begin{aligned} M \mathbf{x} &amp;=\left(\mathbf{v}{1} \cdot \mathbf{x}\right) M \mathbf{N}{1}+\left(\mathbf{v}{2} \cdot \mathbf{x}\right) M \mathbf{v}{2} \ M \mathbf{x} &amp;=\left(\mathbf{v}{1} \cdot \mathbf{x}\right) \sigma{1} \mathbf{u}{1}+\left(\mathbf{v}{2} \cdot \mathbf{x}\right) \sigma{2} \mathbf{u}{2} \end{aligned} $$ $$ \begin{array}{c}{M \mathbf{x}=\mathbf{u}{1} \sigma{1} \mathbf{v}{1}^{\top} \mathbf{x}+\mathbf{u}{2} \sigma_{2} \mathbf{v}{2}^{\top} \mathbf{x}} \ {M=\mathbf{u}{1} \sigma_{1} \mathbf{v}{1}^{\top}+\mathbf{u}{2} \sigma_{2} \mathbf{v}_{2}^{\top}}\end{array} $$ so $$ M=U \Sigma V^{T} $$ ¶奇异值分解的推导过程 $u=(u_1,u_2,…,u_m)$ $v=(v_1,v_2,…,v_n)$ $u,v$都是空间的基,是正交矩阵 $uTu=E,vTv = E$ 任何一个矩阵$M_{m*n}$，$rank(M)=k$，一定存在ＳＶＤ,换句话说，M可以将一组单位正交基映射到另一组单位正交基。答案是肯定的 证明如下： 在n为空间中，有一组单位正交基{$\vec{v}1,\vec{v}2,…,\vec{v}n$},线性变化作用以后 $$ {M\vec{v}1,M\vec{v}2,…,M\vec{v}n} $$ 也是正交的，则有 $$ (M\vec{v}i,M\vec{v}j) = (M\vec{x}i)TM\vec{v}_j=\vec{v}_iTM^TM\vec{v}j=0 $$ 注意喔，$MTM$是矩阵喔，则会有$MTM\vec{v}j=\lambda \vec{v}j$ 接下去， $$ \begin{aligned} v{i}^{T} M^{T} \mathrm{M} v{j}=&amp; v{i}^{T} \lambda{j} v{j} \ &amp;=\lambda{j} v{i}^{T} v{j} \ &amp;=\lambda{j} v{i}\dot v{j}=0 \end{aligned} $$ 上述就证明了是有的：任何一个矩阵，都可以将一组单位正交基转换成另外一组正交基。 当$i=j$,$&lt;M\vec{v}i,M \vec{v}i&gt;=\lambda_i \vec{v}i \vec{v}i=\lambda_i$ 进行一些单位化，记$u_i=\frac{A\vec{v}i}{|M\vec{v}i|}=\frac{1}{\sqrt{\lambda_i}}M\vec{v}i$ 则 $$ A v{i}=\sigma{i} u{i}, \sigma{i}(\operatorname{奇异值})=\sqrt{\lambda{i}}, 0 \leq i \leq \mathrm{k}, \mathrm{k}=\operatorname{Rank}(\mathrm{A}) $$ 当$k &lt; i &lt;= m$时，对$u1，u2，…，uk$进行扩展$u(k+1),…,um$，使得$u1，u2，…，um$为$m$维空间中的一组正交基.也可对$\vec{v}1,\vec{v}2,…,\vec{v}k$进行扩展，扩展的$\vec{v}{k+1},…,\vec{v}{n}$存在零子空间里面。 $$ M\left[ \begin{array}{lll}{\vec{v}{1}} &amp; {\cdots} &amp; {\vec{v}{k}}\end{array}\right| \vec{v}{k+1} \quad \cdots \quad \vec{v}{m} ]= \left[ \begin{array}{c}{\vec{u}{1}^{T}} \ {\vdots} \ {\frac{\vec{u}{k}^{T}}{\vec{u}{k+1}}} \ {\vdots} \ {\vec{u}{n}^{T}}\end{array}\right] \left[ \begin{array}{ccc|c}\sigma_{1} &amp; &amp; 0 &amp; 0\ &amp; {\ddots} &amp; \sigma_{k} &amp; 0 \ \hline 0 &amp; &amp; 0 &amp;0\end{array}\right] $$ $$ M=\left[ \begin{array}{lll}{\vec{u}{1}} &amp; {\cdots} &amp; {\vec{u}{k}}\end{array}\right] \left [ \begin{array}{ccc}\sigma_{1} &amp; &amp; \ &amp; {\ddots} &amp; \ &amp; &amp; {\sigma_{k}}\end{array}\right] \left[ \begin{array}{c}{\vec{v}{1}^{T}} \ {\vdots} \ {\vec{v}{k}^{T}}\end{array}\right]+ \left[ \begin{array}{ccc}{\vec{u}{k+1}} &amp; {\cdots} &amp; {\vec{u}{m}}\end{array}\right] \left[\begin{array}{c} 0 \end{array} \right] \left[ \begin{array}{c}{\vec{v}{k+1}^{T}} \ {\vdots} \ {\vec{v}{n}^{T}}\end{array}\right] $$ ¶SVD算例 U：$AA^T$的特征值和特征向量，用单位化的特征向量构成 U V: $A^TA$ 的特征值和特征向量，用单位化的特征向量构成 V $\sum_{mn} $ :将$ AA^{T} $或者 A^{T}A 的特征值求平方根，然后构成 Σ 以矩阵$A = \left[\begin{matrix} 1 &amp; 1\1 &amp;1\ 0 &amp;0\\end{matrix} \right]$ 第一步 U ，下面是一种计算方法 对矩阵 $$ A A^{T}=\left[ \begin{array}{lll}{2} &amp; {2} &amp; {0} \ {2} &amp; {2} &amp; {0} \ {0} &amp; {0} &amp; {0}\end{array}\right] $$ 特征分解， 特征是4，0，0 特征向量是 $\left[\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]^{T},\left[-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]{T},[0,0,1]{T}$,可得到 $$ U=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} &amp; {-\frac{1}{\sqrt{2}}} &amp; {0} \ {\frac{1}{\sqrt{2}}} &amp; {\frac{1}{\sqrt{2}}} &amp; {0} \ {0} &amp; {0} &amp; {1}\end{array}\right] $$ 第二步 计算矩阵$A^TA$的特征分解，可得 特征值4，0， $$ V=\left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} &amp; {-\frac{1}{\sqrt{2}}} \ {\frac{1}{\sqrt{2}}} &amp; {\frac{1}{\sqrt{2}}}\end{array}\right] $$ 第三步 计算$\sum_{mn}$ $$ \Sigma=\left[ \begin{array}{ll}{2} &amp; {0} \ {0} &amp; {0} \ {0} &amp; {0}\end{array}\right] $$ 最后， $$ A=U \Sigma V^{T}=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} &amp; {-\frac{1}{\sqrt{2}}} &amp; {0} \ {\frac{1}{\sqrt{2}}} &amp; {\frac{1}{\sqrt{2}}} &amp; {0} \ {0} &amp; {0} &amp; {1}\end{array}\right] \left[ \begin{array}{ll}{2} &amp; {0} \ {0} &amp; {0} \ {0} &amp; {0}\end{array}\right] \left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} &amp; {-\frac{1}{\sqrt{2}}} \ {\frac{1}{\sqrt{2}}} &amp; {\frac{1}{\sqrt{2}}}\end{array}\right]^{T}=\left[ \begin{array}{cc}{1} &amp; {1} \ {1} &amp; {1} \ {0} &amp; {0}\end{array}\right] $$ ¶如何通过Matlab和Python Matlab： 1234567891011s = svd(A)[U,S,V] = svd(A)[U,S,V] = svd(A,'econ')[U,S,V] = svd(A,0)input: A 矩阵output: s:奇异值，以列向量形式返回。奇异值是以降序顺序列出的非负实数 S： U:左奇异向量，以矩阵的列形式返回。 V:奇异值，以对角矩阵形式返回。S 的对角元素是以降序排列的非负奇异值。 右奇异向量，以矩阵的列形式返回。 Python 123import numpy as npM = np.array([ [1,1,2],[0,0,1]])U,S,V = np.linalg.svd(M) 应用举例 ¶应用 2.1 信息检索 2.2 推荐系统 2.3 基于协同过滤的推荐系统 2.4 图像压缩 特征值分解和奇异值分解的区别 特征值分解只能是方阵，而奇异值分解是矩阵就可以 特征值分解只考虑了对矩阵缩放效果，奇异值分解对矩阵有选择、收缩、投影的效果]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python库]]></title>
    <url>%2F2019%2F02%2F24%2Fpython%E5%BA%93%2F</url>
    <content type="text"><![CDATA[开始接触Python是大二结束的时候，到现在都快两年了，其实一直并不是很细节的学习，只是希望能够跑个结果。不过呢？，以后肯定是会经常用Python，所以呢？我接下来会认真学习Python ¶Python 高级用法总结 基本数据类型：整型、浮点型、布尔类型 ¶容器： Containers 容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用in, not in关键字判断元素是否包含在容器中。通常这类数据结构把所有的元素存储在内存中（也有一些特例，并不是所有的元素都放在内存，比如迭代器和生成器对象）在Python中，常见的容器对象有： list, deque set, frozensets dict, defaultdict, OrderedDict, Counter tuple, namedtuple str ¶list推导（list comprehensions) 官方解释：列表解析式是Python内置的非常简单却强大的可以用来创建list的生成式。 1对于一个列表，既要遍历索引又要遍历元素。 123array = ['I', 'love', 'Python']for i, element in enumerate(array): array[i] = '%d: %s' % (i, seq[i]) 12345def getitem(index, element): return '%d: %s' % (index, element)array = ['I', 'love', 'Python']arrayIndex = [getitem(index, element) for index, element in enumerate(array)] ¶迭代器和生成器 ¶可迭代对象： 凡是可以返回一个迭代器的对象都可称之为可迭代对象 例如：list dic str set tuple range() enumerate(枚举) f=open()（文件句柄） 123456789### 迭代器(iterator)是一个带状态的对象，他能在你调用next()方法的时候返回容器中的下一个值，任何实现了__iter__和__next__()（python2中实现next()）方法的对象都是迭代器，__iter__返回迭代器自身，__next__返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常### 生成器(generator)生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面的类一样写__iter__()和__next__()方法了，只需要一个yiled关键字。 生成器一定是迭代器（反之不成立）#列表生成式lis = [x*x for x in range(10)]# 受到内存限制，列表容量肯定是有限的#生成器表达式generator_ex = (x*x for x in range(10)) 生成器： 不用创建完整的list，为节省大量的空间，在Python中，这种一边循环一边计算的机制，称为生成器：generator Tuples:() 字典：{：，} Sets: {,} 函数 类 ¶Python库----numpy ¶What NumPy=Numerical+Python 主要是提供了高性能多维数组这个对象，以及处理相关的方法 ¶How 自定义一个（1D or MD)数组或者特殊的数组,一维，二维 数组切片（也就是提取数组元素），注意 a[:,0]和a[:,0:1]是不同的喔 关于数组属性的方法 数组运算 索引 where 函数 索引的布尔数组 广播（Broadcasting） 用于处理不同性状的 数组。 Broadcasting提供了一种矢量化数组操作的方法，使得循环发生在C而不是Python。标量乘以一个矢量的时候，用Boradcasting更快，因为 broadcasting在乘法期间移动较少的内存 array 和 matrix 选择哪个? 戳我 矢量化和广播、索引 在Python中循环数组或任何数据结构时，会涉及很多开销。 NumPy中的向量化操作将内部循环委托给高度优化的C和Fortran函数，从而实现更清晰，更快速的Python代码。 ¶stack|vstack|hstack 1234567891011121314151617181920212223242526272829303132a = np.array([1, 2, 3])b = np.array([2, 3, 4])np.stack((a, b))array([[1, 2, 3], [2, 3, 4]])% hstacka = np.array((1,2,3))b = np.array((2,3,4))np.hstack((a,b))array([1, 2, 3, 2, 3, 4])a = np.array([[1],[2],[3]])b = np.array([[2],[3],[4]])np.hstack((a,b))array([[1, 2], [2, 3], [3, 4]])% vstacka = np.array([1, 2, 3])b = np.array([2, 3, 4])np.vstack((a,b))array([[1, 2, 3], [2, 3, 4]])a = np.array([[1], [2], [3]])b = np.array([[2], [3], [4]])np.vstack((a,b))array([[1], [2], [3], [2], [3], [4]]) ¶mean 123456a = np.array([[1, 2], [3, 4]])np.mean(a)np.mean(a, axis=0)np.mean(a, axis=1) ¶reshape reshape(x, y)，其中x表示转换后数组的行数，y表示转换后数组的列数。当x或者y为-1时，表示该元素随机分配，如reshape(2, -1)表示列数随机，行数为两行。 123456789格式：np.reshape((x, y, z))参数的含义：x：表示生成的三维数组中二维数组的个数y：表示单个二维数组中一维数组的个数z：表示三维数组的列数 ¶numpy数组去掉冗余的维度-----squeeze()函数 import numpy as np a = [[[10, 2, 3]]] a = np.array(a) a_sque = np.squeeze(a) print(a) print(a_sque) ¶Python库----pandas 记得学习pandas是在大三时候的美赛，花了一天多时间学习pandas，然后预处理数据，当时三个队友都是各自的家，是非常愉快的！！！ ¶what Python Data Analysis Library 三种数据结构 序列： Series 1D 数据帧： DataFrame 2D 面板： Panel &gt;2D 自定义创建 可以通过字段、数据、series、列表 列表传入的时候，主要行列，如果单个列表：列；如果是[[],[]]是按行[] 如果位置不对可转置 创建空 pd.DataFrame() 选择区块 a) Series [] b) DataFrame 列选择 [‘colums的名字’] 行列选择：.loc[列名,行名]名称 .iloc[列索引,行索引]整数 array .value 统计描述 .descibe(include = ‘all’) .head() .tail() .select_dtype(include=[]) .columns .dtype 缺少数据 查看缺失值 isnull() notnull() 也可以 做一些统计，sum, any,all 清理缺失值 dropna(axis=0)：axis = 0:index axis=1,columns 填充缺少指 fillna() 标量替换 替换 统计函数 Pandas 函数应用 表合理函数应用：pipe() 行或列函数应用：apply() 元素函数应用：applymap() eg： pd.pipe(lambda x: x*100) 类别变量向量化 非数值类型的处理方法 时间序列生成 data_range pandas.date_range(“11:00”, “21:30”, freq=“30min”) 参数 1Return a fixed frequency DatetimeIndex. Parameters startstr or datetime-like, optional Left bound for generating dates. endstr or datetime-like, optional Right bound for generating dates. periodsint, optional Number of periods to generate. freqstr or DateOffset, default ‘D’ Frequency strings can have multiples, e.g. ‘5H’. See here for a list of frequency aliases. tzstr or tzinfo, optional Time zone name for returning localized DatetimeIndex, for example ‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is timezone-naive. normalizebool, default False Normalize start/end dates to midnight before generating date range. namestr, default None Name of the resulting DatetimeIndex. closed{None, ‘left’, ‘right’}, optional Make the interval closed with respect to the given frequency to the ‘left’, ‘right’, or both sides (None, the default). **kwargs For compatibility. Has no effect on the result. Returns rngDatetimeIndex 12345678910111213141516171819202111. DataFrame.stackParameterslevelint, str, list, default -1Level(s) to stack from the column axis onto the index axis, defined as one index or label, or a list of indices or labels.dropnabool, default TrueWhether to drop rows in the resulting Frame/Series with missing values. Stacking a column level onto the index axis can create combinations of index and column values that are missing from the original dataframe. See Examples section.ReturnsDataFrame or SeriesStacked dataframe or series.​```pythondf_single_level_cols weight heightcat 0 1dog 2 3df_single_level_cols.stack()cat weight 0 height 1dog weight 2 height DataFrame.value_connts()返回序列，index=统计值，值：统计个数 ¶Matplotlib matplotlib.pyplot as plt 窗口：figure: 一个窗口，plt.figure(num=,figsize=(h,w))下面数据都属于当前的figure,有一定的顺序喔 画图：plt.plot(x,y,color=,linewidth=,linestyle,label=) 标注信息： plt.xlim((,)), plt.yxlim((,)),plt.xlabel(),plt.ylabel(),ticks:图像的小标，plt.xticks(),plt.yticks([值1，值2],[r’$值1\ 对应的文字$’,r’值2的文字 \alpha]) 坐标轴：axis gac='get current axis’ ax = plt.gca() # 轴 # 获取四个轴 ax.spines[‘right|left|top|’].set_color(‘none’) ax.xaxis.set_ticks_position(‘bottom’) ax.spines[‘bottom’].set_position((‘data’,-1)) 图例：legend: a. plt.plot(,label=), plt.legend() b. l1, = plt.plot() plt.legend(handles=[l1,],labels=[,],loc=‘best|upper right|’) 注解 annotation a. 点的位置(x0，y0) plt.scatter(). plt.plot([x0,y0],[y0,0],‘k–’,lw=) b . method 1: plt.annotate(r’name’,xy=(,)起始点，xycoords=‘data’//基于xy,xytext=(+30,30),textcoords=‘offseet points’//文本基于xy,arrowprops=dict(arrowstyle=’-&gt;'箭头,connectionstyle=‘arc3,rad=.2’)弧度) Bar 柱状图 plt.bar(x,+|-y,facecolor=&quot;&quot;,edgecolor,) |# ha horizontal alignment 对齐方式 for x,y in zip(x,y): plt.text(x+0,4,y+0.05,’%.2f’%y,ha=‘center’,va=‘bottom’) 很多自动 subplot(总行，当前行的列，总的按最小分的第几个) subplot(,) ¶index reset_index:限于DataFrame set_index index scikit-learn 官方教程绝对是最好最棒的选择，有简单数学推导、直观立马就能上手的案例，还能提阅读英文的能力喔，实在是一举多得啊！！！！ scikit-learn.org ¶regression ¶Feature selection ¶Method from sklearn.feature_selection import VarianceThreshold ¶sklearn.feature_selection.SelectFromModel class sklearn.feature_selection.SelectFromModel(estimator, , threshold=None, prefit=False, norm_order=1, max_features=None) seaborn seaborn.jointplot(x, y, data=None, kind=‘scatter’, stat_func=None, color=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs) Parameters x, ystrings or vectorsData or names of variables in data.dataDataFrame, optionalDataFrame when x and y are variable names.kind{ “scatter” | “reg” | “resid” | “kde” | “hex” }, optionalKind of plot to draw.stat_funccallable or None, optionalDeprecatedcolormatplotlib color, optionalColor used for the plot elements.heightnumeric, optionalSize of the figure (it will be square).rationumeric, optionalRatio of joint axes height to marginal axes height.spacenumeric, optionalSpace between the joint and marginal axesdropnabool, optionalIf True, remove observations that are missing from x and y.{x, y}limtwo-tuples, optionalAxis limits to set before plotting.{joint, marginal, annot}_kwsdicts, optionalAdditional keyword arguments for the plot components.kwargskey, value pairingsAdditional keyword arguments are passed to the function used to draw the plot on the joint Axes, superseding items in the joint_kws dictionary. Returns gridJointGridJointGrid object with the plot on it. http://seaborn.pydata.org/generated/seaborn.JointGrid.html#seaborn.JointGrid g = sns.jointplot(x=“x”, y=“y”, kind = ‘reg’ , space=0,color = ‘g’, data=df11,stat_func=sci.pearsonr) sns.set() sns.axes_style(“darkgrid”) sns.set_context(“paper”) https://blog.mazhangjing.com/2018/03/29/learn_seaborn/ https://blog.csdn.net/weiyudang11/article/details/51549672 123456789101112131415#初始化类g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)g=g.plot_marginals(sns.distplot,kde=False)from scipy import statsg=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)_=g.ax_marg_x.hist(stock.v_ma10,color=&apos;r&apos;,alpha=.6,bins=50)_=g.ax_marg_y.hist(stock.low,color=&apos;y&apos;,orientation=&quot;horizontal&quot;,bins=20)rquare=lambda a,b:stats.pearsonr(a,b)[0]**2g=g.annotate(rquare,template=&apos;&#123;stat&#125;:&#123;val:.2f&#125;&apos;,stat=&apos;$R^2$&apos;,loc=&apos;upper left&apos;,fontsize=12) ¶颜色和风格设置 ¶调色板 主要使用以下几个函数设置颜色： color_palette() 能传入任何Matplotlib所有支持的颜色 color_palette() 不写参数则默认颜色 current_palette = sns.color_palette() sns.palplot(current_palette) plt.show() set_palette() 设置所有图的颜色 sns.palplot(sns.color_palette(“hls”,8)) plt.show() ¶颜色的亮度及饱和度 l-光度 lightness s-饱和 saturation sns.palplot(sns.hls_palette(8,l=.7,s=.9)) plt.show() ¶xkcd选取颜色 xkcd包含了一套众包努力的针对随机RGB色的命名。产生了954个可以随时通过xkcd_rgb字典中调用的命名颜色 plt.plot([0,1],[0,1],sns.xkcd_rgb[‘pale red’],lw = 3) #lw = 线宽度 plt.plot([0,1],[0,2],sns.xkcd_rgb[‘medium green’],lw = 3) plt.plot([0,1],[0,3],sns.xkcd_rgb[‘denim blue’],lw = 3) plt.show() ¶汇总 http://seaborn.pydata.org/api.html# https://github.com/mwaskom/seaborn/blob/master/seaborn/rcmod.py https://xkcd.com/color/rgb/]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的读书笔记]]></title>
    <url>%2F2019%2F02%2F22%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[¶2019 第十五周 三月份至2019.4.9这段时间，才发现我是如此没有自律的人，充分体现了我是人的特性，那就是我是群体动物，苦笑.jpg,苦笑.jpg, en, 最近突然想给自己打上厨娘的身份，如果可以每天花两个小时做饭就好了 ¶愿你被世界温柔的相待 接触的东西越多，越深入，就会发现我是如此的菜，开始有些知识焦虑了，知识那么多~~~，可是我只有一个头脑啊~~~ 开始不想写一些特别低俗的博客了，一是觉得浪费时间，二是输出效果太差，引不起特别大的关注，虽然我写博客，完全是站在自己的角度，没有考虑读者的意愿，（滑稽.jpg)。 现在的自己，不是停留在基本的问题上，更应该去探索未知 的知识世界，虽然离这个flag可能还有几年的时间，能够给世界的知识创造一点点价值，哪怕只是一小点点。离这个目标还需要努力啊！！！！！ 我想我应该去记录学习知识的过程，突破更大的更困难的问题。 ¶2019-第四周读书笔记 这周读了一本小说，是张爱玲的《倾城之恋》，原来和电视剧的何晟铭主演《倾城之恋》不是同一个事情啊！ 看了《阿甘正传》，“生活就像一盒巧克力，你永远不知道下一颗是什么味道。“这是阿甘对生活最好的诠释。小时候，有人骑着自行车羞辱他，他只会跑，拼命的跑，只会再公路上跑。长大后，别人骑着车想打他，阿甘还是跑，但是这次阿甘学会了网草坪上跑！就被大学看上，进入运动大学，还通过参加比赛赢得了冠军，然后，阿甘当兵了，再后来，打乒乓球很出色。阿甘似乎做什么都能成功，也许心无旁骛，最笨的方法+时间=收获。 我觉得很心酸的是，当珍妮告诉他有儿子时候，阿甘问，”他聪明吗“？ ¶2019第四周安排 改论文，改变自己的办事效率喔，拒绝重复工作 编程能力 慢慢的做事情，先慢后快， 生活、学习、交友、文采 2019-第三周读书笔记 这次读了《极简思维：颠覆传统思维模式的极简法则》作者：S.J斯科特 巴里.达文波特 我们生活充满了各种诱惑、杂乱信息、导致了生活的混乱，产生知识焦虑、年龄危机、人际关系的淡化。作者给我们介绍了许多问题、许多的解决方法，让我们这个信息爆炸的时代可以过的充实些。 每天睡8个小时、还剩下16个小时，在减去2个小时解决个人卫生和饮食，那么还有14个小时，一个星期98个小时。那么98个小时，你投入在哪里呢？ 总的来说，这本书传达的东西，我还是很喜欢的，极简主义者，少不得也多不得！！！！！！！！！！！！！！！ ¶读《拆掉思维里的墙》 摘录 ：我们的生活也由三个支架组成：自我、家庭与团体和职业。这样的支架支撑着我们的灵魂，它在记录我们的生命。我们一直都在调整着三个位置的平稳，使之成为最稳固的联动三脚架。 这句大概是结合我的经历，最具有感悟的。因为一旦走出大学，这三者才开始真正的组成我们的生活。 古典老师，从职业、成功学、爱情、家庭等等不同的案例，给我分析了大多数人会面临的无形的”墙“，给了我们如何拆掉这些墙的方法。但是呢，对于古典老师的爱情观点，我并不是很赞同，因为呢，那些愿意陪你度过余生的人付出的感情，是如此的廉价吗？有的人既可以是白玫瑰，也可以红玫瑰啊！ ¶2019年第二周安T排 每天两个小时阅读论文或者专业书籍的阅读 开题报告修改和PPT制作（3h) 《拆掉思维里面的墙》（3h) 看哈利波特（一集） 2018年的总结 小小的悔恨与遗憾 大三下，在课堂上，打了半学期的游戏 生活还是不规律，超喜欢深夜逛知乎、刷B站 额头上，不停的冒着痘痘啊 英语单词量在下降ing 运动量在降低喔 很讨厌洗衣服 相比于上一年进步的方面 愿意去承担更多的责任 更乐意去交流 越来越重视健康style 不会随意发泄自己的情绪了 更加认识到自身的优势与劣势了 感到愉快的事情 知道自己想要什么，知道自己在做什么 整理完了大学期间所有的东西，往事不堪回首， 但也只能是柳暗花明又一村。 能读研究生了 聊聊2019年的点点期许 学习上 多看19场知乎live 阅读10本书籍，书单也有了 在专业学习上，希望有所提升咯 生活中 早睡早起身体好 看十部美剧，尽管我最大的兴趣是睡觉 时常更新歌单，不想在一年里面都是相同的旋律 静静静静静静静 合理安排 折星星 番茄闹钟 偶尔听听 TED 技术 清理下了github 仓库 重新更新了 github page 多读、多写、多想]]></content>
      <categories>
        <category>读书日常</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MayMay]]></title>
    <url>%2F2019%2F02%2F22%2FMayMay%2F</url>
    <content type="text"><![CDATA[https://www.kaggle.com/dgawlik/house-prices-eda/data https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python]]></content>
      <tags>
        <tag>wan</tag>
      </tags>
  </entry>
</search>
