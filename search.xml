<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[国际和国内标准]]></title>
    <url>%2F2020%2F07%2F17%2F%E7%A7%91%E7%A0%94-%E5%90%84%E8%A1%8C%E5%90%84%E4%B8%9A%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[GB:国标 行业分类 国民经济行业分类与代码（GB/4754-2011）， 国民经济行业分类。A农、林、牧、渔业；B采矿业；C制造业；D电力、热力、燃气及水生产和供应业；E建筑业；F批发和零售业；G交通运输、仓储和邮政业；H住宿和餐饮业；I信息传输、软件和信息技术服务业；J金融业；K房地产业；L租赁和商务服务业；M科学研究和技术服务业；N水利、环境和公共设施管理业；O居民服务、修理和其他服务业；P教育；Q卫生和社会工作；R文化、体育和娱乐业；S公共管理、社会保障和社会组织；T国际组织。 产业 （二）三次产业分类法。这种分类法是根据社会生产活动历史发展的顺序对产业结构的划分。产品直接取自自然界的部门称为第一产业，对初级产品进行再加工的部门称为第二产业，为生产和消费提供各种服务的部门称为第三产业。这种分类方法成为世界上较为通用的产业结构分类方法。 我国的三次产业划分是： 第一产业：农业（包括种植业、林业、牧业和渔业） 第二产业：工业（包括采掘业，制造业，电力、煤气、水的生产和供应业）和建筑业 第三产业：除第一、第二产业以外的其他各业。根据我国的实际情况，第三产业可分为两大部分：一是流通部门，二是服务部门。具体可分为四个层次： 第一层次：流通部门，包括交通运输、仓储及邮电通信业，批发和零售贸易、餐饮业。 第二层次：为生产和生活服务的部门，包括金融、保险业，地质勘查业、水利管理业，房地产业，社会服务业，农、林、牧、渔服务业，交通运输辅助业，综合技术服务业等。 第三层次：为提高科学文化水平和居民素质服务的部门，包括教育、文化艺术及广播电影电视业，卫生、体育和社会福利业，科学研究业等。 第四层次：为社会公共需要服务的部门，包括国家机关、政党机关和社会团体以及军队、警察等。 （三）资源密集程度分类法 这种产业分类方法是按照各产业所投入的、占主要地位的资源的不同为标准来划分的。根据劳动力、资本和技术三种生产要素在各产业中的相对密集度，把产业划分为劳动密集型、资本密集型和技术密集型产业。 1、劳动密集型产业。指进行生产主要依靠大量使用劳动力，而对技术和设备的依赖程度低的产业。其衡量的标准是在生产成本中工资与设备折旧和研究开发支出相比所占比重较大。一般来说，目前劳动密集型产业主要指农业、林业及纺织、服装、玩具、皮革、家具等制造业。随着技术进步和新工艺设备的应用，发达国家劳动密集型产业的技术、资本密集度也在提高，并逐步从劳动密集型产业中分化出去。例如，食品业在发达国家就被划入资本密集型产业。 2、资本密集型产业。指在单位产品成本中，资本成本与劳动成本相比所占比重较大，每个劳动者所占用的固定资本和流动资本金额较高的产业。当前，资本密集型产业主要指钢铁业、一般电子与通信设备制造业、运输设备制造业、石油化工、重型机械工业、电力工业等。资本密集型工业主要分布在基础工业和重加工业，一般被看作是发展国民经济、实现工业化的重要基础。 3、技术密集型产业。指在生产过程中，对技术和智力要素依赖大大超过对其他生产要素依赖的产业。目前技术密集型产业包括：微电子与信息产品制造业、航空航天工业、原子能工业、现代制药工业、新材料工业等。 当前以微电子、信息产品制造业为代表的技术密集型产业正迅猛发展，成为带动发达国家经济增长的主导产业。因此可以说，技术密集型产业的发展水平将决定一个国家的竞争力和经济增长的前景。 职位 《职业分类与代码》 参照国际标准和方法，1986年，我国国家统计局和国家标准局首次颁布了中华人民共和国国家标准《职业分类与代码》（GB6565-86），并启动了编制国家统一职业分类标准的宏大工程。这次颁布的《职业分类与代码》将全国职业分为8个大类、63个中类、303个小类。1992年，原国家劳动部会同国务院各行业部委组织编制了《中华人民共和国工种分类目录》，这个目录根据管理工作的需要，按照生产劳动的性质和工艺技术的特点，将当时我国近万个工种归并为分属46个大类的4700多个工种，初步建立起行业齐全、层次分明、内容比较完整、结构比较合理的工种分类体系，为进一步做好职业分类工作奠定了坚实基础。 《中华人民共和国职业分类大典》 20世纪90年代中期，随着社会主义市场经济体制的逐步建立和科学技术的迅猛发展，我国的社会经济领域发生了重大变革，这对人力资源管理提出了新的要求。为此，国家提出要制定各种职业的资格标准和录用标准，实行学历文凭和职业资格两种证书制度。《中华人民共和国劳动法》中明确规定：“国家确定职业分类，对规定的职业制定职业技能标准，实行职业资格证书制度。”根据社会经济发展的需要，1995年2月，劳动和社会保障部、国家统计局和国家质量技术监督局联合中央各部委共同成立了国家职业分类大典和职业资格工作委员会，组织社会各界上千名专家，经过四年的艰苦努力，于1998年12月编制完成了《中华人民共和国职业分类大典》，并于1999年5月正式颁布实施。 《中华人民共和国职业分类大典》是我国第一部对职业进行科学分类的权威性文献。由于它的编制与国家标准《职业分类与代码》（GB6565-86）的修订同步进行，相互完全兼容，因此，它本身也就代表了国家标准。《中华人民共和国职业分类大典》的重要贡献在于，它在广泛借鉴国际先进经验（特别是《国际标准职业分类》ISCO-88）和深入分析我国社会职业构成的基础上，突破了过去以行业管理机构为主体，以归口部门、单位甚至用工形式来划分职业的传统模式，采用了以从业人员工作性质的同一性作为职业划分标准的新原则，并对各个职业的定义、工作活动的内容和形式、以及工作活动的范围等作了具体描述，体现了职业活动本身固有的社会性、目的性、规范性、稳定性和群体性的特征。《大典》科学地、客观地、全面地反映了当前我国社会的职业构成，填补了我国长期以来在国家统一职业分类领域存在的空白，具有深远的意义和广泛的应用领域。 China has released a new occupational classification system to keep pace with a fast-changing employment （2015版） [中华人民共和国职业分类大典（2015版）] 《中华人民共和国职业分类大典》把我国职业划分为由大到小、由粗到细的四个层次：大类（8个）、中类（66个）、小类（413个）、细类（1838个）。细类为最小类别，亦即职业。8个大类分别是： 第一大类：国家机关、党群组织、企业、事业单位负责人，其中包括5个中类，16个小类，25个细类； 第二大类：专业技术人员，其中包括14个中类，115个小类，379个细类； 第三大类：办事人员和有关人员，其中包括4个中类，12个小类，45个细类； 第四大类：商业、服务业人员，其中包括8个中类，43个小类，147个细类； 第五大类：农、林、牧、渔、水利业生产人员，其中包括6个中类，30个小类，121个细类； 第六大类：生产、运输设备操作人员及有关人员，其中包括27个中类，195个小类，1119个细类； 第七大类：军人，其中包括1个中类，1个小类，1个细类； 第八大类：不便分类的其他从业人员，其中包括1个中类，1个小类，1个细类。 从职业结构看，职业的分布有三个特点：第一，技术型和技能型职业占主导。占实际职业总量的60.88%的职业分布在“生产、运输设备操作人员及有关人员”这一大类，它们分属我国工业生产的各个主要领域。从这类职业的工作内容分析，其特点是以技术型和技能型操作为主。第二，第三产业职业比重较小，仅占实际职业总量的8%左右。三大产业中的职业分布，以第二产业的职业比重最大。第三，知识型与高新技术型职业较少。现有职业结构中，属于知识型与高新技术型的职业数量不超过总量的3%。 国家标准产业分类 国家标准 ¶全国标准信息公共服务平台 http://std.samr.gov.cn/ ¶中华人民共和国中央人民政府 http://www.gov.cn/fuwu/bzxxcx/bzh.htm 国家标准信息查询 ¶中华人民共和国民政部 http://www.mca.gov.cn/article/sj/tjbz/b/ 行业分类标准 ¶中华人民共和国国家档案局 http://www.saac.gov.cn/daj/hybz/dabz_list.shtml ¶国家标准化管理委员会 http://www.sac.gov.cn/ ¶行业标准 中华人民共和国工业和信息化部 工业和信息化部标准库，提供化工行业、石化行业、黑色冶金行业、有色行业、建材行业、机械行业、船舶行业、轻工行业、纺织行业、兵器行业、核工业行业、电子行业、通信行业 、化工行业、船舶行业、民爆行业、轻工行业、化工行业、石化行业、有色行业、黑色冶金行业、建材行业、稀土行业、机械行业、汽车行业、船舶行业、轻工行业、食品行业、纺织行业、包装行业、电子行业 、电子行业、机械行业标准共33个项目标准 http://www.miit.gov.cn/n1146312/index.html ¶常用标准分类 《中华人民共和国行政区划代码》 《国民经济行业分类和代码》 《职业分类标准》 《全国工农业产品(商品、物资)分类与代码》 国际 ¶美国标准职业分类系统 职业分类，全球最普及的就是美国标准职业分类系统（Standard Occupational Classification 简称SOC）。这个职业分类系统被几乎所有英语国家的政府机构直接引用，甚至包括亚洲多个非英语国家。 ¶国际行业标准 International Standard Industrial Classification 联合国颁布了&lt;&lt;全部经济活动的国际标准产业分类&gt;&gt;（ISIC）。 https://unstats.un.org/unsd/classifications/Econ/ISIC.cshtml 中国标准信息服务网 可查询各国标准 https://www.sacinfo.cn/ 地方标准 上海统计局给了较新的国家标准文件 http://tjj.sh.gov.cn/gjbz/index.html 统计局专栏 http://www.stats.gov.cn/tjsj/tjbz/ 查询方法 国际 http://www.iso.gov 中国 http://www.sac.gov.cn/]]></content>
      <categories>
        <category>计算社会经济学</category>
        <category>科研</category>
      </categories>
      <tags>
        <tag>各行各业标准</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PageRank算法]]></title>
    <url>%2F2020%2F07%2F15%2FPageRank%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PageRank是一种网页排序算法，基于页面的质量和数量。可应用于评估网页节点重要性。 PageRank算法PageRank,即\网页排名**，又称网页级别、Google左侧排名或佩奇排名。PageRank是Google用于用来标识网页的等级/重要性的一种方法，是Google用来衡量一个网站的好坏的唯一标准。 假设 数量假设: 如果一个页面节点入链数量越多，则这个页码越重要。 质量假设：指向页面A的入链质量不同，考虑权重的影响，则这个页面越是重要。 算法求解 第一阶段：通过网页链接关系构建起Web图，初始每个页面相同的PageRank值，再通过若干轮得到每个页面的最终pagerank. 每一轮更新页面PageRank得分的计算方法 权重 PR(T)/L(T)\\ where PR(T)的PageRank值，L(T)为T的出链数目修正$L(T)$为0的情况，孤立网页，使得很多网页能被访问到。$q = 0.85$ PR(A) = (\frac{PR(B)}{L(B)}+\frac{PR(C)}{L(C)}+\dots)q+1-q其他网络属性度量方法Centrality indices: degree, betweenness, and closeness. reference提出者： The anatomy of a large-scale hypertextual Web search engine https://en.wikipedia.org/wiki/PageRank]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科研-专业词汇]]></title>
    <url>%2F2020%2F07%2F14%2F%E7%A7%91%E7%A0%94-%E4%B8%93%E4%B8%9A%E8%AF%8D%E6%B1%87%2F</url>
    <content type="text"><![CDATA[词汇常用动词investigate estimate reveal quantify report utilize illustrates be consistent with conduct examine highlight 常用名称mega-city panel dataset medium and small cities provincial capital gap East, Central, West, and Northeast studies on intra-regional inter-regional relative mechanism prefecture level productivity regional disparity patterns of mobility review on urbanization macro-level micro-level coefficient policymakers China City Statistical Yearbooks published by the National Bureau of Statistics China Regional Economic Statistical Yearbook 短语over the period of 1997 to 2012 using China’s city-level data from 2003 to 2015 literature on Methodsuggest measure indicate represent as follows form metrics Correlation and Datacome+time+content This paper constructs a unique data set to describe the HSR program in China from 2003 to 2015, including all rail lines with a maximum speed of 250 km/h or more. This paper uses data from multiple sources. the log of employment Result图表aiming+method summary The pre- and post-HSR trends estimations are reported in Table 4. locaton Columns (1) to (3) report /show/represent/ Columns (1)–(4) In column (4) results coefficients compared indicate extend privide support compare be Statistically significant at the 0.05 confident level 句子目的 Understanding the effect of HSR projects on the urban economy is important for a number of reasons. This paper aims to provide empirical evidence of how China’s High-Speed Railway program, an important infrastructure improvement, affects urban sectoral employment across cities 陈述现状 Most of the extant literature seeks to provide evidence of how reducing transportation costs affects the regional economy in general (Redding and Turner, 2015), assessing roads and various indicators of the urban economy. 引用 format: Problem-Result-Resourse Chandra and Thompson (2000) conducted the first study on the effects of the interstate highway system on aggregate annual earnings by one digit SIC code, and found a marginally positive effect over twenty-four years in the finance, insurance, real estate, and retail and service sectors.]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[空间分析]]></title>
    <url>%2F2020%2F07%2F13%2F%E7%A9%BA%E9%97%B4%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[The geographically weighted regression modelThe ideaOLS V.S GWRGWR的结果包括对回归的每个样本的信息。特别是每个解释变量的回归系数，体现了与被解释变量的相关性。 OLS的结果，反映了与因变量的关系强度。只是平均效果 The format Achieving &amp; Explaining这个博主解析的非常清楚： https://blog.csdn.net/allenlu2008/article/details/59480437 ArcGIS 莫兰指数Moran’s I 指数 可以进行具备相关性和全局相关性分析。 Moran， P． A． P． 1950． Notes on continuous stochastic phenomena． Biometrika 37， 17-23 Geary， R． 1954． The contiguity ratio and statistical mapping． The Incorporated Statistician 5， 115-145．]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科研工具]]></title>
    <url>%2F2020%2F07%2F13%2F%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[地图专题软件Acrmap, Geoda 地图可视化径向图、地图 空间分析空间相关性分析 绘图绘图软件— GephiStep 数据准备 Videohttps://www.udemy.com/course/gephi/learn/lecture/67426#overview 交通https://blog.csdn.net/yirry/article/details/79233176?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare 官网https://gephi.org/users/download/ 其他python https://networkx.github.io/documentation/stable/auto_examples/subclass/plot_antigraph.html#sphx-glr-auto-examples-subclass-plot-antigraph-py]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>科研工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Research-Career]]></title>
    <url>%2F2020%2F07%2F08%2FResearch-Career%2F</url>
    <content type="text"><![CDATA[是不是可以考虑读博士后讷！！！！ 2020-7-20在处理和分析的过程中，你永远不知道答案是什么。猜想和发现有距离，最终解决的就是减小的那部分差距。 2020-7-18数据计算；(聚集性、多样性) 2020-7-17数据汇总 研一：科研入门阶段：绝知此事要躬行2020-7-16 from 2019-9 to 2019-10 看了第一篇英文就是关于土地扩张的，不知如何建模的。当时钻进数据处理上了，还找了几篇同类文章。还看了许多可达性度量方面的东西，不能说技术含量，但是价值和意义是有的。大概看了20篇左右。基本没有什么收获。基本上看着前言不搭后语。知识量不足。 from 2019-11-2020-1 基本上看了很多中文的，只是关心结果。造成大量时间的浪费。其中还有10-20中文的。有点急功近利的感觉。 from 2020-1-20204 练习写作(多年后，回过头看，肯定觉得这是什么垃圾玩意啊)，看别人的写作，感觉看一篇高质量的文章，基本上就知道研究进展了。。。。。忧伤忧伤！所以呢？现在基本上是掌握这方面的文献思路了。 from 2020-4-2020-7 处理json 格式的数据和城市层面的数据。积累了许多容易获取的数据。 还找了副业，价格也不错，感觉自己干什么都可以，听别人安排（就本科知道时间序列的方法，机器学习）所以说，人有事没事的，多看看世界，多学点傍身技能。哪里都能混口饭吃。 2020-7-16 计量经济学，想不到结果如此显著，看见希望了！ 2020-7-13—2020-7-15 数据处理； 时间序列预测 时间序列xgboost. 2020-7-12 什么是出色的科研&amp;数据处理 阅读了一些公众号，关于科研文献调研的 阅读文献并不需要读大量的文献，而是要精读高质量而且相关的论文。只要找到这些论文，加以理解和分析，用批判性思维、创新思维去总结和分析问题，就能提炼出优秀的科研想法。我的习惯是花大量的时间去初步筛选论文，看题目、摘要、作者和作者单位等，当我点击下载时，我大概就知道了这篇论文的主要内容，在后面阅读全文时，就很有针对性，收获就会很大。这样筛选论文，让我只要用简单几个文件夹管理即可，而且让我非常熟悉这些论文的作者，也就知道了哪些是我的国际同行，便于邮件和会议见面交流。 往往出色的引言就交代了发展过程。 找出最厉害的文献和学者，读他们的文献。 处理城市层面数据（心累，如果直接买多好啊，还要直接弄格式，编程统一化） 2020-7-11 处理数据 数据被加密了，手动解密。呜呜呜。基本上搞完了 2020-7-9&amp;10 论文写作(Method) 方法部分算很机械。句子(很中文)-&gt;段落(连贯性差)-很难 语言风格。 文献管理 2020-7-9 1．要写好科研论文，必须先养成读英文文章的习惯，争取每天30-60分钟。刚开始可以选择以读英文报纸、英文新闻为主，逐渐转为读专业杂志。我会在近期专门写一篇博客文章介绍一套行之有效的增强读专业杂志能力的办法。 2．写科研论文，最重要的是逻辑。逻辑的形成来自对实验数据的总体分析。必须先讨论出一套清晰的思路，然后按照思路来做图(Figures)，最后才能执笔。 3．具体写作时，先按照思路（即Figures）写一个以subheading为主的框架，然后开始具体写作。第一稿，切忌追求每一句话的完美，更不要追求词语的华丽，而主要留心逻辑（logic flow），注意前后句的逻辑关系、相邻两段的逻辑关系。写作时，全力以赴，尽可能不受外界事情干扰（关闭手机、座机），争取在最短时间内拿出第一稿。还要注意：一句话不可太长。 4．学会照葫芦画瓢。没有人天生会写优秀的科研论文，都是从别人那里学来的。学习别人的文章要注意专业领域的不同，有些领域（包括我所在的结构生物学）有它内在的写作规律。科研文章里的一些话是定式，比如 “To investigate the mechanism of …, we performed …”, “These results support the former, but not the latter, hypothesis …”, “Despite recent progress, how … remains to be elucidated …” 等等。用两次以后，就逐渐学会灵活运用了。在向别人学习时，切忌抄袭。在美国一些机构，连续7个英文单词在一起和别人的完全一样，原则上就被认为抄袭（plagiarism）。 5．第一稿写完后，给自己不要超过一天的休息时间，开始修改第二稿。修改时，还是以逻辑为主，但对每一句话都要推敲一下，对abstract和正文中的关键语句要字斟句酌。学会用“Thesaurus”（同义词替换）以避免过多重复。第二稿的修改极为关键，再往后就不会大改了。 6．第二稿以后的修改，主要注重具体的字句，不会改变整体逻辑了。投稿前，一定要整体读一遍，对个别词句略作改动。记住：学术期刊一般不会因为具体的语法错误拒绝一篇文章，但一定会因为逻辑混乱而拒绝一篇文章。 2020-7-8 数据准备 开始一段新旅程！羡慕博学渊博的科研工作者。无论是一年，还是n年，立个flag：希望自己终有一天也能达到那样的高度。 记住：这注定是孤独与激勇的旅程。 本科：科研准备阶段：手把手教学2017-2019 西南科技大学理学院东九，马新老师的带领。 学了很多东西！]]></content>
      <tags>
        <tag>科研日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计量经济学]]></title>
    <url>%2F2020%2F07%2F03%2F%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[资料 计量经济学：陈强老师的书籍非常好！ https://www.econometrics-with-r.org/11-2-palr.html http://hadley.nz/index.html https://sites.google.com/site/econometricsacademy/econometrics-software/stata Day Ox 01主要是想拉通一个完整的流程，拉通基本的计量分析结果。在这个过程中，主要参考了《中国工业经济》提供的源代码里面的命令，网上百度的资料。这方面的资料太稀少且不系统。help大法好啊！拉通跑完一个别人的程序，基本上就基准回归可以用了。 Day Ox 02就是把DID,PSM-DID,IV方法看别人的，学会了。还有绘图功能一并学会了。 Introduction to StataPrograms – Stata do files (.do) Data files – stata data files (.dta) and csv files Data editor – where data are imported to Log files - where output is saved Load DataExcel导入edit-&gt;Data Editor -&gt;Excel Summarize可分组描述。 tabstat anad, by(year) s(sum count) tabstat是Stata自带的程序命令，Stata的程序格式通常都是这样安排的 anad是标记公司有没有分析师跟踪的变量 by(year)是分年统计的意思。 s(sum count)意在输出变量anad的两个统计量，总和（sum），总观测数（count） tabstat delta_cash overinv underinv ananum cashflow fcf_p fcf_n absda size lev roa tobinq delta_std , s(count mean median sd min max) tabstat是输出描述性统计非常好用的命令 delta_cash overinv underinv ananum cashflow fcf_p fcf_n absda size lev roa tobinq delta_std是我们要进行统计的一组变量。 s(count mean median sd min max)是说我们要生成：总观测数、均值、中位数、标准差、最小值和最大值。共5项统计量。当然，如果你想生成其他统计量，可以在括号里添加，比如分位数。 eg. tabstat weight, s(mean, count) ,if foreign ==1 tabstat read write math, by(prgtype) stat(n mean sd) gen rename replace drooorder id genderlabel variable schtyp “type of school”rename gender femalegen score=read+write+mathgen score2=score^2gen pass=1 if score&gt;=150replace pass=0 if pass==.drop if read&lt;40drop schtyp stata 排序和分组 sort 升序 sort v1 v2 list gsort gsort [+|-] varname [[+|-] varname …] [, generate(newvar) mfirst] gsort +v1 -v2 3, bysort 简写 by reghdfe 回归快速ssc install reghdfe help reghdfe reghdfe depvar [indepvars] [if] [in] [weight] , absorb(absvars)[options] 固定效应i.industry, i.province 加入虚拟变量 https://www.jianshu.com/p/56285c5ff1e3 异方差稳健标准误 vce(robust) 随机扰动项和自变量有相关性 xtreg cluster(id) 交互性和分组回归的区别分组回归：没有假设，系数可不一致 gen egen使用步骤Ox 00 描述性统计 分组描述 tabstat weight, s(mean, count) ,if foreign ==1 tabstat read write math, by(prgtype) stat(n mean sd) Ox 01 基准回归 12345reg csr X1 lnsize bcash roa lev les tobinq age i.Ind i.year est store m1reg csr X2 lnsize bcash roa lev les tobinq age i.Ind i.yearest store m2esttab m1 m2 m3 m4 using esttab1.rtf, replace 123456789reg csr X1 lnsize bcash roa lev tobinq age i.Ind i.year if zy==1est store m1reg csr X1 lnsize bcash roa lev tobinq age i.Ind i.year if zy==0est store m2reg csr X2 lnsize bcash roa lev tobinq age i.Ind i.year if zy==1est store m3reg csr X2 lnsize bcash roa lev tobinq age i.Ind i.year if zy==0est store m4esttab m1 m2 m3,se scalars(N r2 F p) mtitles title(“图1”),using esttab1.rtf,replace https://mp.weixin.qq.com/s?__biz=MzIwMTQ3MTY0MA==&amp;mid=2247483904&amp;idx=1&amp;sn=5822658f03a1ee6b14cf37510287ac3e&amp;chksm=96ec21f7a19ba8e1997e9600e876976c92d6cdbfeaa068aa42cc3864dc4b43d4440bade1c2b7&amp;token=204946112&amp;lang=zh_CN#rd 自相关和序列相关性1234xtset id timextreg y x i.time, fe rxtreg y x i.time, fe r cluster(id)xtreg y x i.time, fe vce(cluster id) vce(cluster panelvar) https://cloud.tencent.com/developer/news/359411 标准误的选取1.存在异方差且观测值之间独立：vce(robust)或robust或r2.存在异方差且允许观测值组内相关、组间无关：cluster(id) 也就是常说的聚类稳健标准误，id是个体变量在xtreg,fe（固定效应模型）或xtreg,re（随机效应模型）命令下，robust和cluster(id)的命令等价。即：xtreg y x1 x2, fe robust= xtreg y x1 x2, fe cluster(id) 因为面板数据，异方差有两种可能，其一是时间序列上的，另一种是截面上的，你的是后一种。 cluster (var)说明var这个组内有相关性 reghdfe NO false_connect ,absorb(i.stkcd#i.subcityid i.stkcd#i.year i.subcityid#i.year) vce (cl tie) DID reghdfe lngraddegree lnedu lninfr lnpgdp, absorb(i.year#i.pro) vce(pro) xtreg lngraddegree lnedu lninfr lnpgdp i.year, fe vce(cluster pro) savesave “connect_simulations.dta”, replace dropdrop if sgnyea==2010 gengen market_access_g=ln(1+market_g) http://wlm.userweb.mwn.de/Stata/wstatgen.htm DIDareg Dis HSR Cash Invt Lev Size ROA Rec Age PGDP SOE i.year,absorb(company_id) robustest store m_1areg Disw HSR Cash Invt Lev Size ROA Rec Age PGDP SOE i.year,absorb(company_id) robustest store m_2esttab m_1 m_2 using baseline.rtf, replace /// b(%9.4f) star( 0.1 0.05 0.01) t(%9.4f) /// scalar(F N r2_a) nogaps /// mtitle() regress y x 执行y对单个预测变量x的常规最小二乘法回归 regress y x if ethnic==3&amp;income&gt;50 执行y对x的回归，但只使用ethnic等于3且income大于50的数据子集 predict yhat 创建一个新变量yhat，令其等于最近回归所得到的预测值 predict e, resid 创建一个新变量e，令其等于最近回归得到的残差 https://blog.csdn.net/arlionn/article/details/85244336 **动态检验**gen Dyear=year-company_work_hsrgen Before2=(Dyear==-2)lab var Before2 “2 Year Prior”gen Before1=(Dyear==-1)lab var Before1 “1 Year Prior”gen Current=(Dyear==0)lab var Current “Year of Adoption”gen After1=(Dyear==1)lab var After1 “1 Year After”gen After2=(Dyear==2)lab var After2 “2 Year After”gen After3_=(Dyear&gt;=3)lab var After3_ “3 or More Year After”areg Disw Before2 Before1 Current After1 After2 After3_ Cash Invt Lev Size ROA Rec Age PGDP SOE i.year,absorb(company_id) robustest store Dynamic1areg Dis Before2 Before1 Current After1 After2 After3_ Cash Invt Lev Size ROA Rec Age PGDP SOE i.year,absorb(company_id) robustest store Dynamic2 esttab Dynamic1 Dynamic2 using Dynamic.rtf, replace /// b(%6.4f) star( 0.1 0.05 0.01) t(%6.4f) /// scalar(N r2_a) nogaps /// mtitle() **平行趋势图**coefplot Dynamic1, keep(Before2 Before1 Current After1 After2 After3_) vertical recast(connect) lcolor(red0.45) lpattern(-) ciopts(lcolor(edkblue0.8)) mlcolor(gs6) mfcolor(white) msize(1.2) msymbol(h) yline(0,lcolor(edkblue0.6) lwidth(*1.0)) coefplot Dynamic2, keep(Before2 Before1 Current After1 After2 After3_) vertical recast(connect) lcolor(red0.45) lpattern(-) ciopts(lcolor(edkblue0.8)) mlcolor(gs6) mfcolor(white) msize(1.2) msymbol(h) yline(0,lcolor(edkblue0.6) lwidth(*1.0)) PSM-DID倾向性匹配得分 https://mp.weixin.qq.com/s?__biz=MjM5NTM4NjU2OA==&amp;mid=2650714980&amp;idx=1&amp;sn=5bafc8c230fb062d90f04709f683b5b2&amp;chksm=bef356c38984dfd54a0c1ffbf99933b7e8bac528324b6bf1ce5fce888718374bb4cc4fce70d5&amp;scene=0&amp;xtrack=1#rd IVclearuse IV_re2logit hsr near GDPA i.year,rest store IV1esttab IV1 using IV1.rtf, replace /// b(%6.4f) star( 0.1 0.05 0.01) t(%6.4f) /// scalar(N r2_p) nogaps /// mtitle()predict r # 这里就是最近一次回归duplicates drop city_name year,forcemerge 1:m city_name year using distancekeep if _merge==3drop _merge areg Disw r Cash Invt Lev Size ROA Rec Age PGDP SOE Soe2 i.year,absorb(company_id)est store m_1areg Dis r Cash Invt Lev Size ROA Rec Age PGDP SOE i.year,absorb(company_id)est store m_2 esttab m_1 m_2 using iv.rtf, replace /// b(%6.4f) star( 0.1 0.05 0.01) t(%6.4f) /// scalar(N r2_a) nogaps /// mtitle() plothttps://zhuanlan.zhihu.com/p/32432932 graph export len_wei.png,wid(800)hei(600)]]></content>
      <tags>
        <tag>计量经济</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言]]></title>
    <url>%2F2020%2F07%2F03%2FR%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[https://bookdown.org/qiyuandong/intro_r/-r-basics-2.html#section-3.3 入门： https://rc2e.com/ http://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/intro.html 全面： https://github.com/harryprince/R-Tutor 视频： 中文： https://www.youtube.com/watch?v=rPj5FsTRboE 英文：https://www.youtube.com/watch?v=32o0DnuRjfg 这个教程好： https://sites.google.com/site/econometricsacademy/econometrics-models/linear-regression https://www.youtube.com/watch?v=YMt5K68ZvjQ&amp;list=PLRW9kMvtNZOh7Xt1m5Mlhhz2wtr0tCUEE]]></content>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xgboost]]></title>
    <url>%2F2020%2F07%2F03%2FXgboost%2F</url>
    <content type="text"><![CDATA[理论部分该算法思想就是不断地添加树，不断地进行特征分裂来生长一棵树，每次添加一个树，其实是学习一个新函数，去拟合上次预测的残差。当我们训练完成得到k棵树，我们要预测一个样本的分数，其实就是根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点就对应一个分数，最后只需要将每棵树对应的分数加起来就是该样本的预测值。 boosting: https://zhuanlan.zhihu.com/p/38329631 Xgboost 就是回归树的集成 https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/ https://blog.csdn.net/github_38414650/article/details/76061893?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare https://blog.csdn.net/qq_24519677/article/details/81809157 有空再推导了 调用库Python 提供了两种库 xgboost xgboost sklearn接口 搭建模型 参数设置 GridSearchCV 调参(网格法) 调参步骤，参数范围 https://blog.csdn.net/han_xiaoyang/article/details/52665396 12345678import xgboost as xgbfrom xgboost import XGBRegressorfrom sklearn.metrics import mean_absolute_error,make_scorerfrom sklearn.grid_search import GridSearchCVfrom sklearn.cross_validation import KFold, train_test_splitfrom sklearn.datasets import load_boston https://blog.csdn.net/s09094031/article/details/94871596?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare 1sklearn.model_selection.``train_test_split test_size train_size： ​ 三种类型。float，int，None。 float：0.0-1.0之间，代表训练数据集占总数据集的比例。 int：代表训练数据集具体的样本数量。 None：设置为test_size的补。 default：默认为None。 random_state：三种类型。int，randomstate instance，None。 int：是随机数生成器的种子。每次分配的数据相同。 randomstate：random_state是随机数生成器的种子。（这里没太理解） None：随机数生成器是使用了np.random的randomstate。 种子相同，产生的随机数就相同。种子不同，即使是不同的实例，产生的种子也不相同。 shuffle：布尔值，可选参数。默认是None。在划分数据之前先打乱数据。如果shuffle=FALSE，则stratify必须是None。 stratify：array-like或者None，默认是None。如果不是None，将会利用数据的标签将数据分层划分。 若为None时，划分出来的测试集或训练集中，其类标签的比例也是随机的。 若不为None时，划分出来的测试集或训练集中，其类标签的比例同输入的数组中类标签的比例相同，可以用于处理不均衡的数据集。 x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.23, random_state=2) https://blog.csdn.net/qq_43288098/article/details/105407204?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare 参数：分开调 https://blog.csdn.net/zc02051126/article/details/46711047 https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn 模型保存https://www.fatrabbids.com/2018/10/19/xgboost%e7%9a%84%e4%bf%9d%e5%ad%98%e6%a8%a1%e5%9e%8b%e3%80%81%e5%8a%a0%e8%bd%bd%e6%a8%a1%e5%9e%8b%e3%80%81%e7%bb%a7%e7%bb%ad%e8%ae%ad%e7%bb%83/#more-235 XGBoost的特性重要性和特性选择 模型复杂度 特征数量衡量：特征重要性阙值的增加，选择特征数量减少，模型的准确率会下降。当然，特征数量的减少反而会是准确率升高，因为这些被剔除特征是噪声。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F06%2F28%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[Day1现代信息安全的基本要求： 信息的保密性 Confidentiality：防止信息泄漏给未经授权的人（加密解密技术）机密性 信息的完整性 Integrity：防止信息被未经授权的篡改（消息认证码，数字签名） 认证性 Authentication：保证信息来自正确的发送者（消息认证码，数字签名）认为 其他 不可否认性 Non-repudiation：保证发送者不能否认他们已发送的消息（数字签名） 第一章 引言涉及的知识点包括信息安全的要求（主要四个方面），密码学基本概念，安全的定义，密码算法的设计要求，古典密码（替换，代替） o密码学基本概念**,**如密码编码学、密码分析学、明文、密文、加密、解密 o对称密码体制和非对称密码体制 o古典密码体制，如置换密码、单表代换密码、多表代换密码（要会计算） 现代信息安全的基本要求： 信息的保密性 Confidentiality：防止信息泄漏给未经授权的人（加密解密技术） 信息的完整性 Integrity：防止信息被未经授权的篡改（消息认证码，数字签名） 认证性 Authentication：保证信息来自正确的发送者（消息认证码，数字签名） 不可否认性 Non-repudiation：保证发送者不能否认他们已发送的消息（数字签名） http://yuqiangcoder.com/2019/10/07/%E5%AF%86%E7%A0%81%E5%AD%A6%E6%A6%82%E8%BF%B0.html 密码学就是要通过算法和协议实现相应的功能 凯撒密码：移动2位，H K 恺撒密码 安全p无条件安全的(不可破译的)： p无论截获多少密文，都没有足够信息来唯一确定明文，则该密码是无条件安全的，即对算法的破译不比猜测有优势 p计算上安全的： p使用有效资源对一个密码系统进行分析而未能破译，则该密码是强的或计算上安全的 密码算法要求密码算法只要满足以下两条准则之一就行： （1） 破译密文的代价超过被加密信息的价值。 （2 ) 破译密文所花的时间超过信息的有用期。 满足以上两个准则的密码算法在实际中是可用的。 单表代替密码单表代替密码可分为 • 加法密码 • 乘法密码 • 仿射密码 古典密码置换密码 单表代替密码算法 多表代替密码算法 第二章 流密码一次一密，流密码，密钥流三个概念。 o流密码基本概念、特点 o线性反馈移位寄存器 oRC4 一次一密（理想） •优点： •密钥随机产生，仅使用一次 •无条件安全 •加密和解密为加法运算，效率较高 •缺点： •密钥长度至少与明文长度一样长，密钥共享困难，不太实用 流密码密码体制 序列密码 •流密码的基本思想 •利用密钥k产生一个密钥流 •密钥流 •由密钥流发生器 f 产生： Ø内部记忆元件的状态σi独立于明文字符的叫做同步流密码，否则叫做自同步流密码。 密码分析学的目标在于破译（ BC ） A. 明文 B. 密文 C. 密钥 D. 算法结构 保密通信系统的安全威胁 保密通信的安全威胁： 被动攻击：窃听，嗅探流量分析等，主要是破坏消息的机密性； 主动攻击：中断，篡改，假冒等。 中断破坏了信息的可用性 篡改破坏了信息的完整性 假冒破坏了真实性（认证） 所以保密通信系统的安全需求有： 机密性——采用加密机制 完整性——采用完整性验证机制，如Hash函数，消息认证码 真实性——采用认证机制，如数字签名，认证协议 中断——用密码学的技术没有太好的办法（这是我个人的理解） 古典密码学 置换密码：又称换位密码，加密过程中明文的字母保持相同，但是顺序被打乱。只要把位置恢复，就能得到明文。 代换密码：明文中的每一个字符被替换成密文中的另一个字符。接收者对密文做反向替换就可以恢复明文。 多名或同音代替密码 多字母代替密码 多表代替密码 总结古典密码学的特点：加密对象；方法；保密内容；破解； 计算强度小 出现在 DES 之前 数据安全基于算法的保密。这和现代密码有很大的差距，只要知道加密方法，就能轻易的获取明文。现代的密码基于秘钥的加密，算法都是公开的，而且公开的密码算法安全性更高，能被更多人评论和使用，加强漏洞的修补。 以字母表为主要加密对象。古典密码大多数是对有意义的文字进行加密，而现代密码是对比特序列进行加密。这也是现代密码和古典密码的区别，而且古典密码的分析方法也是用字母频率分析表来破解的。 替换和置换技术 密码分析方法基于字母与字母组合的频率特性以及明文的可读性 现代密码学 1976：由 Diffie 和 Hellman 在《 密码学的新方向》（《New Directions in Cryptography》）提出了公钥密码学体制的思想 1977年：美国国家标准局颁布数据加密标准 DES（Data Encryption Standard） 1978年：第一个公钥算法 RSA 算法（由 Ron Rivest、Adi Shamir 和 Leonard Adleman 的姓氏首字母组成） 现代密码学主要有三个方向：私钥密码（对称密码）、公钥密码（非对称密码）、安全协议。 私钥密码也称对称密码，是对文字的加密转换成对比特序列的加密（相对于古典密码），用同一个密钥进行加密和解密操作，这个密钥发送方和接收方都是要保密的，所以称为私钥密码。它的两个基本操作就是代换和置换就是来源于古典密码学的。 对称密码有两个设计原则，一个是扩散（Diffusion）：明文的统计结构被扩散消失到密文的长程统计特性，使得明文和密文之间的统计关系尽量复杂。 另一个是混乱（confusion）：使得密文的统计特性与密钥的取值之间的关系尽量复杂。 对称密码的代表有 DES 算法和 AES 算法， 公钥密码 DH 密钥交换协议 RSA 算法是第一个公钥密码算法，也是第一个数字签名算法。 p q pi(n) =(p-1)(q-1);与n互质的书&lt;=n 选e 与pi(n)最大公约数1，互质， 找d，e*d/pi(n)=1 (n,e)共（n,d)私钥 a^emod n =b b^d mod n=c 根据以上密钥对的生成过程： 如果想知道 d 需要知道欧拉函数 φ(n) 如果想知道欧拉函数 φ(n) 需要知道 P 和 Q 要知道 P 和 Q 需要对 n 进行因数分解。 对于本例中的 4757 你可以轻松进行因数分解，但对于大整数的因数分解，是一件很困难的事情，目前除了暴力破解，还没有更好的办法，如果以目前的计算速度，破解需要50年以上，则这个算法就是安全的 椭圆曲线加密算法，简称ECC，是基于椭圆曲线数学理论实现的一种非对称加密算法。相比RSA，ECC优势是可以使用更短的密钥，来实现与RSA相当或更高的安全，RSA加密算法也是一种非对称加密算法 重合 四、同余运算同余就是有相同的余数，两个整数 a、 b，若它们除以正整数 m所得的余数相等，则称 a， b对于模m同余。 乘法逆元； 六、乘法逆元在模7乘法中： 1的逆元为1 (1*1)%7=1 2的逆元为4 (2*4)%7=1 3的逆元为5 (3*5)%7=1 4的逆元为2 (4*2)%7=1 5的逆元为3 (5*3)%7=1 6的逆元为6 (6*6)%7=1 https://zhuanlan.zhihu.com/p/101907402 第三章现代密码o分组密码基本概念、特点 oFeistel 网络 oDES，密钥长度、分组长度、S盒、多重DES o分组密码的四种运行模式 oAES，密钥长度、分组长度 太难记住了，原理也太难了 Day 2 现代密码一次性密码Frank Miller 在1882 年提出了一次性密码（One-time pad）的概念——加密：将消息和私钥进行异或运算得到密文；解密：将密钥和密文进行异或运算得到原消息，这个过程类似于前面提到的 a ⊕ b ⊕ a = b 。一次性密码的定义如下所示： 无条件安全 密钥随机产生的，只能用一次 异或 1+1 =0 ，0+1 = 1 共享密钥难 流密码体制密钥k,产生密钥流（发 同步流密码（状态无光） 一.加密方法的分类：按照不同的标准有不同的分类标准：1.按照密钥的特征不同，可以分为对称密码与非对称密码。2.按照加密方式的不同，可以分为流密码和分组密码。3.非对称密码均属于分组密码。 1.流密码。又名序列密码。明文称为明文流，以序列的方式表示。加密时候，先由种子密钥生成一个密钥流。然后利用加密算法把明文流和密钥流进行加密，产生密文流。流密码每次只针对明文流中的单个比特位进行加密变换，加密过程所需要的密钥流由种子密钥通过密钥流生成器产生。流密码的主要原理是通过随机数发生器产生性能优良的伪随机序列，使用该序列加密明文流（按比特位加密），得到密文流。由于每一个明文都对应一个随机的加密密钥，所以流密码在绝对理想的条件下应该是算一种无条件安全的一次一密密码。机密流程：种子密码-&gt;随机数发生器-&gt;密钥流明文流-&gt;(通过密钥流)-&gt;加密变换-&gt;密文流设明文流为：m=m1m2·····mi·····，密钥流由密钥流发生器f产生：zi=f（k，ai），ai指加密器存储器在i时刻的状态，f是由种子密钥k和ai产生的函数，设最终的密钥流为k=k1k2···ki·····，加密结果为c=c1c2····ci·····=Ek1（m1）.。。。Eki（mi），解密结果为m=Dk1（c1）Dk2（c2）···Dki（ci）=m1m2···mi，无论加密解密，其关键都是密钥流。 2.流密码的分类分为同步流密码和自同步流密码3.流密码的特性：极大的周期，良好的统计特性，抗线性分析。4.流密码的安全性取决于密钥流的安全性，要求密钥流序列有较好的随机性。5.不明密钥的人如何对流密码进行分析。这种密钥流一般都是周期的，做到完全随机是困难的，这样伪随机序列，理论上是可以分析出来的。举个例子。敌方截获了密文串：101101011110010明文串：011001111111001密钥流：110100100001011可以根据前10个比特建立如下方程 密钥流生成器： 高要求关键 要求： 游程：周期 0.1 发聩函数 产生密钥流的要求，方法、设计 反馈移位寄存器 ​ ：寄存器 ​ ： 返回函数 初始状态 线性反馈移位寄存器 快 周期“ 输出形状：发聩函数 算法 RC4 流密码是一次一密吗？不是 RC4没有实现的m-序列不可约《2^n-1 充要 本原多项式 反馈函数形式 伪随机性 求你12 Day 3 3_13 分组密码应用设计结构原理安全性原则混淆原则 扩散原则 算法要求分组长度足够大 密钥量足够大 DES算法56-64 IBM第一个商业 后面出现了AES 算法框图 IP 初始置换 论函数 16论 分左右32bit 公式：函数（R,轮密钥） S盒 输入六位，8个盒子 输出32bit step1; 32bit-48bit() 选择扩展运算 E 8*4-》两端 置换 S盒 4*16 选择压缩运算 ​ 输入输出 ​ 输入：6bit 二进制-》十进制 确定位置 P盒置换 32 -32 密钥编排 置换-》两组-》循环左移》16轮密钥 性质：互补性和弱密钥性 2DES 56+1 = 57 中间人相遇工具 3DES 分组密码的工作模式 为什么？分组长度是固定，而数据长度和格式是不同的， 电码本模式 密码分组链接模式 ​ CBC加密 完整性（认证码生成）加密，对比 明文校验码-》CBC(M.r)&gt;对比 解决：明文统计规律隐藏 工作模式 2 数据格式： ​ 字节、比特、等等故事 分组密码概述共享密钥 IV 有限域的基本概念单位元：加法 逆元：乘法 AES字节为处理单元 8bits 加法：mod 2 多项式除法 8 4 3 1 0 的末多项式取模 多项式运算 128 128，192，256 S-按列 四个基本做出 10 12 14 s:16 字节代换 She 16*16 S里面查表代换 二进制 十六进展 求逆 混淆效应 乱了 行移位 ​ 循环左移 列混淆 ​ 每一列矩阵现场 ​ 看成多项式 ​ 矩阵选择 轮密钥加 异或：子密钥 居住 ​ 初始密钥， AES ​ 四个位-》一个字节-》16进制 一个字节=》两个十六进数 密钥扩展算法 逆S盒 Day 4 现代密码学 3-27公钥：密钥管理， 非对称密码体制 密钥对 pk sk 加密：公钥 优势： ​ 密钥分发 ​ 密钥管理 ：1 N-1 ​ 开放系统 RSA加密算法数学知识 ​ 算法 大数据分解 密钥生成 最大公因子和乘法逆元的计算方法。 https://blog.csdn.net/boksic/article/details/7014386 https://blog.csdn.net/a745233700/article/details/102341542?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5 https://blog.csdn.net/weixin_34138377/article/details/92199465?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4 https://blog.csdn.net/weixin_41482303/article/details/85417302?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 签名 证书 https://blog.csdn.net/weixin_34007879/article/details/85528967?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2]]></content>
  </entry>
  <entry>
    <title><![CDATA[English-Daily]]></title>
    <url>%2F2020%2F06%2F23%2FEnglish-Daily%2F</url>
    <content type="text"><![CDATA[2020-7-6coincide with v. 与…相符 stalk v. 潜近（猎物或人）；（非法）跟踪；怒冲冲地走；趾高气扬地走 n. 秆；柄；（叶）柄；（花）梗 verge Bella was on the verge of tears when she heard the news. 听到这个消息时，贝拉差点就要哭了。 resistant adj. 抵制的，反抗的，抗拒的；有抵抗力的；抵抗…的；不受……损害的 People are usually resistant to change. 人们通常抗拒改变。 liar The tall guy was a notorious liar. 那个高个子是个臭名昭著的骗子。 politics n. 政治；政治事物（活动）；政见；权术 oblige (以法律、义务等)强迫, 迫使; 帮忙, 效劳; [常用被动]使感激; 使(行为等)成为必要 phrase. (feel obliged to do sth.)觉得有义务做；不得不做 I felt obliged to leave after such an unpleasant quarrel. 发生了这样不愉快的争吵之后，我觉得有必要离开。 2020-7-1jelly n. 果冻；肉冻；果酱；胶状物，胶凝物；轻便塑料鞋 oval adj. 椭圆形的；卵形的 n. 椭圆形；卵形 rigorous /‘rɪɡərəs/ adj. 谨慎的，细致的；严格的，严厉的 He makes a rigorous study of the plants in the area. 他对该地的植物进行了缜密的研究。 ultimately UK/‘ʌltɪmətli/ adv. 最终, 最后, 归根结底, 终究 Everything will ultimately depend on what is said at the meeting. 一切将最终取决于会议的内容。 sturdy UK/‘stɜːdi/ adj. 结实的，坚固的；强壮的；健壮的；坚决的，顽强的 broaden UK/‘brɔːdn/ You should broaden your experience by travelling more. 你应该多到各地走走以增广见识. broaden the horizon 开拓视野 propel UK/prə’pel/ v. 推进，推动；驱使；迫使 voyage UK/‘vɔɪɪdʒ/ n. 航行, （尤指）航海 v. 航行, 远行, （尤指）远航 例句 The voyage from England to India used to take 3 weeks. 从英格兰到印度的航行曾经需要三周。 2020-6-28moist UK/mɔɪst/ adj. 微湿的, 湿润的 insult UK/ɪn’sʌlt/v. 侮辱，辱骂 n. 侮辱，辱骂 spontaneous UK/spɒn’teɪniəs/ They greeted him with spontaneous applause. 他们自发地鼓起掌来欢迎他。 slender UK/‘slendə(r)/ perimeter UK/pə’rɪmɪtə(r)/ n. 周长；外缘，边缘 blouse UK/blaʊz/ He pointed out a woman passing by who was wearing a skirt and blouse. 他指出了一个穿着裙子和衬衫的过路女子。 perfume UK/‘pɜːfjuːm/ n. 香水, 香料, 芳香 v. 使…发出香气, 洒香水 2020-6-272020-6-26Functional foods are food products that have a potentially positive effect on health beyond basic nutritional benefits. Functional foods aim to solve not only all the needs that regular foods provide, but also to address functional needs, which can range from maintaining and improving physical or mental health to adjusting energy levels and moods. Food has been historically used as preventive medicine in many cultures around the world, but the recent rise of functional foods can be directly linked to the rise of the wellness economy, which, in turn, is largely driven by influencer marketing and social media use. 2020-6-25IT IS A truth universally acknowledged that inequality（不平等）in the rich world（发达国家）is high and rising. Or, at least, it used to be. A growing band of economists are challenging the received（被公认的）wisdom, pointing out that trends in the distribution（分布，分配）of income and wealth may not be as bad as is often thought. 众所周知，富裕国家的不平等现象非常严重，而且还在加剧。或者说，至少曾经是这样的。越来越多的经济学家开始质疑既有的观点，他们指出收入和财富的分布趋势可能不是像通常被认为的那么糟糕。 2020-6-24imaginary adj. 想象中的, 幻想的, 虚构的 carriage n. 运输；运费，（旧时）马车；火车车厢；仪态，姿态，举止 message messenger n. 信使, 送信人, 通信员, 邮递员 pavement n. 人行道 postpone v. 延期, 延迟, 暂缓 We’ll have to postpone the meeting until next week. 我们将不得不把会议推迟到下周举行。 velocity n. 速度，速率；高速 reconcile v. 使和谐一致，调和；使和解；将就，妥协 It’s difficult to reconcile these two different points of view. 很难兼顾这两种不同的观点。 2020-6-23￼The success of the brand wasn’t built through big marketing campaigns, but through a savvy digital marketing strategy that increased brand awareness and generated high engagement, traffic, and conversions. 该品牌的成功并不建立于大型营销活动，而是建立于精准的数字营销策略，该策略提高了品牌的知名度，获得了很高的参与度、流量和转化率。 traffic: 信息流量，通信量 With only 40 physical stores, which are mostly used to drive consumers to e-commerce portals, Perfect Diary maintains momentum primarily through its digital footprint. Currently, it has a powerful presence on Little Red Book, Bilibili, Weibo, WeChat, Tmall, and Douyin. Thereafter she wrote articles for papers and magazines for a living. 此后她给报纸和杂志撰稿谋生。 adv. 此后, 之后, 以后 spur n. 刺激, 激励, 鞭策; 踢马刺, 靴刺; 骨刺; 山嘴, 尖坡 v. 刺激, 激励, 促进, 鞭策 stick adj. 黏（性）的, 一面带黏胶的, 闷热的, 感到热得难受的 n. 告事贴 I have to take a shower before going out because the sweat had made my skin sticky. 出门前我得冲个澡，因为汗水让我的皮肤黏乎乎的 devotion n. 关爱，关照；奉献；忠诚；宗教礼拜 The career needs our devotion for all our lives. 这项事业需要我们毕生的奉献。 reckless adj. 鲁莽的；不计后果的；无所顾忌的 wag v. 摇动；摆（尾巴），（尾巴）摇，摆动 n. 摇摆，摆动；老开玩笑的人，爱闹着玩的人 keen adj. 热衷的, 热情的; 渴望的; 敏捷的; 灵敏的; 锋利的; 强烈的 n. 恸哭; 挽歌 v. (为死者)恸哭 be keen on sth对 感兴趣 be keen to do 渴望做某事 offspring n. 子女，后代；幼崽；幼苗 receipt n. 收据，收入]]></content>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day]]></title>
    <url>%2F2020%2F06%2F22%2Ftime-series-01%2F</url>
    <content type="text"><![CDATA[时间序列及其分解 时间序列分类平稳序列（stationary series)序列中的各观察值基本上在某个固定的水平上波动，在不同时F间段波动程度不同，但不存在某种规律。平稳性时间序列的均值和方差都是常数。 方法：a) 看原图。是否在某个常数附近波动，且波动范围有界。如果有明显的趋势性或者周期性，则不是。b) ADF单位根检测。p值。 非平稳序列（non-stationary series)涉及趋势、季节性和周期三种特性，包含其中一种或者多种成分。 趋势(trend)时间序列在长时期内呈现出来的某种上升或者下降的趋势。分为线性和非线性。 季节性（seasonality)是指时间序列在一年内重复出现的周期波动。因季节不同而发生变化，如旅游旺季，旅游淡季。 周期性（cyclicity）是指时间序列呈现出的长期趋势。周期性不同于趋势变动，它是涨落相间的交替波动。不同意季节变动，它无固定规律，变动周期多在一年以上，且周期长短不一。周期性通常是由经济环境的变化引起的。 偶然性因素其导致时间序列呈现出某种随机波动。 时间序列的成分可分为：趋势（T),季节性（S),周期性（C),随机性（I)。 平稳时间序列分析AR模型 自回归模型AR 自回归模型描述当前值与历史值之间的关系，用变量自身的历史时间数据对自身进行预测。自回归模型必须满足平稳性的要求。 移动平均模型MA 移动平均模型关注的是自回归模型中的误差项的累加 自回归移动平均模型ARMA 自回归模型AR和移动平均模型MA模型相结合，我们就得到了自回归移动平均模型ARMA(p,q) 差分自回归移动平均模型ARIMA 将自回归模型、移动平均模型和差分法结合，我们就得到了差分自回归移动平均模型ARIMA(p,d,q) 参数确定拖尾和截尾拖尾指序列以指数率单调递减或震荡衰减，而截尾指序列从某个时点变得非常小。 ARIMA建模过程 将序列平稳（差分法确定d） p和q阶数确定：ACF与PACF ARIMA（p,d,q） 模型 ACF PACF AR（p） 衰减趋于零（几何型或振荡型） p阶后截尾 MA（q） q阶后截尾 衰减趋于零（几何型或振荡型） ARMA（p,q） q阶后衰减趋于零（几何型或振荡型） p阶后衰减趋于零（几何型或振荡型） 参数 p,q 的自动确定方式信息准则在参数估计的时候，我们可以采用似然函数作为目标函数。可以通过加入模型复杂度的惩罚项避免过拟合问题。比如赤池信息准则（AIC)和贝叶斯信息准则(BIC) AIC=2k−2ln(L)一方面引入惩罚项，使得模型参数尽快少，减少过拟合。另一方面，也希望提高模型的拟合度（极大似然） BIC=kLn(n)−2ln(L)k为模型参数个数，n为样本数量，L为似然函数。引入$Kln(n)$惩罚项在维度过大且样本数据相对较少的情况下，可以有效避免出现维度灾难。 时间序列的分解加法模型 X_t = T_t + C_t+S_t + I_t ,t = 1,2,..,n每个时间序列看成是三个部分的叠加，分别是趋势项、循环项，季节项，随机项 乘法模型 X_t = T_t*C_t*S_t*I_t趋势分析趋势拟合法就是把时间作为自变量，相应的序列观察值作为因变量，建立序列值随时间变化的回归模型。可分为线性拟合和曲线拟合。 线性拟合如果长期趋势呈现出线性特征，可用线性模型拟合， \left\{\begin{array}{c} x_t = a+bt+I_t\\ E(I_t) = 0,Var(I_t) = \sigma^2 \end{array} \right.其中，$T_t = a+bt$就是消除随机波动影响后的该序列的长期趋势。 曲线拟合如果长期趋势呈现出线性特征，可用曲线模型来拟合 \left\{ \begin{array}{c|c|c} 二次型& T_t = a+bt+ct^2& 变换后，线性最小二乘法\\ 指数型&T_t = ab^t& 对数变化 & 最小二乘法\\ 修正指数型&T_t = a+bc^t& &迭代法\\ Gompertz型& T_t = e^{a+bc^t}& & 迭代法\\ Logistic & T_t = \frac{1}{a+bc^t}& 迭代法 \end{array} \right.平滑法移动平均法假设在比较短的时间间隔里，序列的取值是较稳定的，这种差异是由随机波动造成的。由此，可用一定时间间隔内的平均值作为某一期的估计值。 n期中心移动平均 \widetilde{x_t} = \frac{1}{n}(\frac{1}{2}x_{t-\frac{n}{2}}+x_{t-\frac{n}{2}+1}+\dots+x_{t+\frac{n}{2}-1}+\frac{1}{2}x_{t+\frac{n}{2}})n期移动平均 \widetilde{x_t} = \frac{1}{n}(x_t+x_{t-1}+\dots+x_{t-n+1})指数平滑法简单指数平滑 \widetilde{x_t} = \alpha x_t+\alpha (1-\alpha )x_{t-1}+\dots)季节效应季节性效应的存在，使得气温会在不同年份的相同月份呈现出相似的性质。 如果只是存在季节性和随机波动性 x_{ij} = \hat{x}S_j+I_{ij}其中$S_j$表示第j个月的季节指数，$\hat{x}$为各月平均气温。 季节指数的计算: Step1: 计算周期内各期的平均数 \hat{x}_k = \frac{\sum_{i= 1}^{n}x_{ik}}{n}（k = 1,2,...,m)其中，m表示周期，n表示周期的数量 Step2: 计算总平均数 \hat{x} = \frac{\sum_{i = 1}^{n}\sum_{k = 1}^{m}x_{ik}}{nm}Step3: 计算季节指数 S_k = \frac{\hat{x}_k}{\hat{x}}混合效应加法模型 x_t = T_t + S_t + I_t乘法模型 x_t = T_t*S_t*I_t混合模型 x_t = S_t*T_t+I_t\\ x_t = S_t*(T_t+I_t)如果季节波动的振幅不受趋势变动的影响，则说明季节性与趋势之间没有相互作用关系，可加。如果季节波动的振幅随趋势的变化而变化，是相互作用的关系，可尝试混合模型和乘法模型。 Tool in Python: xfresh特征提取官网： https://tsfresh.readthedocs.io/en/latest/text/quick_start.html 中文： https://github.com/SimaShanhe/tsfresh-feature-translation Data Formatscolumn_id: Features will be extracted individually for each entity(id); one row per id. column_sort: sorting the time series. 特征提取: 可以一次性提取完；也可以单独提取kind_to_parameters 设置参数；还可以提取 可分布式计算 the rolling mechanism 首先确定滑动窗口 Step1 : 实现单变量特征的提取 Step2 : 实现多变量特征的提取 Day Ox 01知识清单: 特征提取：大概上千种特征（几十种方法） tsfresh.feature_extraction.extraction.extract_features(timeseries_container,default_fc_parameters=None, kind_to_fc_parameters=None**, column_id=None, column_sort=None, column_kind=None, column_value=None, chunksize=None, n_jobs=1, show_warnings=False, disable_progressbar=False, impute_function=None, profile=False, profiling_filename=’profile.txt’, profiling_sorting=’cumulative’, distributor=None)** pandas.DataFrame containing the different time series column_id (str) – The name of the id column to group by. column_sort (str) – The name of the sort column. n_jobs (int) – The number of processes to use for parallelization. 时间序列的滑动窗口（单序列划分成多序列） tsfresh.utilities.dataframe_functions.``roll_time_series(*df_or_dict*, column_id**, column_sort=None, column_kind=None, rolling_direction=1, max_timeshift=None, min_timeshift=0, chunksize=None, n_jobs=1, show_warnings=False, disable_progressbar=False, distributor=None)** max_timeshift (int) – If not None, the cut-out window is at maximum max_timeshift large. If none, it grows infinitely. min_timeshift (int) – Throw away all extracted forecast windows smaller or equal than this. Must be larger than or equal 0. n_jobs (int) – The number of processes to use for parallelization. If zero, no parallelization is used. show_warnings=False （指定）特征提取 显著性检测 https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_selection.html?highlight=select_features#tsfresh.feature_selection.selection.select_features 相关性检测 https://tsfresh.readthedocs.io/en/latest/text/parallelization.html#parallelization-of-feature-selection 123456789101112131415161718192021222324252627282930313233from tsfresh import extract_features, select_features,extract_relevant_featuresfrom tsfresh.utilities.dataframe_functions import imputefrom tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frameimport pandas as pdimport tsfresh as tsf fc_parameters_value1 = &#123;"length": None, "sum_values": None&#125;fc_parameters_value2 = &#123;"maximum": None, "minimum": None&#125;kind_to_fc_parameters = &#123; "value1": fc_parameters_value1, "value2": fc_parameters_value2&#125;if __name__ == '__main__': # ceate data rawdata = &#123;'id1': [0,0,0,0,0,1,1,1,1,1],'time': [1,2,3,4,5,10,11,12,13,14],\ 'value1': [1,2,3,4,5,6,7,8,9,10], 'value2': [1,2,3,4,5,6,7,8,9,10] &#125; df = pd.DataFrame(rawdata)# 设置长度+1 = 真实长度,是当前编号往上数. df_rolled = roll_time_series(df, column_id="id1", column_sort="time", max_timeshift=1, min_timeshift=0)# roll_time_series的返回值 print(df_rolled) df_rolled = df_rolled.drop('id1',axis = 1)# column_id: 聚合列 column_sort:排序，一个column_id就对应一个特征 extracted_features = extract_features(df_rolled, column_id='id', column_sort='time', kind_to_fc_parameters = kind_to_fc_parameters, show_warnings=False) print(extracted_features) Day Ox 02 查看提取特征可根据此提取自动提取的特征，用于预测时候的提取特征 1kind_to_fc_parameters = tsf.feature_extraction.settings.from_columns(extracted_features) 1234# 5. 特征抽取与过滤同时进行（一步到位，省去多余计算）# column_id: group by #features_filtered_direct = extract_relevant_features(timeseries, y, column_id='id', column_sort='time')#print(features_filtered_direct.head()) 学习路径： 1. 数据格式 2. 滑动窗口设置 3. 特征提取 4. 特征选择 专题 时间序列的竞赛方案https://mp.weixin.qq.com/s?__biz=MzU1Nzc1NjI0Nw==&amp;mid=2247485604&amp;idx=1&amp;sn=6283ec080344665bfad90570bf1504a4&amp;chksm=fc31b29ccb463b8acac7acf4d89494aaad0c76620becb2b07c370ccbfaff850edc3c1ad4e0fd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1593390448780&amp;sharer_shareid=fb5716a8ad12ea6329433df53d4cbf64#rd https://www.zhihu.com/question/21229371/answer/533770345 Prophet 工具]]></content>
  </entry>
  <entry>
    <title><![CDATA[回归分析]]></title>
    <url>%2F2020%2F06%2F20%2F%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[[TOC] 回归分析最简单的线性回归，避免多重共线性，过拟合，引入正则项的线性回归模型。涉及到的数学知识：一范数，二范数，多元函数求极值。模型的含义，参数求解算法，目标函数，以及各种模型的优缺点。 定义回归分析是寻找自变量和因变量之间的数量关系，用于预测建模的方法。其一，它可以揭示自变量和因变量之间的显著性检测。其二，揭示多个自变量对一个因变量的影响程度大小。 回归类型1）独立变量的数量 2）度量变量的类型 3）回归线的形状 1. 线性回归（Linear Regression)因变量：连续； 自变量：连续或者离散 模型的形式 Y = a+bX+𝜀\\ \left(\begin{array}{c} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{array}\right)=\left(\begin{array}{cccc} 1 & x_{11} & \cdots & x_{1(p-1)} \\ 1 & x_{21} & \cdots & x_{2(p-1)} \\ \vdots & \vdots & \vdots & \vdots \\ 1 & x_{n 1} & \cdots & x_{n(p-1)} \end{array}\right) \beta+\left(\begin{array}{c} e_{1} \\ e_{2} \\ \vdots \\ e_{n} \end{array}\right)\\ Y_{n*1} = X_{n*p}\beta+𝜀where $a$ and $b$ are the regression coefficients, and 𝜀 is the random error. 目标函数 min SSR = \sum_{i}(y_i-f(x_i))^2\\ min_{w}||Xw-y||_2^2参数估计最小二乘法（Lease Square Method)（OLS) This approach is called the method of ordinary least squares. 模型评估拟合优度 R-square , coefficient of determinationLarger $R^2$ indicates a better fit and means that the model can better explain the variation of the output with different inputs. https://realpython.com/linear-regression-in-python/ 要求 自变量和因变量之间必须满足线性关系。 多元回归存在多重共线性，自相关性和异方差性。 线性回归对异常值非常敏感。异常值会严重影响回归线和最终的预测值。 多重共线性会增加系数估计的方差，并且使得估计对模型中的微小变化非常敏感。结果是系数估计不稳定。 在多个自变量的情况下，我们可以采用正向选择、向后消除和逐步选择的方法来选择最重要的自变量。 逻辑回归（Logistic Regression)Logistic 回归的本质是：假设数据服从这个分布，然后使用极大似然估计做参数的估计。 Logistic 分布 F(x) = P(X]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志]]></title>
    <url>%2F2020%2F06%2F20%2F%E6%88%91%E4%BB%BB%E6%80%A7%2F</url>
    <content type="text"><![CDATA[今天和我本科同学，硕士也在同一所大学。对方已经喜提一篇高分SCI。和我聊了聊读博这件事情。双方只是很怀疑博士生涯的成功否？ 生活其实也不难 生存还是毁灭？这是个问题。究竟哪样更高贵，去忍受那狂暴的命运无情的摧残,还是挺身去反抗那无边的烦恼，把它扫一个干净。去死，去睡就结束了，如果睡眠能结束我们心灵的创伤和肉体所承受的千百种痛苦，那真是生存求之不得的天大的好事。去死，去睡，去睡，也许会做梦！唉，这就麻烦了，即使摆脱了这尘世可在这死的睡眠里又会做些什么梦呢？真得想一想，就这点顾虑使人受着终身的折磨,谁甘心忍受那鞭打和嘲弄，受人压迫，受尽侮蔑和轻视，忍受那失恋的痛苦，法庭的拖延，衙门的横征暴敛，默默无闻的劳碌却只换来多少凌辱。但他自己只要用把尖刀就能解脱了。—莎士比亚 我适合读博吗？—条件参考： https://mp.weixin.qq.com/s?__biz=MjM5Nzc3ODkyMA==&amp;mid=210024495&amp;idx=3&amp;sn=8088481127fadb9e9cb1e7b862555025&amp;chksm=2fa4dca818d355be6d02c5f1fe597a5a034880afc1fddb02bce9829259663bb0434f8b84b23e&amp;mpshare=1&amp;scene=24&amp;srcid=0707XZ5UVRbuOujh3mA4rsRH&amp;sharer_sharetime=1594093816416&amp;sharer_shareid=0e2d0ffe45c3a6dfb66aa422c3a1381d#rd 评价一下自己是否有下述能力： 智力：显然 评价:本科数学，看现状专业领域的文献大部分是OK 时间：往往比你想想的要长，你能承受吗? 评价：本科和研究生可以全身心投入。 创造力：读博需要你用新的思路看待问题。问问自己喜欢“脑筋急转弯”吗？你学高数时感到有意思吗？ 评价：现状还没有什么创新能力。 好奇心：你是不是强烈的想知道周围事物背后的规律？ 评价：不怎么思考 适应能力：读博常会出乎意料的困难，你可能会到一个没有人知道答案的领域。你能忍受郁闷吗？能忍受住找没人知道的答案时的枯燥吗？ 评价：我喜欢独处啊。 自我驱动：教授不会告诉你怎么做，你能自己给自己长期科研的动力吗? 评价：没什么问题。 竞争能力：你将与最聪明的人共事，别人会将你与这些人比较，你扛得住吗? 评价：要做到该领域5%以类的研究。要跟很多人抢饭碗。 成熟：读博时间大部分由你自己支配，你要自己安排自己的日程 评价：细节自己处理 清贫： 评价：博士混的好并不亚于找工作的生活条件。 综上所述：最大的问题不在于肯不肯吃苦，而在于能不能顺利完成博士生涯。感觉自己受限于自己的智商吧! 也可能我对博士要太高了吧！ 渴望读博的原因主要是两方面：一是自身的经历。本科期间的确掌握了基础的科研思路，科研工具。二是自身的喜好。科研环境相对轻松，人际关系不那么复杂。评判标准也相对简单。 难&lt;&lt;——&gt;&gt;想 博弈的过程。]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>生活日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识清单]]></title>
    <url>%2F2020%2F06%2F19%2F%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[主要是列出关于日常中遇到的很好的资料，自己不清楚的文章和资料。 2020-6-29 Z检测和T检测https://mp.weixin.qq.com/s?__biz=MzI4MjkzNTUxMw==&amp;mid=2247485455&amp;idx=1&amp;sn=857066158bf8c2de38939f3037416035&amp;chksm=eb9321b9dce4a8afd68d764c295f8bcc69c62f2b1d000f3e1c5e61a7d9b6e2ec3de8df068174&amp;mpshare=1&amp;scene=24&amp;srcid=&amp;sharer_sharetime=1593403964973&amp;sharer_shareid=0e2d0ffe45c3a6dfb66aa422c3a1381d#rd 2020-6-28视频： http://www.julyedu.com/video/play/58/405 2020-6-19SQL 中文: https://www.liaoxuefeng.com/wiki/1177760294764384 英文： https://www.codecademy.com/courses/learn-sql/lessons/manipulation/exercises/sql 视频： https://www.jikexueyuan.com/course/sql/ 基础 https://study.163.com/course/courseMain.htm?courseId=215012&amp;_trace_c_p_k2_=f68f3d2867a343789ac2d3cfa92dd308 https://www.nowcoder.com/discuss/95812?type=2 https://www.cnblogs.com/zsh-blogs/category/1413021.html]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学]]></title>
    <url>%2F2020%2F06%2F19%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[统计学 day Ox00day Ox00 首先介绍随机实验设计到的基本概念，包括随机实验，样本点，样本空间，基本事件，随机事件；其次介绍概率论的基本概念，包括概率的公理化定义，古典概率，条件概率，全概率，贝叶斯公式等等。特别注意两个容易混淆的概念：事件的独立性和互斥。 day Ox01 首先引出随机变量的定义，从离散随机变量和连续随机变量两个维度，介绍典型的分布函数。其中概率函数和分布函数是非常重要的概念。 基本概念随机试验：记作$E$ 样本点： 随机试验中出现的可能结果称为样本点，记作 $\omega$ 样本空间： 所有样本点组成的集合称为样本空间，随机实验所有的结果的集合，记作$\Omega$ 事件： 样本空间的子集，叫做随机事件，记作A,B,C。 ​ 分类：基本事件（由一个样本点构成），不可能事件（不包含任何样本点），必然事件（样本空间的所有样本点组成） 事件的关系和运算 ​ A与B互斥（互不相容），并为空集。不可能同时发生。 ​ 对立（互逆）：A,B在一次实验中有且仅有一个发生。 事件间的关系包含 相等 互不相容性：不可能同时发生，没有交集 事件的概率概率的公理化定义计算方法古典方法随机事件的要求：(1). 涉及的随机现象只有有限个基本结果（2). 每个基本结果出现的可能性是相同的（等可能性） 事件的基本结果： P(A) = \frac{k}{n} = \frac{事件包含的基本事件的个数}{全空间包含的基本结果总数}事件的独立性两个事件的独立性是指一个事件的发生不影响另一个事件的发生， P(AB) = P(A)P(B)多个事件的独立性 P(A_iA_j) = P(A_i)P(A_j)\\ P(A_iA_jA_k) = P(A_i)P(A_j)P(A_k)\\ \vdots P(A_1A_2\cdots A_n) = P(A_1)P(A_2)\cdots P(A_n)实验的独立性实验$E_1$的任意一个结果（事件）与实验$E_2$的任一个结果都是相互独立的事件，则称实验相互独立 条件概率 P(A|B) = \frac{P(AB)}{P(B)}乘法公式 P(A_1A_2A_3) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)全概率公式 P(A) = P(A|B)P(B)+P(A|\hat{B})P(\hat{B}) P(A) = \sum_{i = 1}^nP(A|B_i)P(B_i)贝叶斯公式 P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i = 1}^nP(A|B_k)P(B_k)}随机变量 day Ox01随机变量表示随机现象结果，一般大写字母X,Y,Z, 随机变量取值用小写字母x,y,z等表示。 用等号或者不等号把X与x联系起来就很多有趣的事件，X=x,Y&lt;y,等等构成了事件。 随机变量定义在基本空间$\Omega$上的实值函数$X = X(w)$成为随机空间 X: w->实数域（映射)随机变量的分布函数分布函数的定义 F(x) = P(X]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data-Science]]></title>
    <url>%2F2020%2F06%2F11%2FData-Science%2F</url>
    <content type="text"><![CDATA[CourseTsinghua Dr. Yuan Data Mining: Theories and Algorithms for Tackling Big Data ToolsStata: https://www.stata.com/why-use-stata/ https://www.youtube.com/watch?v=AyXeh7iojuA BOOOOOOKhttps://www-users.cs.umn.edu/~kumar001/dmbook/index.php]]></content>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天了解多一点]]></title>
    <url>%2F2020%2F06%2F11%2F%E6%AF%8F%E5%A4%A9%E4%BA%86%E8%A7%A3%E5%A4%9A%E4%B8%80%E7%82%B9%2F</url>
    <content type="text"><![CDATA[2020-7-18读万卷书，不如行万里路。书中再多的道理，不如自己闯一闯。 2020-7-17 excel保留破解pandas Nan相加还是nan alt+F11, 插入-模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151 Option Explicit Public Sub AllInternalPasswords()&apos; Breaks worksheet and workbook structure passwords. Bob McCormick&apos; probably originator of base code algorithm modified for coverage&apos; of workbook structure / windows passwords and for multiple passwords&apos;&apos; Norman Harker and JE McGimpsey 27-Dec-2002 (Version 1.1)&apos; Modified 2003-Apr-04 by JEM: All msgs to constants, and&apos; eliminate one Exit Sub (Version 1.1.1)&apos; Reveals hashed passwords NOT original passwordsConst DBLSPACE As String = vbNewLine &amp; vbNewLineConst AUTHORS As String = DBLSPACE &amp; vbNewLine &amp; _&quot;Adapted from Bob McCormick base code by&quot; &amp; _&quot;Norman Harker and JE McGimpsey&quot;Const HEADER As String = &quot;AllInternalPasswords User Message&quot;Const VERSION As String = DBLSPACE &amp; &quot;Version 1.1.1 2003-Apr-04&quot;Const REPBACK As String = DBLSPACE &amp; &quot;Please report failure &quot; &amp; _&quot;to the microsoft.public.excel.programming newsgroup.&quot;Const ALLCLEAR As String = DBLSPACE &amp; &quot;The workbook should &quot; &amp; _&quot;now be free of all password protection, so make sure you:&quot; &amp; _DBLSPACE &amp; &quot;SAVE IT NOW!&quot; &amp; DBLSPACE &amp; &quot;and also&quot; &amp; _DBLSPACE &amp; &quot;BACKUP!, BACKUP!!, BACKUP!!!&quot; &amp; _DBLSPACE &amp; &quot;Also, remember that the password was &quot; &amp; _&quot;put there for a reason. Don&apos;t stuff up crucial formulas &quot; &amp; _&quot;or data.&quot; &amp; DBLSPACE &amp; &quot;Access and use of some data &quot; &amp; _&quot;may be an offense. If in doubt, don&apos;t.&quot;Const MSGNOPWORDS1 As String = &quot;There were no passwords on &quot; &amp; _&quot;sheets, or workbook structure or windows.&quot; &amp; AUTHORS &amp; VERSIONConst MSGNOPWORDS2 As String = &quot;There was no protection to &quot; &amp; _&quot;workbook structure or windows.&quot; &amp; DBLSPACE &amp; _&quot;Proceeding to unprotect sheets.&quot; &amp; AUTHORS &amp; VERSIONConst MSGTAKETIME As String = &quot;After pressing OK button this &quot; &amp; _&quot;will take some time.&quot; &amp; DBLSPACE &amp; &quot;Amount of time &quot; &amp; _&quot;depends on how many different passwords, the &quot; &amp; _&quot;passwords, and your computer&apos;s specification.&quot; &amp; DBLSPACE &amp; _&quot;Just be patient! Make me a coffee!&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND1 As String = &quot;You had a Worksheet &quot; &amp; _&quot;Structure or Windows Password set.&quot; &amp; DBLSPACE &amp; _&quot;The password found was: &quot; &amp; DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; _&quot;Note it down for potential future use in other workbooks by &quot; &amp; _&quot;the same person who set this password.&quot; &amp; DBLSPACE &amp; _&quot;Now to check and clear other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND2 As String = &quot;You had a Worksheet &quot; &amp; _&quot;password set.&quot; &amp; DBLSPACE &amp; &quot;The password found was: &quot; &amp; _DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; &quot;Note it down for potential &quot; &amp; _&quot;future use in other workbooks by same person who &quot; &amp; _&quot;set this password.&quot; &amp; DBLSPACE &amp; &quot;Now to check and clear &quot; &amp; _&quot;other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGONLYONE As String = &quot;Only structure / windows &quot; &amp; _&quot;protected with the password that was just found.&quot; &amp; _ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACKDim w1 As Worksheet, w2 As WorksheetDim i As Integer, j As Integer, k As Integer, l As IntegerDim m As Integer, n As Integer, i1 As Integer, i2 As IntegerDim i3 As Integer, i4 As Integer, i5 As Integer, i6 As IntegerDim PWord1 As StringDim ShTag As Boolean, WinTag As Boolean Application.ScreenUpdating = FalseWith ActiveWorkbookWinTag = .ProtectStructure Or .ProtectWindowsEnd WithShTag = FalseFor Each w1 In WorksheetsShTag = ShTag Or w1.ProtectContentsNext w1If Not ShTag And Not WinTag ThenMsgBox MSGNOPWORDS1, vbInformation, HEADERExit SubEnd IfMsgBox MSGTAKETIME, vbInformation, HEADERIf Not WinTag ThenMsgBox MSGNOPWORDS2, vbInformation, HEADERElseOn Error Resume NextDo &apos;dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126With ActiveWorkbook.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; _Chr(i3) &amp; Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If .ProtectStructure = False And _.ProtectWindows = False ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND1, _&quot;$$&quot;, PWord1), vbInformation, HEADERExit Do &apos;Bypass all for...nextsEnd IfEnd WithNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfIf WinTag And Not ShTag ThenMsgBox MSGONLYONE, vbInformation, HEADERExit SubEnd IfOn Error Resume NextFor Each w1 In Worksheets&apos;Attempt clearance with PWord1w1.Unprotect PWord1Next w1On Error GoTo 0ShTag = FalseFor Each w1 In Worksheets&apos;Checks for all clear ShTag triggered to 1 if not.ShTag = ShTag Or w1.ProtectContentsNext w1If ShTag ThenFor Each w1 In WorksheetsWith w1If .ProtectContents ThenOn Error Resume NextDo &apos;Dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If Not .ProtectContents ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND2, _&quot;$$&quot;, PWord1), vbInformation, HEADER&apos;leverage finding Pword by trying on other sheetsFor Each w2 In Worksheetsw2.Unprotect PWord1Next w2Exit Do &apos;Bypass all for...nextsEnd IfNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfEnd WithNext w1End IfMsgBox ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACK, vbInformation, HEADEREnd Sub 2020-6-29 三种相关分析方法的异同 名称 中文 公式 数据要求 含义 person correlation coefficient 皮尔森相关系数 $\rho_{X, Y}=\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X) D(Y)}}$ a. 正太分布。因为计算系数后，通常需要t检测，t检测是基于正态分布的。b. 实验数据之间的差距不同太多 [-1,1线性相关 spearman correlation coefficient 斯皮尔曼相关性系数 $\rho=1-\frac{6 \sum_{i=1}^{N} d_{i}^{2}}{n\left(n^{2}-1\right)}$ 没有。使用范围较广 kendall correlation coefficient 肯德尔相关性系数 $\tau=\frac{C-D}{\frac{1}{2} N(N-1)}$其中C表示XY中拥有一致性的元素对数（两个元素为一对）；D表示XY中拥有不一致性的元素对数。 对象是分类变量。分有序和无序。 2020-6-20当你通过数据可视化来表达观点，首先自己要有一个清晰的结论，然后有针对性地突出自己想要表达的要点，通过视觉化的元素，引导观众正确地理解自己的观点，而不要让观众自行得出结论。 最后，分享一下我在知识星球上面发的关于分析数据的 5 点思考。 1. 分析数据的平均值和中位数 比如说，客户的年龄、购买金额的平均值和中位数分别是多少？中位数往往比平均值更具有分析价值。 2. 分析数据的极值和分布 比如说，在所有的购买者中，年龄最大的是谁？年龄最小的是谁？是否服从正态分布？ 3. 分析数据的相关性 比如说，年龄与购买金额是否有相关性？相关系数是多少？ 4. 分析数据背后的原因 比如说，客户为什么会购买？销售下降的原因是什么？ 5. 提出数据分析的建议 比如说，经过前期的分析，知道销售下降的原因，主要是因为老年客户群体的认知度偏低，故提出建议：针对老年客户群体开展宣传活动。 总之，不要当一个纯粹的「统计者」，要做数据的分析者，最好是问题的解决者。 2020-6-19 论数据的重要性！！！！！ 论数据的重要性！！！！！ 2020-6-18 et-al格式的参考文献的设置方法 参考文献类型 2020-6-17 统计学资料收集： 视频 哈佛大学 https://www.bilibili.com/video/av455440626/?p=2 2020-6-16 一面 1h 1.自我介绍 2.统计 1）假设检验，A城市平均工资X1，方差sigma1，B城市平均工资X2，方差sigma2. 设计假设检验，验证X1显著大于X2，要求H0，H1，假设检验统计量及其分布 2）概率论，甲乙两人同时玩一个游戏，投至均匀骰子，两个人轮流投掷，谁先投到6谁赢， 问甲先投，获胜的概率 3.机器学习 1）100万个样本量，70个feature，如果你用random forest，你会选择多深的树 2）简述bagging，rf，boosting的区别 4.产品 1）快手内部生态分为生产者和消费者，你如何选择一个指标，用于评判尽可能多的人发作品 2）直播间价值用观看时长来评判，选择一个指标去评判直播间的价值 5.python 一个简单编程，list a = [10,20,30,40,50,60,70,80,90] 在list 中先取出20的倍数，i.e., 20,40,60,80，再取出30的倍数，依此类推一直到90，最后取出10的倍数 6.Sql leetcode, top three department salary 变种 二面 30mins 隔天 1.得到一个AB test结果，你怎么分析 2.经典product题目，一个指标下降了，如何分析 3.宏观问题，怎么分析南北方用户差异 2020-6-13 大数据挖掘与分析实习生一面面经 自我介绍 sql怎么样 python怎么自学的 讲一个数据挖掘与分析实习或项目。 5.讲实习经历 https://www.nowcoder.com/contestRoom 尽管我看了很大这方面的东西， 2020-6-12 一个数据分析报告的内容 我对这个很感兴趣啊！！！！ 遵循的标准展示分析结果-》验证分析质量-》提供决策参考 需求层：目的，目标 数据层：数据清洗 分析层：描述分析和建模分析，前者是洞察结论，后者是模型测试， 输出层：模型+报告撰写。 简单版本 项目背景：简述项目相关背景，为什么做，目的是什么 项目进度：综述项目的整体进程，以及目前的情况 名词解释：关键性指标定义是什么，为什么这么定义 名词解释：关键性指标的定义是说明，为什么这么定义。有何不同。 数据获取方法：如何取样，怎么获取到的数据，会有哪些问题 数据获取方法：如何取样，相关问题。包括异常值补充，如何填充。数据清洗和数据补全。 数据概览：重要指标的趋势，变化情况，重要拐点成因解释 可视化或者表格展示 数据拆分：根据需要拆分不同的维度，作为细节补充 结论汇总：汇总之前数据分析的主要结论，作为概览 后续改进：分析目前存在的问题，并给出解决改进防范 致谢 附件：详细数据 专业版本 标题业 目标 前言 a. 其对能否解决业务问题，起到决策性作用。包括分析背景、目的以及思路。 正文 a. 报告的核心观点是什么？由哪些子观点组成，支持每个子观点的数据，展示方式，量化结果（遵循金字塔原理) 现状描述；2， 什么量化指标；3，同比、环比等等 4. 选择原因 结论 a. 根据分析结果，通常以综述性文字来说明，要紧密结合业务。 附录 a. 资料，重要数据，地图 关键词： 指标；数据；可视化；逻辑；实事求是 难点： 建模分析；计量 重点： 维度；指标 最忌讳的就是分析出一大推显而易见的结论，就像数据挖掘一样。 2020-6-11 经济学的顶级期刊。 经济学中文期刊的 “四大金刚”，即《经济研究》、《经济学(季刊)》、《世界经济》、《管理世界》 经济学英文期刊的 “Top 5”，即 American Economic Review，Econometrica，Journal of Political Economy，Quarterly Journal of Economics，Review of Economic Studies。 https://www.aeaweb.org/journals/mac]]></content>
      <categories>
        <category>科普</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F06%2F09%2FReading-Record%2F</url>
    <content type="text"><![CDATA[2020-7-22 啦啦啦啦基本结果还可以果然一两天写一篇论文不是什么问题。只要有数据和图片。 2020-7-21 出报告和结果了虽然感觉很垃圾。 2020-7-20思路差不多定了。在初试结果的过程中，各种意外结果， 2020-7-18 Modelling the relation between incomeand commuting distance 幂律分布假设变量$x$服从参数$\alpha$, 概率密度函数 f(x) = cx^{-\alpha-1}The spatial optimal job search model The closest opportunity model We discuss the distribution of commuting distances and its relation to income. Using data from Denmark, the UK and the USA, we show that the commuting distance is (i) broadly distributed with a slow decaying tail that can be fitted by a power law with exponent g =3 and (ii) an average growing slowly as apower law with an exponent less than one that depends on the country considered. 2020-7-17 影响人口流动的指标研究industry construct ; population; GDP; wage; foreign capital investment; environment ; Population is the first indicator that contributes to these movements since it reflects the demographic status (Shen, 2016). Gross regional product (GRP) is the general and direct reflection of economic development of an area (Cao, Zheng, Liu, Li, &amp; Chen, 2018; Shen, 2016), and it will be considered as the economic variable. Average wage is a very important factor since the expected income differential between two cities is the main driver that attracts people to migrate (Liu, Qi, &amp; Cao, 2015; Liu &amp; Shen, 2014b). In addition, relying on foreign capital investment, labor-intensive industries could have attracted massive nonlocal labor forces (Liu &amp; Shen, 2014a; Shen, 2012), and hence foreign capital investment is also taken into account in ourstudy. 、 Wang et al. found that migration are significantly associated with the development of secondary and tertiary industries, wage levels and foreign investments. 2020-7-16 影响人口迁移的文献综述Theory人口迁移的理论和模型：人口迁移七大定理；推拉理论；新古典经济学理论提出的人口迁移机制；等等见链接。 我怀疑这篇文章就是抄的百度百科的综述。这还是我国名校的风格？？？？https://baike.baidu.com/item/%E4%BA%BA%E5%8F%A3%E8%BF%81%E7%A7%BB/3869295?fromtitle=%E4%BA%BA%E5%8F%A3%E8%BF%81%E5%BE%99&amp;fromid=4316399 Many influential theories and models are proposed explaining the origin, mechanism and extension of population migration. Ravenstein (1889) first proposed “the laws of migration” and postulated seven laws pertaining to population migration. “Push and pull theory”, developed by Bouge (1959), tries to explain the motivation of migration and is further summarized by Lee (1966), who argues that both push and pull factors coexist at the origin and the destination. 拉文斯坦（E. G. Raven stein（1885, 1889））认为人们进行迁移的主要目的是为了改善自己的经济状况，并对人口迁移的机制、结构、空间特征规律分别进行了总结，提出著名的人口迁移七大定律。 1938年，赫伯尔第一次系统总结了“推拉”理论概念，他认为人口迁移是由一系列“力”引起的，一部分为推力，另一部分为拉力。该理论认为，人口迁移是由于迁出地的推力或排斥力和迁入地的拉力或吸引力共同作用的结果。从迁移者个体的行为决策过程来看，推力——拉力理论的成立包含两个基本假设：一是假设人们的迁移行为是一种理性的选择，二是认为迁移者对原驻地和迁入地的信息有比较充分的了解。只有这样他才能根据两地之间的推力和拉力，从比较利益的角度出发做出相应的选择。Lee（1966）在其《迁移理论》一文中系统总结了“推力——拉力”理论。他将影响迁移行为的因素概况为4个方面：（1）与迁入地有关的因素；（2）与迁出地有关的因素；（3）各种中间障碍；（4）个人因素。 推拉理论还有许多[量化模型]，美国社会学家吉佛把“[万有引力定律]引入推拉模型，并应用于人口迁移研究。他认为，两地之间迁移人口与两地人口规模成正比，与两地之间距离成反比，并基于此提出了[引力模型]（gravity model）：式中，Mij为i地与j地之间的人口迁移量，Pi、Pj分别为两地的人口规模，d为两地之间的距离，k为常数，a为距离[衰减系数] The macro-level neoclassical theories believe that there are geographical differences between labor supply and demand, and the resulting differences in wages are the main reasons for labor migration (Lewis, 1954; Ranis &amp; Fei,1961, pp. 533–565; Todaro, 1976), while the micro-level neoclassical theories conceptualize migration as a form of human capital investment to maximize individual benefit (Sjaastad, 1962). 新古典经济学理论（Neoclassical theory） 新古典经济学]家将经济学中供给与需求关系引入人口迁移的研究中，认为劳动力供给与需求的区域差异引起了不同区域之间劳动力的调整，人口迁移是这一调整过程的体现。根据[舒尔茨]的人力资本理论.对于个人来说，迁移被视为是一种在个人人力资本上的投资，这种个人投资可以增强自身的经济效益从而提高自身的整体生活水平。多数研究表明，人口迁移主要是在市场调节下移民对经济机会的选择。Courchene（1970）通过对加拿大各省区的调查，发现迁移率与人均收入成正相关。Cebula &amp; Vedder（1973）发现在美国39个都市统计区中，人口净迁入量与人均收入呈弱正相关关系 Instead of focusing on economic factors that drive migration, the equilibrium approach focuses on the role of location-specific amenities (e.g., natural environment, public services and social life quality) and claims that migration is primarily driven by the change in demand for amenities rather than interregional wage differentials (Knapp &amp; Graves, 1989; Mueser &amp; Graves, 1995). ChinaContent: Based on these theories, migration in China has been studied by many scholars, focusing on the spatial characteristics and patterns of migration (Fan, 2005; Shen, 1996; Shen &amp; Liu, 2016), its relationship with urbanization (Zhang &amp; Song, 2003), the determinants of migration (Cai &amp; Wang, 2003; Liu &amp; Shen, 2014b) and the influence of migration on regional development (Fan, 2005). A set of determinants including gravity, economy, labor market, housing market and environment variables identified by Stillwell (2005) are widely used in modelling population migration (Liu &amp; Shen, 2014b; Shen, 2015), and these approaches are often based on the gravity model or “push and pull theory”. In any case, regional disparity of various kinds is still regarded as a combinational complex motivation for migration and explaining migration patterns is beneficial for understanding demographic change and associated socioeconomic development. 下面两篇文章共同主题都是研究人口迁移模式。一个是腾讯迁移大数据。一个是手机相关数据。前者注重分析网络结构层面的模式，关注在春节前后的变化，构造出吸引力。后者选择春节前的使用QQ的人数为因变量，重点在定量化空间模式与相关元素的关系。 2020-7-15 Difference of urban development in China from the perspective of passenger transport around Spring FestivalJun Xu , Aoyong Li , Dong Li , Yu Liu ， Yunyan Du , Tao Pei , Ting Ma , Chenghu Zhou Applied Geography 87 (2017) 85-96 Data： during 2016 Spring Festival from Tencent Location Big Data Aiming: this paper analyzed the unbalanced migrationbetween cities and the spatial difference of urban development Method: Four method 1）Network analysis methods are employed to evaluate interactions among cities. 2）A community detection method identifies 19 city communities, and the directions of migrant flows in the communities are explored. 3）The PageRank algorithm is employed to evaluate the importance of cities on the migration network and divide the cities into 5 grades, 4) and then the hierarchical structure of the migrant network is illustrated and analyzed. 2020-7-13 Migration patterns in China extracted from mobile positioning data(How-What-Why-Where-When) Problem: Using a mobile positioning dataset, this paper first analyzes the spatial patterns of mobile-data-based active population estimation (MAPE) and aims to uncover the socioeconomic factors associated with migrant patterns based on the MAPE change around the Chinese SpringFestival of 2016. 人口迁移模式，以及影响因素的关系 研究人类移动模式： 理论-&gt;引力模型(影响因素)，城市化等的影响-&gt;大规模微观数据（精度提高，应用） 2020-7-9 News and the city: understanding online press consumption patternsthrough mobile data 2020-7-6 diversity of city(neighborhood)MIT: Economic outcomes predicted by diversity in cities Shannon entropy Abstract: Gap: Much recent work has illuminated the growth, innovation, and prosperity of entire cities, but there is relatively less evidence concerning the growth and prosperity of individual neighborhoods. Aiming;: In this paper we show that diversity of amenities within a city neighborhood, computed from openly available points of interest on digital maps, accurately predicts human mobility (“flows”) between city neighborhoods and that these flows accurately predict neighborhood economic productivity Conclusion: Our results suggest that the diversity of goods and services within a city neighborhood is the largest single factor driving both human mobility and economic growth 2020-7-5 Supporting Information S1: New Metrics for the Economic Complexity of Countries and ProducesKey: Revealed Comparative Advantage 2020-7-5 What Do We Mean by Economic Complexity?2020-7-2 Women’s Political Participation and Gender Gaps of Education in China: 1950–1990yang yao and wuyue you 社会科学问题： 女性政治地位的提高是否促进性别平等。 女性政治地位： 女性党员比例 性别平等：男女出生比例 计量模型的设置，控制变量的选择！还做了影响机制的检测！ 2020-6-26 A review on time series forecasting techniques for building energy consumptionThis study presents a comprehensive review of existing nine most popular forecasting techniques. Beautiful!!!!1 2.1 Artificial neural network(ANN) 2.1.1 Overview of ANN 2.1.2 Review of application studies on ANN Model: Hamzacebi [42] developed forecasting models using ANN for net electricity consumption of Turkey. Input time series: The ANN model forecasted the sectoral electricity consumption of the four sectors which were the transportation, agriculture, residential and the industry sectors respectively. Dataset: The data used to develop, validate and test the model was for a period between 1970 and 2004. Results: The MAPE computed for the four sector’s electricity consumption were 23.59%, 3.56%, 3.26% and 2.25% respectively . Very clear! 2.2 Autoregressive Integrated Moving Average(ARIMA) 2.3 Support Vector Machine(SVM) 2.4. Case-Based Reasoning (CBR) 2.4.1. Overview of CBR 2.4.2. Review of application studies using CBR 2.5. Fuzzy time series 2.6. Grey prediction model 2.7. Moving average and exponential smoothing (MA &amp; ES) 2.8. K – Nearest Neighbor prediction method (kNN) 2.9. Hybrid models Summary of qualitative comparison for the 9 major time series forecasting techniques. the distance between theory and application. Application is the first step, then the theory is next creation. 2020-6-25 Time Series PredictionTitle: Financial Time Series Prediction Using Least SquaresSupport Vector Machines Within the Evidence Framework The least squares support support vector machine(LS-SVM) regression applied to predict financial time series. 2020-6-18 Data MiningPreprocessing Methods and Pipelines of Data Mining: An Overview. IEEE conference, 2019. arXiv: 1906.008510 总结了常用在数据预处理流程: data preprocessing technoques which are categorized as the data cleaning, data transformation and data preprocessing is given. data type data distribution noise of data Exploring ​ Before modeling the data, people may want to get to know the underlying distribution of the data, the correlation between variables, and the their correlation with the lables. Modeling with underling patterns existed in the data source, modeling makes it possible to represent the pattern explicitly with the data mining models. data mining models, loss functions are defined. mean squared error cross entropy Interpreting 感觉这个综述写的还是简单，大致流程给出来了。 2020-6-172020-6-13I have summarized some metrics which are used to measure social and economic development. Symbolic Explanation c : represents unit region c n : the number of region a : represents a economic index of region m : the number of region The complexity location quotient(LQ)[1] LQ_{c,a} = \frac{\frac{P_{c,a}}{\sum_{a=1}^{n}p_{s,a}}}{\frac{\sum_{s=1}^{n}p_{s,a}}{\sum_{a=1}^{m}\sum_{s = 1}^{n}p_{s,a}}}where $p_{s,a}$ is the number of index a in region s, $\sum_{a =1}^{m}p_{s,a}$ is the total number of index belongs to a in regions, $\sum_{s = 1}^{n}p_{s,a}$; $\sum_{s = 1}^{n}\sum_{a = 1}^{m}p_{s,a}$ is the number of index a in countrywide. The $m_{s, a}$ matrix is definded by \left\{ \begin{array}{cc} 1 & if \ LQ_{s,a}>LQ^{*}\\ 0 & otherwise \end{array} \right.The diversification Diversification: k_{s,0}=\sum_{a = 1}^{n}m_{s,a} Ubiquity: k_{a,o} = \sum_{s=1}^{n}m_{s,a}The average value of the prior period’s level for the measures of diversification and ubiquity. The iterative process is defined as follows: K_{s,N} = \frac{1}{K_{s,0}}\sum_{a = 1}^{m}m_{s,a}\cdot K_{a,N-1} K_{a,N} = \frac{1}{K_{a,o}}\sum_{s = 1}^{n}m_{s,a}\cdot K_{s,N-1} [1] Economic Complexity and Regional Growth Performance: Evidence from the Mexican Economy 2020-6-11Reference: Gao Jian, Jun Bogang, et al. Collective Learning in China’s Regional Economic Development. arXiv: 1703.01369, 2017. Using China’s stock market extracted from the RESSET Financial Research Database coving 1990-2015, Gao et-al investigated inter-regional and inter-industry learning which make contribution to economic development. I mainly learn how to quantify industry similarities and dominance of region by mathematical tool. Beautiful results tell a good story. 2020-6-9 Transportation large-scale dataset reveals economic development statusTitle: Estimation of Regional Economic Development Indicator from Transportation Network Analytics. Reference: Li BIn, Gao Song, et al. Estimation of regional economic development indicator from transportation network analytics. Scientific reports, 2020: 10(1), 1-15. I appreciate this works, not only the dataset but all the content. I can try all my knowledge to understand it. At the same time, I can learn how to analyze complex questions to get deep information. I will detail to review as following structure. The Introduction P1.S1: The meaning of economy: With the booming economy in China, many researches have pointed out that the improvement of regional trans-portation infrastructure, the mobility of labor and capital, and industry reform along with other socioeconomicfactors play an important role on economic growth. The meaning of policy maker; Timely estimation of social and economic status of cities and regions has important implications for enterprise investment and government policy making. P1.S2: The disadvantage. Traditional inference approaches to economic status mainly rely on official reports and census surveys, which usually take a long period and are labor intensive. P1.S3: The applicaiton of big data. With the rapid development of information, communication and technology (ICT), new data sources of human activities 1 and vehicle movement flow , air transport flow , financial flow, information flow , communication flow , and others have become available for better understanding and monitoring the status of our socioeconomic environments . For example: Liu et al. 1 found that online social activity could reflect the macro economic status of 282 prefecture-level cities in China. Recently, Gao et al. 16 conducted a comprehensive review on data resources, computational tools, analytical methods, theoretical models, and applications in computational socioeconomics. P2 Review on old methodology. In the past decades, a wealth of works have been dedicated to studying the pattern of human mobility involving passenger transportation . Foucuse on their topic : A comparatively smaller literature has been dedicated to the pattern of transportation activity embedded in goods movement . The shortest : The scarcity of reliable data sources on freight transportation appears to be one of the challenges. Early studies rely on traditional freight traffic surveys, which are typically enterprise questionnaire surveys to obtain information such as the traffic volume and speed in specific road sections. MethodsData : A excellent research must be constructed by a high-quality dataset.Information: annual transportation data between years 2014 and 2017 for the Shaanxi, Jiangsu, Liaoning at city level. The vehicle is divided into two categories: cars&amp;buses, and freight trucks. The aiming is to investigate the relationship between regional economy and transportation networks. Indictors: the total number of vehicles, the sum of passengers(for cars and buses) and the weights(for trucks) as well as the distance (km) between paired cities were calculated respectively. Models: 最小二乘法+ 正则化泛化能力（过拟合？？？？）我觉得是多重共线性的原因，解释变量之间太线性相关了！！！！！ MLR(multiple linear regression) with ordinary least squares (OLS) paramete estimation is used to discover the realtionship between the transport flows of people and goods. The independent variables includs. incoming flow, outgoing flow, intracity flow. Linear model with regularization combine machine learning with MLR to improve generalization. 本科阶段已经学过 Ridge regression applies and Lasso regression with different regularization term. 如果改成支持向量回归就更好了，我准备试试 http://kernelsvm.tripod.com/ 感觉只是在应用两个模型，并没有创新之处 要把这种线性模型正则化技术整理一篇 Model 2: The gravity model fitting with linear regression and linear G_{ij} = k\frac{p_ip_j}{d_{ij}^{\beta}}(i!=j)参数$\beta$ 的确定，代表了距离的影响，d距离衰减影响，拟合，参数显著性检验， Model 3: The null model Model 4: Network structure analyses ​ 1. 计算或定义了有些网络连通性的刻画指标 Betw、Close、 PageRanke 1. 相关性的刻画 2. 主成分分析（还不知道） 首先，我从中学到了把一个问题拆解，怎么一步一步分析的，有时候数据量大了，能得到的信息就越大，怎么挖掘自己觉得有价值的东西，而不是人人都能看的结果。本文就从三个大的方面，分层次研究了交通流与经济发展的关系。但是这篇文章很大程度是建立在大数据之上的，但有创新的方法都是借鉴过来的，偏重于方法的应用，解释经济发展与交通流。读完这篇文章，有种自己成就感，这个好的文章我都看明白了。不得不说，知识面、写作方法、分析思路、绘图，都是该常常拿出来学习的文章。 计量经济学模型和机器学习预测模型的区别在哪里？OLS估计 https://www.nber.org/chapters/c14009.pdf 机器学习长于预测，计量经济学长于解释 https://www.aeaweb.org/conference/cont-ed/2018-webcasts 计量模型的设置：强调参数估计的经济学含义 log-normal log -log 等等，有经济学含义，并且要参数显著性检验 机器学习模型：模型的结果，预测效果 线性模型，核技巧 https://otexts.com/fppcn/causality.html]]></content>
      <tags>
        <tag>Paper Recording</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F18%2F%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D%2F</url>
    <content type="text"><![CDATA[$\alpha$ $\beta$ $\gamma$ $\Gamma$ $\delta$ $\Delta$ $\epsilon$ $\varepsilon$ $\zeta$ $\eta$ $\theta$ $\Theta$ $\vartheta$ $\iota$ $\kappa$ $\lambda$ $\Lambda$ $\mu$ $\nu$ $\xi$ $\Xi$ $\pi$ $\Pi$ $\varpi$ $\rho$ $\varrho$ $\sigma$ $\Sigma$ $\varsigma$ $\tau$ $\upsilon$ $\Upsilon$ $\phi$ $\Phi$ $\varphi$ $\chi$ $\psi$ $\Psi$ $\Omega$ $\omega$ alpha beta gamma delta epsilon theta]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python Basics]]></title>
    <url>%2F2019%2F05%2F28%2FPython-basic%2F</url>
    <content type="text"><![CDATA[重新学习开始很乱的学习Python，现在想系统学习基础，真正了解pythonic, zip() functiona. function: zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 b. zip([iterable, …]) c. return : 返回元组列表。在 Python 3.x 中为了减少内存，zip() 返回的是一个对象。如需展示列表，需手动 list() 转换。 123456a = [1,2,3]b = [4,5,6]zipped = zip(a,b) # 打包为元组的列表[(1, 4), (2, 5), (3, 6)]zip(*zipped) # 与 zip 相反，可理解为解压，返回二维矩阵式[(1, 2, 3), (4, 5, 6)] enumerate() functiona. 将可遍历的数据对象(列表、元组或者字符串) 组合为一个索引序列，同时给出数据和数据下标。主要用于for循环 b. enumerate(sequence, [start=0]) c. return : enumerate(枚举) 对象。 d eg: 123seq = ['one', 'two', 'three']for i, element in enumerate(seq): print(i, element) Matplotlib bar() 和barh()a. 绘制直方图和条形图，主要用于查看各个分组的数量分布 b. atplotlib.pyplot.bar(left, height, width=0.8, bottom=None, hold=None, data=None, **kwargs) c.参数 参数 接收值 说明 默认值 left array x轴 无 height arrat 柱状图的高度 无 alpha 数值 颜色透明度 1 width 数值 宽度 0.8 color string 填充颜色 随机色 label string 每个图像的代表的含义 无 linewidth 数值 线的刻度 1 d 例子 Demo 1: 基本骨架 123456789101112131415161718192021import pandas as pdimport matplotlib.pyplot as plt #读取数据datafile = u'D:\\pythondata\\learn\\matplotlib.xlsx'data = pd.read_excel(datafile)# 画布plt.figure(figsize = (10, 5))plt.title('Example of Histogram', fontsize = 20)plt.xlabel(u'x-year', fontsize = 14)plt.ylabel(u'y-income',fontsize = 14)# 多个柱状图的分离距离width_val = 0.4plt.bar(data['time'],data['manincome'],width = width_val)plt.bar(data['time']+width_val, data['femaleincome'],width = width_vale)plt.legend(loc = 2)plt.show() Demo 2： 显示直方图的数值 1234567891011rect1 = plt.bar(data['time'],data['manincome'],width = width_val)rect2 = plt.bar(data['time']+width_val, data['femaleincome'],width = width_vale)python# 添加数据标签def add_labels(rects): for rect in rects: height = rect.get_height() plt.text(rect.get_x() + rect.get_width()/2, height, height, ha='center', va='bottom') rect.set_edgecolor('white') Demo 3: 直方图堆叠显示（bottom 参数调节) 123plt.bar(data['time'],data['manincome'],width = width_val)plt.bar(data['time'], data['femaleincome'], bottom = data['manincome'], width = width_vale)python Case 2 实现细节：barh的参数 left设置：The x coordinates of the left sides of the bars (default: 0). matplotlib.pyplot.barh(y, width, height=0.8, left=None, ,align=’center’, kwargs) DataFrame.interpolate插值法，填充NaN 1DataFrame.interpolate(self, method=&apos;linear&apos;, axis=0, limit=None, inplace=False, limit_direction=&apos;forward&apos;, limit_area=None, downcast=None, **kwargs)[source] 参数 12345method: str,default&quot;linear&apos;&apos;linear&apos;&apos;time&apos;&apos;index&apos;&apos;nearest&apos;,&apos;zero&apos;,&apos;slinear&apos;,‘quadratic’, ‘cubic’, ‘spline’, ‘barycentric’, ‘polynomial’ 例子 12 subplots_adjust(wspace, hspace)function：调整子图间距 DateTimetimedelta时间和日期的计算 表示日期差 计算规则 1234from datetime import timedeltatd = timedelta(days=92) # days hours minutesprint(d1 + td) datetime.strptime()字符串转换为日期和时间类型 12from datetime import datetimecday = datetime.strptime('2017-8-1 18:20:20', '%Y-%m-%d %H:%M:%S') datetime.strftime()datatime转化为字符串 123from datetime import datetimenow = datetime.now()print(now.strftime(&apos;%a, %b %d %H:%M&apos;)) DataFrame.rolling 窗口函数1DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None) 参数说明： window:时间窗的大小,数值int,即向前几个数据(可以理解将最近的几个值进行group by)min_periods:最少需要有值的观测点的数量,对于int类型，默认与window相等center:把窗口的标签设置为居中,布尔型,默认Falsewin_type: 窗口的类型,截取窗的各种函数。字符串类型，默认为Noneon: 可选参数,对于dataframe而言，指定要计算滚动窗口的列,值为列名closed：定义区间的开闭，支持int类型的window,对于offset类型默认是左开右闭的即默认为right,可以根据情况指定为left、both等axis：方向（轴）,一般都是0 常用聚合函数： mean() 求平均count() 非空观测值数量sum() 值的总和median() 值的算术中值min() 最小值max() 最大std() 贝塞尔修正样本标准差var() 无偏方差skew() 样品偏斜度（三阶矩）kurt() 样品峰度（四阶矩）quantile() 样本分位数（百分位上的值）cov() 无偏协方差（二元）corr() 相关（二进制） 注意：设置的窗口window=3，也就是3个数取一个均值。index 0,1 为NaN]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析]]></title>
    <url>%2F2019%2F05%2F22%2FPandas%20%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Pandas 做数据分析https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv Step 1: 读取文件 csv/txt names: columns，当names没被赋值时，header会变成0，即选取数据文件的第一行作为列名。当 names 被赋值，header 没被赋值时，那么header会变成None。如果都赋值，就会实现两个参数的组合功能。header = 0:是第一行是名字 sep=‘\t’ header=None:指定列名，数据开始行数。默认0行;None = 无标题 index_col :None； 指定列作为行索引 数值。 False表示无索引 usecols ; 如果列有很多，而我们不想要全部的列、而是只要指定的列就可以使用这个参数。 prefix .prefix 参数，当导入的数据没有 header 时，设置此参数会自动加一个前缀。 https://www.jianshu.com/p/42f1d2909bb6 Step 2: 缺省值处理1. dropDataFrame.drop(*self*, *labels=None*, *axis=0*, index=None**, columns=None, level=None, inplace=False, errors=’raise’)** Parameters labels single label or list-like Index or column labels to drop. axis {0 or ‘index’, 1 or ‘columns’}, default 0 Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’). index single label or list-like Alternative to specifying axis (labels, axis=0 is equivalent to index=labels).New in version 0.21.0. columns single label or list-like Alternative to specifying axis (labels, axis=1 is equivalent to columns=labels).New in version 0.21.0. level int or level name, optional For MultiIndex, level from which the labels will be removed. inplace bool, default False If True, do operation inplace and return None. errors{‘ignore’, ‘raise’}, default ‘raise’ If ‘ignore’, suppress error and only existing labels are dropped. 2. dropnaDataFrame.dropna(*self*, *axis=0*, *how=’any’*, thresh=None**, *subset=None*, *inplace=False*)**4 3. isna()DataFrame.isna(*self*) 填充 4. fillna()DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs) 填充空值，values可以是字典 values = {‘A’: 0, ‘B’: 1, ‘C’: 2, ‘D’: 3} drop使用 dropna删除缺省值 df = df.drop(some labels) df = df.drop(df[].index) ​ axis: 0(index) ​ how: any all ​ subset: label ​ inplace : bool drop删除 drop(labels(index, column labels), axis=0(行), level=None, inplace=False, errors=’raise’) ​ axis: label ​ index, columns fillna 填充 ​ fillna(value, method, limit) Step 3: 选取字段 列 df[labels] 行 df.loc[index_label,] df.iloc[整数值,] 列[“”] 也可以传入条件语句 描述性统计函数sum().mean().count()​ axis:1;按列求和，水平线 。往右看；所有列计算 ​ axis:0; 按行求和, 垂直线；把字段的所有的所有行和。往下按 ；所有行计算 .describle() .transpose()功能性函数groupby[].多个DataFame归并​ ### pd.merge(left, right, how=’inner交集/Outer并集（存在不重合的key是’, on=’key’可以是一个列表[]) .apply()方法 传入函数名：然后每一个元素都背计算​ lambda x : x*x 排序 .sort_values()整个表格都这么排列 DataFrame.sort_values(by=[lables],axis=[0,1], ascending:, kind:排序算法，) 日期类型: 日期等数值处理str列转换成日期类型 pd.to_datetime注意非日期类型的特殊处理 12345678df[&apos;日期时间&apos;] = pd.to_datetime(df[&apos;日期时间&apos;],format=&apos;%Y/%m/%d %H:%M:%S&apos;) #获取 日期数据 的年、月、日、时、分df[&apos;年&apos;] = df[&apos;日期时间&apos;].dt.yeardf[&apos;月&apos;] = df[&apos;日期时间&apos;].dt.monthdf[&apos;日&apos;] = df[&apos;日期时间&apos;].dt.daydf[&apos;时&apos;] = df[&apos;日期时间&apos;].dt.hourdf[&apos;分&apos;] = df[&apos;日期时间&apos;].dt.minute 指定类型​ method1 df1[‘year_month’] = df1[‘date’].apply(lambda x : x.strftime(‘%Y-%m’)) ​ method2 df1[‘period’] = df1[‘date’].dt.to_period(‘M’) 参数 M 表示月份，Q 表示季度，A 表示年度，D 表示按天 strp/ftime字符串和日期的转换 strftime: time-&gt;str strptime: str-&gt;time datetime.timedelta表示时间间隔，两个时间点之间的长度，主要用于时间计算,如时间序列预测的时候，需要外推，可能涉及到时间的计算1timedelta(weeks=0, days=0, hours=0, minutes=0, seconds=0, milliseconds=0, microseconds=0, ) #依次为 "周" "天", "时","分","秒","毫秒","微秒" datetime模块 类型 说明 date 以公历形式存储日历日期（年、月、日） time 将时间存储为时、分、秒、毫秒 datetime 存储日期和时间 1）python标准库函数 日期转换成字符串：利用str 或strftime 字符串转换成日期：datetime.strptime 12345678910stamp = datetime(2017,6,27)str(stamp) '2017-06-27 00:00:00'stamp.strftime('%y-%m-%d')#%Y是4位年，%y是2位年 '17-06-27'#对多个时间进行解析成字符串date = ['2017-6-26','2017-6-27']datetime2 = [datetime.strptime(x,'%Y-%m-%d') for x in date]datetime2[datetime.datetime(2017, 6, 26, 0, 0), datetime.datetime(2017, 6, 27, 0, 0)] 3）pandas处理成组日期 pandas通常用于处理成组日期，不管这些日期是DataFrame的轴索引还是列，to_datetime方法可以解析多种不同的日期表示形式。 datetime 格式定义 代码 说明 %Y 4位数的年 %y 2位数的年 %m 2位数的月[01,12] %d 2位数的日[01，31] %H 时（24小时制）[00,23] %l 时（12小时制）[01,12] %M 2位数的分[00,59] %S 秒[00,61]有闰秒的存在 %w 用整数表示的星期几[0（星期天），6] %F %Y-%m-%d简写形式例如，2017-06-27 %D %m/%d/%y简写形式 字符串转换成datetime格式: strptimedatetime.strptime(str, ‘%Y/%m/%d’).date() datetime变回string格式: strftime1234567df = pd.DataFrame(&#123;&quot;y&quot;: [1, 2, 3]&#125;,... index=pd.to_datetime([&quot;2000-03-31 00:00:00&quot;,... &quot;2000-05-31 00:00:00&quot;,... &quot;2000-08-31 00:00:00&quot;]))&gt;&gt;&gt; df.index.to_period(&quot;M&quot;)PeriodIndex([&apos;2000-03&apos;, &apos;2000-05&apos;, &apos;2000-08&apos;], dtype=&apos;period[M]&apos;, freq=&apos;M&apos;) 1—pd.Period()参数：一个时间戳生成器 Step 4: 数据透析表 pivot_table.pivot_table 数据透析表 分类汇总的统计数据​ (data,values= column to aggregate optional, index = grouper, columns=grouper, aggfunc:np.sum ) ​ table = pd.pivot_table(df, values=[‘D’, ‘E’], index=[‘A’, ‘C’], aggfunc={‘D’: np.mean, ‘E’: np.mean}) .groupby() 由于通过groupby()函数分组得到的是一个DataFrameGroupBy对象，而通过对这个对象调用get_group()，返回的则是一个·DataFrame·对象，所以可以将DataFrameGroupBy对象理解为是多个DataFrame组成的。 12grouped = df.groupby('Gender')grouped_muti = df.groupby(['Gender', 'Age']) 123456789print(grouped.get_group('Female'))print(grouped_muti.get_group(('Female', 17))) Name Gender Age Score2 Cidy Female 18 934 Ellen Female 17 967 Hebe Female 22 98 Name Gender Age Score4 Ellen Female 17 96 123456789101112131415print(grouped.count())print(grouped.max()[['Age', 'Score']])print(grouped.mean()[['Age', 'Score']]) Name Age ScoreGender Female 3 3 3Male 5 5 5 Age ScoreGender Female 22 98Male 21 100 Age ScoreGender Female 19.0 95.666667Male 19.6 89.000000 如果其中的函数无法满足你的需求，你也可以选择使用聚合函数aggregate，传递numpy或者自定义的函数，前提是返回一个聚合值 12345678910def getSum(data): total = 0 for d in data: total+=d return totalprint(grouped.aggregate(np.median))print(grouped.aggregate(&#123;'Age':np.median, 'Score':np.sum&#125;))print(grouped.aggregate(&#123;'Age':getSum&#125;)) 迭代 1234567891011121314151617grouped = df.groupby('A')for name, group in grouped: print(name) print(group) bar A B C D1 bar one 0.254161 1.5117633 bar three 0.215897 -0.9905825 bar two -0.077118 1.211526foo A B C D0 foo one -0.575247 1.3460612 foo two -1.143704 1.6270814 foo two 1.193555 -0.4416526 foo one -0.408530 0.2685207 foo three -0.862495 0.024580 可视化 对组内的数据绘制概率密度分布： 12grouped['Age'].plot(kind='kde', legend=True)plt.show() 计算不同组的某一列的值 12data.groupby('race')['age'].mean()要求被不同种族内被击毙人员年龄的均值: 对不同取值的计数: .value_counts() 12data.groupby('race')['signs_of_mental_illness'].value_counts()求不同种族内, 是否有精神异常迹象的分别有多少人 12data.groupby('race')['signs_of_mental_illness'].value_counts().unstack()组内操作的结果不是单个值, 是一个序列, 我们可以用.unstack()将它展开，得到DateFrame 1data.groupby('race')['flee'].value_counts().unstack().plot(kind='bar', figsize=(20, 4)) 这里有一个之前介绍的.unstack操作, 这会让你得到一个DateFrame, 然后调用条形图, pandas就会遍历每一个组(unstack后为每一行), 然后作各组的条形图 按不同逃逸类型分组, 组内的年龄分布是如何的?1data.groupby('flee')['age'].plot(kind='kde', legend=True, figsize=(20, 5)) 这里data.groupby(&#39;flee&#39;)[&#39;age&#39;]是一个SeriesGroupby对象, 顾名思义, 就是每一个组都有一个Series. 因为划分了不同逃逸类型的组, 每一组包含了组内的年龄数据, 所以直接plot相当于遍历了每一个逃逸类型, 然后分别画分布图. Step 5: 写入表格to_csv（path_or_buf，sep，header: bool or list of str : default：true， index: bool, default true） 字符串处理多个字符串分割Python中的spilt方法只能通过指定的某个字符分割字符串，如果需要指定多个字符，需要用到re模块里的split方法。 1234567&gt;&gt;&gt; import re&gt;&gt;&gt; a = &quot;Hello world!How are you?My friend.Tom&quot;&gt;&gt;&gt; re.split(&quot; |!|\?|\.&quot;, a)[&apos;Hello&apos;, &apos;world&apos;, &apos;How&apos;, &apos;are&apos;, &apos;you&apos;, &apos;My&apos;, &apos;friend&apos;, &apos;Tom&apos;] 去掉多余空格 filter aStr_splited = aStr.split(‘ ‘) print(filter(lambda x : x, aStr_splited)) list(filter(None,s.split(‘,’))) 列表 [x for x in s.split(‘,’) if x] 正则表达式https://docs.python.org/zh-cn/3/library/re.html 正则表达式：一种特殊的字符串，用于查找某种形式的字符串，满足某种条件的格式。 用于查找，匹配 re模块 re. pattern ​ [a-z] [abc] ​ ab 1\d 匹配任何十进制数字；这等价于类 [0-9]。 1\D 匹配任何非数字字符；这等价于类 [^0-9]。 1\s 匹配任何空白字符；这等价于类 [ \t\n\r\f\v]。 1\S 匹配任何非空白字符；这相当于类 [^ \t\n\r\f\v]。 1\w 匹配任何字母与数字字符；这相当于类 [a-zA-Z0-9_]。 1\W 匹配任何非字母与数字字符；这相当于类 [^a-zA-Z0-9_]。 ca*t 将匹配 &#39;ct&#39; (0个 &#39;a&#39; 字符)，&#39;cat&#39; (1个 &#39;a&#39; )， &#39;caaat&#39; (3个 &#39;a&#39; 字符) 另一个重复的元字符是 +，它匹配一次或多次。 要特别注意 * 和 + 之间的区别；* 匹配 零次 或更多次，因此重复的任何东西都可能根本不存在，而 + 至少需要 一次。 使用类似的例子，ca+t 将匹配 &#39;cat&#39; (1 个 &#39;a&#39;)，&#39;caaat&#39; (3 个 &#39;a&#39;)，但不会匹配 &#39;ct&#39;。 最复杂的重复限定符是 {m,n}，其中 m 和 n 是十进制整数。 这个限定符意味着必须至少重复 m 次，最多重复 n 次。 例如，a/{1,3}b 将匹配 &#39;a/b&#39; ，&#39;a//b&#39; 和 &#39;a///b&#39; 。 它不匹配没有斜线的 &#39;ab&#39;，或者有四个的 &#39;a////b&#39;。 ^表示行的开头，^\d表示必须以数字开头。 `表示行的结束，`\d表示必须以数字结束。 方法 / 属性 目的 match() 确定正则是否从字符串的开头匹配。 search() 扫描字符串，查找此正则匹配的任何位置。 findall() 找到正则匹配的所有子字符串，并将它们作为列表返回。 finditer() 找到正则匹配的所有子字符串，并将它们返回为一个 iterator。 匹配对象返回值的函数 方法 / 属性 目的 1group() 返回正则匹配的字符串 1start() 返回匹配的开始位置 1end() 返回匹配的结束位置 1span() 返回包含匹配 (start, end) 位置的元组 123456&gt;&gt;&gt; m.group()&apos;tempo&apos;&gt;&gt;&gt; m.start(), m.end()(0, 5)&gt;&gt;&gt; m.span()(0, 5) re.``search(pattern, string, flags=0)¶ 扫描整个 字符串 找到匹配样式的第一个位置，并返回一个相应的 匹配对象。如果没有匹配，就返回一个 None ； 注意这和找到一个零长度匹配是不同的。 re.``match(pattern, string, flags=0) 如果 string 开始的0或者多个字符匹配到了正则表达式样式，就返回一个相应的 匹配对象 。 如果没有匹配，就返回 None ；注意它跟零长度匹配是不同的。 Matplotlibimport matplotlib.pyplot as plt plt.figure() 画布 plt.subplot() 划分子图基本属性标题 market linstyle plt.text() 设置图内文本 轴标签 plt.xlabel() 设置坐标轴标签 plt.ylabel() 范围 plt.xlim() 设置坐标取值范围 元组 plt.ylim() plt.imshow() plt.axis(“off”) 设置记号刻度 刻度标签plt.xticks（[-np.pi，-np.pi / 2,0，np.pi / 2，np.pi]） plt.yticks（[ - 1，0，+1]） plt.xticks(new_ticks)plt.yticks([-2, -1.8, -1, 1.22, 3], [r’$really\ bad$’, r’$bad$’, r’$normal\ \alpha$’, r’$good$’, r’$really\ good$’]) 设置记号标签plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r’$-\pi$’, r’$-\pi/2$’, r’$0$’, r’$+\pi/2$’, r’$+\pi$’]) plt.yticks([-1, 0, +1], [r’$-1$’, r’$0$’, r’$+1$’]) 设置坐标plt.plot([],[],) linestyle marker marketsize https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html linestyle or ls {‘-‘, ‘—‘, ‘-.’, ‘:’, ‘’, (offset, on-off-seq), …} linewidth or lw float marker marker style markeredgecolor or mec color markeredgewidth or mew float markerfacecolor or mfc color markerfacecoloralt or mfcalt color markersize or ms float plt.axis([2011,2014,0.04,0.18]) plt.xticks(np.arange(2011,2015,1)) plt.yticks(np.arange(0.04,0.20,0.02)) plt.ylabel(“RMSE”) plt.xlabel(“(a) LSTM”) plt.grid(True） plt.figure(2) #plt.subplot(222) pandas1df.plot(subplots=True, figsize=(6, 6)); plt.legend(loc=&apos;best&apos;) data : DataFrame x : label or position, default None y : label or position, default None Allows plotting of one column versus another kind : str ‘line’ : line plot (default) ‘bar’ : vertical bar plot ‘barh’ : horizontal bar plot ‘hist’ : histogram ‘box’ : boxplot ‘kde’ : Kernel Density Estimation plot ‘density’ : same as ‘kde’ ‘area’ : area plot ‘pie’ : pie plot ‘scatter’ : scatter plot ‘hexbin’ : hexbin plot ax : matplotlib axes object, default None 时间序列123456789101112131415161718192021222324252627import datetimeimport matplotlib.pyplot as pltimport matplotlib.dates as mdatesimport numpy as npfig, ax = plt.subplots()months = mdates.MonthLocator()dateFmt = mdates.DateFormatter("%m/%d/%y")ax.xaxis.set_major_formatter(dateFmt)ax.xaxis.set_minor_locator(months)ax.tick_params(axis="both", direction="out", labelsize=10)date1 = datetime.date(2005, 8, 8)date2 = datetime.date(2015, 6, 6)delta = datetime.timedelta(days=5)dates = mdates.drange(date1, date2, delta)y = np.random.normal(100, 15, len(dates))ax.plot_date(dates, y, "#FF8800", alpha=0.7)fig.autofmt_xdate()plt.show() plot()12345678910111213141516171819202122232425262728293031323334DataFrame.plot(self, *args, **kwargs)kindstrThe kind of plot to produce:‘line’ : line plot (default)‘bar’ : vertical bar plot‘barh’ : horizontal bar plot‘hist’ : histogram‘box’ : boxplot‘kde’ : Kernel Density Estimation plot‘density’ : same as ‘kde’‘area’ : area plot‘pie’ : pie plot‘scatter’ : scatter plot‘hexbin’ : hexbin plot.figsizea tuple (width, height) in inchesx :labely:labelxlim:xticks:titlepandas.DataFrame.plot.barpandas.DataFrame.plot.barhpandas.DataFrame.plot.boxpandas.DataFrame.plot.densitypandas.DataFrame.plot.hexbinpandas.DataFrame.plot.histpandas.DataFrame.plot.kdepandas.DataFrame.plot.linepandas.DataFrame.plot.piepandas.DataFrame.plot.scatterpandas.DataFrame.boxplotpandas.DataFrame.hist https://blog.csdn.net/fengbingchun/article/details/81035861?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase https://www.cnblogs.com/Summer-skr--blog/p/11705925.html 时间序列绘图坐标轴xtick设置方法plt.xticks(statiem,[datetime.strftime(x,’%Y-%m’) for x in statiem]) 注意事项list() dict()的拷贝1、b = a: 赋值引用，a 和 b 都指向同一个对象。 2、b = a.copy(): 浅拷贝, a 和 b 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）。 b = copy.deepcopy(a): 深度拷贝, a 和 b 完全拷贝了父对象及其子对象，两者是完全独立的。 访问 df[-1:] #最后一行 df[-3:-1] *#倒数第3行到倒数第1行（不包含最后1行即倒数第1行） Linuxnohuplinux后台执行命令：&amp;和nohup 用途：不挂断地运行命令。 语法：nohup Command [ Arg … ] [ &amp; ] 例子： nohup sh example.sh &amp; nohup 命令可以使命令永久的执行下去，和终端没有关系，退出终端也不会影响程序的运行；&amp; 是后台运行的意思，但当用户退出的时候，命令自动也跟着退出。那么，把两个结合起来nohup 命令 &amp;这样就能使命令永久的在后台执行 nohup 命令 &gt; output.log 2&gt;&amp;1 &amp;让命令在后台执行。 其中 0、1、2分别代表如下含义：0 – stdin (standard input)1 – stdout (standard output)2 – stderr (standard error) nohup+最后面的&amp;是让命令在后台执行 &gt;output.log 是将信息输出到output.log日志中 2&gt;&amp;1是将标准错误信息转变成标准输出，这样就可以将错误信息输出到output.log 日志里面来。 &amp; 后台执行> 输出到不过联合使用也有其他意思，比如nohup输出重定向上的应用例子：nohup abc.sh &gt; nohup.log 2&gt;&amp;1 &amp;其中2&gt;&amp;1 指将STDERR重定向到前面标准输出定向到的同名文件中，即&amp;1就是nohup.log ps -ef|grep pythonps命令将某个进程显示出来 grep命令是查找 中间的|是管道命令 是指ps命令与grep同时执行 PS是LINUX下最常用的也是非常强大的进程查看命令 grep命令 是查找， 是一种强大的文本搜索工具，它能 使用正则表达式 搜索文本，并把匹 配的行打印出来。 grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 以下这条命令是检查 java 进程是否存在：ps -ef |grep java 字段含义如下：UID PID PPID C STIME TTY TIME CMD zzw 14124 13991 0 00:38 pts/0 00:00:00 grep —color=auto dae UID ：程序被该 UID 所拥有 PID ：就是这个程序的 ID PPID ：则是其上级父程序的ID C ：CPU使用的资源百分比 STIME ：系统启动时间 TTY ：登入者的终端机位置 TIME ：使用掉的CPU时间。 CMD ：所下达的是什么指令]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Networks]]></title>
    <url>%2F2019%2F05%2F12%2FDeel%20Learning%20ai_Convolutional%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[C4 : Convolutional Neural Networks(卷积神经网络)W1 :Convolutional Neural Networks(卷积神经网络)L1: Computer Vision Image classification Object detection Neural Style Transfer Problem : input big 神经网络结构复杂，数据量相对较少，容易出现过拟合； 所需内存和计算量巨大。 L2: Edge detection example我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。 卷积运算（Convolutional Operation）是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。 常见的边缘检测 垂直边缘（Vertical Edges) 和 水平边缘（horizontal Edges) 这张图的栏杆就对应垂直线，栏杆的水平线是水平边缘。 那么图片是怎么检测边缘的呢？ 过滤器：filter 在数学中“”就是卷积的标准标志，但是在Python中，这个标识常常被用来表示乘法或者元素乘法。 Output; 4 by 4 具体运算： 1） 为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（element-wise products）运算 2）为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉： 6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器。 举例说明： Vertical edge detection 这里在结果可能有点不对头，检测到的边缘太粗了，主要是图片太小了， 卷积操作API 在 Python 中，卷积用conv_forward()表示； 在 Tensorflow 中，卷积用tf.nn.conv2d()表示； 在 keras 中，卷积用Conv2D()表示。 L3: Edge Detection Example 颜色由暗到亮，还是亮到暗 这种滤波器可以区分明暗变化，取绝对值没有区别了 水平边缘 上边相对较亮，而下方相对较暗 复杂栗子 这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。 filter sobel过滤器，优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。 charr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。 学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。 这样可能得到一个出色的边缘检测 相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。 不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。 Padding按照我们上面讲的图片卷积，如果原始图片尺寸为$n x n$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n-f+1) x (n-f+1)$，注意f一般为奇数。这样会带来两个问题： 卷积运算后，输出图片尺寸缩小 原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息 边缘像素点只被一个输出所触碰或者使用， 为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行填充（Padding），以增加矩阵的大小。通常将 0 作为填充值。 经过padding之后，填充p,原始图片尺寸为$(n+2p) x (n+2p)$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n+2p-f+1) x (n+2p-f+1)$。若要保证卷积前后图片尺寸不变，则p应满足：$ p=(f-1)/2$,f通常是奇数，如果是偶数，造成不对称填充，第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置 p=0,Valid convolution p=((f-1))/2,Same convolution L05: Strided convolution（卷积步长）Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。 我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为： \left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor向下取整 目前为止我们学习的“卷积”实际上被称为互相关（cross-correlation），而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。 互相关：过滤器沿水平和垂直轴翻转，元素相乘来计算，这些视频中定义卷积运算时，我们跳过了这个镜像操作。（不进行翻转操作）叫做卷积操作 L06: Convolution over volumes(三维卷积) 卷积运算 过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。 不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 若输入图片的尺寸为n x n x nc，nc: 通道数目，filter尺寸为f x f x nc，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x nc′。其中，nc为图片通道数目，nc′为滤波器组个数。 L7 : One layer of a convolution network (单层神经网络) CNN单层的所以标记符号，设层数$l$, \begin{array}{l}{f^{[l]}=\text { filter size }} \\ {p^{[l]}=\text { padding }} \\ {g^{[l]}=\text { stride }} \\ {n_{c}^{[l]}=\text { number of filters }}\end{array} \begin{array}{c}{n_{H}^{[l]}=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor} \\ { n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor}\end{array}如果$m$个样本，进行向量化运算，相应的输出维度，为 \mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}L8 : A simple convolution network example（简单卷积网络示例） 一般而言，图片的height $n^{[l]}_{H}$和width $n^{[l]}_W$随着层数的增加逐渐降低，但channel $n^{[l]}_C$逐渐增加。 CNN有三种类型的layer： Convolution层（CONV） Pooling层（POOL） Fully connected层（FC） L9: Pooling layers(池化层)卷积神经网络除了卷积层，还有池化层来缩减模型的大小，提高运算速度和鲁棒性 池的类型有max pooling(最大池化) 这里步幅是s=2，filter = 2*2是最大池化的超参数,如果是三维，则单独在每个通道执行最大池化操作 关于max pooling的直觉解释： 元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。 Pooling layer: Average pooling 但是最大池化更好用 summary : 输入$n_Hn_Wn_C$,如果没有padding,输出$(n_h-f)/s+1(n_w-f)/s+1n_c$ L10: Convolutional neural network example (卷积神经网络实例)做一个识别数字的CNN网络 LeNet-5架构如下： 通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练 常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax 最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。 在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。 关于CNN如何选择超参：可以参考论文的经验。 Activation shape Activation Size #parameters Input: (32, 32, 3) 3072 0 CONV1(f=5, s=1) (28, 28, 6) 4704 156 (=556+6) POOL1 (14, 14, 6) 1176 0 CONV2(f=5, s=1) (10, 10, 16) 1600 416 (=5516+16) POOL2 (5, 5, 16) 400 0 FC3 (120, 1) 120 48120 (=120*400+120) FC4 (84, 1) 84 10164 (=84*120+84) Softmax (10, 1) 10 850 (=10*84+10) L11 Why convolution 参数共享（parameter sharing) 如果用FC的话，参数爆炸啊！如果conv layer 就需要filter检测器，这个参数就少了，还参数共享 稀疏连接(sparsity of connection) 输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。 summary1. 卷积神经网络的基本构造和计算过程 2. 如何整合这些模型 3. 哪些超参数 4. 为什么使用卷积 W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)L1 : Why look at case studies?(为什么要进行实例探究？)本文将主要介绍几个典型的CNN案例。通过对具体CNN模型及案例的研究，来帮助我们理解知识并训练实际的模型。 典型的CNN模型包括： LeNet-5 AlexNet VGG 还会介绍Residual Network（ResNet）。其特点是可以构建很深很深的神经网络（目前最深的好像有152层）。还会介绍Inception Neural Network L2 : Classic networks(经典网络)1. LeNet-5LeNet-5是针对灰度图片训练的，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，padding为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。 该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。 1. AlexNetAlexNet模型是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton共同提出的，其结构如下所示： AlexNet首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层,f=3，步幅为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，padding之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次same卷积，相同的padding，得到的结果是13×13×384，384个过滤器。再做一次same卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用softmax函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。 实际上，这种神经网络与LeNet有很多相似之处，不过AlexNet要大得多。正如前面讲到的LeNet或LeNet-5大约有6万个参数，而AlexNet包含约6000万个参数。当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点AlexNet表现出色。AlexNet比LeNet表现更为出色的另一个原因是它使用了ReLu激活函数。原作者还提到了一种优化技巧，叫做Local Response Normalization(LRN)。 而在实际应用中，LRN的效果并不突出。 3. VGG-16 首先用3×3，步幅为1的过滤器构建卷积层，padding参数为same卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此VGG网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。 数字16，就是指在这个网络中包含16个卷积层和全连接层。总共包含约1.38亿个参数 L3 : Residual Networks (ResNets)(残差网络(ResNets))我们知道，如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功。解决的方法之一是人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为Residual Networks(ResNets)。 L4: Why ResNets work?(残差网络为什么有用？) 因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。 注意，如果$ a[l]$与 $a[l+2]$的维度不同，需要引入矩阵 $W_s$与 $a_{[l]}$相乘，使得二者的维度相匹配。参数矩阵 $W_s$既可以通过模型训练得到，也可以作为固定值，仅使 $a[l]$截断或者补零。 L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积) 作用 假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_c$）的方法，对于池化层我只是压缩了这些层的高度和宽度 doing something pretty non-trivial 它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。 L6 : Inception network motivation(谷歌 Inception 网络简介) 有了这样的Inception模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。有了这样的Inception模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。 1x1 的卷积层通常被称作瓶颈层（Bottleneck layer） 计算量为 28x28x32x5x5x192 = 1.2亿 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。 L7 : Inception network(Inception 网络) L8 : Using open-source implementations( 使用开源的实现方案)开源项目 L9 ： Transfer Learning（迁移学习）如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。 只有很小数据集： 可以你只需要训练softmax层的权重，把前面这些层的权重都冻结。 稍微更大的数据集： 你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元；或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的softmax输出层，这些方法值得一试。 大量数据： 你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。 L10 ： Data augmentation（数据增强）数据量远远不够 Mirroring Random Cropping 彩色转换color shifting r,g,b数据改变 除了随意改变RGB通道数值外，还可以更有针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法。这样也能增加有效的样本数量。具体的PCA color augmentation做法可以查阅AlexNet的相关论文。 常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。 L11：The state of computer vision(计算机视觉现状) 神经网络需要数据，不同的网络模型所需的数据量是不同的。Object dection，Image recognition，Speech recognition所需的数据量依次增加。一般来说，如果data较少，那么就需要更多的hand-engineering，对已有data进行处理。 hand-engineering是一项非常重要也比较困难的工作。很多时候，hand-engineering对模型训练效果影响很大，特别是在数据量不多的情况下。 当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。在别人做好的基础上研究 提升性能 * 由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。 所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。 summary1. CNN的常见网络结构 重点说了一些残差网络 2.数据增加的方法 3. 多用开源框架，不用从头开始训练 W3 Object detection(目标检测)L1 :Object localization(目标定位)目标定位和目标检测 模型 输入还包括位置信息 损失函数 情况一：检测到了 情况二： L2: Landmark detection(特征点检测) 该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值。通过检测人脸特征点可以进行情绪分类与判断，或者应用于AR领域等等。 除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示： L3 :Object detection(目标检测)学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。 训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。 选定特定大小的窗口，窗口圈定输入卷积神经网络，卷积神经网络开始预测。 重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或 如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。 这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。 滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。但是其缺点也很明显，首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。所以，滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活。 L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现) 全连接层转化为卷积层 单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，步进长度为2，CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。 之前的滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。值得一提的是，窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。 L5 ： Bounding box predictions（Bounding Box预测） YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。 如果目标中心坐标(bx,by)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。判断有目标的网格中，bx,by,bh,bw限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(bx,by)范围限定在[0,1]之间，但是bh,bw可以大于1。因为目标可能超出该网格，横跨多个区域，如上图所示。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。 L6 ：Intersection over union（交并比) 一般约定，在计算机检测任务中，如果lou&gt;=0.5，就说检测正确，如果预测器和实际边界框完美重叠，loU就是1，因为交集就等于并集。但一般来说只要lou&gt;=0.5，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将loU定得更高，比如说大于0.6或者更大的数字，但loU越高，边界框越精确。 L7: Non-max suppression(非极大值抑制)到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。 假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。 实际情况是格子1，2，3，4，5，6都认为里面有车。因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc,我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。 非最大值抑制（Non-max Suppression）做法很简单，图示每个网格的Pc值可以求出，Pc值反映了该网格包含目标中心坐标的可信度。首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示： 总结一下非最大值抑制算法的流程： 剔除Pc值小于某阈值（例如0.6）的所有网格； 选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格； 对剩下的网格，重复步骤2。 到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用anchor box这个概念，我们从一个例子开始讲吧。方法是使用不同形状的Anchor Boxes。 这就是anchor box的概念，我们建立anchor box这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生 L9 : YOLO 算法（Putting it together: YOLO algorithm） 这就是YOLO对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路 Region proposals (Optional)（候选区域（选修））之前介绍的滑动窗算法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，例如下图所示。这样会降低算法运行效率，耗费时间。 为了解决这一问题，尽量避免对无用区域的扫描，可以使用Region Proposals的方法。具体做法是先对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。 Region Proposals共有三种方法： R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。 Fast R-CNN: 利用卷积实现滑动窗算法，类似第4节做法。 Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。 W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)C1 ： What is face recognition?首先简单介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。 人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。 人脸识别：输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题。 L2 ： One-shot learningOne-shot learning就是说数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型来进行人脸识别。若数据库有K个人，则CNN模型输出softmax层就是K维的。 但是One-shot learning的性能并不好，其包含了两个缺点： 每个人只有一张图片，训练样本少，构建的CNN网络不够健壮。 若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活。 为了解决One-shot learning的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用： d(img1,img2)≤τ : 一样 d(img1,img2)&gt;τ : 不一样 现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数。 L3: Siamese network最后一层去掉softmax单元做分类 如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x^{(2)})$。这里我用$x^{(1)}$和$x^{(2)}$仅仅代表两个输入图片, d(x^{(1)},x^{(2)})=||f(x^{(1)}-f(x^{(2)}||^2不同的图片的CNN网络结构和参数都是一样的，目标就是利用梯度下降算法，调整网络参数]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Deep Learning Specialization]]></title>
    <url>%2F2019%2F05%2F05%2FDeep%20Learning%20ai_Deep%20Learning%20Specialization%2F</url>
    <content type="text"><![CDATA[C3 Improving Model Performance W1 ML Strategy(1)L01 Improving Model Performance需要提高训练结果的表现，表现得更好的措施 Machine Learning Strategy L2 : Orthogonalization(正交化)所谓正交，就是你的操控效果尽量只影响一个方面。比如以老式电视机为例，调节图像的大小、左右偏移、上下偏移。而不是一个按钮可以同时调节图像大小和左右偏移，那样会很难操作。 具体到supervised learning，有以下4个假设是正交的？ Fit training set well in cost function If it doesn’t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help. Fit development set well on cost function If it doesn’t fit well, regularization or using bigger training set might help. Fit test set well on cost function If it doesn’t fit well, the use of a bigger development set might help Performs well in real world If it doesn’t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing. 在训练集上表现欠佳，需要切换到好的优化算法 在验证集上表现不好，一组正则化按钮 在测试集表现不好，需要更好的验证集 在用户体验不好，需要改变测试集大小或者成本函数 L3 Single number evaluation metric(单一数字评估指标)classification Precesion （查准率） recall（查全率） F 1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2 P R}{P+R}L4 Satisficing and optimizing metrics(满足和优化指标)如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。这时，我们可以将某些指标作为优化指标（Optimizing Matric），寻求它们的最优值；而将某些指标作为满足指标（Satisficing Matric），只要在一定阈值以内即可。 在这个例子中，准确率就是一个优化指标，因为我们想要分类器尽可能做到正确分类；而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个阈值，那最终选择的分类器就应该是以这个阈值为界里面准确率最高的那个。 如此，accuracy就变成了optimizing metric，而running time则是satisfying metric，statisfying metric只要达到标准即可，而optimizing metric则追求更好。一般的，选择一项metric作为optimizing metric，其他的则设置为satisfying metric： L 5: Train/dev/test distributions(训练/开发/测试集划分)开发（dev）集也叫做开发集（development set），有时称为保留交叉验证集（hold out cross validation set）。 如何设置Train/dev/test集，很大程度上影响了机器学习的速度。 Train/dev/test的区别 Workflow in machine learning is that you try a lot of ideas, train up different models on the training set, and then use the dev set to evaluate the different ideas and pick one. And, keep innovating to improve dev set performance until, finally, you have one class that you’re happy with that you then evaluate on your test set. 开发集合和开发集合来自同一分布，如果是不同分布，相当于靶心移动了 L 6: Size of dev and test sets(开发集和测试集的大小) L7 : When to change dev/test sets and metrics(什么时候该改变开发/测试集和指标)如果发现设定目标和实际期望不符，那就调整目标。 举个例子 A可能把一些色情照片也分类成猫了，因此改变优化指标 我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。 后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，$J=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)$你要最小化训练集上的损失。你可以做的其中一件事是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，$J=\frac{1}{\sum w^{(i)}} \sum_{i=1}^{m} w^{(i)} L\left(\hat{y}^{(i)}, y^{(i)}\right)$ 再次，如何定义J并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数J。 L8 : Why human-level performance?(为什么是人的表现？) 上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为贝叶斯最优误差（Bayes Optimal Error）。 也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。 当模型的表现超过人类后，这些手段起的作用就微乎其微了。 L9 : Avoidable bias(可避免偏差) training error 我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。 dev error 贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差 L 10: Understanding human-level performance(理解人的表现)还记得上个视频中，我们用过这个词“人类水平错误率”用来估计贝叶斯误差，那就是理论最低的错误率，任何函数不管是现在还是将来，能够到达的最低值 L11 : Surpassing human- level performance(超过人的表现)现在，机器学习有很多问题已经可以大大超越人类水平了。 L12 : Improving your model performance(改善你的模型的表现)你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。 method summary这一周的内容主要是改善模型的表现，主要是按照正交化，使得更好的满足 1. 评价指标 2. 数据集的划分 3. 人的表现的重要性 4. 当出现表现不好的时候，如何改善呢，有哪些方法呢？ W2 ML Strategy(2)C 1: Carrying out error analysis(进行误差分析)1. simple analysis 通过观察发现算法分类出错的例子，是把狗分成猫，提高准确率的方法就是如何针对狗的图片优化算法。你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。现在考虑的是应该不应该这么去做呢？统计一下dev set里面多少是错误标记是狗的个数，分析出可以改善的算法的上限。 mutiply analysis C2 : Cleaning up Incorrectly labeled data(清除标注错误的数据)incorrct labeltraning setDL algorithms are quite robust to random errors in the traning set so long as your errors or your labeled example to once those errors are not too far from random . distribution首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。开发集确定了你的目标，当你击中目标后，你希望算法能够推广到测试集上，这样你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正以确保它们继续来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。 suggestion最后我讲几个建议： 首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。 其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。 这就是错误分析过程，在下一个视频中，我想分享一下错误分析是如何在启动新的机器学习项目中发挥作用的。 C3: Build your first system quickly, then iterate(快速搭建你的第一个系统，并进行迭代)1. iterationI recommend that you first quickly set up a definition and metrics so this is really you know deciding where to place your target and you get it wrong you can always move it later we just set up a target somewhere and then I recommend you build an inital machine learning system quickly find the traning set train it and see start to see and understand how well your are doing against your Devon chess setting evaluation metric when you build your initial system you then be able to use bias variance analysis we should talk about earlier as well as error analysis whick we talked about just in last several videos to prioritize the next step in particular if error analysis causes you to realize that a lot of the errors are from the spearker being very far from the mirophone which causes special challenges speech recognitin then that would give you a good reason to focus on techniques to address this it called fast used speech recognition which basically means handling when the speaker is very far from microphone along the value of building this inital system it can be a quick and diry implementation you know do not overthink it but all the value of the inital system is having some learning system having some tranin system allows you lok at bias and variance to do error analysis look at some mistakes to figure out all the different directins you could go in. 我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。 C4 : Training and testing on different distributions(使用来自不同分布的数据，进行训练和测试)this is resulted in many teams sometimes taking one of the days you can find and just shoving it into the training set . Cat app example 假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这10,000张图片，因为这样你的训练集就太小了，使用这20万张图片似乎有帮助。但是，困境在于，这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢？ 我们真正关心的是来自手机手机收集的数据，而不是来自网页。方法一，随机分配训练集、验证集、测试集，这样的后果就是花了大量时间在实际不关心的数据分布去优化。 训练集20万张网络，5000手机，验证集和测试集各2500，这样可以保证验证集和测试集更接近实际应用场景，我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。 C5: Bias and Variance with mismatched data distributions（数据分布不匹配时，偏差与方差的分析）首先算法只看过训练集数据，没看过开发集数据。第二，开发集数据来自不同的分布。很难确认这增加的9%误差率有多少是因为算法没看到开发集中的数据导致的，这么评估呢？到底哪个影响元素更大， 评估方法，训练集的分布挖出，traning-dev set : Same distributation as traning set ,but not used for training. 现在，我们有了训练集错误率、训练-验证集错误率，以及验证集错误率。其中，训练集错误率和训练-验证集错误率的差值反映了方差；而训练-验证集错误率和验证集错误率的差值反映了样本分布不一致的问题，从而说明模型擅长处理的数据和我们关心的数据来自不同的分布，我们称之为数据不匹配（Data Mismatch）问题。 C6: Addressing data mismatch（处理数据不匹配问题）I Data: Artifical data synthesis 所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。 C7: Transfer learning（迁移学习）迁移学习（Tranfer Learning）是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。 例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（$W[L]$、$b[L]$），随后用新的训练集进行训练，就完成了以上的迁移学习。 如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即$W[L]$$、b[L]$，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为预训练（Pre-Training），之后的权重更新过程称为微调（Fine-Tuning）。 在下述场合进行迁移学习是有意义的： 两个任务有同样的输入（比如都是图像或者都是音频）；拥有更多数据的任务迁移到数据较少的任务；某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。 C8; Multi-task learning （多任务学习）For example, autonomous driving example,check cars,stop signs,trfffic lights ,输出也是一个向量， C9 : What is end-to-end deep learning?(什么是端到端的深度学习)在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而端到端深度学习（End-to-end Deep Learning）只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。 优点与缺点应用端到端学习的优点： 只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析； 所需手工设计的组件更少，简化设计工作流程； 缺点： 需要大量的数据； 排除了可能有用的人工设计组件； 根据以上分析，决定一个问题是否应用端到端学习的关键点是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？ Whether to use end-to-end learning?(是否要使用端到端的深度学习?)Pros: ​ let the data speak : x-&gt;y ​ less hand-designing of components needed Cons: ​ May need large amount of data ​ excludes potentially useful hand-designed components Key question: Do you hava sufficient data to learn a function of the complexity needed to map x to y? 如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的x到y映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。 Summary学习如何通过一些手段提高模型的表现，首先了解模型的性能的体现，bias、variance、贝叶斯误差。以及如何一步步的改善性能。具体解决了如下问题，1. 数据的划分 2. 人的表现与机器性能的关系、偏差、方差 3. 训练集和验证集的分布问题，当数据样本对于解决问题不足的时候的解决办法，4. 迁移学习 5. 端到端的学习 6. 多任务学习。6. 在性能不好的情况下，可能需要手动的分析误差，对测试集错误样例做统计等等，]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aiai_]]></title>
    <url>%2F2019%2F04%2F17%2FImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning%2C%20Regularization%20and%20Optimization%2F</url>
    <content type="text"><![CDATA[C2W1L01 : Train/Dev/Test Sets1. process应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。 2. data split 训练集（train set）：用训练集对算法或模型进行训练过程； 验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行交叉验证，选择出最好的模型或者验证不同算法的有效性。 测试集（test set）：最后利用测试集对模型进行测试，获取模型运行的无偏估计（对学习方法进行评估）。 假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（dev set），其实都是同一个概念，最后一部分则作为测试集。 在机器学习发展的小数据量时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分： 无验证集的情况：70% / 30%； 有验证集的情况：60% / 20% / 20%； 在如今的大数据时代，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。 验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。 测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。 100 万数据量：98% / 1% / 1%； 超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%） 3. 建议验证集要和训练集来自于同一个分布（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。 如果不需要用无偏估计来评估模型的性能，则可以不需要测试集。如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。 L02 : Bias/Variance“偏差-方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。 泛化误差可分解为偏差、方差与噪声之和： 偏差：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力； 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响； 噪声：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了学习问题本身的难度。 high bias ,underfitting high variance, overfitting just right 1. example Your algorithms ever on the training set and dev set you can try to diganose whether has problems high barriers or high variances or both or neither. L03 Basic Recipe for Machine learning1. METHOD Training a bigger network almost never hurts. And the main cost of training a neural network that’s too big is just computational time, so long as you’re regularizing. 今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高，我们下节课再细讲，以便大家更好理解如何实现神经网络的正则化。 第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同 只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。 L041. over fittingregularizationL2 regularization L1 regularizaion: w will be sparse L1 正则化最后得到 w 向量中将存在大量的 0 为什么只正则化参数w？为什么不再加上参数b 呢？你可以这么做，只是我习惯省略不写，因为通常w是一个高维参数矢量，w已经可以表达高偏差问题，可能w包含有很多参数，我们不可能拟合所有参数，而只是b单个数字，所以w几乎涵盖所有参数，而不是，如果加了参数b，其实也没太大影响，因为b只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。 2. 矩阵范数被称作“弗罗贝尼乌斯范数”，用下标标注F 反向传播时，填上正则化的一项 因此L2正则化也被称为“权重衰减”。 to get more training data L05 :Why Regularization Reduces Overfitting我们添加正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩范数，或者弗罗贝尼乌斯范数或者参数可以减少过拟合？我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单.Regularization其实是让函数变得简化。 直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。 总结一下，如果正则化参数变得很大，w参数很小，z也会相对变小，此时忽略的b影响，z会相对变小，实际上，z的取值范围很小，这个激活函数tanh，也就是曲线函数会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。 L2 regularization的不足：要通过不断的选用不同的λ进行测试，计算量加大了。 L06 : Dropout Regularization1. 工作原理 如果上面这幅图存在over fitting。复制这个神经网络，dropout会遍历网络的每一层。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用backprop方法进行训练。 我们针对每个训练样本训练规模极小的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练极小的网络。 2. inverted dropout（反向随机失活）对第L 1234keep_prob = 0.8 # 设置神经元保留概率dl = np.random.rand(al.shape[0], al.shape[1]) &lt; keep_probal = np.multiply(al, dl)al /= keep_prob 最后一步al /= keep_prob是因为 a[l]a[l]中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z[l+1]=W[l+1]a[l]+b[l+1]$的期望值，因此除以一个keep_prob。举例解释我们假设第三隐藏层上有50个单元或50个神经元，在一维上是50，我们通过因子分解将它拆分成维的，保留和删除它们的概率分别为80%和20%，这意味着最后被删除或归零的单元平均有10（50×20%=10）个，现在我们看下$z^{[4]}$，，我们的预期是$z^{[4]}=w^{[4]}a^{[3]}$，$a^{[3]}$减少20%，也就是说中有$a^{[3]}$20%的元素被归零，为了不影响的$a^{[4]}$期望值，我们需要用$w^{[4]}a^{[3]}/keep_prob$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变，划线部分就是所谓的dropout方法。 L07 : Understanding Dropout直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。 计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以dropout在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，dropout是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用dropout的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于dropout函数的原因。直观上我认为不能概括其它学科。dropout将产生收缩权重的平方范数的效果。当然，不同的层，值可以设置成不同，如果你觉得某一层容易过拟合，把值设置小一点。 dropout 的一大缺点是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将keep_prob全部设置为 1.0 后运行代码，确保 $J(w,b)​$函数单调递减，再打开 dropout。 L08 : Other Regularization Methods 数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。 早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，当训练集误差降低但验证集误差升高，两者开始发生较大偏差时及时停止迭代，并返回具有最小验证集误差的连接权和阈值，以避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。 但对我来说early stopping的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数，因为现在你不再尝试降低代价函数，所以代价函数的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。 Early stopping的优点是，只运行一次梯度下降，你可以找出的w较小值，中间值和较大值，而无需尝试正则化超级参数的很多值。 L09 ： Normalizing inputs 零均值 $u=\frac{1}{m}\sum x^{(i)}$,$x-u$ 归一化方差； $\delta^2=\frac{1}{m}(x^{(i)})^2$,每个特征的方差，每个特征数据除以它，就归一化方差了 why 在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。 L10 : Vanishing /Exploding Gradients训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。 在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与相关的指数级数增长或下降，它也适用于与层数相关的导数或梯度函数，也是呈指数级增长或呈指数递减。 假定 g(z)=z,b[l]=0g(z)=z,b[l]=0，对于目标输出有： $y^=W[L]W[L−1]…W[2]W[1]X$ 对于$ W[l]$的值大于 1 的情况，激活函数的值将以指数级递增； 对于 $W[l]$的值小于 1 的情况，激活函数的值将以指数级递减。 对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。 L11 : Weight initialization in a deep network为了预防值z过大或过小，你可以看到n越大，你希望w越小，因为z是wx+b的和,最合理的方法$w_i=1/n$ 因此，实际上，你要做的就是设置某层权重矩阵 $w^{[l]}=n p . random. randn (shape) * np.sqrt \left(\frac{1}{n^{[l-1]}}\right)​$ 当多个节点时，也一样的看，使得这个节点$z^{L}$不要太大，单独看每个节点既可以 relu : var(w(i)) = 2/n or $\frac{2}{n^{[l-1]}*n^{[l]}}$ tanh: var(w(i)) = 1/n 通过设置初始化化权重矩阵，使得不会增长太快或者太慢 L12 ： Numerical Approximations of Gradients单边误差 $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0} \frac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}$ 误差$O(\varepsilon)$ 双边误差 $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0}=\frac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2 \varepsilon}$ $O\left(\varepsilon^{2}\right)$ L 13 Gradient Checking梯度检验帮我们节省了很多时间，也多次帮我发现backprop实施过程中的bug，接下来，我们看看如何利用它来调试或检验backprop的实施是否正确。 首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵w转换成一个向量，把所有矩阵w转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数J是所有W和b的函数，现在你得到了一个的代价函数（即）。接着，你得到与和顺序相同的数据，你同样可以把$dW^{[l]}$,和$db^{[l]}$ 转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。 梯度的逼近值 d \theta_{\text { approx }}[i]=\frac{J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}+\varepsilon, \ldots\right)-J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}-\varepsilon, \ldots\right)}{2 \varepsilon} 现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多bug，希望它对你也有所帮助。 L 14 : Gradient Checking Implementation notes 不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；太慢了 如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大； 当成本函数包含正则项时，也需要带上正则项进行检验； 梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout； Summary回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如正则化和**dropout**，还有加快神经网络训练速度的技巧，最后是梯度检验。 C2W2 :Optimization AlgorithmL 01 : Mini Batch Gradient Descent Vectorization Mini batch not entire training set bady training set i，$x^{\{i\}}$ mini batch training set mini batch gradient descent L 02 : Understanding Mini-Batch Gradient Decent 左图，随着iterations increased, it should decrease .if it ever goes up on iteration,something is wrong. 右图 : it’s as if on every iteration you’re training on a different training set or really training on a different mini batch. It should trend downwards, but it’s also going to be a little bit noisier.So if you plot J{t}, as you’re training mini batch in descent it may be over multiple epochs,you might expect to see a curve like this. Choosing your mini-batch size 1. 优缺点 通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的mini-batch尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果mini-batch大小为1000个样本，你就可以对1000个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每次训练集允许我们采取5000个梯度下降步骤，所以实际上一些位于中间的mini-batch大小效果最好。 使用batch梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数是迭代次数的一个函数，它应该会随着每次迭代而减少，如果在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。 在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。 用mini-batch梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会讲到学习率衰减，也就是如何减小学习率。 batch : too long,too time 随机： lose speeding ,噪声大 mini-batch和stochastic都存在噪声问题，且在local optima附近会徘徊。但设置合适大小的mini-batch size，噪声和徘徊问题可接受的范围内。 size=1,又叫随机梯度下降法 stochastic gradient descent how如何选择mini-batch size（这是一个hyperparameter）： 小数据量，比如总的样本只有几千个，完全可以直接用batch gradient descent 大数量，mini-batch size倾向于选择2^n个，比如64, 128, 256等 mini-batch 与CPU/GPU memory的内存容量。 In practice of course the mini batch size is another hyper parameter that you might do a quick search over to try to figure out which one is most sufficient of reducing the cost function j. 按照上面的方法 L 03: Exponentially Weighted AveragesIn order to understand those algorithms, you need to be able they use something called exponentially weighted averages. Also called exponentially weighted moving averages in statistics. 1. 指数加权平均数（Exponentially weighted averages） $\theta _i$表示每一日的温度值，蓝色的点，$v_t$表示加权平均后的,红色 权平均方法是：每天的温度值加权值$vt$设置为前一天的温度加权值$vt−1$和当天的温度实际值$θt$做加权平均： v_{t}=\beta v_{t-1}+(1-\beta) \theta_{t}由于以后我们要考虑的原因，在计算时可视$v_T$大概是$\frac{1}{(1-\beta)}$的每日温度的加权平均， 如果是$\beta$=0.9，这是十天的平均值，红色 如果$\beta$=0.98,是50天的结果，绿色 如果$beta$=0.5,是2day的结果，黄色 由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。 当 $\beta$较大时，指数加权平均值适应地更缓慢一些。 $ L 04 : Understanding Exponentially Weighted Averages假如β=0.9，每个v的计算如下： \begin{aligned} v_{100} &=0.9 v_{99}+0.1 \theta_{100} \\ v_{99} &=0.9 v_{98}+0.1 \theta_{99} \\ v_{98} &=0.9 v_{97}+0.1 \theta_{98} \end{aligned}递推可得： v_{100}=0.1 \theta_{100}+0.1 * 0.9 \theta_{99}+0.1 *(0.9)^{2} \theta_{98}+\ldots指数的衰减规律 一般的 v_{t}=\sum_{i=1}^{t}(1-\beta) \beta^{t-i} \theta_{i}无穷级数求和： \sum_{t=1}^{n}(1-\beta) \beta^{t}=1因此可以近似的认为所有项的系数之和正好为100%。 即，$vt$是对t日之前所有的实际温度的加权平均,权重是指数递减的。 十天后，曲线高度下降到了1/3,赋予权重$\beta^{t-i}$ 0.9^{10}~=0.35~=1/e一般认为，$v_t$近似前$\frac{1}{1-\beta}$的加权平均值 L05 : Bias correction in exponentially weighted averages指数加权平均的偏差修正 由于计算$v1$的时候，并没有历史值做加权，这个时候令其前一个加权值$v0=0$，则会导致$v_1$远小于$\theta_1$,依次类推，在靠近前面的值会出现显著的小于实际值的情况 因此做一个修正 v_{t}=\frac{\beta v_{t-1}+(1-\beta) \theta_{t}}{1-\beta^{t}}你会发现随着$\beta^t$增加，接近于0，所以当t很大的时候，偏差修正几乎没有作用，因此当t较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。 因为在Machine Learning中看重的是很多次迭代后的结果，初期的偏差影响并不大。 L 06 : Gradient Descent With Momentum动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法， 当慢慢下降到最小值，上下波动的梯度下降法的速度减缓，无法使用更大的学习率， 在纵轴上，希望学校慢一点，不需要摆动，横着上，加快学校，基于此就有了Gradient descent with momentum。 \begin{array}{c}{v_{d W} :=\beta v_{d W}+(1-\beta) d W} \\ {v_{d b} :=\beta v_{d b}+(1-\beta) d b} \\ {w=w-\alpha v_{d W}} \\ {b=b-\alpha v_{d b}}\end{array}这样，可以让gradient更平滑 对于上图垂直方向，原来是会上下震荡，但引入了exponentially weighted average，相当于对前面的震荡进行了平均，结果就是上下震荡互相抵消了。而水平方向都是向右没有震荡，因此平均后还是向右。最终导致呈现上图红色的下降路线。 L 07 : RMSpropRMSprop (Root Mean Square Propagation，均方根传递)，与momentum一样，也是降低梯度的抖动。而是平抑不同大小梯度的更新速率。实际上 作用在α上的 回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设b纵轴代表参数，横轴代表参数W，可能有w1，或者w2其它重要的参数，为了便于理解，被称为b和w。 我们希望学习速度快，而在垂直方向，也就是例子中的方向，我们希望减缓纵轴上的摆动，所以有了$S_{d W} $和$ S_{d b}$，我们希望$S_{d W} $会相对较小，所以我们要除以一个较小的数，而希望$ S_{d b}$又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。 这些微分，垂直方向的要比水平方向的大得多，所以斜率在方向特别大，所以这些微分中，db较大，dw较小，因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是方向上W。db的平方较大，所以$Sdb$也会较大，而相比之下，dw会小一些，亦或dw平方会小一些，因此$Sdw$会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。 RMSprop的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率，然后加快学习，而无须在纵轴上垂直方向偏离。 实际中dw是一个高维度的参数向量，db也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是RMSprop，全称是均方根，因为你将微分进行平方，然后最后使用平方根。 解释平方： 垂直方向，比较陡，梯度比较大，但我们又希望它下降的慢。因此对梯度除以一个较大的值，所以用梯度的平方的平均来表示。让不同的参数拥有不同的learning rate。 从某种角度看，RMSprop会根据当前的梯度自动调整参数的learning rate，梯度大降低learning rate，梯度小的时候提高learning rate，从而一方面避免了震荡，另一方面避免在平坦的地方徘徊太久。 为了避免出现分母为0 \begin{array}{c}{s_{d w}=\beta s_{d w}+(1-\beta)(d w)^{2}} \\ {s_{d b}=\beta s_{d b}+(1-\beta)(d b)^{2}} \\ {w :=w-\alpha \frac{d w}{\sqrt{s_{d w}+\varepsilon}}} \\ {b :=b-\alpha \frac{d b}{\sqrt{s_{d b}+\varepsilon}}}\end{array}$\varepsilon$取$10^{-8}$不错的选择. 补充： RMSProp算法对梯度计算了微分平方加权平均数。这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快 L 08 Adam optimization algorithmAdam（Adaptive Moment Estimation，自适应矩估计）就是momentum和RMSprop的结合。momentum负责平滑梯度，而RMSprop负责调解learning rate。 1. Adama. 引入的变量有： $v$ : 计算同momentum算法，将梯度进行指数加权平均 $s$: 计算同RMSprop，将梯度的平方进行指数加权平均 $β1$ : 计算vv的加权参数 $β2$ : 计算ss的加权参数 b. 在迭代前，初始化参数v和s v_{d W}=0, s_{d W}=0, v_{d b}=0, s_{d b}=0c. 对第t次梯度下降的迭代 a. 首先计算dw和db的v和s \begin{array}{c}{v_{d W}=\beta_{1} v_{d W}+\left(1-\beta_{1}\right) d W} \\ {s_{d W}=\beta_{2} s_{d W}+\left(1-\beta_{2}\right)(d W)^{2}} \\ {v_{d b}=\beta_{1} v_{d b}+\left(1-\beta_{1}\right) d b} \\ {s_{d b}=\beta_{2} s_{d b}+\left(1-\beta_{2}\right)(d b)^{2}}\end{array}d. 修正 v_{d W}^{\text {corrected}}=\frac{v_{d W}}{1-\left(\beta_{1}\right)^{t}}\\ \begin{aligned} s_{d W}^{\text {corrected}} &=\frac{s_{d W}}{1-\left(\beta_{2}\right)^{t}} \\ v_{d b}^{\text {corrected}} &=\frac{v_{d b}}{1-\left(\beta_{1}\right)^{t}} \\ s_{d b}^{\text {corrected}} &=\frac{s_{d b}}{1-\left(\beta_{2}\right)^{t}} \end{aligned}e. 最后更新参数W和b W=W-\alpha \frac{v_{d W}^{\text {corrected}}}{\sqrt{s_{d W}^{\text { corrected }}+\varepsilon}}\\ b=b-\alpha \frac{v_{d b}^{\text {corrected}}}{\sqrt{s_{d b}^{\text { corrected }}+\varepsilon}}超参的选择： α：需要调优 β1: 通常选择为0.9 β2: 通常选择为0.999 ε: 一般不需要调优，选择一个小数，比如10−8 你可以尝试一系列值α，然后看哪个有效 L09 : Learning Rate Decay why 为什么要做learning rate decay？ 较大的learning rate虽然在算法开始阶段会加快收敛速度，但在收敛接近到优化点的时候，算法会在优化点附近震荡，如下图： 2.如何做learning rate decay？ 思路很简单，就是引入一个函数，让α随着迭代（比如min-batch的epoch）递减。为此可以采用的decay函数有： 倒数： \alpha :=\frac{1}{1+\text { decay rate * epoch num}} \alpha L 10: The Problem of local Optima事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。 但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$，因此更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。所有，担心收敛到local optima，真是人们想多了，实际上并没有想象的那么多local optima。在高维空间，几乎不太可能被困在一个local optima，这是一个好消息。 因此，在高维空间遇到的问题是高原问题（Problem of plateaus） Adam算法可以加速学习 W3 Hyperparameter tuningL01 Tuning process 到目前为止，我们接触到的hyperparameter有： learning rate: αα momentum 参数: ββ Adam参数: β1β1和 β2β2以及εε 神经网络层数: L 神经网络隐藏层neuron数：n[l]n[l] learning rate decay参数 min-batch size 这些hyperparameter重要性排序： 最重要的： learning rate: αα 比较重要的： momentum 参数: ββ 神经网络层数: L 神经网络隐藏层neuron数：n[l]n[l] 次重要的： 神经网络隐藏层neuron数 learning rate decay参数 基本不需调整的 β1β1和 β2β2以及ε 1. Try random values : Don’t use a grid why: 举个例子，假设超参数1是（学习速率），取一个极端的例子，假设超参数2是Adam算法中，分母中的$\varepsilon$。在这种情况下，a的取值很重要，而$\varepsilon$取值则无关紧要。如果你在网格中取点，接着，你试验了a的5个取值，那你会发现，无论$\varepsilon$取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的值只有5个，我认为这是很重要的。 对比而言，如果你随机取值，你会试验25个独立的a,$\varepsilon$，似乎你更有可能发现效果做好的那个。 2. 由粗糙到精细的策略 L 02: Using an Appropriate Scale to pick hyperparameters$a$取值0.0001,1,如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。 同时在范围内搜索，也不是均匀分布（uniformly random）的，通常有这个参数的scale，比如对数scale。 反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。 L 03 : Hyperparameter tuning i practice 不同的算法和场景，对超参的scale敏感性可能不一样. 根据计算资源和数据量，可以采取两种策略来调参 Panda（熊猫策略）：对一个模型先后修改参数，查看其表现，最终选择最好的参数。就像熊猫一样，一次只抚养一个后代。 Caviar（鱼子酱策略）：计算资源足够，可以同时运行很多模型实例，采用不同的参数，然后最终选择一个好的。类似鱼类，一次下很多卵，自动竞争成活。 L 04: Normalizing Activations in a Network1. Implementing Batch NormalizingBatch归一化,Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。 可以normalize $a^{[l]},z^{[l]}$,选择$z^{[L]}$ 设置 γ 和 β 的原因是，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。 需要注意的是，β和γ不是超参，而是梯度下降需学习的参数。 L 05 : Fitting Batch Norm Into Neural Networks 注意 先前我说过每层的参数是$w^{[l]}$和$b^{[l]}$，还有$\beta^{[l]}$和$b^{[l]}$，请注意计算的方式如下，$z^{[l]}=w^{[l]} a^{[l-1]}+b^{[l]}$，但Batch归一化做的是，它要看这个mini-batch，先将$z^{[l]}$归一化，结果为均值0和标准方差，再由$\beta$和b重缩放，但这意味着，无论$b^{[l]}$的值是多少，都是要被减去的，因为在Batch归一化的过程中，你要计算的$z^{[l]}$均值，再减去平均值，在此例中的mini-batch中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消. 最后，请记住的维$z^{[l]}$，因为在这个例子中，维数会是$\left(n^{[l]}, 1\right)$，的尺寸为，如果是l层隐藏单元的数量，那$ \beta^{[l]}$和$ \gamma^{[l]}$的维度也是$\left(n^{[l]}, 1\right)$，因为这是你隐藏层的数量，你有隐藏单元，所以$\gamma^{[l]}$和$ \beta^{[l]}​$用来将每个隐藏层的均值和方差缩放为网络想要的值。 L 06 Why Doest Batch Norm Work? 首先，起到了normalization的作用，同对输入数据X的normalization作用类似。 让每一层的学习，一定程度解耦了前层参数和后层参数，让各层更加独立的学习。无论前一层如何变，本层输入的数据总是保持稳定的均值和方差。（主要原因） 所以使你数据改变分布的这个想法，有个有点怪的名字“Covariate shift”，想法是这样的，如果你已经学习了到 的映射，如果 的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由 到 映射保持不变，正如此例中，因为真实函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。 关于第二点，如果实际应用样本和训练样本的数据分布不同（例如，橘猫图片和黑猫图片），我们称发生了“Covariate Shift”。这种情况下，一般要对模型进行重新训练。Batch Normalization 的作用就是减小 Covariate Shift 所带来的影响，让模型变得更加健壮，鲁棒性（Robustness）更强。 即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。 另外，Batch Normalization 也起到微弱的正则化（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 z~(i)z~(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。 因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。 最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。 L 07 : Batch Norm At Test Time问题：BN算法在训练时是一个批次的数据训练，能算出每一层Z的均值和方差；而在测试时，输入的则是单个数据，单条数据没法做均值和方差的计算，怎么在测试期输入均值和方差呢? 实际应用中一般不使用这种方法，而是使用之前学习过的指数加权平均的方法来预测测试过程单个样本的 μ 和 $σ^2$ 计算$z_{\text { norm }}^{(\hat{2})}$，用$\mu$ 和$ \sigma^{2}$的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的和你在神经网络训练过程中得到的$\beta$和$\sigma$参数来计算你那个测试样本的z值。 L 08 : Softmax Regression1. [Multi-class classification] 最后一层是概率，之和为1，要用到Softmax层，Softmax激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。 2. Softmax example没有隐藏层的softmax,代表一些决策边界 L 09 Training SoftMax classifier Softmax这个名称的来源是与所谓hardmax对比,Softmax回归或Softmax激活函数将logistic激活函数推广到类，而不仅仅是两类，结果就是如果C=2，那么C=2的Softmax实际上变回了logistic回归， Loss Function J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right) 3. Gradient descent with softmax 最后一层求导，softmax激活函数 J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)L11 TensorFlow1. 基本流程使用tensorflow，只要告诉tensorflow forward prop，它自己就会做backprop，因此不用自己实现backprop 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as npimport tensorflow as tf#导入TensorFlow​w = tf.Variable(0,dtype = tf.float32)#接下来，让我们定义参数w，在TensorFlow中，你要用tf.Variable()来定义参数​#然后我们定义损失函数：​cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)#然后我们定义损失函数J然后我们再写：​train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)#(让我们用0.01的学习率，目标是最小化损失)。​#最后下面的几行是惯用表达式:​init = tf.global_variables_initializer()​session = tf.Session()#这样就开启了一个TensorFlow session。​session.run(init)#来初始化全局变量。​#然后让TensorFlow评估一个变量，我们要用到:​session.run(w)​#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：：​print(session.run(w))​所以如果我们运行这个，它评估等于0，因为我们什么都还没运行。#现在让我们输入：​$session.run(train)，它所做的就是运行一步梯度下降法。#接下来在运行了一步梯度下降法后，让我们评估一下w的值，再print：​print(session.run(w))#在一步梯度下降法之后，w现在是0.1。 2. 如何用训练数据placeholder 在实际的训练过程中，要用不同的样本反复放到一个待优化函数中的，这个时候就可以用tensorflow的placeholder实现,在run的时候，对应给出feed_dict，表名占位符x的实际值。 123456789101112131415161718192021import numpy as npimport tensorflow as tf # 导入Tensorflowcoefficient = np.array([[2.],[-10.],[25.]])w = tf.Variable(0, dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1]) # 3x1大小的placeholdercost = w**x[0][0] - x[1][0]*w + x[2][0] # 要优化的cost function（即forward prop的形式）train = tf.train.GradientDescentOptimizer(0.01).minimize(cost) init = tf.global_variables_initializer()session = tf.Session()session.run(init)print(session.run(w))session.run(train, feed_dict=&#123;x:coefficient&#125;) # x占位符替换为coefficientprint(session.run(w))for i in range(1000): session.run(train, feed_dict=&#123;x:coefficient&#125;) # # x占位符替换为coefficientprint(session.run(w)) 3. 计算流TensorFlow程序的核心是计算损失函数，然后TensorFlow自动计算出导数，以及如何最小化损失，因此这个等式或者这行代码所做的就是让TensorFlow建立计算图， with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。建立计算流的过程，前向传播的过程，operation Summaryhow to systematically organize the hyper parameter search process and batch normalization and framework http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Improving_Deep_Neural_Networks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2 http://www.ai-start.com/dl2017/html/lesson2-week1.html#header-n3 http://dl-notes.imshuai.com/#/c2w1?id=_4-heros-of-deep-learning-yoshua-bengio-interview https://www.youtube.com/watch?v=4Ct3Yujl1dk&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=14]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彩铅DailyLifeStyle]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%BD%A9%E9%93%85DailyLifeStyle%2F</url>
    <content type="text"><![CDATA[Day one 1. 工具简单介绍 彩铅水溶性，油性 彩铅纸 铅笔 B2B&lt;4B黑的程度 H4H&lt;8H软度 橡皮 软橡皮 硬橡皮 电动橡皮擦 铅笔刀 可跳档类型 勾线笔 针管笔 （樱花） 笔套 高光笔 可以用修正液替换（三棱) 纸擦笔 玛丽 刷子 画板 速写板2. 颜色三原色： 红 黄 蓝 色相颜色 饱和度 鲜艳程度 明度 明暗程度 邻近色 对比色 红-绿 蓝-橙 紫-黄 暖色和冷色 3. 排线 一个方向往同一个方向排，无连接 来回相连接，一条线 不同方向排列注意：力度和间距4. 平涂力度一致5. 渐变力度不一致]]></content>
      <categories>
        <category>娱乐生活</category>
      </categories>
      <tags>
        <tag>彩铅</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%20test%2F</url>
    <content type="text"><![CDATA[Logistics Regression 如何凸显你是一个对逻辑回归已经非常了解的人呢。那就是用一句话概括它！逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。 ​ 这里面其实包含了5个点 1：逻辑回归的假设，2：逻辑回归的损失函数，3：逻辑回归的求解方法，4：逻辑回归的目的，5:逻辑回归如何分类。这些问题是考核你对逻辑回归的基本了解。 逻辑回归的基本假设 任何的模型都是有自己的假设，在这个假设下模型才是适用的。逻辑回归的 第一个 基本假设是 假设数据服从伯努利分布。 伯努利分布有一个简单的例子是抛硬币，抛中为正面的概率是p,抛中为负面的概率是 1-p,在逻辑回归这个模型里面是假设 $h_θ(x)$为样本为正的概率， $1−h_θ(x)$为样本为负的概率。那么整个模型可以描述为$h_θ(x;θ)=p$ 逻辑回归的第二个假设是假设样本为正的概率是 $p=\frac{1}{1+e^{w^Tx}}$ 所以逻辑回归的最终形式 $h_θ(x;θ)=\frac{1}{1+e^{w^Tx}}$ 逻辑回归的损失函数 逻辑回归的损失函数是它的极大似然函数 $Lθ(x)=\pi_{i=1}^{m}h_θ(xi;θ)^y_i∗(1−h_θ(xi;θ))^{1−y_i}$ 逻辑回归的求解方法 由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有随机梯度下降，批梯度下降，small batch 梯度下降三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。 简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。 随机梯度下降是以高方差频繁更新，优点是使得sgd会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。 小批量梯度下降结合了sgd和batch gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。 其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。 第一个是如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。 第二个是如何对参数选择合适的学习率。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。这里我们不展开，有空我会专门出一个专题介绍。 逻辑回归的目的 该函数的目的便是将数据二分类，提高准确率。 逻辑回归如何分类 逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。 3.对逻辑回归的进一步提问​ 逻辑回归虽然从形式上非常的简单，但是其内涵是非常的丰富。有很多问题是可以进行思考的 逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？ 损失函数一般有四种，平方损失函数，对数损失函数，HingeLoss0-1损失函数，绝对值损失函数。将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。至于原因大家可以求出这个式子的梯度更新 $w_j=w_j−(y^i−h_w(x^i;w))∗x_j^i\theta​$ 这个式子的更新速度只和$x_j,y_j 相关。和sigmod函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。 为什么不选平方损失函数的呢？其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。 逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？ 先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。 但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。 如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。 为什么我们还是会在训练的过程当中将高度相关的特征去掉？ 去掉高度相关的特征会让模型的可解释性更好 可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。 4.逻辑回归的优缺点总结​ 面试的时候，别人也经常会问到，你在使用逻辑回归的时候有哪些感受。觉得它有哪些优缺点。 ​ 在这里我们总结了逻辑回归应用到工业界当中一些优点： 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。 模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。 训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。 资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。 ​ 但是逻辑回归本身也有许多的缺点: 准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。 很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。 模型、策略、算法Codings]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%2F</url>
    <content type="text"><![CDATA[英伟达:芯片，GPU 开发框架：tensorflow，pytorch caffe 监督学习学习目的是学习一个输入到输出的映射，称为模型。模型的集合就是假设空间。 模型：概率模型；非概率模型； 学习过程：搜索过程]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow]]></title>
    <url>%2F2019%2F04%2F11%2Ftensorflow%2F</url>
    <content type="text"><![CDATA[official definition What is tensorflowflow of tensors “TensorFlow is an open source software library for numerical computation using dataflow graphs. Nodes in the graph represents mathematical operations, while graph edges represent multi-dimensional data arrays (aka tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.”* A major difference between numpy and TensorFlow is that TensorFlow follows a lazy programming paradigm. It first builds a graph of all the operation to be done, and then when a “session” is called, it “runs” the graph. It’s built to be scalable, by changing internal data representation to tensors (aka multi-dimensional arrays). Building a computational graph can be considered as the main ingredient of TensorFlow. It’s easy to classify TensorFlow as a neural network library, but it’s not just that. Yes, it was designed to be a powerful neural network library. But it has the power to do much more than that. You can build other machine learning algorithms on it such as decision trees or k-Nearest Neighbors. You can literally do everything you normally would do in numpy! It’s aptly called “numpy on steroids” The advantages of using TensorFlow are: It has an intuitive construct, because as the name suggests it has “flow of tensors”. You can easily visualize each and every part of the graph. Easily train on cpu/gpu for distributed computing Platform flexibility. You can run the models wherever you want, whether it is on mobile, server or PC. scikit-learn 123456# define hyperparamters of ML algorithmclf = svm.SVC(gamma=0.001, C=100.)# train clf.fit(X, y)# test clf.predict(X_test) The usual workflow of running a program in TensorFlow is as follows: Build a computational graph, this can be any mathematical operation TensorFlow supports. Initialize variables, to compile the variables defined previously Create session(会话）, this is where the magic starts! Run graph in session, the compiled graph is passed to the session, which starts its execution. Close session, shutdown the session. Lets write a small program to add two numbers! 12345678910111213141516171819# import tensorflowimport tensorflow as tf# build computational grapha = tf.placeholder(tf.int16)b = tf.placeholder(tf.int16)addition = tf.add(a, b)# initialize variablesinit = tf.initialize_all_variables()# create session and run the graphwith tf.Session() as sess: sess.run(init) print "Addition: %i" % sess.run(addition, feed_dict=&#123;a: 2, b: 3&#125;)# close sessionsess.close() A typical implementation of Neural Network would be as follows: Define Neural Network architecture to be compiled Transfer data to your model Under the hood, the data is first divided into batches, so that it can be ingested. The batches are first preprocessed, augmented and then fed into Neural Network for training The model then gets trained incrementally Display the accuracy for a specific number of timesteps After training save the model for future use Test the model on a new data and check how it performs 三类非常重要的变量占位符tensorFlow中接收值的方式为占位符(placeholder)，创建placeholder 123- # b = tf.placeholder(tf.float32, [None, 1], name='b')第二个参数值为[None, 1]，其中None表示不确定，即不确定第一个维度的大小，第一维可以是任意大小。特别对应tensor数量(或者样本数量)，输入的tensor数目可以是32、64… placeholder: A way to feed data into the graphsfeed_dict: A dictionary to pass numeric values to computational graph 常量tf.constant()`定义常量 1const = tf.constant(2.0, name='const') 变量 ​ 使用tf.Variable()定义变量 1c = tf.Variable(1.0, dtype=tf.float32, name='c') TensorFlow中所有的变量必须经过初始化才能使用，**初始化方式分两步： 定义初始化operation 12# 1. 定义init operationinit_op = tf.global_variables_initializer() 运行初始化operation 12# 2. 运行init operation sess.run(init_op) reference https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/ https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial https://github.com/aymericdamien/TensorFlow-Examples video:https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/ course: https://classroom.udacity.com/courses/ud187 tensorflow: GOOGLE 开源、Deep learning 练数成金C1 tensorboard ：a tool;visual network;debug alter dir of jupyter 顺便改了下新下载的路径（GOOD） CPU or GPU C2graphs 代表计算任务，节点（op)，一个op可以获得o个或者多个tensor,输出1个或者多个tensor Session(会话)的上下文（context)中执行 tensor表示数据,n维数组 C3 简单的回归神经网络（拟合二次函数），貌似学了理论没有实践，还真是忘得快啊 手写体分类、Softmax函数 softmax函数可以给不同的对象分配概率，softmax($x_i$)=$\frac{exp(x_i)}{\sum_j{exp(x_j)}}$ 如输出[1,2,5] ,$p1=\frac{exp(1)}{exp(1)+exp(2)+exp(5)}$,$p2=\frac{exp(2)}{exp(1)+exp(2)+exp(5)}$,$p1=\frac{exp(5)}{exp(1)+exp(2)+exp(5)}$ Keras 安装 backend 基于什么做运算（tensorflow or theano) import keras 查看 底层搭建 a） /.keras/keras.json 相关的配置信息 b) 终端改，单次 import os os.environ[‘KERAS_BACKEND’]= ‘tensorflow’ import keras For example model :Sequential layer : Dense activation 训练算法：model.compile(参数optimizer=’梯度下降法的变种’ , loss=’rms/‘) 训练：model. fit (x,y) model.train_on_batch evaluate:model.evaluate prediction: model.predict(x_test, batch_size=128) https://github.com/MorvanZhou/tutorials/blob/master/kerasTUT/5-classifier_example.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 4 - Regressor exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.models import Sequential # 按顺序建立from keras.layers import Dense # 全连接层import matplotlib.pyplot as plt# create some dataX = np.linspace(-1, 1, 200)np.random.shuffle(X) # randomize the dataY = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))# plot dataplt.scatter(X, Y)plt.show()X_train, Y_train = X[:160], Y[:160] # first 160 data pointsX_test, Y_test = X[160:], Y[160:] # last 40 data points# build a neural network from the 1st layer to the last layermodel = Sequential()model.add(Dense(units=1, input_dim=1)) # choose loss function and optimizing methodmodel.compile(loss='mse', optimizer='sgd')# trainingprint('Training -----------')for step in range(301): cost = model.train_on_batch(X_train, Y_train) if step % 100 == 0: print('train cost: ', cost)# testprint('\nTesting ------------')cost = model.evaluate(X_test, Y_test, batch_size=40)print('test cost:', cost)W, b = model.layers[0].get_weights()print('Weights=', W, '\nbiases=', b)# plotting the predictionY_pred = model.predict(X_test)plt.scatter(X_test, Y_test)plt.plot(X_test, Y_pred)plt.show() 51234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: 莫烦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 5 - Classifier exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activationfrom keras.optimizers import RMSprop# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# X shape (60,000 28x28), y shape (10,000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(X_train.shape[0], -1) / 255. # normalizeX_test = X_test.reshape(X_test.shape[0], -1) / 255. # normalizey_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your neural netmodel = Sequential([ Dense(32, input_dim=784), Activation('relu'), Dense(10), Activation('softmax'),])# Another way to define your optimizerrmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)# We add metrics to get more results you want to seemodel.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=2, batch_size=32)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('test loss: ', loss)print('test accuracy: ', accuracy) 6 CNN卷积神经网络不是对 https://www.cnblogs.com/skyfsm/p/6790245.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: 莫烦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 6 - CNN example# to try tensorflow, un-comment following two lines# import os# os.environ['KERAS_BACKEND']='tensorflow'import numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flattenfrom keras.optimizers import Adam# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(-1, 1,28, 28)/255.X_test = X_test.reshape(-1, 1,28, 28)/255.y_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your CNNmodel = Sequential()# Conv layer 1 output shape (32, 28, 28)model.add(Convolution2D( batch_input_shape=(None, 1, 28, 28), filters=32, kernel_size=5, strides=1, padding='same', # Padding method data_format='channels_first',))model.add(Activation('relu'))# Pooling layer 1 (max pooling) output shape (32, 14, 14)model.add(MaxPooling2D( pool_size=2, strides=2, padding='same', # Padding method data_format='channels_first',))# Conv layer 2 output shape (64, 14, 14)model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))model.add(Activation('relu'))# Pooling layer 2 (max pooling) output shape (64, 7, 7)model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)model.add(Flatten())model.add(Dense(1024))model.add(Activation('relu'))# Fully connected layer 2 to shape (10) for 10 classesmodel.add(Dense(10))model.add(Activation('softmax'))# Another way to define your optimizeradam = Adam(lr=1e-4)# We add metrics to get more results you want to seemodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=1, batch_size=64,)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('\ntest loss: ', loss)print('\ntest accuracy: ', accuracy)]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>tensorlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning Neural Network and Deep Learning]]></title>
    <url>%2F2019%2F04%2F11%2FDeep%20Learning.ai_Neural%20Networks%20and%20Deep%20Learning%2F</url>
    <content type="text"><![CDATA[Course one : Neural Networks and Deep Learning(Course 1 of the Deep Learning Specialization)C1W1C1W1L01: WelcomeAI is the new Electricity! Course 1: Neural Networks and Deep Learning Course 2: Improving Deep Neural Networks: Hyperparameter tuning,Regularization and Optimization Course 3: Structuring your Machine Learning project Course 4: Convolutional Neural Networks Course 5: Natural Langurge Processing: Building sequence models C1W1L02 : What is Neural NetworkDeep Learning = training (very large) neural network For example of house prize prediction : the simplest neural network如果现在有六栋房子的信息，分别是房子的大小(size of house)和对应的价格(prize),绘制出如下的。自然的想法：线性回归，得到拟合的直线。值得注意的是，房价不可能是负数吧！因此下图中蓝色的线，大致就是我们所需要的函数。这个对应一个最简单神经网络（neural network） 上述是一个tiny little neural network，更大的，更复杂的神经网络是 把很多最简单的single neural堆积(stacking)到一起。 For example of house prize prediction : stacking the neural上面这个例子，仅仅考虑特征是size,实际情况上，与房屋相关的特征还有number of bedrooms、zip code、wealth, number of bedrooms and size affect family size. The zip code is a feature that tells you you know walkability. The wealth tells you how good is the school quality hidden layer 用输入层计算得到，因此说输入层与中间层紧密连接起来了 The actual application of neural networkshidden layer 与上一层的连接情况并不是手工确定，每一层都是上一层所有的输入函数，所以建立的神经网络如下： The remarkable thing about neural network Given enough data about X&amp;Y (x,y) which good at freaking out functions :map x to y Most powerful in supervised learning C2W1CL03 : Supervised Learning with Neural Network常见的监督学习截止到目前，Neural Network的成功应用基本都在Supervised Learning。比如：Ad，Images vision, Audio to Text, Machine translation, Autonomous Driving 常见的神经网络的设计 卷积神经网络：Convolutional Neural Network (CNN) 通常有用图像数据 递归神经网络： Recurrent Neural Network (RNN) 通常用于time series 对应复杂的应用中，定制一些复杂的混合的神经网络结构 结构化和非结构化数据 处理非结构化数据是很难的，与结构化数据比较，让计算机理解非结构化数据很难 C1W1L04: Why is deep learning taking offAnswer: scale If you want to hit this very high level of performance ,firstly, you need to be able train a big enough neural network in order to take advantage of the huge amount of data and second you need to be out here on the x axes you do need a lot of data. If you do not have a lot training data is often up to your skill at hand engineering features that determines the foreman.在这个小的训练集中，各种算法的优先级事实上定义的也不是很明确，所以如果你没有大量的训练集，那效果会取决于你的特征工程能力，那将决定最终的性能。 这个图形区域的左边，各种算法之间的优先级并不是定义的很明确，最终的性能更多的是取决于你在用工程选择特征方面的能力以及算法处理方面的一些细节. 只是在某些大数据规模非常庞大的训练集，也就是在右边这个会非常的大时，我们能更加持续地看到更大的由神经网络控制其它方法. The Reason the scale of data the speed of computation such as GPUS innovation of algorithm 许多算法方面的创新，一直是在尝试着使得神经网络运行的更快 switch sigmoid function to relu function 在这个区域，也就是这个sigmoid函数的梯度会接近零，所以学习的速度会变得非常缓慢，因为当你实现梯度下降以及梯度接近零的时候，参数会更新的很慢，所以学习的速率也会变的很慢，而通过改变这个被叫做激活函数的东西，神经网络换用这一个函数，叫做ReLU的函数（修正线性单元），ReLU它的梯度对于所有输入的负值都是零，因此梯度更加不会趋向逐渐减少到零。 训练你的神经网络的过程，很多时候是凭借直觉的，往往你对神经网络架构有了一个想法，于是你尝试写代码实现你的想法，然后让你运行一个试验环境来告诉你，你的神经网络效果有多好，通过参考这个结果再返回去修改你的神经网络里面的一些细节，然后你不断的重复上面的操作，当你的神经网络需要很长时间去训练，需要很长时间重复这一循环，在这里就有很大的区别，根据你的生产效率去构建更高效的神经网络。当你能够有一个想法，试一试，看效果如何。在10分钟内，或者也许要花上一整天，如果你训练你的神经网络用了一个月的时间，有时候发生这样的事情，也是值得的，因为你很快得到了一个结果。在10分钟内或者一天内，你应该尝试更多的想法，那极有可能使得你的神经网络在你的应用方面工作的更好、更快的计算，在提高速度方面真的有帮助，那样你就能更快地得到你的实验结果。 Summary早上花了2h小时学习第一周的视频，先看一遍视频的字幕，逐字逐句的理解，虽然很多时候都是自己乱猜的，大概清楚讲的什么！然后再看大牛的笔记，然后再看一篇结合PPT。下午也看了半个多小时。问题：1. 自己的英文水平不够，这个需要大大的提高讷。2. 其实只要看别人的笔记就可以知道内容，但是还是想听andow ng的讲解。3. 视频都比较短，每个视频设计的知识点或者内容不多，1到3个，分成知识点做笔记还是不错的 这一周的内容，也就是今天我学习的知识简单和容易理解。学习了神经网络的大致结构，神经网络的应用领域，深度学习为什么取得快速的发展的三点原因，尤其是数据scale与其他方法和神经网络规模的大致性能关系 C1W2C1W2L01: Binary ClassificationIn this week, we’re going to go over the basics of neural network programming. We are going to study handle data without for loop. forward password for propagation backward pass or what’s called a backward propagation step Why the computations in learning in a neural network can be organized in this board propagation and a separate backward propagation by using logistic regression to convey(传达) theses ideas. Binary ClassificationInput； an image . three separate matrices corresponding red green and blue color channels of this image. 如果你的图片大小为64x64像素，那么你就有三个规模为64x64的矩阵，分别对应图片中红、绿、蓝三种像素的强度值 unroll all of these pixel intensity values into a feature vector pixel intensity values of this image notation (x,y)： a pair X comma Y $M_{train}$: M subscript train 每条测试集在矩阵中都是以列向量的形式存在 Matrix capital Model : hypothesis Function :Logistic RegressionSo given an input X and the parameters W and b, how do we generate the output Y hat? Well, one thing you could try, that doesn’t work, would be to have Y hat be w transpose X plus B, kind of a linear function of the input X. And in fact, this is what you use if you were doing linear regression. But this isn’t a very good algorithm for binary classification because you want Y hat to be the chance that Y is equal to one. So,Y hat should really be between zero and one. This is what the sigmoid function looks like. sigmoid function \sigma(z) = \frac{1}{1+e^{-z}}因为你想让$\hat{y}$表示实际值$y$等于1的机率的话， 应该在0到1之间。这是一个需要解决的问题，因为可能比1要大得多，或者甚至为一个负值。对于你想要的在0和1之间的概率来说它是没有意义的，因此在逻辑回归中，我们的输出应该是等于由上面得到的线性函数式子作为自变量的sigmoid函数中，公式如上图最下面所示，将线性函数转换为非线性函数。 注意：原来$w,b$是分开在，这里就合并，引入变量$x_0=1$,对应偏置$b$, Strategy：Cost functionFirstly : Loss function L(\hat{y},y)=\frac{1}{2}\sum{(y_i-\hat{y_i})^2}这个优化问题不是凸优化问题(non-convex)，因此不选用这个 Secondly， L(y,\hat{y})=-(ylog^{\hat{y}}+(1-y)log^{1-\hat{y}}) Algorithm: Gradient Descent Gradient Descent算法步骤： Initialize $w$, $b$ to zero repeat： $w :=w−\alpha \frac{∂J(w,b)}{∂w}​$ $b :=b-\alpha \frac{∂J(w,b)}{∂b}$ C1W2L05 &amp; C1W2L06 Derivatives求导，这个是微积分的内容，不用写了！ C1W2L07： Computation GraphC1W2L08 : Derivatives with compution graphs链式法则 \frac{\partial L}{\partial v}=\frac{\partial L}{\partial u}\frac{\partial u}{\partial v}C1W2L09 : Logistic Regression Gradient Descentsingle training exampleYou’ve seen the loss function that measures how well you’re doing on the single training example. You’ve also seen the cost function that measures how well your parameters w and b are doing on your entire training set. You’ve heard me say that the computations of a neural network are organized in terms of a forward pass or a forward propagation step, in which we compute the output of the neural network, followed by a backward pass or back propagation step, which we use to compute gradients or compute derivatives. \frac{\partial L}{\partial w}=\frac{\partial L}{\partial \alpha }\frac{\partial \alpha }{\partial z}\frac{\partial z}{\partial w} \\=-(\frac{y}{a}+\frac{1-y}{1-a})a(1-a)x=(a-y)xC1W2L10 Gradient Descent on m example \min L(w,b)=\sum_{i=1}^{m}L(\alpha_i,y_i)/m\\ \frac{\partial L }{\partial w}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial w})/m=(\sum_{i=1}^{m}(a-y_i)x_i)/m\\ \frac{\partial L }{\partial b}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial b})/m=(\sum_{i=1}^{m}(a-1)x_i)/m 上面的伪代码告诉我们，需要多次for loop完成代码，但是这会造成运算速度下降！因为我们越来越多地训练非常大的数据集，因此你真的需要你的代码变得非常高效。所以在接下来的几个视频中，我们会谈到向量化，以及如何应用向量化而连一个for循环都不使用。所以学习了这些，我希望你有关于如何应用逻辑回归，或是用于逻辑回归的梯度下降，事情会变得更加清晰 summary今天主要学习了以logistics regression 为例，如何通过链式求导的过程，简单的练习一下，以及再次了解什么是梯度下降法，以及训练学习算法的需要一个损失函数，训练的过程就是求损失函数最优值的过程 C1W2L11: Vectorization1. 什么是Vectorization：将 for loop 尽可能转换为矩阵运算通过numpy内置函数和避开显式的循环(loop)的方式进行向量化，从而有效提高代码速度。 123np.dot(a,b)如果a,b是一维数组，则计算点积如果a,b是多维数据，则矩阵乘法 2. An example of vectorizationvectorization的好处：conciser code, but faster execution 一个简单的对比实验：1,000,000大小的两个向量内积计算，for loop要比Vectorization快300倍。 在Deep Learning时代，vectorization是一项重要的技能。 123456789101112131415161718192021import numpy as np #导入numpy库a = np.array([1,2,3,4]) #创建一个数据aprint(a)# [1 2 3 4]import time #导入时间库a = np.random.rand(1000000)b = np.random.rand(1000000) #通过round随机得到两个一百万维度的数组tic = time.time() #现在测量一下当前时间#向量化的版本c = np.dot(a,b)toc = time.time()print(“Vectorized version:” + str(1000*(toc-tic)) +”ms”) #打印一下向量化的版本的时间​#继续增加非向量化的版本c = 0tic = time.time()for i in range(1000000): c += a[i]*b[i]toc = time.time()print(c)print(“For loop:” + str(1000*(toc-tic)) + “ms”)#打印for循环的版本的时间 3. GPU or CPU 大规模的深度学习再GPU或者图像处理单元运行”，CPU和GPU都有并行化的指令，他们有时候会叫做SIMD指令，这个代表了一个单独指令多维数据，这个的基础意义是，如果你使用了built-in函数,像np.function或者并不要求你实现循环的函数，它可以让python的充分利用并行化计算。 只是在GPU和CPU上面计算，GPU更加擅长SIMD计算，但是CPU事实上也不是太差，可能没有GPU那么擅长吧。SIMD Both CPU and GPU have parallelization instructions(i.e. SIMD, Signle Instruction Multiple Data) C12L12 ： More Vectorization Example矩阵和向量乘法 向量函数 原则：whenever possible, avoid explict for-loops 使用Element wised的矩阵运算，将函数作用在每个矩阵元素上，比如： np.exp() np.log() np.abs() np.maxium() 1/v v**2 C1W2L13: Vectorizing Logistic Regression1. 前向传播 \hat{y}=σ(w^TX+b)=(a(1),a(2),...,a(m−1),a(m))=\\ (\alpha(z_1),\alpha(z_m),...,\alpha(z_m))=\\ (\alpha(w^Tx_1+b),\alpha(w^Tx_2+b),...,\alpha(w^Tx_m+b))=1234import numpy as npz=np.dot(W^T,X)+b# z这里就是python 巧妙的地方，b是实数，但是向量加上实数后，b扩展成向量，被称为广播（brosdcasting） 个人经验： 首先，熟悉每个变量的记号和维度，必要的话，可以画出来，更直观。 先从一个样本做向量化，再把m个样本的操作向量化。 for-loop里面是循环乘法，则向量化一定是一个乘法形式，若对于不确定乘法的左右关系，是否需转置，可以根据目标变量的维度推测。或者先乘起来，再根据目标变量看是否要转置。 C1W2L14 : Vectorzing Logistic Regression’s Gradient Compution backforwd \frac{∂J}{∂w}=\frac{1}{m}X(A−Y)T\\ \frac{∂J}{∂b}=\frac{1}{m}(a(i)−y(i)) 重要的是弄清楚，里面的行列关系，代表的意思，运算时候，先自己理清楚。还有点积、等等运算性质对应的操作，或者对应的内置函数 C1W2L15: Broadcasting in PythonOne Example A.sum(axis = 0)中的参数axis。axis用来指明将要进行的运算是沿着哪个轴执行，在numpy中，0轴是垂直的，也就是列，而1轴是水平的，也就是行。 第二个A/cal.reshape(1,4)指令则调用了numpy中的广播机制。这里使用 3 by 4的矩阵除以1 by 4 的矩阵。技术上来讲，其实并不需要再将矩阵 reshape(重塑)成 ，因为矩阵本身已经是 了。但是当我们写代码时不确定矩阵维度的时候，通常会对矩阵进行重塑来确保得到我们想要的列向量或行向量。重塑操作reshape是一个常量时间的操作，时间复杂度是，它的调用代价极低。 Secondly Example python的广播机制会将常数扩展成4by 1的列向量 其实是将1by*n 的矩阵复制成为mbyn的矩阵 广播机制的举例 axis补充：numpy中，类似sum的函数，经常涉及axis参数，可以取值为0或1，甚至其他。经常记不住，这里我查了了一下，是这样的（原文）： axis的数字，和数组的shape参数的索引是对应的。比如一个数组的shape是(5,6)，则代表5个row，6个column。即在shape中，row和column的个数的索引是0和1。也就第1个坐标，在shape中的第一个元素，索引是0，代表row的方向；第2个坐标，在shape中的第2个元素，索引是1，代表row的方向。 对于sum函数，axis指的是sum“沿着”的方向，经过计算，这个方向的维度因为求和后就消失了，比如sum(axis=0)代表是沿着“row”方向进行求和， 当然axis可以是一个tupe，那就相当于沿着多个多个方向求和。 sum如果不传入axis参数，默认是对所有维度求和。 broadcasting 当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作，这种机制叫做广播（broadcasting）。 三种广播情况 C1W2L16 A Note on Python/numpy vectors本节主要讲Python中的numpy一维数组的特性，以及与行向量或列向量的区别 1. 一维数组的特性首先设置a = np.array.random.randn(5)，这样会生成存储在数组a中的5个高斯随机数变量。之后输出 ，从屏幕上可以得知，此时a 的shape（形状）是一个的结构。这在Python中被称作一个一维数组。它既不是一个行向量也不是一个列向量，这也导致它有一些不是很直观的效果。举个例子，如果我输出一个转置阵，最终结果它会和看起来一样，所以和的转置阵最终结果看起来一样。而如果我输出和的转置阵的内积，你可能会想：乘以的转置返回给你的可能会是一个矩阵。但是如果我这样做，你只会得到一个数。 所以我建议当你编写神经网络时，不要在使用的shape(5,1)是还是(n,)或者一维数组。相反，如果你设置(5,1)，那么这就是5行1列向量。在先前的操作里a和a的转置看起来一样，而现在这样的 a变成一个新的a 的转置，并且它是一个行向量。请注意一个细微的差别，在这种数据结构中，当我们输出a 的转置时有两对方括号，而之前只有一对方括号，所以这就是1行5列的矩阵和一维数组的差别。 2. 行向量和列向量rank 1 array问题：shape是(x,)的数组，既不是行向量，也不是列向量，没法参与正常的矩阵运算，应该总是使用(x,1)或(1,x)的shape来表示向量。但可以通过reshape方法将rank 1 array转换为行向量或列向量。（什么是rank，就是一个数组的维度）一维的数组既不是行向量也不是列向量，转置后，依然是本身。 3. 解决方法12assert(a.shape=（5，1)）# 为了确保你的矩阵或向量所需要的维数时，不要羞于 reshape 操作 C1W2L18 ：Quick Tour of Jupyter/iPython NotebooksC1W2L18: Explanation of Logistic Regression Cost Function对应logistic regression，输出$\hat{y}=p(y=1|x)$,那么$p(y=0|x)=1-\hat{y}$ 综合上面 p(y|x)= \hat{y}^y*(1-\hat{y})^{1-y}对于整个训练集， 假设所有的训练样本服从同一分布且相互独立，也即独立同分布的，所有这些样本的联合概率就是每个样本概率的乘积: p(labels \ in\ training\ set)=\Pi_{i=1}^mp(y_i|x_i)如果利用极大似然法做，找到一组参数，使得样本观测值概率最大 \max log p(label \ in \ training \ set)=log \Pi_{i=1}^mp(y_i|x_i)=\sum -L(\hat{y^i},y^i) \min cost J(w,b)=\frac{1}{m}L(\hat{y^i},y^i)总结一下，为了最小化成本函数，我们从logistic回归模型的最大似然估计的角度出发，假设训练集中的样本都是独立同分布的条件下 Day3 : summary主要学习了python编程的如何才能高效率，内置函数的具有并行性，simd指令，以及一维数组的使用注意事项，logistic regression的lost function的原理证明 C1W3C1W3L01 : Neural Network Overview 许多sigmoid单元堆叠起来形成一个神经网络。 正向传播：输入层到layer one \left.\begin{array}{c}{x} \\ {W^{[1]}} \\ {b^{[1]}}\end{array}\right\} \Longrightarrow z^{[1]}=W^{[1]} x+b^{[1]} \Longrightarrow a^{[1]}=\sigma\left(z^{[1)}\right)layer one 到layer two \left.\begin{array}{r}{a^{(1]}=\sigma\left(z^{[1]}\right)} \\ {W^{[2]}} \\ {b^{[2]}}\end{array}\right\}\begin{array}{l}{\Longrightarrow z^{[2]}=W^{[2]} a^{[1]}+b^{[2]} \Longrightarrow a^{[2]}=\sigma\left(z^{[2]}\right)} \\ {\Longrightarrow L\left(a^{[2]}, y\right)}\end{array}反向传播 \left.\begin{array}{r}{d a^{[1]}=d \sigma\left(z^{[1]}\right)} \\ {d W^{[2]}} \\ {d b^{[2]}}\end{array}\right\}\begin{array}{l}{\Longleftarrow d z^{[2]}=d\left(W^{[2]} \alpha^{[1]}+b^{[2]}\right) \Longleftarrow d a^{[2]}=d \sigma\left(z^{[2]}\right)} \\ {\Longleftarrow d L\left(a^{[2]}, y\right)}\end{array} $W$的行数是本次结点个数，列数是上层节点个数 C1W3L02 : Nerual Network Representations符号说明 C1W3L03： Computation Neural Network OutputA simple training examples 其中，x表示输入特征，a表示每个神经元的输出，W表示特征的权重，上标表示神经网络的层数（隐藏层为1），下标表示该层的第几个神经元。这是神经网络的符号惯例，下同。 神经网络的计算 关于神经网络是怎么计算的，从我们之前提及的逻辑回归开始，如下图所示。用圆圈表示神经网络的计算单元，逻辑回归的计算有两个步骤，首先你按步骤计算出，然后在第二步中你以sigmoid函数为激活函数计算（得出），一个神经网络只是这样子做了好多次重复计算。 说明：$w_i^{[1]}$和$W^{[1]}$的关系，一个按照logistic regression ，一个是矩阵表示。 向量化计算 如果你执行神经网络的程序，用for循环来做这些看起来真的很低效。所以接下来我们要做的就是把这四个等式向量化。向量化的过程是将神经网络中的一层神经元参数纵向堆积起来，例如隐藏层中的纵向堆积起来变成一个(4,3)的矩阵，用符号$W^{[1]}$表示。另一个看待这个的方法是我们有四个逻辑回归单元，且每一个逻辑回归单元都有相对应的参数——向量，把这四个向量堆积在一起，你会得出这4×3的矩阵。 z^{[n]}=W^{[n]}X+b^{[n]} a^{[1]}=\left[ \begin{array}{c}{a_{1}^{[1]}} \\ {a_{2}^{[1]}} \\ {a_{3}^{[1]}} \\ {a_{4}^{[1]}}\end{array}\right]=\sigma\left(z^{[1]}\right) Given input X（a single training set) \begin{array}{c}{z^{[1]}=W^{[1]} a^{[0]}+b^{[1]}} \\ {a^{[1]}=\sigma\left(z^{[1]}\right)} \\ {z^{[2]}=W^{[2]} a^{[1]}+b^{[2]}} \\ {a^{[2]}=\sigma\left(z^{[2]}\right)}\end{array}说明： $W$的第$i$行表示，当前层到上一层的权重行向量，再计算单个的时候，由于是按照logristics regression的方式，所以认为$w_i$是列向量，所以转置成行向量。上面的图也说明了：如何从单个操作到矩阵操作，权重矩阵是怎么构造，怎么表示的。 b是列向量。 C1W3L04: Vectorizing Across Mutilple ExampleDifferent training examples in different columns of the matrix for loop vectorizing : stacking training set in columns x=\left[ \begin{array}{cccc}{\vdots} & {\vdots} & {\vdots} & {\vdots} \\ {x^{(1)}} & {x^{(2)}} & {\dots} & {x} \\ {\vdots} & {\vdots} & {\vdots} & {\vdots}\end{array}\right] 就有 \left\{\begin{array}{l}{A^{[1]}=\sigma\left(z^{[1]}\right)} \\ {z^{[2]}=W^{[2]} A^{[1]}+b^{[2]}} \\ {A^{[2]}=\sigma\left(z^{[2]}\right)}\end{array}\right. 当垂直扫描，是索引到隐藏单位的数字。当水平扫描，将从第一个训练示例中从第一个隐藏的单元到第二个训练样本，第三个训练样本……直到节点对应于第一个隐藏单元的激活值，且这个隐藏单元是位于这个训练样本中的最终训练样本。 从水平上看，矩阵代表了各个训练样本。从竖直上看，矩阵的不同的索引对应于不同的隐藏单元。 C1W3L05 : Explanation for vectorized implement C1W3L06 : Activation Function在讨论优化算法时，有一点要说明：基本已经不用sigmoid激活函数了，tanh函数在所有场合都优于sigmoid函数。 sigmoid函数和tanh函数两者共同的缺点是，在z特别大或者特别小的情况下，导数的梯度或者函数的斜率会变得特别小，最后就会接近于0，导致降低梯度下降的速度。 在机器学习另一个很流行的函数是：修正线性单元的函数（ReLu），ReLu函数图像是如下图。$ a = max(0,z)$： 所以，只要是正值的情况下，导数恒等于1，当是负值的时候，导数恒等于0。从实际上来说，当使用的导数时，=0的导数是没有定义的。但是当编程实现的时候，的取值刚好等于0.00000001，这个值相当小，所以，在实践中，不需要担心这个值，是等于0的时候，假设一个导数是1或者0效果都可以。 如果输出是0、1值（二分类问题），则输出层选择sigmoid函数，然后其它的所有单元都选择Relu函数。 这是很多激活函数的默认选择，如果在隐藏层上不确定使用哪个激活函数，那么通常会使用Relu激活函数。有时，也会使用tanh激活函数，但Relu的一个缺点是：当z是负值的时候，导数等于0。 这里也有另一个版本的Relu被称为Leaky Relu。 当是负值时，这个函数的值不是等于0，而是轻微的倾斜。 两者的优点是： 第一，在的区间变动很大的情况下，激活函数的导数或者激活函数的斜率都会远大于0，在程序实现就是一个if-else语句，而sigmoid函数需要进行浮点四则运算，在实践中，使用ReLu激活函数神经网络通常会比使用sigmoid或者tanh激活函数学习的更快。 第二，sigmoid和tanh函数的导数在正负饱和区的梯度都会接近于0，这会造成梯度弥散，而Relu和Leaky ReLu函数大于0部分都为常数，不会产生梯度弥散现象。(同时应该注意到的是，Relu进入负半区的时候，梯度为0，神经元此时不会训练，产生所谓的稀疏性，而Leaky ReLu不会有这问题) 在ReLu的梯度一半都是0，但是，有足够的隐藏层使得z值大于0，所以对大多数的训练数据来说学习过程仍然可以很快。 sigmoid激活函数：除了输出层是一个二分类问题基本不会用它。 tanh激活函数：tanh是非常优秀的，几乎适合所有场合。 ReLu激活函数：最常用的默认函数，，如果不确定用哪个激活函数，就使用ReLu或者Leaky ReLu。 通常的建议是：如果不确定哪一个激活函数效果更好，可以把它们都试试，然后在验证集或者发展集上进行评价。然后看哪一种表现的更好，就去使用它。 C1W3L07 : Why non-linear activation Functions 通过推导可以得出，如果使用线性激活函数，相当于没有隐藏层。无论你的神经网络有多少层一直在做的只是计算线性函数，所以不如直接去掉全部隐藏层。当当然，在output layer是可以不用activation function，或者用linear activation function；这种情况一般是要求输出实数集结果（比如预测房价）。即便如此，在hidden layer还是要用non-linear activation function。 sigmoid activation function \frac{d}{d z} g(z)=\frac{1}{1+e^{-z}}\left(1-\frac{1}{1+e^{-z}}\right)=g(z)(1-g(z))tanh activation function g(z)=\tanh (z)=\frac{e^{z}-e^{-z}}{e^{x}+e^{-z}} \frac{d}{d z} g(z)=1-(\tanh (z))^{2}Rectified linear unit(RelU) g(z)^{\prime}=\left\{\begin{array}{ll}{0} & {\text { if } z0} \\ {\text {undefined}} & {\text { if } z=0}\end{array}\right.注：通常在z= 0的时候给定其导数1,0；当然=0的情况很少 Leaky linear unit (Leaky ReLU) g(z)=\max (0.01 z, z) g(z)^{\prime}=\left\{\begin{array}{ll}{0.01} & {\text { if } z0} \\ {\text {undefined}} & {\text { if } z=0}\end{array}\right.注：通常在的z=0时候给定其导数1,0.01；当然的情况很少。 C1W3L09 : Gradient Descent For Neural Networks gradient descent的关键是求cost function对参数的偏导数 求导过程使用的是Backpropagation 首先做forward propagation，求解出每一层的输出A (1) z^{[1]}=W^{[1]} x+b^{[1]}\\ (2) a^{[1]}=\sigma\left(z^{[1]}\right)\\(3) z^{[2]}=W^{[2]}=W^{[2]} a^{[1]}+b^{[2]}\\(4) a^{[2]}=g^{[2]}\left(z^{[z]}\right)=\sigma\left(z^{[2]}\right) 然后向后，逐层求解对每一层参数的偏导数 sum，keepdims是防止python输出那些古怪的秩数(n,)，加上这个确保阵矩阵这个向量输出的维度为(n,1）这样标准的形式。 C1WL10: Backpropagation intuition (optional) 实现后向传播有个技巧，就是要保证矩阵的维度相互匹配 其实，对于一个神经元，输入部分：是权重和上一层输出的线性组合；输出：激活函数作用于输入，因此对$W$求偏导时，对激活函数求一次，再对线性组合求一次。对$b$求偏导是，对线性部分求偏导是1,这里用求和。 C1W3L11: Random Initialization` 与logistic regression不同，初始化参数不可固定为0，而是每个参数都要随机初始化。 主要原因是：如果每个参数w和b都是0，则同一层的每个neuron计算结果完全一样（输入一样a，参数一样w，则z一样,symmetry breaking problem）；接下来反向传播时的偏导数也一样，下一轮迭代同一层的每个neuron的w又是一样的。这样整个neural Network上每一层的neuron是同质的，自然不会有好的performance。 .png) 不过，对b参数，可以都初始化为0。 另外需要注意，虽然w是随机初始化，但最好使用较小的随机数。主要是避免让z的计算值过大，导致activation function对z的偏导数趋于0，导致Gradient descent下降较慢。 通常的做法是对random的值乘以一个比率，比如0.01（但具体怎么选这个比率，也要根据情况而定，这应该又是一个超参了）： $W[1]=np.random.randn((2,2))∗0.01$ 因为如果你用tanh或者sigmoid激活函数，或者说只在输出层有一个Sigmoid，如果（数值）波动太大，当你计算激活值时如果很大，就会很大或者很小，因此这种情况下你很可能停在tanh/sigmoid函数的平坦的地方，这些地方梯度很小也就意味着梯度下降会很慢，因此学习也就很慢。 事实上有时有比0.01更好的常数，当你训练一个只有一层隐藏层的网络时（这是相对浅的神经网络，没有太多的隐藏层），设为0.01可能也可以。但当你训练一个非常非常深的神经网络，你可能要试试0.01以外的常数。 summary如何建立一个一层的神经网络了，初始化参数，用前向传播预测，还有计算导数，结合反向传播用在梯度下降中。 1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model's parameters 1. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent) C1W4C1W4L01 Deep-layer neural network1. logistics regression and shallow neural network and deep-layer neural network 2. notation神经网络模型 \begin{array}{l}{X \in \mathbb{R}^{n_{x} \times m}} 代表输入的矩阵\\{x^{(i)} \in \mathbb{R}^{n_{x}}} 代表第 i 个样本的列向量\\ {Y \in \mathbb{R}^{n_{y} \times n}} 标记矩阵\\ {y^{(i)} \in \mathbb{R}^{n_{v}}}是第i样本的输出标签\\ W^{[l]} \in \mathbb{R}^{l \times(l-1)}代表第[l]层的权重矩阵\\ b^{[l]} \in \mathbb{R}^{l}代表第[l]层的偏差矩阵\\ {\hat{y}^{(i)} \in \mathbb{R}^{n_{v}}}是预测输出向量\end{array} 通用激活公式： a_{j}^{[l]}=g^{[l]}\left(z_{j}^{[l]}\right)=g^{ | l ]}\left(\sum_{k} w_{j k}^{[l]} a_{k}^{[l-1]}+b_{j}^{[l]}\right)C1W4L02： Forward and Backward propagation1. forward propagation 2. backward propagation \begin{array}{l}{d z^{[l]}=d a^{[l]} * g^{[l]}\left(z^{l l}\right)} \\ {d w^{[l]}=d z^{[l]} \cdot a^{[l-1]}}\\d b^{[l]}=d z^{[l]}\\ d a^{[l-1]}=w^{[l]} \cdot d z^{[l]}\\ d z^{[l]}=w^{[l+1] T} d z^{[l+1]} \cdot g^{[l]^{\prime}}\left(z^{[l]}\right)\end{array}向量化 \begin{array}{l}{d Z^{[l]}=d A^{[l]} * g^{[l]}\left(Z^{[l]}\right)} \\ {d W^{[l]}=\frac{1}{m} d Z^{[l]} \cdot A^{[l-1] T}}\\ \begin{array}{l}{d b^{[l]}=\frac{1}{m} n p \cdot \operatorname{sum}\left(d z^{[l]}, \text { axis }=1, \text {keepdims}=\text {True}\right)} \\ {d A^{[l-1]}=W^{[l] T} \cdot d Z^{[l]}}\end{array}\end{array}summary C1W4L03 : Forward Propagation in d deep network 这里只能用一个显式for循环，从1到，然后一层接着一层去计算。 C1W4L04 Getting matrix dimension right当实现深度神经网络的时候，其中一个常用的检查代码是否有错的方法就是拿出一张纸过一遍算法中矩阵的维数。 $d_w^{[l]}$和$w^{[l]}$维度相同，$db^{[l]}$和$b^{[l]}$维度相同，且w和b向量化维度不变，但z,a以及x的维度会向量化后发生变化。 反向传播的维数检查 在你做深度神经网络的反向传播时，一定要确认所有的矩阵维数是前后一致的，可以大大提高代码通过率。 C1W4L05 Why deep representations?神经网络不需要很大，但是得有深度，也就是隐藏层需要很多， 1. for example of face detector C1W4L06 :Building blocks of a deep neural network 可以看得出，再反向传播的时候，需要用到$Z^{[L]},W^{[L]},b^{[L]}$,因此cash them 正向传播：$Z^{[1]},A^{[1]}…………$,反向传播：$dA^{[L]},dZ{[L]},dW^{[L]}dB^{[L]},dA^{[L-1]}$ C1W4L07：Parameters vs Hyperparameters1 What 2 How Idea—Code—Experiment—Idea这个循环，尝试各种不同的参数，实现模型并观察是否成功，然后再迭代 今天的深度学习应用领域，还是很经验性的过程，通常你有个想法，比如你可能大致知道一个最好的学习率值，可能说最好，我会想先试试看，然后你可以实际试一下，训练一下看看效果如何。然后基于尝试的结果你会发现，你觉得学习率设定再提高到0.05会比较好。如果你不确定什么值是最好的，你大可以先试试一个学习率，再看看损失函数J的值有没有下降。然后你可以试一试大一些的值，然后发现损失函数的值增加并发散了。然后可能试试其他数，看结果是否下降的很快或者收敛到在更高的位置。你可能尝试不同的并观察损失函数这么变了，试试一组值，然后可能损失函数变成这样，这个值会加快学习过程，并且收敛在更低的损失函数值上（箭头标识），我就用这个值了。 在前面几页中，还有很多不同的超参数。然而，当你开始开发新应用时，预先很难确切知道，究竟超参数的最优值应该是什么。所以通常，你必须尝试很多不同的值，并走这个循环，试试各种参数。试试看5个隐藏层，这个数目的隐藏单元，实现模型并观察是否成功，然后再迭代。这页的标题是，应用深度学习领域，一个很大程度基于经验的过程，凭经验的过程通俗来说，就是试直到你找到合适的数值。 所以我经常建议人们，特别是刚开始应用于新问题的人们，去试一定范围的值看看结果如何。然后下一门课程，我们会用更系统的方法，用系统性的尝试各种超参数取值。然后其次，甚至是你已经用了很久的模型，可能你在做网络广告应用，在你开发途中，很有可能学习率的最优数值或是其他超参数的最优值是会变的，所以即使你每天都在用当前最优的参数调试你的系统，你还是会发现，最优值过一年就会变化，因为电脑的基础设施，CPU或是GPU可能会变化很大。所以有一条经验规律可能每几个月就会变。如果你所解决的问题需要很多年时间，只要经常试试不同的超参数，勤于检验结果，看看有没有更好的超参数数值，相信你慢慢会得到设定超参数的直觉，知道你的问题最好用什么数值。 有一条经验规律：经常试试不同的超参数，勤于检查结果，看看有没有更好的超参数取值，你将会得到设定超参数的直觉。 总结：超参数的设定，靠经验，尝试，并调，根据结果调， C1W4L08 : What does this have to do with the brain?# summary : forward prop and back prop1. logistics regression,shallow neural network and deep neural networklogistics regression Z = W^TX+B\\ A = \frac{1}{1+e^{-Z}}\\ L(A,Y)=-\frac{1}{m}(Ylog^A+(1-Y)log^{1-A}\\ \frac{\partial L}{\partial Z}=(A-Y)\\ \frac{\partial L}{\partial W}=X(A-Y)\\说明：X是样本按列堆积，W是列向量 shallow neural network 以二分问题为例 Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}\\ A^{[1]}=g^{[1]}(Z^{[1]})\\ \ \\ Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}\\ A^{[2]}=g^{[2]}(Z^{[2]})\\ \ \ \\ \ \\ L(A^{[2]},Y)=-\frac{1}{m}(Ylog^{A}+(1-Y)log^{1-A})\\ \frac{\partial L}{\partial Z^{[2]}}=(A^{[2]}-Y)\\ \frac{\partial L}{\partial W^{[2]}}=(A^{[2]}-Y)A^{[1]^T}\\ \frac{\partial L}{\partial b^{[2]}}=(A^{[2]}-Y)1_{1*m}^T\\ \frac{\partial L}{\partial a^{[1]}}=W^{[2]^T}(A^{[2]}-Y)\\ \ \\ \frac{\partial L}{\partial Z^{[1]}}=W^{[2]^T}(A^{[2]}-Y)* g^{'[1]}(Z^{[1]})\\说明：W是按列排$W^{[L]}$是$n^{[L]}*n^{[L-1]}$矩阵，A,Z是按列堆积，记得检查矩阵维数就好了 deep neural network Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}\\ A^{[l]}=g^{[l]}(Z^{[l]})\\ \ \ \\ \ \\ \frac{\partial L}{\partial Z^{[l]}}=\partial A^*g^{'[l]}(Z^{l})\\ \frac{\partial L}{\partial W^{[l]}}=\partial Z^{[l]} A^{[1-1]^T}\\ \frac{\partial L}{\partial b^{[l]}}=\partial Z^{[l]}\\ \frac{\partial L}{\partial a^{[l-1]}}=W^{[l]^T}\partial Z^{[l]}\\ \ \\ \frac{\partial L}{\partial Z^{[l-1]}}=W^{[l]^T}\partial Z^{[l]}* g^{'[l-1]}(Z^{[l-1]})\\2. vectorization 推导的时候要向量化，注意矩阵维数表示，可以从单个推导到mutli 充分利用python的广播属性，和内置函数的并行化 python一维，二维数组的特性 3. 知识结构]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep_learning.ai深度学习笔记]]></title>
    <url>%2F2019%2F04%2F11%2Fdeep-learning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[C5: Sequence ModelsW1 : Recurrent Neural Networks (循环序列模型)L1 ： Why Sequence Models?循环神经网络（RNN）之类的模型在语音识别、自然语言处理和其他领域中引起变革。 序列模型的列子 L2 : Notation 数学符号NLP 我们用$X^{(i)}$来表示第个i训练样本，所以为了指代第个t元素，或者说是训练样本i的序列中第t个元素用$X^{(i)}$这个符号来表示。如果是序列长度$T_x$，那么你的训练集里不同的训练样本就会有不同的长度，所以$T_x^{(i)}$就代表第个训练样本的输入序列长度。同样$y^{(i)}$代表第i个训练样本中第t个元素，$T_y^{(i)}$就是第i个训练样本的输出序列的长度。 预先有一个词典 L3 : Recurrent Neural Network Model (循环神经网络模型)现在我们讨论一下怎样才能建立一个模型，建立一个神经网络来学习X到Y的映射 $a^{}$通常 是零向量 N模型包含三类权重系数，分别是Wax，Waa，Wya。且不同元素之间同一位置共享同一权重系数。 RNN的正向传播（Forward Propagation）过程为： 循环神经网络用的激活函数经常是tanh，不过有时候也会用ReLU，但是tanh是更通常的选择，我们有其他方法来避免梯度消失问题，我们将在之后进行讲述。选用哪个激活函数是取决于你的输出y，如果它是一个二分问题，那么我猜你会用sigmoid函数作为激活函数，如果是k类别分类问题的话，那么可以选用softmax作为激活函数。不过这里激活函数的类型取决于你有什么样类型的输出y，对于命名实体识别来说y只可能是0或者1，那我猜这里第二个激活函数g可以是sigmoid激活函数。 c4: Backpropagation through time ( 通过时间的反向传播) 参数的关系* 单个元素的Loss function: 该样本所有元素的Loss function为： 然后，反向传播（Backpropagation）过程就是从右到左分别计算L(y^,y)对参数Wa，Wy，ba，by的偏导数。思路与做法与标准的神经网络是一样的。一般可以通过成熟的深度学习框架自动求导，例如PyTorch、Tensorflow等。这种从右到左的求导过程被称为Backpropagation through time L5: Different types of RNNs (不同类型的循环神经网络) L6 : Language model and sequence generation (语言模型和序列生成) L7 : Sampling novel sequences (对新序列采样) Vanishing gradients with RNNs (循环神经网络的梯度消失)首先从左到右前向传播，然后反向传播。但是反向传播会很困难，因为同样的梯度消失的问题，后面层的输出误差（上图编号6所示）很难影响前面层（上图编号7所示的层）的计算。这就意味着，实际上很难让一个神经网络能够意识到它要记住看到的是单数名词还是复数名词，然后在序列后面生成依赖单复数形式的was或者were。而且在英语里面，这中间的内容（上图编号8所示）可以任意长，对吧？所以你需要长时间记住单词是单数还是复数，这样后面的句子才能用到这些信息。也正是这个原因，所以基本的RNN模型会有很多局部影响 http://www.ai-start.com/dl2017/html/lesson5-week1.html https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&amp;mid=2247484029&amp;idx=1&amp;sn=c93b5eddec33dc29dc172a5ea0d76822&amp;chksm=976fa7e0a0182ef61e36d1c32aa0706c4e81e1762a7ee2554165beecde929b72cf026c5b7a64&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>学习の历程(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>我的读书笔记</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F07%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[: [TOC] 利用听力材料学英语最高效有效输出应该是稍高于现有水平的、更准确、更得体的表达输出 先记住以下两点，下面我们再一一解析应该要怎么做到。 1. 学习需要反馈，来告诉我们这输出是正确的，可以继续；或者是错误的，需要修正。 2. 将输入内化，变成自己的知识。 我一般会听四遍，但不是全听原文。 第一遍：泛听原文，不要看字幕或脚本，清楚录音的内容。听第一遍的时候我通常连笔记都不做，目的是为了让自己流畅的听完，对听力的内容有一个整体的掌握。 第二遍：先听原文，根据内容段落，开始复述内容，并录音。这一步的目的是强迫自己调用已经学过的知识，组织语言和进行练习。 第三遍，听自己的录音，然后做出修正。这一步很重要，可以让你了解自己的发音问题和语法问题，并把可听出来的语法问题进行修改。通过这一步，我们就可以把简单重复输入的语言材料，转化为有效输出。 第四遍，听原文看字幕和脚本，看把听不懂的地方标注，说明为什么听不懂（比如是因为自己发音不准导致的听不出，或者就是因为这个词没背过、不熟悉）。不熟悉的用法和自己用错的地方总结，背下来，下次试着用。 Tips： 不要选择太难的材料，太难的材料容易使自己丧失学习兴趣。 一开始，不要选择太长的听力材料。10分钟左右最佳。在这里推荐ted，可以选择有字幕或关闭字幕。 在一个相近的时间段内，选择相近题材的材料。比如我会在两个星期内选择“心理”题材的录音。这样我就会有更大的几率用上刚学过的结构和词汇。 及时总结，及时复习已背过的材料，复习的重要性大家都懂，这里就不多说了。 真题听写 材料选择 能够听得懂 70%的材料 2 具体执行方法 先泛听一篇 再循环听几遍 再逐句逐句的听 美剧精听 先看中文听 英文，查 听找 台词，跟读 重复三四至少10]]></content>
  </entry>
  <entry>
    <title><![CDATA[deeplearningvideo]]></title>
    <url>%2F2019%2F04%2F03%2Fdeeplearningvideo%2F</url>
    <content type="text"><![CDATA[Coursera深度学习教程中文笔记 课程概述 https://mooc.study.163.com/university/deeplearning_ai#/c 这些课程专为已有一定基础（基本的编程知识，熟悉Python、对机器学习有基本了解），想要尝试进入人工智能领域的计算机专业人士准备。介绍显示：“深度学习是科技业最热门的技能之一，本课程将帮你掌握深度学习。” 在这5堂课中，学生将可以学习到深度学习的基础，学会构建神经网络，并用在包括吴恩达本人在内的多位业界顶尖专家指导下创建自己的机器学习项目。Deep Learning Specialization对卷积神经网络 (CNN)、递归神经网络 (RNN)、长短期记忆 (LSTM) 等深度学习常用的网络结构、工具和知识都有涉及。 笔记是根据视频和字幕写的，没有技术含量，只需要专注和严谨。 2018-04-14 本课程视频教程地址：https://mooc.study.163.com/university/deeplearning_ai#/c （该视频从www.deeplearning.ai 网站下载，因众所周知的原因，国内用户观看某些在线视频非常不容易，故一些学者一起制作了离线视频，旨在方便国内用户个人学习使用，请勿用于商业用途。视频内嵌中英文字幕，推荐使用potplayer播放。版权属于吴恩达老师所有，若在线视频流畅，请到官方网站观看。） 笔记网站(适合手机阅读) 吴恩达老师的机器学习课程笔记和视频：https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes 深度学习笔记目录第一门课 神经网络和深度学习(Neural Networks and Deep Learning)第一周：深度学习引言(Introduction to Deep Learning) 1.1 欢迎(Welcome) 1.2 什么是神经网络？(What is a Neural Network) 1.3 神经网络的监督学习(Supervised Learning with Neural Networks) 1.4 为什么神经网络会流行？(Why is Deep Learning taking off?) 1.5 关于本课程(About this Course) 1.6 课程资源(Course Resources) 1.7 Geoffery Hinton 专访(Geoffery Hinton interview) 第二周：神经网络的编程基础(Basics of Neural Network programming) 2.1 二分类(Binary Classification) 2.2 逻辑回归(Logistic Regression) 2.3 逻辑回归的代价函数（Logistic Regression Cost Function） 2.4 梯度下降（Gradient Descent） 2.5 导数（Derivatives） 2.6 更多的导数例子（More Derivative Examples） 2.7 计算图（Computation Graph） 2.8 计算图导数（Derivatives with a Computation Graph） 2.9 逻辑回归的梯度下降（Logistic Regression Gradient Descent） 2.10 梯度下降的例子(Gradient Descent on m Examples) 2.11 向量化(Vectorization) 2.12 更多的向量化例子（More Examples of Vectorization） 2.13 向量化逻辑回归(Vectorizing Logistic Regression) 2.14 向量化逻辑回归的梯度计算（Vectorizing Logistic Regression’s Gradient） 2.15 Python中的广播机制（Broadcasting in Python） 2.16 关于 Python与numpy向量的使用（A note on python or numpy vectors） 2.17 Jupyter/iPython Notebooks快速入门（Quick tour of Jupyter/iPython Notebooks） 2.18 逻辑回归损失函数详解（Explanation of logistic regression cost function） 第三周：浅层神经网络(Shallow neural networks) 3.1 神经网络概述（Neural Network Overview） 3.2 神经网络的表示（Neural Network Representation） 3.3 计算一个神经网络的输出（Computing a Neural Network’s output） 3.4 多样本向量化（Vectorizing across multiple examples） 3.5 向量化实现的解释（Justification for vectorized implementation） 3.6 激活函数（Activation functions） 3.7 为什么需要非线性激活函数？（why need a nonlinear activation function?） 3.8 激活函数的导数（Derivatives of activation functions） 3.9 神经网络的梯度下降（Gradient descent for neural networks） 3.10（选修）直观理解反向传播（Backpropagation intuition） 3.11 随机初始化（Random+Initialization） 第四周：深层神经网络(Deep Neural Networks) 4.1 深层神经网络（Deep L-layer neural network） 4.2 前向传播和反向传播（Forward and backward propagation） 4.3 深层网络中的前向和反向传播（Forward propagation in a Deep Network） 4.4 核对矩阵的维数（Getting your matrix dimensions right） 4.5 为什么使用深层表示？（Why deep representations?） 4.6 搭建神经网络块（Building blocks of deep neural networks） 4.7 参数VS超参数（Parameters vs Hyperparameters） 4.8 深度学习和大脑的关联性（What does this have to do with the brain?） 第二门课 改善深层神经网络：超参数调试、正则化以及优化(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)第一周：深度学习的实用层面(Practical aspects of Deep Learning) 1.1 训练，验证，测试集（Train / Dev / Test sets） 1.2 偏差，方差（Bias /Variance） 1.3 机器学习基础（Basic Recipe for Machine Learning） 1.4 正则化（Regularization） 1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?） 1.6 dropout 正则化（Dropout Regularization） 1.7 理解 dropout（Understanding Dropout） 1.8 其他正则化方法（Other regularization methods） 1.9 标准化输入（Normalizing inputs） 1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients） 1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing /Exploding gradients） 1.12 梯度的数值逼近（Numerical approximation of gradients） 1.13 梯度检验（Gradient checking） 1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes） 第二周：优化算法 (Optimization algorithms) 2.1 Mini-batch 梯度下降（Mini-batch gradient descent） 2.2 理解Mini-batch 梯度下降（Understanding Mini-batch gradient descent） 2.3 指数加权平均（Exponentially weighted averages） 2.4 理解指数加权平均（Understanding Exponentially weighted averages） 2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages） 2.6 momentum梯度下降（Gradient descent with momentum） 2.7 RMSprop——root mean square prop（RMSprop） 2.8 Adam优化算法（Adam optimization algorithm） 2.9 学习率衰减（Learning rate decay） 2.10 局部最优问题（The problem of local optima） 第三周超参数调试，batch正则化和程序框架（Hyperparameter tuning, Batch Normalization and Programming Frameworks) 3.1 调试处理（Tuning process） 3.2 为超参数选择和适合范围（Using an appropriate scale to pick hyperparameters） 3.3 超参数训练的实践：Pandas vs. Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar） 3.4 网络中的正则化激活函数（Normalizing activations in a network） 3.5 将 Batch Norm拟合进神经网络（Fitting Batch Norm into a neural network） 3.6 为什么Batch Norm奏效？（Why does Batch Norm work?） 3.7 测试时的Batch Norm（Batch Norm at test time） 3.8 Softmax 回归（Softmax Regression） 3.9 训练一个Softmax 分类器（Training a softmax classifier） 3.10 深度学习框架（Deep learning frameworks） 3.11 TensorFlow（TensorFlow） 第三门课 结构化机器学习项目 (Structuring Machine Learning Projects)第一周：机器学习策略（1）(ML Strategy (1)) 1.1 为什么是ML策略？ (Why ML Strategy) 1.2 正交化(Orthogonalization) 1.3 单一数字评估指标(Single number evaluation metric) 1.4 满足和优化指标 (Satisficing and Optimizing metric) 1.5 训练集、开发集、测试集的划分(Train/dev/test distributions) 1.6 开发集和测试集的大小 (Size of the dev and test sets) 1.7 什么时候改变开发集/测试集和评估指标(When to change dev/test sets and metrics) 1.8 为什么是人的表现 (Why human-level performance?) 1.9 可避免偏差(Avoidable bias) 1.10 理解人类的表现 (Understanding human-level performance) 1.11 超过人类的表现(Surpassing human-level performance) 1.12 改善你的模型表现 (Improving your model performance) 第二周：机器学习策略（2）(ML Strategy (2)) 2.1 误差分析 (Carrying out error analysis) 2.2 清除标注错误的数据(Cleaning up incorrectly labeled data) 2.3 快速搭建你的第一个系统，并进行迭代(Build your first system quickly, then iterate) 2.4 在不同的分布上的训练集和测试集 (Training and testing on different distributions) 2.5 数据分布不匹配的偏差与方差分析 (Bias and Variance with mismatched data distributions) 2.6 处理数据不匹配问题(Addressing data mismatch) 2.7 迁移学习 (Transfer learning) 2.8 多任务学习(Multi-task learning) 2.9 什么是端到端的深度学习？ (What is end-to-end deep learning?) 2.10 是否使用端到端的深度学习方法 (Whether to use end-to-end deep learning) 第四门课 卷积神经网络（Convolutional Neural Networks）第一周 卷积神经网络(Foundations of Convolutional Neural Networks) 1.1 计算机视觉（Computer vision） 1.2 边缘检测示例（Edge detection example） 1.3 更多边缘检测内容（More edge detection） 1.4 Padding 1.5 卷积步长（Strided convolutions） 1.6 三维卷积（Convolutions over volumes） 1.7 单层卷积网络（One layer of a convolutional network） 1.8 简单卷积网络示例（A simple convolution network example） 1.9 池化层（Pooling layers） 1.10 卷积神经网络示例（Convolutional neural network example） 1.11 为什么使用卷积？（Why convolutions?） 第二周 深度卷积网络：实例探究(Deep convolutional models: case studies) 2.1 为什么要进行实例探究？（Why look at case studies?） 2.2 经典网络（Classic networks） 2.3 残差网络（Residual Networks (ResNets)） 2.4 残差网络为什么有用？（Why ResNets work?） 2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions） 2.6 谷歌 Inception 网络简介（Inception network motivation） 2.7 Inception 网络（Inception network） 2.8 使用开源的实现方案（Using open-source implementations） 2.9 迁移学习（Transfer Learning） 2.10 数据扩充（Data augmentation） 2.11 计算机视觉现状（The state of computer vision） 第三周 目标检测（Object detection） 3.1 目标定位（Object localization） 3.2 特征点检测（Landmark detection） 3.3 目标检测（Object detection） 3.4 卷积的滑动窗口实现（Convolutional implementation of sliding windows） 3.5 Bounding Box预测（Bounding box predictions） 3.6 交并比（Intersection over union） 3.7 非极大值抑制（Non-max suppression） 3.8 Anchor Boxes 3.9 YOLO 算法（Putting it together: YOLO algorithm） 3.10 候选区域（选修）（Region proposals (Optional)） 第四周 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition &amp;Neural style transfer） 4.1 什么是人脸识别？(What is face recognition?) 4.2 One-Shot学习（One-shot learning） 4.3 Siamese 网络（Siamese network） 4.4 Triplet 损失（Triplet 损失） 4.5 面部验证与二分类（Face verification and binary classification） 4.6 什么是神经风格转换？（What is neural style transfer?） 4.7 什么是深度卷积网络？（What are deep ConvNets learning?） 4.8 代价函数（Cost function） 4.9 内容代价函数（Content cost function） 4.10 风格代价函数（Style cost function） 4.11 一维到三维推广（1D and 3D generalizations of models） 第五门课 序列模型(Sequence Models)第一周 循环序列模型（Recurrent Neural Networks） 1.1 为什么选择序列模型？（Why Sequence Models?） 1.2 数学符号（Notation） 1.3 循环神经网络模型（Recurrent Neural Network Model） 1.4 通过时间的反向传播（Backpropagation through time） 1.5 不同类型的循环神经网络（Different types of RNNs） 1.6 语言模型和序列生成（Language model and sequence generation） 1.7 对新序列采样（Sampling novel sequences） 1.8 循环神经网络的梯度消失（Vanishing gradients with RNNs） 1.9 GRU单元（Gated Recurrent Unit（GRU）） 1.10 长短期记忆（LSTM（long short term memory）unit） 1.11 双向循环神经网络（Bidirectional RNN） 1.12 深层循环神经网络（Deep RNNs） 第二周 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings） 2.1 词汇表征（Word Representation） 2.2 使用词嵌入（Using Word Embeddings） 2.3 词嵌入的特性（Properties of Word Embeddings） 2.4 嵌入矩阵（Embedding Matrix） 2.5 学习词嵌入（Learning Word Embeddings） 2.6 Word2Vec 2.7 负采样（Negative Sampling） 2.8 GloVe 词向量（GloVe Word Vectors） 2.9 情绪分类（Sentiment Classification） 2.10 词嵌入除偏（Debiasing Word Embeddings） 第三周 序列模型和注意力机制（Sequence models &amp; Attention mechanism） 3.1 基础模型（Basic Models） 3.2 选择最可能的句子（Picking the most likely sentence） 3.3 集束搜索（Beam Search） 3.4 改进集束搜索（Refinements to Beam Search） 3.5 集束搜索的误差分析（Error analysis in beam search） 3.6 Bleu 得分（选修）（Bleu Score (optional)） 3.7 注意力模型直观理解（Attention Model Intuition） 3.8注意力模型（Attention Model） 3.9语音识别（Speech recognition） 3.10触发字检测（Trigger Word Detection） 3.11结论和致谢（Conclusion and thank you） 人工智能大师访谈 吴恩达采访 Geoffery Hinton 吴恩达采访 Ian Goodfellow 吴恩达采访 Ruslan Salakhutdinov 吴恩达采访 Yoshua Bengio 吴恩达采访 林元庆 吴恩达采访 Pieter Abbeel 吴恩达采访 Andrej Karpathy 附件 深度学习符号指南（原课程翻译）]]></content>
      <categories>
        <category>视频学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯分类器]]></title>
    <url>%2F2019%2F03%2F28%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[[TOC] 概率论的知识 条件概率 P(A|B)=P(A\cap B)/P(B)已知B发生的概率，求A发生的概率 全概率 P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i)贝叶斯推断 P(A|B)=P(A)\frac{P(B|A)}{P(B)} P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)}$P(A)$：Prior probability 先验概率，在B事件发生之前，对A事件做一个判断 $P(A|B)$:Posterior probability 后验概率，在B事件发生之后，对A事件的概率重新评估 $P(B|A)/P(B)$:称为可能性函数，一个调整因子 后验概率=先验概率*调整因子 （可知，调整因此&gt;1,发生概率增大了， 贝叶斯决策论英文：Bayesian decision theory 设有$N$种可能的类别, 即γ=${c_1,c_2,…,c_N}$. $λ_ij$是将一个真实类别为$c_j$的样本判为$c_x$的损失。 基于后验概率可得将样本分类所产生的期望损失, 或者成为条件风险(Conditional Risk) R(C_i|x)=∑_{j=1}^Nλ_{ij}P(c_j|x)于是， 我们的任务就是寻找判定准则h， 令$χ→γ$ 使得最小化总体风险，$R(h)=E_x[R(h(x)|x]$最小. 对于每一个$x$，若$h$都能最小化条件风险，那么总体也被最小化了。 可以简化为对每个样本选择其条件风险最小的分类, 即: h(x)=arg \min_{c⊂λ}R(c|x)此$h(x)$就是贝叶斯最优分类器。 $R(h)$为贝叶斯风险(Bayes Risk), $1−R(h)$反映了分类器的最优性能. 具体来说，如果目标是最小化分类错误率， \lambda_{ij}=\begin{cases} 0\ \ i==j\\1 \ \ \ i!=j \end{cases}则$R(c|x)=1-p(c|x)$，因此可知，$h(x)=\max_{c\in C} p(c|x)$ 对于样本$x$,选择后验概率$P(c|X)$最大的类别为标记。 问题转换为 P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)}求先验概率和似然($P(x|c)$) 其中 $P(c)$表达了样本空间种各类样本所占的比列，根据大数定律，当样本足够充分的独立同分布样本是，可以频率估计 $P(x|c)$,涉及关于x所以属性的联合概率，用频率估计概率可能不太好，对于估计类条件概率的一种宠用策略是先假设具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。 $P(x|c)$是类条件概率，由某个分布决定，$P(x|\theta_c)$来表示了 频率注意派认为可以通过优化似然函数估计参数。$D_c$类别c的样本集合，独立同分布 P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c) LL(\theta_c)=log P(D_c|\theta_c)朴素贝叶斯分类器英文：naive Bayes classifier 假设：属性条件独立性假设，每个属性独立性对分类结果发生影响 P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)\Pi_{i=1}^{d}P(x_i|c)}{P(x)}对于一个$x$，$P(x)$都是相同的，因此贝叶斯模型可写为 h_{nb}(x)=arg max_{c\in y}P(c)\Pi_{i=1}^{d}P(x_i|c)计算过程假设$D_{c_i}$表示第i类的样本集合， $P(c_i)=\frac{|D_{c_i}|}{|D|}$ 如果是离散属性 P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|}如果是连续属性，$P(x_i|c_i)$服从$N(u_{c,i},\theta_{c,i}^2)$的分布 P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2}) $P(c_i)\Pi_{i=1}^{N}P(x_i|c_i)$ 注意为了避免其他属性携带的信息被训练集中未出现的属性值抹去，因此用拉普拉斯修正（Laplacian correction) P(c)=\frac{|D_{c_i}|+1}{|D|+N}\\ P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}$N$:训练集可能出现的类别数 $N_i$:第i个属性可能的取值数 显然，拉普拉斯修正避免因训练集不充分导出的概率估值为0的情况 朴素贝叶斯的种类再scikit-learn中，一共有三个朴素贝叶斯，分别是 GaussianNB P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})12345678910111213141516171819202122#导入包import pandas as pdfrom sklearn.naive_bayes import GaussianNBfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_score#导入数据集from sklearn import datasetsiris=datasets.load_iris()#切分数据集Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=42)#建模clf = GaussianNB()clf.fit(Xtrain, ytrain)#在测试集上执行预测，proba导出的是每个样本属于某类的概率clf.predict(Xtest)clf.predict_proba(Xtest) #每一类计算结果都输出#测试准确率accuracy_score(ytest, clf.predict(Xtest)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npimport pandas as pdimport randomdataSet =pd.read_csv('iris.txt',header = None)dataSet.head()def randSplit(dataSet, rate): l = list(dataSet.index) #提取出索引 random.shuffle(l) #随机打乱索引 dataSet.index = l #将打乱后的索引重新赋值给原数据集 n = dataSet.shape[0] #总行数 m = int(n * rate) #训练集的数量 train = dataSet.loc[range(m), :] #提取前m个记录作为训练集 test = dataSet.loc[range(m, n), :] #剩下的作为测试集 dataSet.index = range(dataSet.shape[0]) #更新原数据集的索引 test.index = range(test.shape[0]) #更新测试集的索引train,test=randSplit(dataSet, 0.8)def gnb_classify(train,test): labels = train.iloc[:,-1].value_counts().index #提取训练集的标签种类 mean =[] #存放每个类别的均值 std =[] #存放每个类别的方差 result = [] #存放测试集的预测结果 for i in labels: item = train.loc[train.iloc[:,-1]==i,:] #分别提取出每一种类别 m = item.iloc[:,:-1].mean() #当前类别的平均值 s = np.sum((item.iloc[:,:-1]-m)**2)/(item.shape[0]) #当前类别的方差 mean.append(m) #将当前类别的平均值追加至列表 std.append(s) #将当前类别的方差追加至列表 means = pd.DataFrame(mean,index=labels) #变成DF格式，索引为类标签 stds = pd.DataFrame(std,index=labels) #变成DF格式，索引为类标签 for j in range(test.shape[0]): iset = test.iloc[j,:-1].tolist() #当前测试实例 iprob = np.exp(-1*(iset-means)**2/(stds*2))/(np.sqrt(2*np.pi*stds)) #正态分布公式 prob = train.iloc[:,-1].value_counts()/len(train.iloc[:,-1]) #初始化当前实例总概率 for k in range(test.shape[1]-1): #遍历每个特征 prob *= iprob[k] #特征概率之积即为当前实例概率 cla = prob.index[np.argmax(prob.values)] #返回最大概率的类别 result.append(cla) test['predict']=result acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean() #计算预测准确率 print(f'模型预测准确率为&#123;acc&#125;') return testgnb_classify(train,test)for i in range(20): train,test= randSplit(dataSet, 0.8) gnb_classify(train,test) MultinomialNB先验概率多项式分布的朴素贝叶斯，假设特征是由一共简单多项式分布生成，多项分布可以描述各种类型样本出现的频率，该模型常用于文本分类，特别表示次数。$\lambda$常取值1 P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda}12345678910def loadDataSet(): dataSet=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] #切分好的词条 classVec = [0,1,0,1,0,1] #类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇 return dataSet,classVecdataSet,classVec = loadDataSet() 12345678def createVocabList(dataSet): vocabSet = set() #创建一个空的集合 for doc in dataSet: #遍历dataSet中的每一条言论 vocabSet = vocabSet | set(doc) #取并集 vocabList = list(vocabSet) return vocabListvocabList = createVocabList(dataSet) 12345678def setOfWords2Vec(vocabList, inputSet): returnVec = [0] * len(vocabList) #创建一个其中所含元素都为0的向量 for word in inputSet: #遍历每个词条 if word in vocabList: #如果词条存在于词汇表中，则变为1 returnVec[vocabList.index(word)] = 1 else: print(f" &#123;word&#125; is not in my Vocabulary!" ) return returnVec #返回文档向量 12345678def get_trainMat(dataSet): trainMat = [] #初始化向量列表 vocabList = createVocabList(dataSet) #生成词汇表 for inputSet in dataSet: #遍历样本词条中的每一条样本 returnVec=setOfWords2Vec(vocabList, inputSet) #将当前词条向量化 trainMat.append(returnVec) #追加到向量列表中 return trainMattrainMat = get_trainMat(dataSet) 1234567891011121314151617181920def trainNB(trainMat,classVec): n = len(trainMat) #计算训练的文档数目 m = len(trainMat[0]) #计算每篇文档的词条数 pAb = sum(classVec)/n #文档属于侮辱类的概率 p0Num = np.zeros(m) #词条出现数初始化为0 p1Num = np.zeros(m) #词条出现数初始化为0 p0Denom = 0 #分母初始化为0 p1Denom = 0 #分母初始化为0 for i in range(n): #遍历每一个文档 if classVec[i] == 1: #统计属于侮辱类的条件概率所需的数据 p1Num += trainMat[i] p1Denom += sum(trainMat[i]) else: #统计属于非侮辱类的条件概率所需的数据 p0Num += trainMat[i] p0Denom += sum(trainMat[i]) p1V = p1Num/p1Denom p0V = p0Num/p0Denom return p0V,p1V,pAb #返回属于非侮辱类,侮辱类和文档属于侮辱类的概率p0V,p1V,pAb=trainNB(trainMat,classVec) 1234567891011121314151617181920212223from functools import reducedef classifyNB(vec2Classify, p0V, p1V, pAb): p1 = reduce(lambda x,y:x*y, vec2Classify * p1V) * pAb #对应元素相乘 p0 = reduce(lambda x,y:x*y, vec2Classify * p0V) * (1 - pAb) print('p0:',p0) print('p1:',p1) if p1 &gt; p0: return 1 else: return 0def testingNB(testVec): dataSet,classVec = loadDataSet() #创建实验样本 vocabList = createVocabList(dataSet) #创建词汇表 trainMat= get_trainMat(dataSet) #将实验样本向量化 p0V,p1V,pAb = trainNB(trainMat,classVec) #训练朴素贝叶斯分类器 thisone = setOfWords2Vec(vocabList, testVec) #测试样本向量化 if classifyNB(thisone,p0V,p1V,pAb): print(testVec,'属于侮辱类') #执行分类并打印分类结果 else: print(testVec,'属于非侮辱类') #执行分类并打印分类结果 testVec1 = ['love', 'my', 'dalmation']testingNB(testVec1) BernoulliNB伯努利分布，如果是二元伯努利分布 P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il})如果样本属性大多数属于连续，GaussionNB 如果是离散值，使用MultinomialNB 如果样本特征是二元离散值或者稀疏离散值，BernoulliNB 半朴素贝叶斯信息量、熵、联合熵、条件熵、互信息信息量反应了随机变量取某个值含的可能性大小，或者是含有的信息多少 I(X=x)=-log_2^{p(x）}熵(entropy)反应了信源平均每个符号的信息量,或者是随机变量不确定性的衡量 H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)})联合熵反应了多个随机变量的平均信息量 H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)})条件熵（Conditional entropy）反应了已知一个随机变量下，另一个随机变量的不确定性 H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)}互信息(mutual information)反应了已知一个随机变量的情况下，另外一个随机变量不确定性减少了多少,可以把互信息看成由于知道 y 值而造成的 x 的不确定性的减小 I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\\ =H(X)-H(X|Y)=H(Y)-H(Y|X)如果两个随机变量独立，则互信息为0,因此，互信息可以衡量两个随机变量的相关程度 条件互信息在条件z发生时的条件互信息 I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}} 半朴素贝叶斯适当的考虑一部分属性间的相互依赖关系，这个关系可以用互信息描述 独依赖假设每个属性只有一个其他 的属性.则计算公式改下如下 p(C)\Pi_{i=1}^{d} P(x_i|C_i,pa_i)$pa_i$是属性$x_i$所依赖的属性，被称为$x_i$的父属性 1) SPODE 最简单的方法是：都选一个属性作为父属性 可以通过交叉验证的方法 2) TAN :最大带权生成树 权重：当y划分为$c_k$类时条件熵 I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}}step 1: 计算任意两个属性之间条件互信息 I(X;Y|Y)=\sum_{i}I(X;Y|c_i)step 2: 以属性为结点构建完全图 step 3: 最大带权生成树，挑选根变量 step 4: 加入类别结点y,增加到每个属性的有向边 条件互信息反应了属性在已知类别下的相关性大小 集成学习AODE选择模型尝试将每个属性作为超父构建SPODE P(c_i|X)正比于 \sum_{i=1,|D_{x_i}>=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i)$m$通常取30, P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\\ P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j}贝叶斯网(Bayesian network)借助有向无环图来刻画属性之间的依赖关系，条件概率表来描述属性的联合概率分布。 一个贝叶斯网络$B$,包括结构$G$和参数$\Theta$ ,$B(G,\Theta)$,如果两个属性有直接依赖关系，用边连接，对于属性$x_i$,其父节点集合$G_i$,则$\Theta$包括每个属性条件概率$\Theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$ 结构 p(x_1,x_2,...,x_n)=\Pi_{i=1}^{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}^{d}\Theta_{xi|\pi_i}\\ =\Pi_{i=1}^{d}P(x_i|Parents(x_i))推断一旦训练好贝叶斯网后，就能回答query,通过一些属性的观测者来推断其他属性变量的取值，其中，已知变量的值观测推测待查询的过程“推断”,已知变量的观测者”证据“]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>贝叶斯分类器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二次规划]]></title>
    <url>%2F2019%2F03%2F25%2F%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[[TOC] KKT(Karush-Kuhn-Tucher)条件 给定优化问题 \min f(x)\\ subject\ to \begin{cases} g_i(x) = 0 (i=1,,,,m\\ h_i(x) =0 (i=m+1,...,n)\\ \lambda_i h_i(x)=0(i=m+1,..,n)二次规划问题问题的数学表达 \min Q(x) = \frac{1}{2}x^THx+g^Tx\\ s.t. a_i^Tx = b_i (i=1,..,m)\\ \ \ \ \ \ \ \ a_i^Tx =x^{*T}H(x-x^{*})+g^T(x-x^{*})=\lambda^TA(x-x^{*})http://www.hankcs.com/ml/lagrange-duality.html#h3-7 SMO ：Sequential minimal optimization支持向量机的对偶问题 \min \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^{m}\alpha_i\\ s.t. \sum_{i=1}^{m}\alpha_iy_i=0\\ 0]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle]]></title>
    <url>%2F2019%2F03%2F24%2Fkaggle%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[scikit-learn]]></title>
    <url>%2F2019%2F03%2F23%2Fscikit-learn%2F</url>
    <content type="text"><![CDATA[Cross-validation: evaluating estimator performance¶ 12345import numpy as npfrom sklearn.model_selection import train_test_split# 调用train_test_split函数 自动划分数据集 40%for testingX_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, test_size=0.4, random_state=0) corss validation 1234567from sklearn.model_selection import cross_validatefrom sklearn.metrics import recall_scorescoring = [&apos;precision_macro&apos;, &apos;recall_macro&apos;]clf = svm.SVC(kernel=&apos;linear&apos;, C=1, random_state=0)scores = cross_validate(clf, iris.data, iris.target, scoring=scoring, cv=5, return_train_score=False)sorted(scores.keys()) cross-validation metrics12from sklearn.model_selection import cross_val_scoreclf = svm.SVC(kernel = &apos;linear&apos;, C = 1) Cross validation of time series data Tuning the hyper-parameters of an estimatorA search consists of: an estimator (regressor or classifier such as sklearn.svm.SVC()); a parameter space; a method for searching or sampling candidates; a cross-validation scheme; and a score function. Grid Search1234param_grid = [ &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;kernel&apos;: [&apos;linear&apos;]&#125;, &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;gamma&apos;: [0.001, 0.0001], &apos;kernel&apos;: [&apos;rbf&apos;]&#125;, ] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from __future__ import print_functionfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.model_selection import GridSearchCVfrom sklearn.metrics import classification_reportfrom sklearn.svm import SVCprint(__doc__)# Loading the Digits datasetdigits = datasets.load_digits()# To apply an classifier on this data, we need to flatten the image, to# turn the data in a (samples, feature) matrix:n_samples = len(digits.images)X = digits.images.reshape((n_samples, -1))y = digits.target# Split the dataset in two equal partsX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=0)# Set the parameters by cross-validationtuned_parameters = [&#123;'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]&#125;, &#123;'kernel': ['linear'], 'C': [1, 10, 100, 1000]&#125;]scores = ['precision', 'recall']for score in scores: print("# Tuning hyper-parameters for %s" % score) print() clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score) clf.fit(X_train, y_train) print("Best parameters set found on development set:") print() print(clf.best_params_) print() print("Grid scores on development set:") print() means = clf.cv_results_['mean_test_score'] stds = clf.cv_results_['std_test_score'] for mean, std, params in zip(means, stds, clf.cv_results_['params']): print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params)) print() print("Detailed classification report:") print() print("The model is trained on the full development set.") print("The scores are computed on the full evaluation set.") print() y_true, y_pred = y_test, clf.predict(X_test) print(classification_report(y_true, y_pred)) print()# Note the problem is too easy: the hyperparameter plateau is too flat and the# output model is the same for precision and recall with ties in quality. Randomized Parameter Optimization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566print(__doc__)import numpy as npfrom time import timefrom scipy.stats import randint as sp_randintfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.datasets import load_digitsfrom sklearn.ensemble import RandomForestClassifier# get some datadigits = load_digits()X, y = digits.data, digits.target# build a classifierclf = RandomForestClassifier(n_estimators=20)# Utility function to report best scoresdef report(results, n_top=3): for i in range(1, n_top + 1): candidates = np.flatnonzero(results['rank_test_score'] == i) for candidate in candidates: print("Model with rank: &#123;0&#125;".format(i)) print("Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)".format( results['mean_test_score'][candidate], results['std_test_score'][candidate])) print("Parameters: &#123;0&#125;".format(results['params'][candidate])) print("")# specify parameters and distributions to sample fromparam_dist = &#123;"max_depth": [3, None], "max_features": sp_randint(1, 11), "min_samples_split": sp_randint(2, 11), "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run randomized searchn_iter_search = 20random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, cv=5)start = time()random_search.fit(X, y)print("RandomizedSearchCV took %.2f seconds for %d candidates" " parameter settings." % ((time() - start), n_iter_search))report(random_search.cv_results_)# use a full grid over all parametersparam_grid = &#123;"max_depth": [3, None], "max_features": [1, 3, 10], "min_samples_split": [2, 3, 10], "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run grid searchgrid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)start = time()grid_search.fit(X, y)print("GridSearchCV took %.2f seconds for %d candidate parameter settings." % (time() - start, len(grid_search.cv_results_['params'])))report(grid_search.cv_results_) step1： 交叉验证（评价模型） step2: 超参数选择，每一组参数：对应一次交叉验证 step 3: 集成学习 也可进行参数的调解 12345678from sklearn.model_selection import cross_val_scorefrom sklearn.datasets import load_irisfrom sklearn.ensemble import AdaBoostClassifieriris = load_iris()clf = AdaBoostClassifier(n_estimators=100)scores = cross_val_score(clf, iris.data, iris.target, cv=5)scores.mean() 1234567891011121314151617181920212223from sklearn import datasetsfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCfrom itertools import productfrom sklearn.ensemble import VotingClassifier# Loading some example datairis = datasets.load_iris()X = iris.data[:, [0, 2]]y = iris.target# Training classifiersclf1 = DecisionTreeClassifier(max_depth=4)clf2 = KNeighborsClassifier(n_neighbors=7)clf3 = SVC(gamma=&apos;scale&apos;, kernel=&apos;rbf&apos;, probability=True)eclf = VotingClassifier(estimators=[(&apos;dt&apos;, clf1), (&apos;knn&apos;, clf2), (&apos;svc&apos;, clf3)], voting=&apos;soft&apos;, weights=[2, 1, 2])clf1 = clf1.fit(X, y)clf2 = clf2.fit(X, y)clf3 = clf3.fit(X, y)eclf = eclf.fit(X, y) sklearn.model_selectionGridSearchCVclass sklearn.model_selection.``GridSearchCV(estimator, param_grid, **, scoring=None, n_jobs=None, iid=’deprecated’, refit=True, cv=None, verbose=0, pre_dispatch=’2*n_jobs’, error_score=nan, return_train_score=False*)’ estimator**estimator object.** param_grid**dict or list of dictionaries** scoring**str, callable, list/tuple or dict, default=None** cv**int, cross-validation generator or an iterable, default=None** 12345678910from sklearn import svm, datasetsfrom sklearn.model_selection import GridSearchCViris = datasets.load_iris()parameters = &#123;'kernel':('linear', 'rbf'), 'C':[1, 10]&#125;svc = svm.SVC()clf = GridSearchCV(svc, parameters)clf.fit(iris.data, iris.target)sorted(clf.cv_results_.keys())]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boosting]]></title>
    <url>%2F2019%2F03%2F22%2FBoosting%2F</url>
    <content type="text"><![CDATA[[TOC] Boosting原理Boosting算法是将“弱学习算法“提升为“强学习算法”的过程。 加法模型 F_n(x;P) = \sum_{t=1}^{n}\alpha_th_t(x;a_t) 前向分步 F_m(x) = F_{m-1}(x)+\alpha_mh_m(x,a_m)如果选取不同损失函数，则产生不同的类型 AdaBoostAdaBoost就是损失函数为指数损失的Boosting算法。 每一次迭代的弱学习$h(x;a_m)$有何不一样，如何学习？ AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。 弱分类器权值$β_m$如何确定？ AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。 原理理解基于Boosting的理解，对于AdaBoost，我们要搞清楚两点： 每一次迭代的弱学习h(x;am)有何不一样，如何学习？弱分类器权值βm如何确定？对于第一个问题，AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。然后，再根据所采用的一些基本机器学习算法进行学习，比如逻辑回归。 对于第二个问题，AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。 公式推导指数损失函数 L(Y,f(x))=exp(-Yf(x))权重更新公式: 采用的指数误差函数 l_{exp}(a_th_t|D_t)=E(exp(-f(x)a_th_t(x)))\\ =p(f(x)=h_t(x))e^{-at}+p(f(x)!=h_t(x))e^{at}\\ =e^{-at}(1-\xi)+e^{at}\xi a_t=\frac{1}{2}ln \frac{1-\xi}{\xi}分布更新公式 \begin{aligned} l\left(H_{t-1}(x)+\alpha h_{t}(x) | D\right) &=E_{X \sim D}\left(\exp \left(-y(x)\left(H_{t-1}(x)+\alpha h_{t}(x)\right)\right)\right) \\ &=E_{x \sim D}\left(\exp \left(-y(x) H_{t-1}(x)\right) \exp \left(-y(x) \alpha h_{t}(x)\right)\right) \end{aligned}在泰勒展开$exp(-y(x)h_t(x))$ \begin{aligned} l\left(H_{t-1}(x)+h_{t}(x) | D\right) & \approx E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-\alpha y(x) h_{t}(x)+\frac{\alpha^{2} y^{2}(x) h_{t}^{2}(x)}{2}\right)\right] \\ &=E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-y(x) h_{t}(x)+0.5 \alpha^{2}\right)\right] \end{aligned} \begin{aligned} h(x) &=\arg \min _{h} l\left(H_{t-1}(x)+\alpha h_{t} | D\right) \\ &=\arg \max _{h} E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right) \alpha y(x) h_{t}(x)\right] \\ &=\arg \max _{h}\left[\frac{\exp \left(-y(x) H_{t-1}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} y(x) h(x)\right] \end{aligned} 令一个新分布,注意分子是常数 D_{t}(x)=\frac{D(x) \exp \left(-y(x) H_{t-1}(x)\right)^{L}}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} \begin{aligned} h(x) &=\arg \max _{h} E_{x \sim D,}(y(x) h(x)) \\ &=\arg \max _{h} E_{x \sim D_{t}}(1-2 \mathcal{I}(y(x) \neq h(x))) \\ &=\arg \min _{h} E_{x \sim D_{i}}(\mathcal{I}(y(x) \neq h(x))) \end{aligned}同理可得 \begin{aligned} D_{t+1} &=\frac{D(x) \exp \left(-y(x) H_{t}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=\frac{D_{t}(x) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right] \cdot \exp \left(-y(x) H_{t}(x)\right)}{\exp \left(-y(x) H_{t-1}(x)\right) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=D_{t}(x) \exp \left(-y(x) \alpha h_{t}(x)\right) \cdot C . \quad(C i s a \text {constant}) \end{aligned} Z_{t}=\sum_{i}^{m} D_{t}(x) \exp \left(-y(x) \alpha_{t} h_{y}(x)\right)指数误差函数 \begin{aligned} l(H(x) | D) &=\frac{1}{m} \sum_{i}^{m} \exp \left(-y_{i} H\left(x_{i}\right)\right) \\ &=\frac{1}{m} \sum_{i}^{m} \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=\sum_{i}^{m} D_{1}\left(x_{i}\right) \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=Z_{1} Z_{2}\left(x_{i}\right) \exp \left(-\sum_{j=2}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ & \vdots \\ &=\prod_{i=1}^{T} Z_{i} \end{aligned}算法描述总结一下，得到AdaBoost的算法流程： 输入：训练数据集$T={(x1,y1),(x2,y2),(xN,yN)}T={(x1,y1),(x2,y2),(xN,yN)}$，其中，$xi∈X⊆Rnxi∈X⊆Rn，yi∈Y=−1,1yi∈Y=−1,1，$迭代次数M 初始化训练样本的权值分布：$D1=(w1,1,w1,2,…,w1,i),w,i=1,2,…,N$。 对于$m=1,2,…,M$ (a) 使用具有权值分布$D_m$的训练数据集进行学习，得到弱分类器$h_m(x)$ (b) 计算$h_m(x)$在训练数据集上的分类误差率： $e_m=∑_{i=1}^{N}w_m,iI(h_m(xi)≠y_i)$ (c) 计算$h_m(x)$在强分类器中所占的权重： $\alpha_m=\frac{1}{2}log(\frac{1−e_m}{e_m})$ (d) 更新训练数据集的权值分布（这里，$z_m是归一化因子，为了使样本的概率分布和为1）： w_{m+1,i}=\frac{w_{m,i}}exp(−α_my_ih_m(xi))，i=1,2,…,10z_m=∑_{i=1}^{N}w_{m,i}exp(−α_my_ih_m(xi)) 得到最终分类器： F(x)=sign(∑_{i=1}^{N}α_mh_m(x))面经今年8月开始找工作，参加大厂面试问到的相关问题有如下几点： 手推AdaBoost 与GBDT比较 AdaBoost几种基本机器学习算法哪个抗噪能力最强，哪个对重采样不敏感？ 算法流程实例计算Python实现https://www.cnblogs.com/davidwang456/articles/8927029.html]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Boosting, AdaBoost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支持向量回归]]></title>
    <url>%2F2019%2F03%2F19%2FSVR%2F</url>
    <content type="text"><![CDATA[[TOC] 支持向量机用于分类:硬间隔和软件间隔支持向量机。尽可能分对 支持向量机回归： 希望$f(x)$与$y$尽可能的接近。 支持向量机基本思想英文名:support vector regression 简记：SVR 标准的线性支持向量回归模型学习的模型: f(x)=w^Tx+b假设能容忍$f(x)$与$y$之间差别绝对值$\xi$,这就以$f(x)=w^Tx+b$形成了一个$2\xi$的间隔带，因此模型 \min \frac{1}{2}w^Tw\\ s.t -\xi]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>支持向量机回归</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F03%2F17%2FSVMClassifiar%2F</url>
    <content type="text"><![CDATA[title: 支持向量机(SVM) ——- 分类器date: 2019-03-17 08:50:59tags: 支持向量机categories: 机器学习mathjax: true [TOC] 预备的数学知识约束优化问题原问题,带等式约束，也带不等式约束的一般约束问题 \begin{cases} \min_{x}f(x)\\ s.t \begin{cases} m_i(x)>=0, i=1,..,m\\ n_j(x)=0，j=1,..,m\\ \end{cases} \end{cases}\tag{1}构造lagrange乘子法 L(x,\lambda_i,\eta_j)= f(x)-\sum_{i=1}^{m}\lambda_im_i(x)-\sum_{j=1}^{n}\eta_j \tag{2} \begin{cases} \min_{x} max_{\lambda_i,\eta_j} L(R^p)\\ s.t \lambda_i>=0 \end{cases}上述两个问题的等价性证明 如果x不满足约束$m_i(x)$,则$\lambda_i&gt;=0$,同时$m_i(x)&lt;$,则$L(R^{p},\lambda,\eta)$趋近无穷，反之，则存在最大值 min_{x} max_{\lambda,\eta}=min_{x}(max f满足条件,max f不满足约束)\\=min_{x} max_{\lambda,\eta}{f满足条件}对偶问题: 关于$\lambda,\eta​$的最大化问题 max min L(x,\lambda,\eta)\\ s.t \lambda_i>=0​弱对偶问题：对偶问题&lt;=原问题 证明: $max_{x} min(\lambda \eta ) L&lt;=min_{\eta,\lambda } max_{x} L$ \underbrace{\min_{x}L(x,\lambda,\eta)}_{A(\lambda,\eta)}0\end{cases}​注意，$y_i(w^Tx_i+b)&gt;0$,所以$\exists r&gt;0, min(y_i(w^Tx_i+b))=r$,可令$r=1$,这是对超平面范数的固定作用，因为$y=w^Tx+b$和$y=2w^T+2b$是同一个超平面，总能找到缩放$w,b$使得，可以将$r$缩放到1 \Longrightarrow\begin{cases} max \frac{1}{||w||}\\ st. y_i(w^Tx_i+b)>=1\end{cases}\Longrightarrow\begin{cases} \min \frac{1}{2}w^Tw\\ st. y_i(w^Tx_i+b)>=1\end{cases}这是一个土二次规划问题 第二宝 对偶利用lagrange乘子法得出对偶问题 带约束 \begin{cases} \min \frac{1}{2}w^Tw\\ st. y_i(w^Tx_i+b)-1>=0\end{cases}​\Longrightarrow L(w,b,\lambda）=\frac{1}{2}w^Tw-\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b)无约束 \begin{cases}min_{w,b} max_{\lambda}L(w,b,\lambda) \\ s.t \lambda_i>=0\end{cases}​此时关于$w,b​$无约束的。 对$(L(w,b,\lambda))​$ 对$w​$,$b​$求偏导 \frac{\partial L}{\partial w}=w+\sum_{i=1}^{N}y_ix_i\lambda_i=0 \Longrightarrow w=-\sum_{i=1}^{N}y_ix_i\lambda_i\\ \frac{\partial L}{\partial b}=-\sum_{i=1}^{N}\lambda_iy_i=0带回$L(w,b,\lambda)​$,可得对偶问题 \begin{cases} max_{\lambda}L(w,b,\lambda ) =-\frac{1}{2}\sum_i^N\sum_j^N\lambda_i \lambda_jy_iy_jx_i^Tx_j +\sum_i^N\lambda_i \\ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i>=0\end{cases} \Longrightarrow\\\begin{cases} min_{\lambda}L(w,b,\lambda ) =\frac{1}{2}\sum_i^N\sum_j^N\lambda_i \lambda_jy_iy_jx_i^Tx_j -\sum_i^N\lambda_i \\ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i>=0\end{cases}原问题和对偶问题有相同解的充要条件满足 KKT \begin{cases} \frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0,\frac{\partial L}{\partial \lambda}=0\\ \lambda_i(y_i(w^Tx_i+b)-1)=0\\ \lambda_i>=0\\ y_i(w^Tx_i+b)-1>=0 \end{cases}如果存在$(x_k,y_k)=+1or -1​$使得​$y_i(w^Tx_i+b)-1=0​$即可求解$b=y_k-\sum_{i=0}^{N}\lambda_ix_i^Tx_k​$ 代入模型 f(x)=sign(\sum_i^Na_iy_ix_i^Tx+y_k-\sum_{i=0}^{N}\lambda_ix_i^Tx_k)注意，对于任意的训练样本，总有$\lambda_i=0$或者$y_if(x_i)=1$,如果$\lambda_i&gt;0$,说明样本点落在最大间隔的边界上，这些点就是支持向量，这条边界$w^Tx+b=1or-1$ soft-marign 软间隔 想法：允许一部分样本可以不被正确分类 优化目标 \min_{w,b} \frac{1}{2}w^Tw+loss一些损失函数 0-1损失 个数 loss=\sum_{i=1}^NI\{y_i(w^Tx+b)=0,\\ 1-y_i(w^tx_i+b), y_i(w^Tx_i+b)=1-\xi_i\\ \xi_i>=0 \end{cases} 指数损失（exponential loss ) l_{exp}(z)=exp(-z) 对率损失logistic loss l_{log}(z)=log(1+exp(-z)） 核方法核函数的定义设 $\chi$为输入空间（Input Space）， $\mathrm{H}$为特征空间(Feature Space,一定是希尔伯特空间），存在一个映射 \varphi : \chi \rightarrow \mathrm{H}对任意的 $x, y \in \mathrm{X}​$，函数 $K(x, y)​$，满足 K(x, y)=则称 $K(x, y)$为核函数。可以看出，我们并不需要知道输入空间和特征空间满足的映射关系 ，只需要知道核函数就可以算出，输入空间中任意两点映射到特征空间的内积。]]></content>
  </entry>
  <entry>
    <title><![CDATA[回归树]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%9B%9E%E5%BD%92%E6%A0%91%2F</url>
    <content type="text"><![CDATA[[TOC] 分类树与回归树分类树用于分类问题。分类决策树在选取划分点，用信息熵、信息增益、或者信息增益率、或者基尼系数为标准。Classification tree analysis is when the predicted outcome is the class to which the data belongs. 回归决策树用于处理输出为连续型的数据。回归决策树在选取划分点，就希望划分的两个分支的误差越小越好。 Regression tree analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient’s length of stay in a hospital)。 回归树英文名字：Regression Tree 原理介绍决策树最直观的理解其实就是，输入特征空间($R^n$)，然后对特征空间做划分，每一个划分属于同一类或者对于一个输出的预测值。那么这个算法需要解决的问题是1. 如何决策边界(划分点)？2. 尽可能少的比较次数(决策树的形状) 如上图，每一个非叶子对于某个特征的划分。 最小二乘回归树生成算法Q1: 选择划分点？遍历所有的特征($n$),对于每一个特征对应$s_i$个取值，尝试完所有特征，以及特征所以有划分，选择使得损失函数最小的那组特征以及特征的划分取值。 Q2: 叶节点的输出？取每个区域所以结果的平均数作为输出 节点的损失函数的形式 \min _{j, s}\left[\min _{c_{1}} Loss(y_i,c_1)+\min _{c_{2}} Loss(y_i,c_2)\right]节点有两条分支，$c1$是左节点的平均值，$c2$是右节点的平均值，换句话说，分一次划分都是使得划分出的两个分支的误差和最小。最终得到函数是分段函数 CART算法输入： 训练数据集 输出：回归树$f(x)$ 选择最优的特征$j$和分切点$s$ \min _{j, s}\left[\min _{c_{1}} \sum_{x_{i} \in R_{1}(j, s)}\left(y_{i}-c_{1}\right)^{2}+\min _{c_{2}} \sum_{x_{i} \in R_{2}(j, s)}\left(y_{i}-c_{2}\right)^{2}\right] 对于选定的$(j,s)$划分区域，并确定该区域的预测值 对两个区域递归1. 2. 直到满足停止条件 返回生成树 注：分切点选择：先排序，二分。 Python代码节点类属性：左右节点、loss、特征编号或者特征、分割点 12345678class Node(object): def __init__(self, score=None): # 构造函数 self.score = score self.left = None self.right = None self.feature = None self.split = None 回归树类构造方法 1234class RegressionTree(object): def __init__(self): self.root = Node() self.height = 0 给定特征、划分点，返回计算MAPE 12345678910111213141516def _get_split_mse(self, X, y, idx, feature, split): ''' X:训练样本输入 y:训练样本输出 idx:该分支对应的样本编号 feaure: 特征 split: 划分点 ''' split_x1=X[X[idex,feature]&lt;split] split_y1=y[X[idex,feature]&lt;split] split_x2=X[X[idex,feature]&gt;=split] split_y2=y[X[idex,feature]&gt;=split] split_avg = [np.mean(split_y1), np.mean(split_y2)] split_mape = [np.sum((split_y1-split_avg[0])**2),np.sum((split_y2-split_avg[1])**2)] return split_mse, split, split_avg 计算给定特征的最佳分割点 遍历特征某一列的所有的不重复的点，找出MAPE最小的点作为最佳分割点。如果特征中没有不重复的元素则返回None。 12345678910def _choose_split_point(self, X, y, idx, feature): feature_x = X[idx,feature] uniques = np.unique(feature_x) if len(uniques)==1: return Noe mape, split, split_avg = min( (self._get_split_mse(X, y, idx, feature, split) for split in unique[1:]), key=lambda x: x[0]) return mape, feature, split, split_avg 选择特征遍历全部特征，计算mape,然后确定特征和对应的切割点，注意如果某个特征的值是一样的，则返回None12345678910111213141516171819def _choose_feature(self, X, y, idx): m = len(X[0]) split_rets = [x for x in map(lambda x: self._choose_split_point( X, y, idx, x), range(m)) if x is not None] if split_rets == []: return None _, feature, split, split_avg = min( split_rets, key=lambda x: x[0]) idx_split = [[], []] while idx: i = idx.pop() xi = X[i][feature] if xi &lt; split: idx_split[0].append(i) else: idx_split[1].append(i) return feature, split, split_avg, idx_split 对应叶子节点，打印相关的信息1234def _expr2literal(self, expr): feature, op, split = expr op = "&gt;=" if op == 1 else "&lt;" return "Feature%d %s %.4f" % (feature, op, split) 建立好二叉树以后，遍历操作12345678910111213141516171819def _get_rules(self): que = [[self.root, []]] self.rules = [] while que: nd, exprs = que.pop(0) if not(nd.left or nd.right): literals = list(map(self._expr2literal, exprs)) self.rules.append([literals, nd.score]) if nd.left: rule_left = [] rule_left.append([nd.feature, -1, nd.split]) que.append([nd.left, rule_left]) if nd.right: rule_right =[] rule_right.append([nd.feature, 1, nd.split]) que.append([nd.right, rule_right]) 建立二叉树的过程，也就是训练的过程 控制深度 控制节叶子节点的最少样本数量 至少有一个特征是不重复的12345678910111213141516171819202122232425def fit(self, X, y, max_depth=5, min_samples_split=2): self.root = Node() que = [[0, self.root, list(range(len(y)))]] while que: depth, nd, idx = que.pop(0) if depth == max_depth: break if len(idx) &lt; min_samples_split or set(map(lambda i: y[i,0], idx)) == 1: continue feature_rets = self._choose_feature(X, y, idx) if feature_rets is None: continue nd.feature, nd.split, split_avg, idx_split = feature_rets nd.left = Node(split_avg[0]) nd.right = Node(split_avg[1]) que.append([depth+1, nd.left, idx_split[0]]) que.append([depth+1, nd.right, idx_split[1]]) self.height = depth self._get_rules() 打印叶子节点12345def print_rules(self): for i, rule in enumerate(self.rules): literals, score = rule print("Rule %d: " % i, ' | '.join( literals) + ' =&gt; split_hat %.4f' % score) 预测单样本 123456789101112def _predict(self, row): nd = self.root while nd.left and nd.right: if row[nd.feature] &lt; nd.split: nd = nd.left else: nd = nd.right return nd.score # 预测多条样本def predict(self, X): return [self._predict(Xi) for Xi in X] 1234567891011121314 def main(): print("Tesing the accuracy of RegressionTree...") X_train=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]) y_train=np.array([[5.56 ],[5.7],[5.91],[6.4 ],[6.8],[7.05],[8.9],[8.7 ],[9 ],[9.05]]) reg = RegressionTree() print(reg) reg.fit(X=X_train, y=y_train, max_depth=3) reg.print_rules()main() 简单的例子训练数据 x 1 2 3 4 5 6 7 8 9 10 y 5.56 5.7 5.91 6.4 6.8 7.05 8.9 8.7 9 9.05 根据上表，只有一个特征$x$. 选择最优的特征$j$和分切点$s$ | 分切点(s) | 1.5 | 2.5 | 3.5 | 4.5 | 5.5 | 6.5 | 7.5 | 8.5 | 9.5 || ————- | ——- | ——- | —— | —— | —— | —— | —— | ——- | ——- || $c_1$ | 5.56 | 5.63 | 5.72 | 5.89 | 6.07 | 6.24 | 6.62 | 6.88 | 7.11 || $c_2$ | 7.5 | 7.73 | 7.99 | 8.25 | 8.54 | 8.91 | 8.92 | 9.03 | 9.05 || loss | 15.72 | 12.07 | 8.36 | 5.78 | 3.91 | 1.93 | 8.01 | 11.73 | 15.74 | 当分切点取$s=6.5$,损失最小$l(s=6.5)=1.93$,此时划分出两个分支，分别是$R_1=\{1,2,3,4,5,6\}$,$c_1=6.42$,$R_2=\{7,8,9,10\}$,$c_2=8.91$ a) 对R1继续划分 | x | 1 | 2 | 3 | 4 | 5 | 6 || —— | —— | —— | —— | —— | —— | —— || y | 5.56 | 5.7 | 5.91 | 6.4 | 6.8 | 7.05 | | 分切点(s) | 1.5 | 2.5 | 3.5 | 4.5 | 5.5 || ————- | ——— | ——- | ——— | ——— | ——— || $c_1$ | 5.56 | 5.63 | 5.72 | 5.89 | 6.07 || $c_2$ | 6.37 | 6.54 | 6.75 | 6.93 | 7.05 || loss | 1.3087 | 0.754 | 0.2771 | 0.4368 | 1.0644 | 当分切点取$s=3.5$,损失函数$l(s=3.6)=0.2771$(假设此时满足停止条件）,此时得到两个分支，分别是$R_1=\{1,2,3\}$，$c_1=5.72$,$R_2={4,,5,6}$,$c_2=6.75$ b) 对R2继续划分 | x | 7 | 8 | 9 | 10 || —— | —— | —— | —— | —— || y | 8.9 | 8.7 | 9 | 9.05 | | 分切点(s) | 7.5 | 8.5 | 9.5 || ————- | ——— | ——— | ——— || $c_1$ | 8.9 | 8.8 | 8.87 || $c_2$ | 8.92 | 9.03 | 9.05 || loss | 0.0717 | 0.0213 | 0.0467 | 当分切点取$s=8.5$,损失函数$l(s=8,5)=0.0213$(假设此时满足停止条件）,此时得到两个分支，分别是$R_1=\{7,8\}$，$c_1=8.8$,$R_2=\{9,10\}$,$c_2=9.03$ 函数表达式 $$ \begin{equation} f(x)=\left\{ \begin{aligned} 5.72 &amp; &amp; x&lt;3.5\\ 6.7 5&amp; &amp;3.5&lt;=x&lt;6.5\\ 8.8&amp; &amp;6.5&lt;=x&lt;8.5\\ 9.03&amp; &amp;8.5&lt;=x&lt;10\\ \end{aligned} \right. \end{equation} $$ Python库1class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False) 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-"""Created on Wed Mar 13 19:59:53 2019@author: 23230"""import numpy as npfrom sklearn.tree import DecisionTreeRegressorimport matplotlib.pyplot as pltX=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])y=np.array([[5.56 ],[5.7],[5.91],[6.4],[6.8],[7.05],[8.9],[8.7],[9 ],[9.05]])# Fit regression modelregr_1 = DecisionTreeRegressor(max_depth=2)regr_2 = DecisionTreeRegressor(max_depth=3)regr_3 = DecisionTreeRegressor(max_depth=4)regr_1.fit(X, y)regr_2.fit(X, y)regr_3.fit(X, y)X_test = np.copy(X)y_1 = regr_1.predict(X_test)y_2 = regr_2.predict(X_test)y_3 = regr_3.predict(X_test) # Plot the resultsplt.figure()plt.scatter(X, y, s=20, edgecolor="black",c="darkorange", label="data")plt.plot(X_test, y_1, color="cornflowerblue",label="max_depth=2", linewidth=2)plt.plot(X_test, y_2, color="yellowgreen", label="max_depth=4", linewidth=2)plt.plot(X_test, y_3, color="r", label="max_depth=8", linewidth=2)plt.xlabel("data")plt.ylabel("target")plt.title("Decision Tree Regression")plt.legend()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP算法]]></title>
    <url>%2F2019%2F03%2F05%2FBP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[TOC] 1. 需要的微积分知识1.1 导数对于一元函数，在导数存在的情况下，在某一点的导数，也就是该点的斜率。对于多元函数，对于某一点求导，则需要指明方向，两个特殊的方向，1. 偏导：在坐标轴方向的导数 2. 梯度的方向:总有一个方向是变化最快的。 1.2 求导的链式法则 $x \in R$, $z=g(f(x))$, $y=f(x)$ \frac{\partial z}{\partial x}=\frac{\partial z}{\partial y} \frac{\partial y}{\partial x} $ x \in R^m $, $f(x)$是$R^M$到$R^n$的映射，$g(f)$是$R^n$到R的映射 \frac{\partial g}{\partial x_i}=\sum_j^n \frac{\partial g}{\partial f_i} \frac{\partial f_i}{\partial x_i} 如果使用向量表示 \nabla_x^z=(\frac{\partial f}{\partial x})^T \nabla_y^z2. 梯度下降法2.1 梯度梯度其实本质也是一个向量，对于函数$f(X,y)$在$(W,y)$这一点的梯度 $(\frac{\partial f}{\partial X},\frac{\partial f}{\partial y})$梯度的几何意义：在该店变化增加最快的地方 2.2 梯度算法的解释图来自吴恩达的机器学习课程颜色偏红(A)的地方开始，根据梯度的负方向通过9次更新，达到了最小值(B)。现在给定一个点$A(\theta_0,\theta_1)$,干嘛呢，我们想从A到B点（最小值点),类似人类下山，需要知道往那个方向吧、走大多一步呢？方向：梯度的负方向 $ \delta=(\frac{\partial L}{\partial \theta_0},\frac{\partial L}{\partial \theta_1})$)步长：学习率（$\alpha$)因此，计算一次里目标更近了 $(\theta_0,\theta_1)=(\theta_0,\theta_1)-\alpha \dot (\delta)$在重复上两步，直到满意为止。 3.误差反向传播算法3.1 理论推导 3.1.1 符号说明上图是一个L层的神经网络，输入层为第一层，隐藏层：2至$L-1$层，输出层L 令 输入向量 $\vec{X}$ \vec{X} = (x_1,x_2,...,x_{m-1},x_m)输出向量 $\vec{Y}$ \vec{Y}=(y_1,y_2,...,y_{n-1},y_n)$$a 第j层隐藏层的输出向量 $\vec{h^{(j)}}$ $$\vec{h^{(j)}}=(h_1^{(j)},h_2^,...,h_{t-1}^{(j)},h_tj^{(j)})其中，$tj$:表示第j的隐藏层个数第$(l-1)$层的第i个神经元到第$l$层的第j个神经元的连接权重：$w_{ij}^{(l)}$，则第$(l-1)$层神经元到第$l$层神经元的连接权重矩阵 W^{(l)}=\left( \begin{matrix}w_{11}^{(l)}& \cdots & w_{1(tj)}\\ & \dots &\\ w_{s(l-1)}^{l}&\cdots&w_{s(l-1)s(l)}^{l} \end{matrix}\right)3.1.2 推导过程3.1.2.1 误差定义的误差函数,常见的衡量性指标见 戳我,这里选择的误差平方和最小第$i$个输出的误差,假设实际输出$(d(1),d(2),…,d(n))$：,一个输入样本对应的误差 E(i)=\frac{1}{2}\sum_{k=1}^n(y(i)-d(i))^2=\frac{1}{2}||y-d||^2所有训练样本($N$)的误差： E(i)=\frac{1}{2}\sum_{j=1}^{N}(\sum_{k=1}^n(y(i)-d(i))^2)=\frac{1}{2N}\sum_{j=1}^{N}(||y(i)-d(i)||^2)因此， E = \frac{1}{2N}\sum_{i=1}^N(||y(i)-d(i)||^2)其实，神经网络的输出是关于节点的复合函数。代价函数是关于$W$和$b$的函数。 3.1.2.2 正向传播输入层$\hat{X}$： X =(x_1,x_2,x_3,...,x_m)当有$N$个训练样本时，可用矩阵表示 X=\left( \begin{matrix} x_{11} &x_{12}&...&x_{1m}\\ x_{21} & x_{22}&...&x_{2m}\\ \vdots & \vdots&\dots&\vdots\\ x_{N1} & \vdots&\vdots&x_{Nm}\\ \end{matrix} \right)第二层 $h^{(2)}$,一共$s2$个节点:第i个节点的计算 h^{(2)}(i)=f(\sum_{j=1}^{s2}x(j)*w_{ji}^{(l)}+b_i)=f(x*w(:,i)+b_i)矩阵表示 h^{(2)}=f(x*W^{(l)}+b^{(2)})第i层 矩阵形式 h^{(l)}=f(h^{(l-1)}*W^{(l)}+b)3.1.2.3 反向传播梯度下降法更新权重，不断迭代到最优解。对$w_{ij}$求导数可得,可更新$w_{ij}$更新公式： w_{ij}=w_{ij}-\alpha \frac{\partial E}{\partial w_{ij}}当然简单的情况下，可直接写出公式，当太复杂的时候，引入BP简化求导 方便书写公式，对于第i的输入$h^{(i-1)}*W^{(i)}+b^{(i)}$记作$net^{(i)}$,其中，第$i$的输入和输出的关系，$输入=f(输出)$下面开始推导 首先，对于$L$层， 对于$W^{(L)}$，先看对$W_{ij}^{(L)}$求导， \frac{\partial E}{\partial W_{ij}^{(L)}} =\frac{\partial E}{\partial y(j)} * \frac{\partial y(i)}{\partial net_{j}^{L}} * \frac{\partial net_{j}^{L}}{\partial W_{ij}^{(L)}}\\ =(y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}h_i^{(L-1)}令$\delta_i^{(L)}=y(i)-d(i)$ 上述给出了单个分量的求偏导的结果，对于$W^{(L)}$ \frac{\partial E}{\partial W^{(L)}} =\left[\begin{matrix} \frac{\partial E}{\partial W_{11}^{(L)}} & \frac{\partial E}{\partial W_{12}^{(L)}}&\dots & \frac{\partial E}{\partial W_{1n}^{(L)}}\\ \frac{\partial E}{\partial W_{21}^{(L)}} & \frac{\partial E}{\partial W_{22}^{(L)}}&\dots& \frac{\partial E}{\partial W_{2n}^{(L)}}\\ \vdots& \dots& \dots& \dots\\ \frac{\partial E}{\partial W_{sL,1}^{(L)}} & \frac{\partial E}{\partial W_{sL,2}^{(L)}}&\dots& \frac{\partial E}{\partial W_{sL,n}^{(L)}} \end{matrix}\right] \\= \left[ \begin{matrix} h^{(L-1)}_1\\h^{(L-1)}_2\\ \dots\\h^{(L-1)}_n \end{matrix} \right] *\left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right] ^T =h^{(L-1)}S^{(L)}其中， S^{(L)}=\left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right]^T同理可得， \frac{\partial E}{\partial b_k^{(L)}}=(y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}其次，对于隐含层$L-1$层，对$W_{ij}^{(L)}$求导 \frac{\partial E}{\partial W_{ij}^{(L-1)}} =\sum_{k=1}^{n}\frac{\partial E}{\partial y(k)} * \frac{\partial y(k)}{\partial net_{k}^{L}} * \frac{\partial net_{k}^{L}}{\partial f(net_j^{(L-1)})}*\frac{\partial f(net_j^{(L-1)})}{\partial net_j^{(L-1)}}*\frac{\partial net_j^{(L-1)}}{\partial W_{ij}^{(L-1)}}\\ =\sum_{k=1}^{n} (y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}W_{kj}^{(L)}f(x)^{'}|_{x=net_j^{L-1}}h_i^{L-2}\\ =\sum_{k=1}^{n}S_i^{(L)}W_{kj}^{(L)}f(x)^{'}|_{x=net_j^{L-1}}h_i^{L-2}\\写出矩阵形式,对$W^{(L-1)}$ \frac{\partial E}{\partial W^{(L-1)}}=\left[\begin{matrix} h^{(L-2)}_1\\h^{(L-2)}_2\\\vdots\\h^{(L-2)}_{s(L-2)}\end{matrix}\right] \left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right]^T \left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)} \end{matrix}\right]^T \\ \left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\\ =h^{(L-2)}S^{(L-1)} S^{(L-1)}=\left(\left[\begin{matrix} f(x)^{'(L)}|_{x=net_1^{(L)}}&0& \dots& 0\\ 0&f(x)^{'}|_{x=net_2^{(L)}}0& \dots& 0\\ 0&\dots&\dots&0\\ 0&0&0&f(x)^{'(L)}|_{x=net_n^{(L)}} \end{matrix}\right]\left[\begin{matrix} \delta_1^{(L)}\\\delta_2^{(L)}\\\vdots\\\delta_n^{(L)}\end{matrix}\right] \right)^T\\ \left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T \left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\\ =S^{(L)}\left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T\left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]*\\对$1&lt;l&lt;L$,求$W^{(l)}$的偏导, 最后，根据上述的推导喔，很容易得出$S^{(l)}$和$S^{(l+1)}$, S^{(l)}=S^{(l+1)}W^{(l+1)^T}F^{'(l)}(net^{(l)})\\ S^{(L)}=(Y-\hat{Y})F^{'(L)}(net^{(L)}) \frac{\partial E}{\part W^{(l)}}=\left[\begin{matrix}h^{(l-1)}_1\\h^{(l-1)}_2 \\\dots \\h^{(l-1)}_{sl}\end{matrix}\right]S^{(l+1)} \left[\begin{matrix}W_{11}^{(l+1)}&W_{12}^{(l+1)} &\dots& W_{2(sl+1)}^{(l+1)}\\ W_{21}^{(l+1)}&W_{22}^{(l+1)} &\dots& W_{2(sl+1)}^{(l+1)}\\ \dots&\dots&\dots&\dots\\ W_{sl1}^{(l+1)}&W_{sl2}^{(l+1)} &\dots& W_{sl(sl+1)}^{(l+1)}\\ \end{matrix} \right]^T\left[\begin{matrix} \part f^{'(l)}(net_1^{l})&0&\dots & 0\\ 0\\0 &\part f^{'(l)}(net_2^{l})&\dots&0\\ 0 & 0&\dots&0\\ 0&0&\dots&\part f^{'(l)}(net_l^{l})\end{matrix}\right]3.2 BP算法的小结算法分为两个阶段：前向阶段和后向传播阶段 后向阶段算法： Step 1: 计算$\hat{y}^{(L)}$ Step 2: for l =L:2 ​ 计算$S^{(l)}=S^{(l+1)}W^{(l+1)}F’(net^{(l)})$ ​ 计算 $\Delta W^{(l)}=h^{(l-1)}S^{(l)} $ ​ 计算$W^{(l)}=W^{(l)}-\delta \Delta W^{(l)}$ 3.3 Python实现3.3.1 最简单三层网络1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071'''不用任何框架，自己写一个三层的神经网络# input-3,hidden-4 output-1'''import numpy as npnp.random.seed(1)# Input MatrixX = np.array([[0, 0, 1], [0, 1, 1], [1, 0 ,1], [1, 1, 1],])# Output Matrixy = np.array([[0], [1], [1], [0]])# Nonlinear functiondef sigmoid(X,derive=False): if not derive: return 1 / (1 + np.exp(-X)) else: return X*(1-X)# reludef relu(X,derive = False): if not derive: return np.maximum(0,X) else: return (X&gt;0).astype(float) # Weight biasW1 = 2 * np.random.random((3, 4))-1b1 = 0.1 * np.ones((4,)) W2 = 2 * np.random.random((4,1))-1b2 = 0.1 * np.ones((1,)) rate = 0.1noline = relu# Trainingtrain_times = 200 for time in range(train_times): # Layer one A1 = np.dot(X,W1)+b1 Z1 = noline(A1) # Layer two A2 = np.dot(Z1, W2)+b2 Z2 = noline(A2) cost = -y+Z2 # Calc deltas S2= cost*noline(A2,True) delta_W2 = np.dot(Z1.T,S2) bias2 = S2.sum(axis=0) S1 = np.dot(S2, W2.T)*noline(A1,True) delta_W1= np.dot(X.T, S1) bias1 = S1.sum(axis=0) # update W1 = W1-rate*delta_W1 b1 = b1-rate*bias1 W2 = W2-rate*delta_W2 b2 = b2-rate*bias2 print('error',np.mean(((y-Z2)*(y-Z2))**2))print("prediction",Z2) 3.4 附录： Name Abbreviation Mean absolute percentage error MAPE Root mean squares percentage error RMSPE Mean absolute percentage error MAE Mean squares error MSE Index of agreement IA Theil U statistic 1 U1 Theil U statistic 2 U2 Correlation coefficient R MAPE = $\frac{1}{n} \sum_{k=1}^{n}\left|\frac{x^{(0)}(k)-\hat{x}^{(0)}(k)}{x^{(0)}(k)}\right| \times 100$RMSPE = $\sqrt{\frac{1}{n} \sum_{k=1}^{n}\left(\frac{\hat{x}^{(0)}(k)-x^{(0)}(k)}{x^{(0)}(k)}\right)^{2}} \times 100$MAE = $\frac{1}{n} \sum_{k=1}^{n}\left|\hat{x}^{(0)}(k)-x^{(0)}(k)\right|$MSE = $\frac{1}{n} \sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}$IA = $1-\frac{\sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}}{\sum_{k=1}^{n} \left( \left| \hat{x}^{(0)}(k)-\overline{x} \right|+\left| x^{(0)}(k)-\overline{x}\right| \right)^{2}}$U1 = $\frac{\sqrt{\frac{1}{n} \sum_{k=1}^{n}\left(x^{(0)}(k)-x^{(0)}(k)\right)^{2}}}{\sqrt{\frac{1}{n} \sum_{k=1}^{n} x^{(0)}(k)^{2}}+\sqrt{\frac{1}{n} \sum_{k=1}^{n} x^{(0)}(k)^{2}}}$U2 = $\frac{\left[\sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}\right]^{1 / 2}}{\left[\sum_{k=1}^{n} x^{(0)}(k)^{2}\right]^{1 / 2}}$R = $\frac{\operatorname{Cov}(\hat{x}^{(0)}, x^{(0)})}{\sqrt{\operatorname{Var}[\hat{x}^{(0)}] \operatorname{Var}[x^{(0)}]}}$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>BP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[主要是分享决策的基本知识点，重点在分类决策树上，对于回归的决策树后面在给出。希望大家和我一起做知识的传播者啦！:smile: :smiley: :grin: :open_mouth: [TOC] 决策树英文名字：Descision Tree 什么是决策树举个校园相亲的例子，今天校园的小猫(女)和小狗(男)准备配对，小猫如何才能在众多的优质🐶的心仪的狗呢？于是呢？有一只特乖巧的小猫找到了你，你正在学习机器学习，刚好学习了决策树，准备给这只猫猫挑选优质狗，当然，你不仅仅是直接告诉猫哪些狗是合适你的？你更应该详细的给猫讲解决策树是如何根据它提出的标准选出的符合要求的狗呢？猫给出如下信息：年龄=0.5 6.5&lt;=体重&lt;=8.5;心仪; 年龄&gt;=0.5 体重&gt;8.5 长相好 心仪;其余情况不心仪; 根据上述条件可以构造一颗树：上面的图就是决策树，最终的结果是心仪或者不心仪。决策树算法以树形结构表示数据分类的结果 基本概念决策树属于也只能非参数学习算法、可以用于解决(多)分类问题，回归问题。 回归问题的结果，叶子结点的平均值是回归问题的解。根节点：决策树具有数据结构里面的二叉树、树的全部属性非叶子节点 ：（决策点） 代表测试的条件，数据的属性的测试叶子节点 ：分类后获得分类标记分支： 测试的结果 数学问题-熵-Gini系数什么是熵：熵的概念源于物理学，用于度量一个热力学系统的无序程度。信息熵：不得不提香农这个大写的人啦！信息论里面的知识。在信息论里面，信息熵衡量信息量的大小，也就是对随机变量不确定度的一个衡量。熵越大，不确定性越大；对于某个单符号无记忆信源，发出符号($x_i$)的概率是$p_i$,概率越大，符号的信息量就越小，香农公式 $I(x_i)=-log_{p_i}$。信源所含的信息熵就是信息量的期望]$H(x)=-\sum p_i*log_{p_i}$Gini系数： $Gimi(p) = 1-\sum_{k=1}^{K}p_k^2$ 决策树如何构建的问题自我提问阶段： 每个节点的位置如何确定？特征的选择：每次选入的特征作为分裂的标准，都是使得决策树在这个节点的根据你自己选择的标准（信息熵最小、信息增益最大、gini系数最小）. 每个节点在哪个值上做划分，确定分支结构呢？遍历划分的节点的分界值操作来解决这个问题 可以想象，我们构造的决策树足够庞大，决策树可以把每一个样本都分对，那么决策树的泛化能力就可以很差了为了解决这个问题，就需要剪枝操作了 训练算法基于信息熵的构造当选择某个特征作为节点时，我们就希望这个特征的信息熵越小越好，那么不确定性越小。计算特征的信息熵公式如下： H(x) = -p_i(x)log^{p_i(x)} = -\frac{n_j}{S}log^{\frac{n_j}{S}}$n_j$: 第j个类别，在样本中出现的频数$S$: 样本个数对于离散属性，直接计算信息熵，连续属性，就需要划分区间，按区间计算信息熵。 基于某一层的数据集 a. 遍历计算所有属性，遍历相应属性以不同值为分截点的信息熵 b. 选择信息熵最小的作为节点 如果到达终止条件，返回相应信息，否则，按照分支重复步骤1ID3算法： 信息增益最大化C:类别H(C)=-\sum_{i=1}^{m}p_i log _2^{p_i}按照D组划分CH(C/D)=\sum_{i=1}^{v}\frac{|C_i|}{|C|}H(C_i)信息增益gain(D) = gain(C)-H(C/D)这里我就以网上给出的数据为例，给出根据信息熵构成决策树的计算过程。 确定特征，统计属性值和分解结果，总共四个特征，四种特征的统计结果如下图： 根据历史数据，在不知到任何情况下，计算数据本身的熵为 - \frac{9}{14}log_2 \frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940 计算每个特征做为节点的信息熵以天气为例，天气三种属性，当Outlook = sunny时，H(x) = $-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}$; 当Outlook= overcast,$H(x)=0$,当Outlook = rainy ,$H(x) = 0.971$所以，当选天气作为节点时，此时$H(x)=\frac{5}{14}0.971+\frac{4}{14}0+\frac{5}{14}*0.971 = 0.693$,gain(天气) = 0.247同理，可得gain(温度) =0.029 gain(湿度)=0.152，gain(风)=0.048因此选择天气节点，在递归实现其他节点的选择。信息增益的方法偏向选择具有大量值的属性，也就是说某个属性特征索取的不同值越多，那么越有可能作为分裂属性，这样是不合理的； C4.5: 信息增益率如果这里考虑了一列ID,每个ID出现一次，所以算出的信息增益大。$ H(x) = 0$,信息增益最大化了，可以引入信息增益率 C(T) = \frac{信息增益}{H(T)} =\frac{H(C)-H(C/T)}{H(T)}CART:基尼(Gini)系数G = 1-\sum_{i=l_k}^{k}p_i^2$$,也是对随机变量不确定性的一个衡量，gini越大，不确定性越大 ### 连续属性的处理方法 选取分解点的问题： 分成不同的区间（二分、三分....)，分别计算增益值，然后比较选择。 将需要处理的样本（对应根节点）或样本子集（对应子树）按照连续变量的大小从小到大进行排序 假设该属性对应不同的属性值共N个，那么总共有N-1个可能的候选分割值点，每个候选的分割阈值点的值为上述排序后的属性值中两两前后连续元素的中点 ## 评价 评价函数： $$C(T) = \sum_{releaf} N_t*H(T)$ N_t$：每个叶子节点里面含有的样本个数$H(T)$:叶子节点含有的信息熵 过拟合如果决策树过于庞大，分支太多，可能造成过拟合。对应训练样本都尽可能的分对，也许样本本身就存在异常点呢？I. 预剪枝：边构建，边剪枝 指定深度d 节点的min_sample 节点熵值或者gini值小于阙值熵和基尼值的大小表示数据的复杂程度，当熵或者基尼值过小时，表示数据的纯度比较大，如果熵或者基尼值小于一定程度数，节点停止分裂。 当所以特征都用完了 指定节点个数当节点的数据量小于一个指定的数量时，不继续分裂。两个原因：一是数据量较少时，再做分裂容易强化噪声数据的作用；二是降低树生长的复杂性。提前结束分裂一定程度上有利于降低过拟合的影响。 II. 后剪枝： 构建好后，然后才开始裁剪 C_\alpha(T) = C(T)+\alpha|T_{leaf}|在构造含一棵树后，选一些节点做计算，看是否需要剪枝 决策树单个节点选择的代码实现简单实现了单个节点决策构造过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def split(X,y,d,value):'''在d纬度上，按照value进行划分''' index_a =(X[:,d]&lt;=value) index_b =(X[:,d]&gt;value) return X[index_a],X[index_b],y[index_a],y[index_b]from collections import Counterfrom math import log from numpy as npdef entropy(y): counter = Counter(y) # 字典 res = 0.0 for num in counter.values(): p = num/len(y) res+=-p*log(p) return resdef gain(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) e = len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return (entropy(y)-e)def gainratio(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) gain =entropy(y) - len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return gain/(entropy(y_l)+entropy(y_r))def gini(y): counter = Counter(y) res = 1.0 for num in counter.values(): p = num / len(y) res += -p**2 return res #X_l,X_r,y_l,y_r = split(X,y,d,v) #return 1-(len(y_l)/len(y))**2-(len(y_r)/len(y))**2def try_split(X,y): best_entropy = float('inf') best_d,best_v=-1,-1 for d in range(X.shape[1]): sorted_index = np.argsort(X[:,d]) for i in range(1, len(X)): if (X[sorted_index[i],d] != X[sorted_index[i-1],d]): v = (X[sorted_index[i-1],d]+X[sorted_index[i],d])/2 X_l,X_r,y_l,y_r = split(X,y,d,v) # 信息熵 e = entropy(y_l)+entropy(y_r) #gini e = gini(y_l) + gini(y_r) # 信息增益 e = -gain(X,y,d,v) if e &lt; best_entropy: best_entropy, best_d,best_v = e,d,v return best_entropy, best_d, best_v# 手动来划分data =np.array([[ 0.3 , 5 , 2 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.5 , 6.5 , 1 , 1 ],[ 0.6 , 6 , 0 , 0 ],[ 0.7 , 9 , 2 , 1 ],[ 0.5 , 7 , 1 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.6 , 8.5 , 0 , 1 ],[ 0.3 , 5.5 , 2 , 0 ],[ 0.9 , 10 , 0 , 1 ],[ 1 , 12 , 1 , 0 ],[ 0.6 , 9 , 1 , 0 ],])X =data[:,0:3]y = data[:,-1]# 手动来划分best_entropy, best_d, best_v = try_split(X, y)print(best_entropy, best_d, best_v)X1_l, X1_r, y1_l, y1_r = split(X,y,best_d,best_v)print(X1_l, X1_r, y1_l, y1_r)best_entropy2, best_d2, best_v2 = try_split(X1_r, y1_r)X2_l, X2_r, y2_l, y2_r = split(X1_r,y1_r,best_d2,best_v2)entropy(y2_l) Python sklean里面tree模块里面的DecisionTreeClassifier1234from sklearn import treeclf =tree.DecisionTreeClassifier(max_depth=1,criterion ='gini') # criterion='entropy|gini'clf = clf.fit(X,y) 训练好一颗决策树之后，我们可以使用export_graphviz导出器以Graphviz格式导出树。1234import graphviz dot_data = tree.export_graphviz(clf, out_file=None,) graph = graphviz.Source(dot_data) graph.render("data") 在运行时可以出错：ExecutableNotFound: failed to execute [‘dot’, ‘-Tpdf’, ‘-O’, ‘data’], make sure the Graphviz executables are on your systems’ PATH原因：graphviz本身是一个软件，需要额外下载，并将其bin加入环境变量之中。下载]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的读书笔记]]></title>
    <url>%2F2019%2F02%2F28%2FSVD%2F</url>
    <content type="text"><![CDATA[目录 :smile::one: 简单说一下特征值、特征向量与特征分解&nbsp;&nbsp; I. 特征值、特征向量与特征分解&nbsp;&nbsp; II. 几何意义&nbsp;&nbsp; III. 如何实现通过Matlab、Python实现:two:详细解说SVD&nbsp;&nbsp; I. 几何意义&nbsp;&nbsp; I. 奇异值分解的推导过程&nbsp;&nbsp; I. SVD算例&nbsp;&nbsp; I. 如何通过Matlab和Python:three:应用举例&nbsp;&nbsp; I. 特征值、特征向量与特征分解:four:特征分解、奇异值分解的区别&nbsp;&nbsp; I. 特征分解、奇异值分解的区别 简单说一下特征值、特征向量与特征分解 特征值、特征向量与特征分解Theory:对于一个正阵$M$，满足如下： Mx=\lambda x其中$\lambda$被成为特征值，满足$||M-\lambda E||=0$再有$(M-\lambda E)x=0$，可计算其特征向量。如果有了特征值和特征向量后呢，则可以将矩阵$M$用特征分解： M=W\sum W^{-1}$W={w_1,w_2,…,w_n}$分别是特征值$\lambda_1,\lambda_2,…,\lambda_n$对应的特征向量构成的方阵 几何意义 对应矩阵M,其对应的线性变化 Mx = x'上面这个式子，$Mx，x’$是一个向量，$x,x’$可能是不共线的(如图(b))，如果向量$Mx,x’$满足$Mx=x’=\lambda x$,则如图(b)，这说明了这个变换就是对向量x做一个拉伸或者压缩。 如何实现通过Matlab、Python实现数学推导： Mx = \lambda xMx-\lambda x=(M-\lambda E)x=0齐次线性方程组有非零解，则$||M-\lambda E||=0$可求得特征向量再带回，可得特征向量。Matlab:123d = eig(M) % 求取矩阵M的特征值，向量形式存储[V,D] = eig(M) % 计算M的特征值对角阵D和特征向量V，使得MV = VD成立[V,D] = eig(M,'nobalance') %当矩阵M中有与截断误差数量级相差不远的值时，该指令可能更精确。'nobalance'起误差调节作用 Pythonnumpy科学计算库提供相应的方法1234import numpy as npx = np.diag((1,2,3)) # 这是你想要求取特征值的数组a,b = numpy.linalg.elg(x) # 特征值赋值给a,对应的特征向量赋值给b 详细解说SVDSVD的英文全称： Singular Value Decomposition，中文名字：奇异值分解 几何意义图来源以二维空间为例几何意义就是把一个单位正交的网格，转换为另外一个单位正交的网格 假如选取了一组单位正交基{$\vec{v}_1$,$\vec{v}_2$},刚好矩阵$M$的线性变化$M\vec{v}_1 $,$M\vec{v}_2 $ 也正交，用$\vec{u}_1,\vec{u}_2 $分别表示$M\vec{v}_1 $,$M\vec{v}_2 $ 的单位向量，用$\lambda_1,\lambda_2 $表示$M\vec{v}_1 $,$M\vec{v}_2$的长度，描述网格在这些特定方向上的拉伸量，也被称作矩阵M的奇异值。$M\vec{v}_1 =\lambda_1\vec{u}_1 $$M\vec{v}_2 =\lambda_2\vec{u}_2 $对任意给定的向量 $\vec{x}$ ,则有 \mathbf{x}=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) \mathbf{v}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) \mathbf{v}_{2} 再将M的线性变换 \begin{aligned} M \mathbf{x} &=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) M \mathbf{N}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) M \mathbf{v}_{2} \\ M \mathbf{x} &=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) \sigma_{1} \mathbf{u}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) \sigma_{2} \mathbf{u}_{2} \end{aligned} \begin{array}{c}{M \mathbf{x}=\mathbf{u}_{1} \sigma_{1} \mathbf{v}_{1}^{\top} \mathbf{x}+\mathbf{u}_{2} \sigma_{2} \mathbf{v}_{2}^{\top} \mathbf{x}} \\ {M=\mathbf{u}_{1} \sigma_{1} \mathbf{v}_{1}^{\top}+\mathbf{u}_{2} \sigma_{2} \mathbf{v}_{2}^{\top}}\end{array} so M=U \Sigma V^{T}奇异值分解的推导过程$u=(u_1,u_2,…,u_m)$$v=(v_1,v_2,…,v_n)$$u,v$都是空间的基,是正交矩阵 $u^Tu=E,v^Tv = E$任何一个矩阵$M_{m*n}$，$rank(M)=k$，一定存在ＳＶＤ,换句话说，M可以将一组单位正交基映射到另一组单位正交基。答案是肯定的证明如下：在n为空间中，有一组单位正交基{$\vec{v}_1,\vec{v}_2,…,\vec{v}_n$},线性变化作用以后 {M\vec{v}_1,M\vec{v}_2,...,M\vec{v}_n}也是正交的，则有 (M\vec{v}_i,M\vec{v}_j) = (M\vec{x}_i)^TM\vec{v}_j=\vec{v}_i^TM^TM\vec{v}_j=0注意喔，$M^TM$是矩阵喔，则会有$M^TM\vec{v}_j=\lambda \vec{v}_j$接下去， \begin{aligned} v_{i}^{T} M^{T} \mathrm{M} v_{j}=& v_{i}^{T} \lambda_{j} v_{j} \\ &=\lambda_{j} v_{i}^{T} v_{j} \\ &=\lambda_{j} v_{i}\dot v_{j}=0 \end{aligned} 上述就证明了是有的：任何一个矩阵，都可以将一组单位正交基转换成另外一组正交基。 当$i=j$,$=\lambda_i \vec{v}_i \vec{v}_i=\lambda_i$ 进行一些单位化，记$u_i=\frac{A\vec{v}_i}{|M\vec{v}_i|}=\frac{1}{\sqrt{\lambda_i}}M\vec{v}_i$则 A v_{i}=\sigma_{i} u_{i}, \sigma_{i}(\operatorname{奇异值})=\sqrt{\lambda_{i}}, 0 \leq i \leq \mathrm{k}, \mathrm{k}=\operatorname{Rank}(\mathrm{A}) 当$k &lt; i &lt;= m$时，对$u1，u2，…，uk$进行扩展$u(k+1),…,um$，使得$u1，u2，…，um$为$m$维空间中的一组正交基.也可对$\vec{v}_1,\vec{v}_2,…,\vec{v}_k$进行扩展，扩展的$\vec{v}_{k+1},…,\vec{v}_{n}$存在零子空间里面。 M\left[ \begin{array}{lll}{\vec{v}_{1}} & {\cdots} & {\vec{v}_{k}}\end{array}\right| \vec{v}_{k+1} \quad \cdots \quad \vec{v}_{m} ]= \left[ \begin{array}{c}{\vec{u}_{1}^{T}} \\ {\vdots} \\ {\frac{\vec{u}_{k}^{T}}{\vec{u}_{k+1}}} \\ {\vdots} \\ {\vec{u}_{n}^{T}}\end{array}\right] \left[ \begin{array}{ccc|c}\sigma_{1} & & 0 & 0\\ & {\ddots} & \sigma_{k} & 0 \\ \hline 0 & & 0 &0\end{array}\right] M=\left[ \begin{array}{lll}{\vec{u}_{1}} & {\cdots} & {\vec{u}_{k}}\end{array}\right] \left [ \begin{array}{ccc}\sigma_{1} & & \\ & {\ddots} & \\ & & {\sigma_{k}}\end{array}\right] \left[ \begin{array}{c}{\vec{v}_{1}^{T}} \\ {\vdots} \\ {\vec{v}_{k}^{T}}\end{array}\right]+ \left[ \begin{array}{ccc}{\vec{u}_{k+1}} & {\cdots} & {\vec{u}_{m}}\end{array}\right] \left[\begin{array}{c} 0 \end{array} \right] \left[ \begin{array}{c}{\vec{v}_{k+1}^{T}} \\ {\vdots} \\ {\vec{v}_{n}^{T}}\end{array}\right]SVD算例U：$AA^T$的特征值和特征向量，用单位化的特征向量构成 UV: $A^TA$ 的特征值和特征向量，用单位化的特征向量构成 V$\sum_{mn} $ :将$ AA^{T} $或者 A^{T}A 的特征值求平方根，然后构成 Σ以矩阵$A = \left[\begin{matrix} 1 &amp; 1\\1 &amp;1\\ 0 &amp;0\\\end{matrix} \right]$第一步 U ，下面是一种计算方法对矩阵 A A^{T}=\left[ \begin{array}{lll}{2} & {2} & {0} \\ {2} & {2} & {0} \\ {0} & {0} & {0}\end{array}\right] 特征分解， 特征是4，0，0 特征向量是 $\left[\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]^{T},\left[-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]^{T},[0,0,1]^{T}$,可得到 U=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} & {0} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}} & {0} \\ {0} & {0} & {1}\end{array}\right] 第二步 计算矩阵$A^TA$的特征分解，可得 特征值4，0， V=\left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}}\end{array}\right]第三步计算$\sum_{mn}$ \Sigma=\left[ \begin{array}{ll}{2} & {0} \\ {0} & {0} \\ {0} & {0}\end{array}\right] 最后， A=U \Sigma V^{T}=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} & {0} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}} & {0} \\ {0} & {0} & {1}\end{array}\right] \left[ \begin{array}{ll}{2} & {0} \\ {0} & {0} \\ {0} & {0}\end{array}\right] \left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}}\end{array}\right]^{T}=\left[ \begin{array}{cc}{1} & {1} \\ {1} & {1} \\ {0} & {0}\end{array}\right]如何通过Matlab和PythonMatlab：1234567891011s = svd(A)[U,S,V] = svd(A)[U,S,V] = svd(A,'econ')[U,S,V] = svd(A,0)input: A 矩阵output: s:奇异值，以列向量形式返回。奇异值是以降序顺序列出的非负实数 S： U:左奇异向量，以矩阵的列形式返回。 V:奇异值，以对角矩阵形式返回。S 的对角元素是以降序排列的非负奇异值。 右奇异向量，以矩阵的列形式返回。 Python123import numpy as npM = np.array([ [1,1,2],[0,0,1]])U,S,V = np.linalg.svd(M) 应用举例应用 2.1 信息检索 2.2 推荐系统 2.3 基于协同过滤的推荐系统 2.4 图像压缩 特征值分解和奇异值分解的区别 特征值分解只能是方阵，而奇异值分解是矩阵就可以 特征值分解只考虑了对矩阵缩放效果，奇异值分解对矩阵有选择、收缩、投影的效果]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python库]]></title>
    <url>%2F2019%2F02%2F24%2Fpython%E5%BA%93%2F</url>
    <content type="text"><![CDATA[开始接触Python是大二结束的时候，到现在都快两年了，其实一直并不是很细节的学习，只是希望能够跑个结果。不过呢？，以后肯定是会经常用Python，所以呢？我接下来会认真学习Python Python 高级用法总结基本数据类型：整型、浮点型、布尔类型 容器： Containers容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用in, not in关键字判断元素是否包含在容器中。通常这类数据结构把所有的元素存储在内存中（也有一些特例，并不是所有的元素都放在内存，比如迭代器和生成器对象）在Python中，常见的容器对象有：list, dequeset, frozensetsdict, defaultdict, OrderedDict, Countertuple, namedtuplestr list推导（list comprehensions)官方解释：列表解析式是Python内置的非常简单却强大的可以用来创建list的生成式。 1对于一个列表，既要遍历索引又要遍历元素。 123array = ['I', 'love', 'Python']for i, element in enumerate(array): array[i] = '%d: %s' % (i, seq[i]) 12345def getitem(index, element): return '%d: %s' % (index, element)array = ['I', 'love', 'Python']arrayIndex = [getitem(index, element) for index, element in enumerate(array)] 迭代器和生成器可迭代对象：凡是可以返回一个迭代器的对象都可称之为可迭代对象例如：list dic str set tuple range() enumerate(枚举) f=open()（文件句柄）123456789### 迭代器(iterator)是一个带状态的对象，他能在你调用next()方法的时候返回容器中的下一个值，任何实现了__iter__和__next__()（python2中实现next()）方法的对象都是迭代器，__iter__返回迭代器自身，__next__返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常### 生成器(generator)生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面的类一样写__iter__()和__next__()方法了，只需要一个yiled关键字。 生成器一定是迭代器（反之不成立）#列表生成式lis = [x*x for x in range(10)]# 受到内存限制，列表容量肯定是有限的#生成器表达式generator_ex = (x*x for x in range(10)) 生成器： 不用创建完整的list，为节省大量的空间，在Python中，这种一边循环一边计算的机制，称为生成器：generatorTuples:() 字典：{：，} Sets: {,}函数类 Python库——numpyWhatNumPy=Numerical+Python主要是提供了高性能多维数组这个对象，以及处理相关的方法 How 自定义一个（1D or MD)数组或者特殊的数组,一维，二维 数组切片（也就是提取数组元素），注意 a[:,0]和a[:,0:1]是不同的喔 关于数组属性的方法 数组运算 索引 where 函数 索引的布尔数组 广播（Broadcasting）用于处理不同性状的 数组。 Broadcasting提供了一种矢量化数组操作的方法，使得循环发生在C而不是Python。标量乘以一个矢量的时候，用Boradcasting更快，因为 broadcasting在乘法期间移动较少的内存 array 和 matrix 选择哪个? 戳我 矢量化和广播、索引在Python中循环数组或任何数据结构时，会涉及很多开销。 NumPy中的向量化操作将内部循环委托给高度优化的C和Fortran函数，从而实现更清晰，更快速的Python代码。 Python库——pandas记得学习pandas是在大三时候的美赛，花了一天多时间学习pandas，然后预处理数据，当时三个队友都是各自的家，是非常愉快的！！！ whatPython Data Analysis Library 三种数据结构序列： Series 1D数据帧： DataFrame 2D面板： Panel &gt;2D 自定义创建 可以通过字段、数据、series、列表 列表传入的时候，主要行列，如果单个列表：列；如果是[[],[]]是按行[] 如果位置不对可转置 创建空 pd.DataFrame() 选择区块 a) Series [] b) DataFrame 列选择 [‘colums的名字’] 行列选择：.loc[列名,行名]名称 .iloc[列索引,行索引]整数 array.value 统计描述 .descibe(include = ‘all’) .head() .tail() .select_dtype(include=[]) .columns .dtype 缺少数据 查看缺失值isnull() notnull() 也可以 做一些统计，sum, any,all 清理缺失值 dropna(axis=0)：axis = 0:index axis=1,columns 填充缺少指 fillna() 标量替换 替换 统计函数 Pandas 函数应用表合理函数应用：pipe()行或列函数应用：apply()元素函数应用：applymap()eg： pd.pipe(lambda x: x*100) 类别变量向量化非数值类型的处理方法 时间序列生成 data_range pandas.date_range(“11:00”, “21:30”, freq=”30min”) 参数1Return a fixed frequency DatetimeIndex. Parametersstartstr or datetime-like, optionalLeft bound for generating dates. endstr or datetime-like, optionalRight bound for generating dates. periodsint, optionalNumber of periods to generate. freqstr or DateOffset, default ‘D’Frequency strings can have multiples, e.g. ‘5H’. See here for a list of frequency aliases. tzstr or tzinfo, optionalTime zone name for returning localized DatetimeIndex, for example ‘Asia/Hong_Kong’. By default, the resulting DatetimeIndex is timezone-naive. normalizebool, default FalseNormalize start/end dates to midnight before generating date range. namestr, default NoneName of the resulting DatetimeIndex. closed{None, ‘left’, ‘right’}, optionalMake the interval closed with respect to the given frequency to the ‘left’, ‘right’, or both sides (None, the default). **kwargsFor compatibility. Has no effect on the result. ReturnsrngDatetimeIndex12345678910111213141516171819202111. DataFrame.stackParameterslevelint, str, list, default -1Level(s) to stack from the column axis onto the index axis, defined as one index or label, or a list of indices or labels.dropnabool, default TrueWhether to drop rows in the resulting Frame/Series with missing values. Stacking a column level onto the index axis can create combinations of index and column values that are missing from the original dataframe. See Examples section.ReturnsDataFrame or SeriesStacked dataframe or series.​```pythondf_single_level_cols weight heightcat 0 1dog 2 3df_single_level_cols.stack()cat weight 0 height 1dog weight 2 height DataFrame.value_connts()返回序列，index=统计值，值：统计个数 Matplotlibmatplotlib.pyplot as plt 窗口：figure: 一个窗口，plt.figure(num=,figsize=(h,w))下面数据都属于当前的figure,有一定的顺序喔 画图：plt.plot(x,y,color=,linewidth=,linestyle,label=) 标注信息： plt.xlim((,)), plt.yxlim((,)),plt.xlabel(),plt.ylabel(),ticks:图像的小标，plt.xticks(),plt.yticks([值1，值2],[r’$值1\ 对应的文字$’,r’值2的文字 \alpha]) 坐标轴：axis gac=’get current axis’ax = plt.gca() # 轴# 获取四个轴ax.spines[‘right|left|top|’].set_color(‘none’)ax.xaxis.set_ticks_position(‘bottom’)ax.spines[‘bottom’].set_position((‘data’,-1)) 图例：legend: a. plt.plot(,label=), plt.legend() b. l1, = plt.plot() plt.legend(handles=[l1,],labels=[,],loc=’best|upper right|’) 注解 annotationa. 点的位置(x0，y0) plt.scatter(). plt.plot([x0,y0],[y0,0],’k—‘,lw=)b . method 1:plt.annotate(r’name’,xy=(,)起始点，xycoords=’data’//基于xy,xytext=(+30,30),textcoords=’offseet points’//文本基于xy,arrowprops=dict(arrowstyle=’-&gt;’箭头,connectionstyle=’arc3,rad=.2’)弧度) Bar 柱状图plt.bar(x,+|-y,facecolor=””,edgecolor,)|# ha horizontal alignment 对齐方式for x,y in zip(x,y): plt.text(x+0,4,y+0.05,’%.2f’%y,ha=’center’,va=’bottom’) 很多自动 subplot(总行，当前行的列，总的按最小分的第几个)subplot(,,)index reset_index:限于DataFrame set_index index scikit-learn官方教程绝对是最好最棒的选择，有简单数学推导、直观立马就能上手的案例，还能提阅读英文的能力喔，实在是一举多得啊！！！！ scikit-learn.org regressionFeature selectionMethod from sklearn.feature_selection import VarianceThresholdsklearn.feature_selection.SelectFromModelclass sklearn.feature_selection.SelectFromModel(estimator, , threshold=None, prefit=False, norm_order=1, max_features=None) seabornseaborn.jointplot(x, y, data=None, kind=’scatter’, stat_func=None, color=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs) Parameters x, ystrings or vectorsData or names of variables in data.dataDataFrame, optionalDataFrame when x and y are variable names.kind{ “scatter” | “reg” | “resid” | “kde” | “hex” }, optionalKind of plot to draw.stat_funccallable or None, optionalDeprecated**colormatplotlib color, optionalColor used for the plot elements.heightnumeric, optionalSize of the figure (it will be square).rationumeric, optionalRatio of joint axes height to marginal axes height.spacenumeric, optionalSpace between the joint and marginal axesdropnabool, optionalIf True, remove observations that are missing from x and y.{x, y}limtwo-tuples, optionalAxis limits to set before plotting.{joint, marginal, annot}_kwsdicts, optionalAdditional keyword arguments for the plot components.kwargs**key, value pairingsAdditional keyword arguments are passed to the function used to draw the plot on the joint Axes, superseding items in the joint_kws dictionary. Returns gridJointGridJointGrid object with the plot on it. http://seaborn.pydata.org/generated/seaborn.JointGrid.html#seaborn.JointGrid g = sns.jointplot(x=”x”, y=”y”, kind = ‘reg’ , space=0,color = ‘g’, data=df11,stat_func=sci.pearsonr) sns.set() sns.axes_style(“darkgrid”) sns.set_context(“paper”) https://blog.mazhangjing.com/2018/03/29/learn_seaborn/ https://blog.csdn.net/weiyudang11/article/details/51549672 123456789101112131415#初始化类g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)g=g.plot_marginals(sns.distplot,kde=False)from scipy import statsg=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)_=g.ax_marg_x.hist(stock.v_ma10,color=&apos;r&apos;,alpha=.6,bins=50)_=g.ax_marg_y.hist(stock.low,color=&apos;y&apos;,orientation=&quot;horizontal&quot;,bins=20)rquare=lambda a,b:stats.pearsonr(a,b)[0]**2g=g.annotate(rquare,template=&apos;&#123;stat&#125;:&#123;val:.2f&#125;&apos;,stat=&apos;$R^2$&apos;,loc=&apos;upper left&apos;,fontsize=12) 颜色和风格设置调色板主要使用以下几个函数设置颜色：color_palette() 能传入任何Matplotlib所有支持的颜色color_palette() 不写参数则默认颜色 current_palette = sns.color_palette() sns.palplot(current_palette) plt.show() set_palette() 设置所有图的颜色 sns.palplot(sns.color_palette(“hls”,8)) plt.show() 颜色的亮度及饱和度l-光度 lightnesss-饱和 saturation sns.palplot(sns.hls_palette(8,l=.7,s=.9)) plt.show() xkcd选取颜色xkcd包含了一套众包努力的针对随机RGB色的命名。产生了954个可以随时通过xkcd_rgb字典中调用的命名颜色 plt.plot([0,1],[0,1],sns.xkcd_rgb[‘pale red’],lw = 3) #lw = 线宽度plt.plot([0,1],[0,2],sns.xkcd_rgb[‘medium green’],lw = 3)plt.plot([0,1],[0,3],sns.xkcd_rgb[‘denim blue’],lw = 3)plt.show() 汇总http://seaborn.pydata.org/api.html# https://github.com/mwaskom/seaborn/blob/master/seaborn/rcmod.py https://xkcd.com/color/rgb/]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的读书笔记]]></title>
    <url>%2F2019%2F02%2F22%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[2019 第十五周三月份至2019.4.9这段时间，才发现我是如此没有自律的人，充分体现了我是人的特性，那就是我是群体动物，苦笑.jpg,苦笑.jpg, en, 最近突然想给自己打上厨娘的身份，如果可以每天花两个小时做饭就好了 愿你被世界温柔的相待 接触的东西越多，越深入，就会发现我是如此的菜，开始有些知识焦虑了，知识那么多~，可是我只有一个头脑啊~ 开始不想写一些特别低俗的博客了，一是觉得浪费时间，二是输出效果太差，引不起特别大的关注，虽然我写博客，完全是站在自己的角度，没有考虑读者的意愿，（滑稽.jpg)。 现在的自己，不是停留在基本的问题上，更应该去探索未知 的知识世界，虽然离这个flag可能还有几年的时间，能够给世界的知识创造一点点价值，哪怕只是一小点点。离这个目标还需要努力啊！！！！！ 我想我应该去记录学习知识的过程，突破更大的更困难的问题。 2019-第四周读书笔记 这周读了一本小说，是张爱玲的《倾城之恋》，原来和电视剧的何晟铭主演《倾城之恋》不是同一个事情啊！ 看了《阿甘正传》，“生活就像一盒巧克力，你永远不知道下一颗是什么味道。“这是阿甘对生活最好的诠释。小时候，有人骑着自行车羞辱他，他只会跑，拼命的跑，只会再公路上跑。长大后，别人骑着车想打他，阿甘还是跑，但是这次阿甘学会了网草坪上跑！就被大学看上，进入运动大学，还通过参加比赛赢得了冠军，然后，阿甘当兵了，再后来，打乒乓球很出色。阿甘似乎做什么都能成功，也许心无旁骛，最笨的方法+时间=收获。 我觉得很心酸的是，当珍妮告诉他有儿子时候，阿甘问，”他聪明吗“？ 2019第四周安排 改论文，改变自己的办事效率喔，拒绝重复工作 编程能力 慢慢的做事情，先慢后快， 生活、学习、交友、文采2019-第三周读书笔记这次读了《极简思维：颠覆传统思维模式的极简法则》作者：S.J斯科特 巴里.达文波特 我们生活充满了各种诱惑、杂乱信息、导致了生活的混乱，产生知识焦虑、年龄危机、人际关系的淡化。作者给我们介绍了许多问题、许多的解决方法，让我们这个信息爆炸的时代可以过的充实些。 每天睡8个小时、还剩下16个小时，在减去2个小时解决个人卫生和饮食，那么还有14个小时，一个星期98个小时。那么98个小时，你投入在哪里呢？ 总的来说，这本书传达的东西，我还是很喜欢的，极简主义者，少不得也多不得！！！！！！！！！！！！！！！ 读《拆掉思维里的墙》摘录 ：我们的生活也由三个支架组成：自我、家庭与团体和职业。这样的支架支撑着我们的灵魂，它在记录我们的生命。我们一直都在调整着三个位置的平稳，使之成为最稳固的联动三脚架。 这句大概是结合我的经历，最具有感悟的。因为一旦走出大学，这三者才开始真正的组成我们的生活。 古典老师，从职业、成功学、爱情、家庭等等不同的案例，给我分析了大多数人会面临的无形的”墙“，给了我们如何拆掉这些墙的方法。但是呢，对于古典老师的爱情观点，我并不是很赞同，因为呢，那些愿意陪你度过余生的人付出的感情，是如此的廉价吗？有的人既可以是白玫瑰，也可以红玫瑰啊！ 2019年第二周安T排每天两个小时阅读论文或者专业书籍的阅读开题报告修改和PPT制作（3h)《拆掉思维里面的墙》（3h)看哈利波特（一集） —-2018年的总结 小小的悔恨与遗憾 大三下，在课堂上，打了半学期的游戏 生活还是不规律，超喜欢深夜逛知乎、刷B站 额头上，不停的冒着痘痘啊 英语单词量在下降ing 运动量在降低喔 很讨厌洗衣服 相比于上一年进步的方面 愿意去承担更多的责任 更乐意去交流 越来越重视健康style 不会随意发泄自己的情绪了 更加认识到自身的优势与劣势了感到愉快的事情 知道自己想要什么，知道自己在做什么 整理完了大学期间所有的东西，往事不堪回首， 但也只能是柳暗花明又一村。 能读研究生了 聊聊2019年的点点期许学习上 多看19场知乎live 阅读10本书籍，书单也有了 在专业学习上，希望有所提升咯生活中 早睡早起身体好 看十部美剧，尽管我最大的兴趣是睡觉 时常更新歌单，不想在一年里面都是相同的旋律 静静静静静静静 合理安排 折星星 番茄闹钟 偶尔听听 TED技术 清理下了github 仓库 重新更新了 github page 多读、多写、多想]]></content>
      <categories>
        <category>读书日常</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MayMay]]></title>
    <url>%2F2019%2F02%2F22%2FMayMay%2F</url>
    <content type="text"><![CDATA[https://www.kaggle.com/dgawlik/house-prices-eda/datahttps://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python]]></content>
      <tags>
        <tag>wan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(周志华)]]></title>
    <url>%2F2019%2F02%2F22%2F%E5%AD%A6%E4%B9%A0%E3%81%AE%E5%8E%86%E7%A8%8B-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E5%91%A8%E5%BF%97%E5%8D%8E%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[阅读目录[TOC] 第一章 What is the machine learning?非常官方的定义： Tom mitchell(1998) Well-posed LearningProblem:A compute program is said to learn from experience E with respect to same task T and some performance measure P,if its performance on T,as measured by P, improves with experience E。（这个我莫法翻译喔）大概意思是强大的计算机能够事先地完成人为非显示编程好的任务，怎么完成呢？对于某个任务T,给定一个性能度量方法P,在经验E的影响下，如果P对T的测量结果得到了改进，则说明该程序从E中学习了机器学习的过程大致如此：让计算机从数据中产生模型(model)，首先提供经验数据，给定学习算法(learning algorithm)和性能测量方法，它就能根据数据产生模型。模型： 泛指从数据中学得的结果模式： 局部性的结果 基本术语数据集: data set样本： sample属性（特征）： attribute（feature)属性值： attribute value属性空间（特征空间）： attribute space （ sample space）特征向量： feature vector学习（训练）：learning（training）训练数据： training data训练集： training set假设：hypothesis 学得模型对应了关于数据的某种潜在规律泛函能力: generalization 假设空间归纳（induction）： 从特殊到一般的“泛化”(generalization)过程演绎（deduction)： 从一般到特殊的“特化”(specialization)过程机器学习显然是归纳学习（inductive learning)归纳学习分狭义与广义，狭义是指要求从training set 中学得概念，广义是指从sample中学习 学习过程（训练过程）看作是在所以假设组成的空间中进行搜索的过程，搜索目标是找到与training set匹配的假设。如果假设的表示一旦确定，假设空间与其规模就确定了。想更详细了解假设空间，戳我啦5.2现实问题中常面临很大的假设空间，我们可以寻找一个与训练集一致的假设集合，称之为版本空间。版本空间从假设空间剔除了与正例不一致和与反例一致的假设，它可以看成是对正例的最大泛化。归纳偏好机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias),也就是学习算法在一个可能很庞大的假设空间中对假设进行选择的启发式或者“价值观”奥卡姆剃刀定律： 若有多个假设与观测一致，则选择做简单的哪个。没有免费的无餐定理（No Free Lunch Theorem[NFL]) 在所以问题出现的机会相同，或者所以问题同等重要下，所有算法的期望一样。但在实际问题中，针对具体的问题，不同的算法才会出现相对优劣。 发展历程推理期：二十世纪五十年代到七十年代初，AI处于推理区，代表性工作主要是A.Newell 和H.Simon的“逻辑理论家”程序和此后的“通用问题求解”程序等。“逻辑理论家”程序证明了数学家罗素和怀特海的《数学原理》里面的某些定理，获得图灵奖。知识期：从二十世纪七十年代中期开始，AI的研究进入了“知识期”，大量的专家系统出现，E.A.Feigenbaum（知识工程之父）在1994获得图灵奖。人们意识到，专家系统面临“知识工程瓶颈”,在那个时候，有人把知识总结出来再教给计算机是相当困难的。1950年，图灵再关于图灵测试的文章中，曾提到机器学习的可能二十世纪五十年代初，A.Samuel著名跳棋程序。五十年代中后期，基于神经网络的”连接主义“学习，如F.Rosenblatt的感知器（Perceptro），B.Widrem的Adaline,六七十年代，基于逻辑表示的”符号主义学习技术蓬勃发展学习期：二十世纪八十年代是机器学习百花初放的时期。一大主流是符号主义学习，代表决策树（decision tree).二十世纪九十年代中期之前，另外一大主流技术是基于神经网络的连接主义学习。二十世纪九十年代中期，”统计学习“占据主流，代表支持向量机。二十一世纪初，连接主义学习掀起了”深度学习“为名的热潮。 第二章 ： 模型评估与选择经验误差与过拟合、欠拟合训练误差（training error) or 经验误差（empirical error): 学习器在训练集上的输出与训练集之间的差异过拟合（over fitting）：在训练集上表现非常好，泛化能力太差，最常见的情况是学习能力太强学习到不太一般的特性，无法彻底避免，只能“缓解”欠拟合（under fitting）：这种情况容易克服模型选择(model selection): 不同的参数配置，产生不同的模型。理论上最好的模型是对泛化能力进行评估，最好的就是泛化误差最小的，泛化误差是无法直接获取的 评估方法设置一个”测试集（testing set)”来测试学习器在新样本的判断能力，用测试误差近似泛化误差要求： 测试样本与训练样本独立同分布的 测试集应该尽可能与训练集互斥，测试样本尽量不出现在训练集中如何产生training set 和 testing set 留出法（hold-out)要求：数据集($D$)划分成两个互斥的集合（训练集($S$,测试集$T$),需要注意的是，划分后，尽量可能的保持数据分布的一致性。不同的划分结果，得到不同的测试误差。单次使用留出法得到的结果是不够稳定的，所以一般采用若干次的随机划分，重复进行实验评估后去平均值 交叉验证法（cross validation)I. 将数据($D$)划分成$k$个大小相似的互斥子集，每个子集$D_i$都尽可能保持数据分布的一致性II. 每次都用$k-1$作为训练集，余下的哪个子集作为测试集，于是乎都到了k个测试结果的均值值得注意的是，$k$的取值对结果的稳定性和保真性有很大的影响，因此也叫k者交叉验证（k-flold cross validation) k的通常取值是10同样的，数据集$D$划分为$k$个子集有很多的划分方式，可重复$P$次$k$折交叉验证。 自助法 (bootstrapping)注意的是我们希望通过所以的训练集（$D$)训练出模型，但是流出法和交叉验证的方法，都保留一部分作为测试集，因此实际评估的模型所使用的训练集更下，这也许会导致估计偏差。自助法： 可重复采样或者有放回采样 记采样产生的数据集（$D’$),每次从$D$中挑选应该样本，将其拷贝至($D’$),并再将采样的样本放回数据集($D$),重复($m$)次以后，得到了包含($m$)个样本的数据集($D’$) 对于可重复采样，样本始终不采到的概率是$(1-\frac{1}{m})^m$,取极限得到：初式数据集中$36.8%$为出现在采样数据集中，因此可将($D$)作为训练集，($D\D’$)作为测试集，又称外包估计(out-of-bag estimate)自助法适用于数据量少，难区别测试集和训练集时，自助法会改变初始数据的分布，在初始数据足够的情况下，流出法和交叉验证更常用一些 调参和最终的模型学习算法都有参数(parameter),不同的参数配置，学得模型的性能也往往不同验证集(validation set): 模型评估和选择中用于估计测试的数据集称为的数据集往往将训练集划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参 性能度量(performance measure)假设检验（其实我一直都并不是特别了解） 假设检验的基本原理是重要的统计推断问题之一，根据样本提供的信息，检验关于总体某个假设是否正确。包括参数的假设检验（均值、方差等）和非参数（分布啊）的假设检验。 参数检验： 提出假设H—-&gt;在构造统计量，确定统计量的分布—-&gt; 确定拒绝域和接受域的分界线—-&gt; 在根据样本计算统计量的值u —-&gt; 推断 分布拟合检验 偏差和方差通过概率论分析对学习算法的期望泛化错误率进行拆解$x$: 测试样本$y_D$： $x$在数据集中的标记$y$: $x$的真实标记$f(x:D)$: 在训练集上学得的模型$f$在$x$上预测输出以回归任务为例子：学习算法的期望预测为： \hat{f}(x) = E_D[f(x;D)]方差：度量同样的样本大小的训练集的变动所导致的学习性能的变化，即刻画数据扰动所造成的影响 var(x)= E_D[(f(x;D)-\hat{f}(x))^2]噪声： 表达了当前任务上任务学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。 \epsilon^2=E_D[(y_D-y)^2]期望输出和真实标记的差别称为偏差(bias): 度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力 bias^2(x)=(f(x)-y)^2若假设噪声期望为零，那么算法的期望泛化误差： E(f;D)=E_D[(f(x;D)-y)^2]\\ =....=E_D[(f(x;D)-\hat{f}(x))^2]+(\hat{f}(x)-y)^2+E_D[(y_D-y)^2]E(f;D)=bias^2(x)+var(x)+\epsilon^2由上式可知，泛化能力由学习算法的能力、数据的充分性、学习任务本身的难度共同决定的。underfitting: 偏差主导泛化误差over fitting： 训练数据发生的扰动渐渐被学习到，方差主导了泛化误差 第三章 线性模型我自己其实是一直停留在线性模型学习过程，因为每次开头都是这一张，所以我就学习了很多次。这次不准备再细看了。 线性判别分析 Linear Discriminant Analysis (LDA)基本思想： 在训练样例集上，设法将样本例子投影到一条直线上使得同类样例的投影尽可能接近、异类投影点尽可能远离。数学表达：$D={(x_i,y_i)}_{i=1}^{m}$: data set$X_i$: 第$i$类集合$u_i$: 第$i$类集合均值向量$\sum{i}$: 第$i$类集合协方差矩阵$ w^Tu_i$： 第$i$类集合在直线上的投影$ w^T\sum_{i}w$: 样本点的在直线上的投影学习算法：同类更近：$\min \sum_{i=1}^{n}(w^T\sum_{i}w)$类中心越大：$\max ||w^{T}u_1-(\sum_{i=2}(w^{T}u_i))||_2^2$因此，想最大化的目标考虑$i = 2$的情况 J = \frac{||w^Tu_0-w^Tu_1||_2^2}{w^T\sum_{i=1}w+w^T\sum_{i=2}w} =\frac{w^T(u_0-u_1)(u_0-u_1)^Tw}{w^T(\sum_1+\sum_2)w} 应用空间几何和矩阵的关系描述 类内散度矩阵($S_W$)\sum_1+\sum_2 类间散度矩阵：(u_0-u_1)(u_0-u_1)^T 所以，我们想优化目标如下：J = \frac{w^T_Sbw}{w^TS_ww}如何确定$w$呢？注意到分子分母都是关于$w$的二次型，因此解这和w的方向有关系，因此，可令 $w^TS_ww=1$,优化问题可是如下： \min -w^TS_bw \\ s.t. w^TS_ww = 1构造lagrange 函数 L = -w^TS_bw+r(w^TS_ww-1)对$w$求导可得： S_bw =rS_ww$S_b w$和$ u_0 - u_1 $ 方向是$u_0-u_1$,不妨设 S_nw=r(u_0-u_1)so,w = s_w^{-1}(u_0-u_1)这里考虑到数值解的稳定性，因此往往把$S_w$进行奇异值分解 第四章 决策树决策树是一种特别普通的符合生活做决策的过程。 第五章 神经网络神经网络最开始出现是根据生物神经网络来的。 最简单的神经网络：神经元模型(neuron|unit)McCulloch and Pitts抽象出“M-P神经元模型” 感知器（Perceptron)输入层和输出层，输出层：M-P神经元感知器的学习过程一定是收敛的 多层前馈神经网络 （multi-layer feddforward neural networks)前馈：网络的拓扑结构不存在环或者回路神经元的学习过程：就是根据训练数据来调整神经元之间的”连接权”(connection weight),以及每个功能神经元的阙值 误差逆传播算法： error BackPropagation (BP)全局最小和局部最小神经网络的训练过程其实也就是参数寻优的过程，基于梯度的搜素是使用最为广泛的参数寻优方法，但是如果误差函数在当前点的梯度为零，则很有可能达到局部极小。 第六章 支持向量机支持向量机的学习原理很简单也很有趣，从分类问题，怎么一步一步建立的优化问题，一步一步的完善优化问题以及求解，从硬间隔到软间隔，分类问题是考虑分对，而回归问题希望预测值和原始值尽可能的接近，这样就造成了约束条件，目标性的不同。 最重要的是引入了核方法，低维空间的非线性关系映射成了高维空间线性关系，这是特别重要的思想 第八章 集成学习基本思想构建一组基学习器（base learner)，在结合 a. 如果集成中是相同类型的个体学习器，如决策树，全是神经网络的集成“同质”（homogeneous),个体学习器叫基学习器 b. 不同的学习器，异质（heterogeneous)，个体学习器叫组件学习器 为什么有效 多样性的基学习器 不同的模型取长补短 每个基学习器都犯错误，综合起来可能性不大 举个栗子 也许一个线性模型不能简单分类，但是多个线性模型综合，可将数据集成功分类 构建不同的机器学习Q 1: 如何建立基学习器 尽量满足多样性 M1: 不同的学习算法 M2: 相同学习算法、不同的参数 M3: 不同的数据集（不同的样本子集、数据集上不同的特征） homogenous ensemble 采用相同的学习算法、不同的训练集 Bagging Boosting 相同算法，不同的参数设置 相同的训练集，不同的学习算法 Q2: 如何综合呢？ t投票法：majority voting weighted voting 训练一个新模型确定如何综合 Stacking 偏好的简单模型 综合Bagging = Boostrap AGGregatING有放回采样，同质学习器 算法1234567891011Input : 训练集 D=&#123;(x1,y1)&#125; 基学习算法A 训练轮数 T过程 for t = 1,2,...,T do h_t= A(D,Dt) // Dt第t次采样的分布 end for输出 回归：Average 分类：投票法 优点没有用于建模的样本，可以用作验证集来对泛化能力进行包外估计，可以得出Bagging泛化误差的包外估计 random forest（RF)输入为样本集$D={(x,y1),(x2,y2),…(xm,ym)}$，弱分类器迭代次数T。 输出为最终的强分类器f(x)f(x) 1）对于t=1,2…,T: a)对训练集进行第t次随机采样，共采集m次，得到包含m个样本的采样集$Dt$ b)用采样集$Dt$训练第t个决策树模型$Gt(x)$，在训练决策树模型的节点的时候， 在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分 2) 如果是分类算法预测，则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，T个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。 参数设置 利用00B样本评估变量的重要性 Boosting 提高顺次建立学习器，就是先从训练集上训练一个基学习器，再根据学习器的表现对训练集分布进行调整，让先学习器错误训练的样本在后续收到更多的关注，然后基于调整的分布训练下一个学习器，最后，在将这T个学习器进行加权结合 基学习器的线性组合 H_N(x;P)=\sum_{t=1}^{N}\alpha_th_t(x;a_t)$a_t$是第$i$个弱学习器的最优参数，$\alpha_t$是在强分类器中的比重，$P$是$a_t$和$\alpha_t$的组合 最小化指数损失函数 l_{exp}(H|D)=E_{x~D}[e^{-f(x)H(x)}] H_n(x)=H_{n-1}(x)+\alpha_{n}h_{n}(x,a_n)l(h_i(x,a_t)|D)=E_{x~D}(exp(-f(x)h_i(x)))\\=p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))\frac{\partial l(h_i(x,a_t)|D)}{\partial h_i(x,a_t)}=\\ -p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))=0h(x)=\frac{1}{2}ln\frac{P(f(x)=1)}{P(f(x)=-1)}采取不同的损失函数，得到不同的类型 https://blog.csdn.net/luanpeng825485697/article/details/79383492 GBDTStacking 不同学习器，相同数据集 第一层 第二层：不用第一层的数据 可用交叉验证 注意事项： 过拟合问题：第二层线性回归 第一层尽可能的多样性： 综合好的模型 防止过拟合 1. 随机性 2. Bagging Boosting Stacking 极大似然估计似然： 相似的样子 对于一组数据，假设符合正态分布，希望已知点在这个正态分布的情况下，所有点对于的概率之和或者积最大， ，蓝色表示数据，红色就是做得正态分布 第十章 降维与度量学习k近邻学习k-Nearest Neighbor 原理： 基于某种距离度量找出训练集中与其最靠近的k个训练样本，根据k个邻居的信息进行预测。 给定测试样本$x$,如果最邻近样本$z$,最邻近分类器出错的概率就是$x$与$z$不再同一类 p(err) = 1-\sum_{c \in y}p(c|x)P(c|z)低维嵌入缓解维数灾难的重要途经之一是降维（dimension reduction）这样使得子空间中样本密度大幅度提高，距离计算变得更容易， 多维缩放（Multiple Dimensional,Scaling）MDS 假定m个样本在原始空间的距离矩阵$D$,在低维空间中，两个样本欧式距离等于原空间的距离，$||z_i-z_j|| = dist_{ij}$, 令$B=Z^TZ$为降维后样本的内积矩阵, dist_{ij}^2=||z_i||^2+||z_j||^2-2z_iz_j=b_{ii}+b_{jj}-2b_{ij}对降维后数据中心化，均值为0,$\sum_{i=1}^{m}z_i$,于是乎就有$\sum_{i=1}^{M}b_{ij}=z_j(z_1+z_2+…+z_m)=0=\sum_{j=1}^{m}x_{ij}$ ,可得 \sum_{i=1}^{m}dist_{ij}^2=\sum_{i=1}^{m}(b_{ii}+b_{jj}-2b_{ij})=tr(B)_mb_{jj}\\ \sum_{i=1}^{m}\sum_{j=1}^{m}dist_{ij}^2 = 2m tr(B)\\ tr(B)=\sum_{i=1}^{m}||z_i||^2可得 b_{ij}=-\frac{1}{2}(dist_{ij}^2-dist_{i.}^2-dist_{.j}^2+dist{..}^2)对矩阵B做特征值分解(eigenvalue decomposition)，$B = V \land V$,则 Z = \land_{*}^{1/2}V_{*}欲获得低维子空间，最简单是对原始高维空间进行线性变换，$Z = W^TX$,特别的，$W$取正交变换，$W={w_1,w_2,…,w_{d’}}$W是d’个d维基向量， 主成分分析Principal Component Analysis ：PCA 在正交空间里面的样本，用一个超平面对样本进行恰当的表达，至少这个样本点满足 最近重构性： 样本点到这个超平面的距离足够近 最大可分性： 样本点在这超平面上的投影尽可能分开 对于最近重构性： 假设样本去中心化，再假设投影变换后得到欣的正交坐标系${w_1,w_2,…,w_d}$,d维空间里面的一组单位正交基，$||w_i||_2=0$,$||w_i^Tw_j||=0$,如果再新坐标系中丢掉一部分坐标，样本点在新坐标的投影是$z_i={w_1^Tx_{i1}},..,w_{d’}^Tx_{i}$,于是又$z_{ij} =w_{j}^Tx_i$,$\hat{x_i}=\sum_{j}^{d’}w_jx_i$ \sum_{i=1}^{m}||\sum_{j=1}^{d'}z_{ij}w_j-x_i||_2^2=\sum_{i=1}^{m}z_i^Tz_i-2\sum_{i=1}^{m}z_i^TW^Tx_i+x_i^Tx_i\\ =\sum_{i=1}^{m}x_i^TWW^Tx_i-2\sum_{i=1}^{m}x_i^TWW^Tx_i+x_i^Tx_i\\ min -\sum_{i=1}^{m}z_i^Tz_i=-tr(Z^TZ)\\ min -tr(\sum_{i=1}^{m}W^Tx_ix_i^TW)=-tr(W^T(\sum_{i=1}^{m}x_i^Tx_i)W）=-tr(W^TXX^TW)\\ s.t W^TW = I对于最大可分性$(W^T\hat{X}=0)$ max tr(W^TXX^TW)\\s.t W^TW = I根据lagrange L(W,\lambda)=-tr(W^TXX^TW)-\lambda(W^TW-I)\\ \frac{\partial L}{\partial w_i}=-2w_iXX^T-2\lambda_i w_i=0\\ XX^Tw_i = \lambda w_i$XX^T$是协方差矩阵,$\lambda$是特征值，$w_i$是特征向量 特别提示，$x$需要中心化 对于线性PCA降维方法是从高维空间映射到低维空间，$Z= W^TX$,然而不少情况，则需要非线性映射才能找到恰当的低维嵌入， $\phi(x)$ \max tr(\phi(X)\phi(X)^T)=tr( W^T\varphi(x)\varphi(x)^TW)\\ W^TW = I于是有 \varphi(x)^T\varphi(x)w_i=\lambda_iw_i\\ w_i=\frac{tr(\varphi(x)^T\varphi(x))}{\lambda_iw_i} z_j = \frac{\sum_{i=1}^{m}\varphi(x)^T\varphi(x)}{\lambda_iw_i}\varphi(x_i)\ =\frac{\sum_{i=1}^{m}\varphi(x_i)K(x_i,x)}{\lambda_iw_i}流形学习（表示学习有点困难)第十一章 特征选择与稀疏学习对于一个学习任务，对任务有用的特征,称为”relevant feature”，对于没有用的属性”irrelevant feature”,因此从给定特征集选择出相关特征子集的过程，特征选择（feature selection),原因一，降维；原因二：降低学习的任务。 无关特征，包括一类冗余特征（redundant feature），能够从其他特征里面推演出来。 特征搜索前向（forward)搜索对于特征集合$\{a_1,a_2,…,a_d \}$,每个特征看作一个候选集，对这$d$候选的单特征子集进行评价，可选出最优子集，然后，再下一轮子集中，构成了两个特征候选的子集， 后向 (backward) 搜索每次尝试去掉一个无关特征 双向(bidirectional)搜索上述操作只是贪心策略，仅仅考虑了本轮选定集合最优 ​ 子集评价（subset evaluation)已知一个数据集$D$,假定第$i$类样本所占比例$p_i$,对于属性子集$A$,假设根据取值D分成V个子集$\{D^1,D^2,…,D^V\}$,则子集A的信心 增益 Gain(A) = Ent(D)-\sum_{i=1}^V\frac{|D^i|}{|D|}Ent(D^i)\\ Ent(D)=\sum_{i=1}^{|y|}p_ilog^{-p_i}​ 信息增益Gain(A)越大，说明特征子集A包含的有助于分类的信息越多，特征子集A是对数据集D的一个划分，样本D的标记信息Y则对应着D的真实划分，就能对A进行评价，对Y对应的划分的差异越小，则说明A越好， 过滤式选择Relief （Relevant Feature） 设计一个“相关统计量”来描述度量特征的重要性，该统计量是一个向量，每个分量对应一个初式特征，而特征子集的重要性则是每个特征对应统计量分量之和来决定，最终只需指定一个阙值，根据阙值选择统计量分量对应的特征即可 如何确定相关统计量 给定训练集$(x_i,y_i)$,对于实例$x_i$,在其同类样本中找最近邻（near-hit),在从异类样本中寻找其最近邻$x_{x,nm}$称为“猜错近邻”， \delta^j =\sum_i-diff(x_i^j,x_{i.nh}^j)^2+diff(x_i^j,x_{i,nm}^j)^2分值越大，说明对应属性的分类能力越强 对于多分类问题 \delta^j = \sum_i-diff(x_i^j,x_{i,nh}^j)^2+\sum_{l \neq k}p_l\ diff(x_i^j,x_{i,l,nm}^j)这种方法看一个属性（特征）重不重要，先计算出每个属性的统计分量，按照公式，子集的评价就是对于分量的和 包裹式选择直接把最终将要使用的学习器的性能作为特征子集的评价准则，特征选择的目的就是为给定学习期选择有利其性能的特征子集。 LVW（Las Vegas Wrapper）是典型的包裹式特征选择方法，拉斯维加斯方法（Las Vegas method）框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价准则 算法 嵌入式选择学习器自动地进行特征选择 L-P范数 L_P = ||X||_P = p\sqrt{\sum_{i=1}^{n}x_i^p} L0范数 ||X||_0=向量中非零元素的个数L1范数 ||x||_1 = \sum|x_i|L2范数，最常用 ||X||_2=\sqrt{x_i^2}无穷范数 ||x||=max|x_i|对于线性回归模型，防止过拟合，如果使用L2,称为岭回归(ridge regression),如果采取L1范数，则有称为LASSO，L1比L2更易于稀疏解，可以看得出L1范数正则化的过程得到了仅采用一部分初始化特征的模型。 L1正则化求解可使用近端梯度下降法(Proximal Gradient Descent)PGD L-Lipschitz条件 设函数$Φ(x)$在有限 区间$[a,b]$上满足如下条件： (1) 当$x∈[a,b]$时，$Φ(x)∈[a,b]$，即$a≤Φ(x)≤b$. (2) 对任意的$x1，x2∈[a,b]$， 恒成立：$|Φ(x1)-Φ(x2)|≤L|x1-x2|$. 如果$f(x)$可导，并且$\nabla f$满足L-Lipschitz条件， ||\nabla f(x')-\nabla f(x)||_2^2]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>西瓜书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习の历程]]></title>
    <url>%2F2019%2F02%2F22%2F%E5%AD%A6%E4%B9%A0Daily%2F</url>
    <content type="text"><![CDATA[贴张伏魔咒 八月要准备考试了 现代密码理论（李发根老师授课）考试时间：2020-08-28，09:30-11:30 软件安全性分析（陈厅老师授课）考试时间：2020-09-03，09:30-11:30 2020-7-22 对不起，我不想在做孩子了 今天早上终于把量化结果弄好了，基本上可以说明很多问题。结果也不错。。。。至少是契合现实的 今天下午写分析报告，词穷。 今天晚上时间序列 今天外婆到我家里，莫名的悲伤了，想想，我能在和外公和外婆见面的次数和相处时间不多了。 人一定要学会世故。不然后果不堪设想。 哪有什么干干净净的追求。纯粹的喜欢和欣赏了！ 2020-7-21 今天早上改代码 今天下午学习3绘图seaborn,不好用啊，字体和字号的设置，不对头。origin可能以后不能用了，matplotlib searborn 才是王道。绘图色彩搭配很重要 今天晚上学习了数据分析。我发现我太喜欢数据分析了，以后要从事这行了。 2020-7-20 今天早上睡觉 今天下午测试数据（感觉应该没什么问题了） 今天晚上跑了xgboost 我不想浪费时间，更不想处理不必要的关系。留给专心作科研的时间不多了啊！ 2020 30周 最近十天，把八月份要干的事情干完，八月份要准备六级和期末考试了，报告和测试，我的个天，心塞啊，我选了什么课啊！全心全意准备考试。 Input ✔️❌ Output ❌❌✔️ 关键最近老是想睡觉。 论文不再是我的主旋律。小问题没什么意思，大问题做不出来。就是干什么方向不是问题。哪怕别人发了nature ,science 我根本无动于衷。 Input time series 数据分析技能 Output 每两天交接一下 增量和差值学习一下 学习人际交往的本质 2020-7-19 你如今的气质里，藏着你走过的路，读过的书，和爱过的人。 今天早上睡觉 下午跑时间序列 晚上处理数据（不显著啊）关键聚类标准稳健误差，加了之后。数据本身也不行。算了，算了 无争无忧！ 2020-7-18 你如今的气质里，藏着你走过的路，读过的书，和爱过的人。 今天早上睡觉，煮饭。 今天下午时间序列&amp;处理数据 今天晚上看《谁说我结不了婚》 《面朝大海，春暖花开》做个幸福的人、种菜、劈柴，周游世界！ 2020-7-17 今天早上，睡觉 今天下午，调研了很多东西。跑了时间序列，交接了工作，下面都好干了 今天晚上，清洗数据。感觉应该快了 2020-7-16 大头儿子和小头爸爸； 终有一天回头看今天，我才发现我研一2019.11-2020.07这几个月，读论文，入门某个专题的研究，才发现转了好大一个弯道了。想起有个人的科研经历，当你博士毕业的时候回头看，明明几个月，甚至更短就可以做完，结果花了很长很长的时间。这就是积累经验的过程。从不可能到可能。 耶耶全部搞定了，基准初步结果还OK，啦啦啦啦啦!!! 问题是样本本身的问题了。 你如今的气质里，藏着你走过的路，读过的书，和爱过的人。 2020-7-15 今天早上处理数据。 今天下午搞时间序列分析。[]倒着索引 今天晚上看论文，对比分析了两篇同类的文章。 明天： ​ 发代码 ​ 把基准结果和学位聚集量化一下，希望出个好结果。慢慢摸索出一条道路。挺好的！ 2020-7-14 今天早上读了几页书籍，感悟颇多。条条大路通罗马，越来越值钱。扯下冠冕堂皇的理由，我之所以拼命，不就是为了富养我自己吗？自始至终都是我的奋斗目标。只要是正当的求生手段，靠自己的本事吃饭，我就干。 今天下午（午睡了很久）学了空间分析工具，工具还挺好用的哇。继续sklearn 今天晚上继续处理数据，跑的时候读了别人的文献，突然觉悟。科研的过程就是浪费时间的过程。 问题：我现在是沦为工具的应用者吗？我原先一直致力于成为这方面的创造者，没有成功。咳咳，现成为工具的应用者，解释一些现象也是十分好的。 2020-7-13 生存还是毁灭？这是个问题。究竟哪样更高贵！要更加厉害！ 今天早上刷视频，学英语！ 今天下午睡觉&amp;学软件&amp;跑程序 今天晚上读论文。虽然是北大的论文，但是总觉意义和价值感不高。我现在提的科研问题也是这个毛病。没有乐趣往下进行了。垃圾中的战斗机哇！ 明天：1. 时间序列调参，交接工作。2. 调研一下数据归一化的方法。3. 读论文 2020 29周 Input 尝试调研小领域（感觉下载的文献质量非常高） 学习写作 时间序列（机器学习算法） Output PPT 多记点专业词汇和句式（我就是照着别人写的，但是读起来不对劲，不通畅） 2020-7-12 **当你知道自己的需求，也知晓别人的需求，所有的事情都十分好干了。**如果出现了问题，一定是我做的不好。 今天找了几篇非常好的文献，可以做这方面的细调研，大概就10篇左右。 今天处理了数据，实在是麻烦。 突然发现文章最难的是文献综述。 Input ✔️❌ Output ❌❌✔️ 2020-7-11 看剧，跑程序 今天早上睡觉，看视频 今天下午和晚上，处理数据，啊麻烦 精英精神： 1. 《谁说我结不了婚》 利益：要不要做；风险：该不该博； 能力：该不该干；结果：划不划算；而不是别人告诉我：对不对。 2. 明确各自需求 2020-7-10 跑程序 今天早上跑程序（封装接口） 今天下午跑程序，学习写作的思维 今天晚上跑程序，看纪晓岚和和珅。 2020-7-9 科研写作好痛苦 今天早上听了听力，刷B站 今天下午学习了如何进行科研写作。太不容易了。《Some Tips on Writing》。原因如下：词汇缺乏；直译；毫无讲故事的思路；交代不清晰，含糊。更别提逻辑了，我觉得中文论文的逻辑关系都把握不好。 2020-7-8 你要自己摸爬打滚的度过艰难时期，你可以找人，但绝不能依靠任何一个人。我们是孤独的个体，更是无数关系连边中的一条。要学会和这个世界产生共鸣。 今天早上啃了一个🍎。 刷刷小红书，B站。 下午写了代码注释。封装成接口。规划了下一步方案。 晚上读了一篇Data Science的文章，数据好才能讲好故事啊。引力模型、线性回归模型。变量的构造是亮点。每天坚持写作（英文写作好难） 2020-7-7 当开启****，就像开启了闯关游戏，要一关一关的打怪升级，换先进装备。不成功便成仁。不成功便成仁。不成功便成仁。 今天早上又被刺激到了。 下午实现了xgboost, 数据-&gt;模型-&gt;调超参数 晚上收拾了论文，感觉就像俄罗斯方块，底层没有做好，越往上堆，就要回归底层。写了1000多点的小论文，也不知道每一个优秀的博士要经历什么才能创造出这么多的文字。值得学习。 释放光芒！ 2020-7-6 继续努力的一天 今天早听了英语访谈 今天下午复习了密码学第1-2章（1h); 把高铁的描述性统计做了，感觉结果还是不错！(用时较长) 2020 28周 2020-7-5 要做的事情还很多，我努力做我喜欢的一切，并不是为了赢别人，而是要自己满足。 今天又是睡得晚起的早的一天。a. 我把trfersh完全搞懂了。b. 谈整合资料的重要性，为什么我总是一个专题的资料，每次都要重复弄呢。不好不好不好。 这一周还是不错的，在精神上，每天睡足了10h，啊哈哈哈哈哈。时间序列基本上搞通了。读了几篇不错的论文，还把stata软件学会了，其实计量经济学无非就是要解决因果关系，遗漏变量，序列相关性，异方差性等等，几个问题，要解决是不容易的。sklearn用的不熟练 Input ✔️ Output ❌✔️ 这周主要把统计学里面的基础复习了，总感觉没找到我想要的那种深度。我也不知道我到底需要怎么样的深度。感觉自己又胖了！ Input 密码学复习两章（PPT+习题+百度） 网络安全复习两章（视频+笔记+概念） 写1000字左右的结课论文（关于大数据下孕育而生的计算社会经济学，抄袭抄袭，借鉴咯） 封装特征提取 论文数据分析(现在就差分析结果)（不知道我怎么会给造成一种，我很会写论文的样子，想太多了吧) 现在还是数据驱动研究，并非研究问题驱动数据的阶段 准备六级 reading record Output 基本的数据分析结果 论文阅读：一定要以PPT的形式给出（每周给自己做个1-3页的PPT) 看一道建模题 学习机器学习集成算法 2020-7-4 懒得的我 今天早上又睡了很久！可以是昨天晚上看别人的vlog太久了，羡慕那种独居生活。我什么时候可以过上独居的日子啊！ 今天下午学了stata这个工具，基本上学会了，我发现机器学习开源工具，有些不良心啊！ 今天晚上看了会电视剧。跟踪公众号。学习统计学。 2020-7-3 睡饱喝足，读会论文，&amp; 敲代码 今天下午玩了xgboost,集成学习有点难，但也要手动推导，这可以加深对算法内涵的理解。 晚上统计学习，stata和计量经济学（学的很基础，但实际应用不是那么回事了）。做数据科学，肯定要学习R语言 沉思：😔😔😔。 2020-7-2 陷入深渊的我 今天又是上课，不知道老师扯了些什么，听着听着就关成静音了。(阴险.jpg) 实现了时间序列的特征工程，读了一篇好文章（关于女性政治地位的提高），还找到了一篇EPJ data science上的好文章（追踪文献的重要性） 明天：1）实现xgboost 2) 模型设置（中文）综述和变量 2020-7-1 无聊的我 今天玩了tsfresh库，怎么那么难理解啊！实在是不知道别人怎么编程的！关键是返回的数据结构，和底层实现有关系！再次学习了参数估计（极大似然估计，最大后验估计）。我可能要手把手教那种。 2020-6-30 心累的一天 今天早上，下午上课，是张老师的课，课程难度很大。我也是半听半玩耍。可能是数学学多了，对这个社会问题感悟能力跟不上。就一句话存在即合理！顺道看了tsfresh的doc 晚上，读了一篇science，开创性工作就是厉害啊！从0到1是飞跃，1到2，3…是发展。还有跨界的精英。温习了机器学习里面的基本概念！ 2020-6-29 今天早上，下午上课去了。还去看了回归分析sklearn的实现。 关键点相关性分析-&gt;因果分析， correlation － causality - prediction - control。解释型研究（描述，统计方法)----&gt;充分解释（因果关系）科学研究： 解释，预测，控制闭环（干预），找不到因果关系。 因果关系分析方法：Causality: Models, Reasoning, and Inference 晚上复习统计学day Ox 01（本科我怎么没有作电子稿笔记啊，哭死了，还去反翻看了过去的笔记和博客，菜死了）。加个学习小组，感觉别人做的资料，和我想要的深度差太远了。数据挖掘上次看那个Dr.yuan的课程，笔记不是特别好！还要把时间序列特征工程做了！ 我发现申请实践学分，做助教，怎么那么多人申请啊！ 统计学习方法那个，我发现我做的笔记，好差劲啊！ 2020-6-28 元气少女的独白-- 个人之旅 2020 27周：躬行实践 INPUT a. Linear Models &amp; Python 学会 https://scikit-learn.org/stable/supervised_learning.html#supervised-learning b. Time series &amp; Feature select tfresh c. English: youtube &amp; shanbei e. reading record f. 概率论（极大似然估计，假设检验，显著性检测，参数估计） OUTPUT a. kaggle project b. 掌握一个中高难度的数学模型 c. Reading Record 今天早上睡觉啦！ 下午和电脑人一起玩麻将，收拾了本周的资料汇总 晚上看了视频学习关于xgboost,和关于一些公众号的文章 F: ​ 输出（✔️）； 论文阅读（✔️）；读书（❌，主要是没有那种心境，不上瘾）；英语（✔️） S: 论资料的收集的重要性。知识在脑海里会忘记，但硬盘不会。一定要把自己遇到的顶级资料收集好，厘成doc。一定是高质量和高密度的资料才记录。原来一直注重资料的学习，忽略了资料整合的重要性。并且最好每段时间，写一篇大汇总。 切记从头开始。学习回路：资料收集（分等级：全局观–&gt;入门-进阶-高级，科普)----&gt; 把自己的输出提升到别人也可以直接用的水平。不错，是这么回事！这也是对自己的一种要求。 快乐夹杂着悲伤，至少结尾不能让自己太难堪！这条路只会与自己相关。 2020-6-27 外公八十岁生日 白天在外婆家，给教书先生外公过生日。 晚上，听了一场讲座，关于“当交通遇上机器学习”,是北交副教授万怀宇博士讲授的专题。主页：http://faculty.bjtu.edu.cn/8793/。全当是科普了，不过，内容挺深奥的。 你永远无法叫醒一个装睡的人 当你真心渴望某样东西时，整个宇宙都会联合起来帮助你完成！ 学到了两句话，我不知道选哪个！ 关键词: 硬核 2020-6-26 今天早上，睡到了11：00 下午，查重，心累！时间序列！ 晚上，读了一篇时间序列在预测能源消费里面的大综述。和本科的经历契合。重点看了最小二乘支持向量机的应用，研究结果拟合精度和预测精度还行。这些模型，我还挺熟悉的。 2020-6-25 端午快乐,biubiubiu 早上，睡到了中午，感觉太热了，不想早起。 中午，我和弟弟去街上吃饭了：豆腐、水饺、水煮肉片。感觉我要是愿意做一次饭，那简直是太阳从西方出来了。妈妈果然是世界上最辛苦的人了。 下午，交接一下时间序列项目，话说这个东西不是很火吗，为什么资料这么少啊！！！跑了一天一夜ARIMA了。帮我表弟写一篇中小企业发展现状的论文，找了几篇文章抄袭，看了别人的硕士学位论文，我才意识到我还是本科论文的水平。 晚上，研读论文。 2020-6-24 7h睡眠不足的我.jpg 今天早上迷迷糊糊起床，和同学唠嗑，昨天睡的好玩，1：30，听说墨西哥地震了，然后我发了消息，居然心安理得的睡着了！ 下午，杉杉说可以偷偷摸摸回去，我心里暗自一想，在家里也很好啊，睡-吃-电脑-吃-睡-醒的无线死循环。。。。。看了本科的学弟学妹毕业了，感叹时光啊，我这一年学了什么，时间都去哪了了？时间都去那儿了？我觉得自己一年什么成功都没有，论文被拒稿，被困家中半年了吧，感觉本科四年都没有在家呆那么长的时间。这不是本科的所有时间，全部回去了吗？ 晚上，了解时间序列的特征提取，什么鬼，怎么那么难啊！晚上看了大数据机器学习时代，科普。 突然想到还有好多复习的课程要考试啊，突然想到了。 看了很久很久的说说了，我发现大学我错过了很多的美好， 怀念大学的时光，无拘无束，可以起很早去实验室，可以认认真真的上课，可以和同学一起建模和熬夜通宵做作业，尤其是和灯夜一起大晚上待在实验室的日子。 Probit vs logit https://www.econometrics-with-r.org/11-2-palr.html 2020-6-23 我要放长假.mp4 今天睡了10h多。晚上十一点睡到早上11.00，中途还迷迷糊糊的在研究生系统打卡！！！！已经是自然状态了啊！ 下午：继续时间序列，理论完全不懂。这是怎么回事。 晚上：开开心心复习四川大学的概率论。好久没有接触机器学习了，差不多还给书本了。 机器学习算法+概率论统计学 2020-6-22 如果可以一直一直睡下去多好啊.eps 今天睡了11多个小时，太幸福了啊！ 下午玩了会时间序列。和灯夜聊了很久的天，就是关于兴趣和人生追求。 2020-6-21 今天上街去了，买了一个大大的冰淇淋。 输出 完成一篇博客 推进时间序列项目（读相关论文） 论文阅读 今天早上和下午睡了好久啊！ 下周规划： 时间序列项目（主线1）：具体把相关的方法整理成笔记 统计学（主线2）：统计学课程每天学一学，做练习。 mooc: https://www.icourse163.org/learn/NJUE-1001752031?tid=1206103246&amp;from=study#/learn/content 编程：SQL、Excel、Python的精髓用法，本着提高效率去的。 看剧 《白箱》 看两篇机器学习回归分析的论文 统计学习补上 书籍阅读： ​ 《大秦帝国》 ​ 《人性的弱点》 每天2h的英语学习，过六级啊 反思： ​ 日出而作，日落而息。 2020-6-20 心塞 今天肚子不舒服，什么都不想干了。好痛，好痛，好痛！！！！ 下午学了python技巧绘制各类bar,barh 2020-06-19 我与春风皆过客，你携秋水揽星河；殊途同归是偶然，背道而驰是常态。 下周规划： 时间序列项目（主线1）：具体把相关的方法整理成笔记 统计学（主线2）：统计学课程每天学一学，做练习。 编程：SQL、Excel、Python的精髓用法，本着提高效率去的。 书籍阅读： ​ 《大秦帝国》 ​ 《人性的弱点》 早上起的晚，还跟导师扯了皮，作为一个从小就逃避老师的人，居然还去打扰大忙人的时间，罪过啊。 下午：搞了会科研，数据不给力啊。哎，内心奔溃了。 晚上：恶补pythonic和统计学 https://mp.weixin.qq.com/s?__biz=MzI1MzAwODMyMQ==&amp;mid=2650338461&amp;idx=1&amp;sn=be67a2565cf5f0922e84e5076fe1c0d2&amp;chksm=f1d75433c6a0dd25fa6e25fae624cb21738b0fc4b28f833db0844f8bbb6e02c1dc9dfddac03a&amp;scene=0&amp;xtrack=1#rd 2020-06-18 😴 心不在焉 。全栈。 今天发现自己离全栈在程度在降低。 ​ 1. 作图、写作、看文献、想科研想法、编程几乎都可以半独立。但是我突破不了，就是往高质量在期刊发，感觉已经达到了自己能力的顶峰了。在继续，可能就是数学层面。要提升啊 自己学了很多东西，但是并没有独特的优势在，问题就是不专业，不透彻。要把自己喜欢在的涉及的知识、编程都要学到位，这很关键。 今天和萌萌组个学习队，加油，考研加油！！！！！！ 就是参考文献的插入。 2020-06-17 玩的fun 明天： 如果不出意外，尽量睡到九点！看会电视剧！ 继续跑程序 学习统计学 今天早上起的很晚，睡了很久！昨天看了好久的电视剧，刷b站。看了关于交通治理与疫情防控的文章。特别学到了新东西，就是矩阵的奇异值分解，所产生的现实意义，可通过降维，获取关键性信息，可得结构信息。https://mp.weixin.qq.com/s?__biz=MjM5MTM5NDAzNA==&amp;mid=2651320319&amp;idx=1&amp;sn=6a0e27ff1e5b9d0f3cc1d4ac5fff2ef0&amp;scene=19#wechat_redirect 下午搞了会数据 晚上： 规划一会统计学学习 看了下自己的塑身计划，纠正体型，感觉还差好多啊 看下自己的技能树 https://github.com/xiemaycherry/picture/blob/master/%E6%88%91%E7%9A%84%E6%8A%80%E8%83%BD%E6%A0%91.png 2020-06-16 今天早上沉思了自己最近的行为。重建了自己的各种行为，我可能脑子里面少了一根筋。哈哈哈哈哈哈哈哈哈 下午继续搬砖。早点办完吧。希望每一段沉潜的时光都可以闪闪发光。虽然在别人看来没有什么意思，但是我依然要努力!发现自己特别没有脑子啊！发觉自己太笨了吧！！！！！！ 下午和爷爷聊天了， 晚上学习了新知识 继续学习统计学 野外一游 古诗词 ​ 愿我如星君如月，夜夜流光相皎洁。 ​ 云想衣裳花想容，春风拂槛露华浓。 ​ 昔我往矣，杨柳依依。今我来思，雨雪霏霏。 ​ 我断不思量，你莫思量我。 ​ 落红不是无情物，化作春泥更护花。 ​ 曾经沧海难为水,除却巫山不是云。 ​ 秋风生渭水，落叶满长安。 2020-6-15 二次元少女的微笑.jpg 哎，我这是怎么了。老是词不达意啊！ 希望大家理解我。我是一个很不合群的人，还有点偏激的人。但不分场合的学习，没关系的啦，不要管我，所有以后我注意下自己的方式方法减少误会哈！！！！！对不起，对不起，对不起，对不起！！！！！！！！！！ 2020-6-14 开心睡觉ing 今天家里没有网，断网啊！ 复盘这周工作，感觉要把某个知识、理论学到脑子里，不忘记，随机应变，太难了！ ​ 第一：跑程序。我觉得要跑大程序，才是把程序精髓学到家，时间效率。 ​ 第二：阅读。显而易见的现象问题啊。 ​ 第三：课程结课。 几门课程，感觉不是自己当初想选的，学起来怎么都不顺心。我就学不来了，配不上！ 最主要的收获 ​ pandas不断新增行的方法。 ​ pandas if 的用法 2020-6-15–2020-6-21计划 感觉自己是听蠢笨的啊。 2020-6-13 不悲不喜.png 今天a .出门拜访亲戚，身心疲惫 b. 好想回学校啊，想念食堂，想念杉杉宝贝 c. 什么能力都在下降。。。。不好的预感啊！过去学的东西，长时间搁置，已经发霉了，啊，啊，啊，啊，啊， 啊---------------------- d. 还是要多元化发展，感觉自己已经是单一维度了，不知道怎么回事。 e. 我发现我记忆力衰退的太厉害了，脑子不够灵活，为什么呢。要及时记录啊。 好有效率问题啊，效率啊，效率啊，效率啊！ f. 看清自己，终能看破红尘。 今天：遇到的一些问题： ​ 1. 对应DataFrame数据类型的行索引。在插入新行的问题，从其他DataFrame或者自定义插入。可以用append()在末尾新增行，但传参数切记是列表，最好用DataFrame 2. 还有列表和字符串的相互转换。如果要把[]传入DataFrame 2020-6-12 不纠结了.svg 明天周末了。今晚要追剧；车水马龙；在月光下奔跑，我什么都不想要，你爱我就好 今天是没有课的一天。还有杉杉在学校了。 2020-6-11 半睡半醒 : 明天 ​ 今天的任务没有做完，明天继续 今天 跑程序的过程中，把文件夹清理了 那么有趣，那么有价值-——评判公平性标准 品读了《喜欢你是寂静的》 听了陈奕迅《我要稳稳的幸福》 2020-6-10 开心.eps 明天： 调用时间序列指标 2. 线性回归模型 3. 跑程序，计算人才流动指标 今天 思考了一个问题：职业规划。我应该怎么给自己一个定位？我喜欢什么？我受什么驱动？ 交接了任务，被问惨了。 2020-6-9 愉悦.jpg 今天： 精读了一篇论文，收获满满，因为都是自己学过，看过的方法，看别人论文里面的应用，有所启发！以后要看顶级的资料 喝着安慕希，看别人的数据分析报告。 最近知识输入太过了，虽然都是本科了解过的（数学方面） 重要要清洗出数据，不知道为什么，我发现我的数据，居然只读了十几万条，然后重新跑。 等忙过了这段时间，一定要好好厘清最近的思路 可视化 数据清洗：python 线性预测模型 计量经济学 2020-6-8 元气 开心 喜出望外 明天1. 基本数据统计结果 2. 项目交接！3. good night 今天早上，发现居然错过新型冠状病毒的课程，已经网上结课，不得以询问辅导员、研管科，打了好多电话。研究生的老师居然给我们重新结课的时间，太爱了！！！！！！！！！！！！！太感谢，感动了！ 今天做了的数据序列项目上周的报告！不得不说自己排版能力越来越厉害了！ 但是跑处理的模型ARIMA效果不行！还有感谢张老师提供的服务器！找到跑代码的感觉了 今天终于预处理完论文数据了，但是能不能用好，挖掘更大隐藏信息，还得加把劲！ 还是要写函数，而不是复制粘贴的 今天阅读了本科做的项目，找了两张图片，虽然已经被拒稿了两次，但是我做的过程还是愉快，更重要的拿到英语课上去吹牛！希望好好搞接下来的研究！！！！ 一些读文献的经验值；怎么用语言表达不同场景的文献内容，这是需要加强的。 这周基本上熟悉了pandas,numpy的相关操作和注意事项，接下来要搞好这个项目(主线2) 继续阅读文献，见哥的文章 2020-6-6 今天又是元气满满的一天，和外婆、姨妈等亲人到我家里面做客，吃了🐟；还有邻居老人赠送的🍑 温习了numpy的用法，numpy,pandas,list直接的相互转换关系，以及sklearn metric里面的各类指标，什么叫指标的鲁棒性，怎么按需求选或者构造适合自己的评估指标。 读了高见师兄的综述。 做了指标体系图和高铁站点（Edraw中文坑，怎么不是矢量图啊，Visio破解不安全，AI还不知道怎么操作） 明天录视频， 2020-6-5 今天熟悉了时间序列流程；1. 平稳性。序列平稳性是做分析的基础。平稳性检测–单位根；非平稳性处理：差分log分解~平滑处理；2. ARIMA模型 基本思路；相关性和偏相关性定阶数 3. 网格+信息准则 调参：惩罚性 nbeats工具封装好了 4. predict样本内，动态和静态预测 forecase外推，timedelt 绘图，指标 假设检验：统计量和显著性水平，总感觉理解起来太难了，等忙了一定要好好复习统计学，参数估计，显著性检测，好好补。 记不住的函数 pd.date_range(start = sub.index[-1],end = sub.index[-1]+timedelta(days = 2),freq = ‘1h’) stat_rawdata = rawdata[rawdata[‘站点名称’]==stat] 布尔类型的切片，不上很明白原理 plt.xlim(sub.index[0],sub.index[-1]+timedelta(days = 2)) 绘制热力图 seaborn里面的heamap() 123456import numpy as npimport seaborn as snsx = np.random.rand(10, 10)sns.heatmap(x, vmin=0, vmax=1, center=0)plt.show() 2020-6-4 今天最大的头疼之处和领悟就是，跑大型程序，一定要准备一份下程序，调好结果才放在服务器上面跑，不然结果难以想象。。。。。。。。。。。。。 感觉调包侠也不是想象中那么好当的，一是现实中的数据一般般不规则，我发誓以后一定要做个合格的客户，二是参数默认是最讨厌的 今天又改程序，数据预处理果然头疼啊！希望周末可以出个大概结果，再重新跑数据 绝知此事要躬行，原来觉得自己学各种库还不错，实践的时候还是用不上的时候，😔 还有就是命名的重要性， 准备出一篇实践的心得，月末，主要是现在写程序太安逸了， 知识 pandas新增列 更改索引 range() 行政单位，变更情况 函数，写函数，不知道为什么，像python这种解释型的语言，自己老是重复，不好，不好， 2020-6-3 今天还是学了不少东西，效率不高，主要是记不住函数传参数！ 掌握了一些pythonic的用法，想in for if ; if else 的一行代码；lambda单行函数功能的简化等等 一些常用的数据分析函数，sort_values();concat; append; time_range();绘图功能；就是就不知道，肯定是别人已经封装好了！ 2020-6-2 今天总体还是满不错的！ 跑了大程序，自己的电脑和服务器的效果还真是不相同。不过，能够做到200行内不调试就能好了，现在找到了写代码的感觉，虽然还是bugbugbug, 原因在于开始交接工作没有做好，导致反反复复的修改codes. 在师兄的介绍下，接了一个时间序列的项目。在毕业设计那会，跑天然气数据，出来了的结果太差了，也不知道why,这次希望能够跟进这个项目。 感觉自己还留有余地，还没有恢复到最佳状态呐~~~~~ 2020-6-1 今天刚好是2020年的一半，忙完第一学期（半梦半醒）,最终如梦初醒！ 今天接触许多新鲜的玩意： ArcMap绘制地图、流向图（关键是起点和终点坐标，如何根据名称获取坐标，要做连接。Arc ToolBox中提供了许多工具，方便了用户完成一些简单的操作，如Join、Excel to Tabel常用的工具箱。今天学习绘制地图和流向图涉及的操作包括：文件夹链接到工作目录；ArcMap导入Excel坐标数据并显示；XY to Line工具流向图；提取面要素的质心点；多表链接操作；属性设置（bar)。渲染结果的确漂亮 linux系统后端运行 nohup &amp;命令的使用，如何记录日志文件，定向输出；学了ps命令 ps 查看进程；还有|通道，grep查找； ps -ef| grep pyton matplotlib绘图的原理。 123456789101112131415创建figure后，还需要轴fig = plt.figure()ax1 = fig.add_subplot(221)ax2 = fig.add_subplot(222)ax3 = fig.add_subplot(224)fig, axes = plt.subplots(nrows=2, ncols=2)axes[0,0].set(title=&apos;Upper Left&apos;)axes[0,1].set(title=&apos;Upper Right&apos;)axes[1,0].set(title=&apos;Lower Left&apos;)axes[1,1].set(title=&apos;Lower Right&apos;)axes[0,0].plot()axes[0,0].set_xlim([-1,6])axes[0,0].legend() matplotlib.plot的基础绘图流程： 创建画布（选择是否绘制子图，指定画布大小，像素） 添加标题–添加x轴的名称，刻度与范围–添加y轴的名称，刻度与范围 绘制图形，设置图形的样式，颜色，背景，并添加图例 保存图形，显示图形 感谢爷爷提供的CSDN账号 下载不少资料，一次性解决完了！ 2020-5-31 这是上完研究生第一学期上，第二学期下中旬！也是隔了很久才更新个人记录。 研一上，换了一个新环境，终于有个特别舒适的环境了！大屏幕，柔软的凳子,太舒服了！怎可辜负呢。 电科的课程实在是太多了，都不能安心玩耍了！ 这段时间算个积淀吧！ 2019.6.2 今天才来写，罪过啊！老师不在，室友不在，无聊至极，只能以视频唯友，解闷也！睡了一个星期，但是我瘦了2斤了。开始不在懒惰了，在这样下去我就完蛋了。。。。。。。 不知道怎么回事，VPN老是 time out ,明明还有$啊！ 造成了只能一段一段翻译，无语凝噎ing 还有百度上说是两篇，可是要求是一篇，于是我多花了2h,天杀的！！！ 下午跑了个步， 越来越发现，事先计划一下，再去做，效率更好了！ 2019.5.12 今天才来更新这个日常，真是罪过，上段时间一直忙其他的事情，毕业设计，回家，处理家务啊。直到今天学完了Course 3,如何改善神经网络的性能，还有英语学习，一定要加油啊！ 2019.4.18 今天学了一部分course two week two的课程，终于学到精彩的部分了，由于今天想练彩铅和帮忙收拾教室，所以就没有学完了，学了几种变种的梯度下降法，提高速度，太棒了，太棒了，太棒了！！！！！！ 2019.4.17 今天学完国course two的第一周课程，大概记时4h，还是颇多收获，学到了以前完全没有接触的东西，正则化方法，梯度消失的和爆炸的问题，感觉很棒， 2019.4.16 今天学了吴恩达老师的第一周关于神经网络的基础的课程，好厉害的 2019.4.15 今天学习了deep-layer neural network的正向传播和反向传播的过程，矩阵化计算的方式。 2019.4.14 今天学习了第三周课程，shallow (2层)神经网络的正向传播和反向传播，以及矩阵化的计算方式，以及和logistics regression的表示上的不同地方 2019.4.13 今天继续学习第二周课程，logistics regression 的模型，策略，算法的相关，如何把学习的到数学知识应用上去。 2019.4.12 今天没有去跑步，处理一些情感问题去了，学了Androw Ng的 第二周的部分课程，主要是链式求导法则，通过计算图，一步一步的复合求导，复合函数用计算图表示，并链式求导 2019.4.11 今天是很愉快的一天，起的很早，精神很足，学了学习，写完了吴恩达老师的第一周深度学习。 2019.4.10 今天刷完了第一遍，完了西瓜书第一章到第十一章，不过呢，还是要继续在刷基础还看论文 这段时间，跑步锻炼第一，睡觉，贪睡第二，第三，开始散漫了，自律的我，在哪里去了啊！ 争取在上研究生这段时间，把机器学习、Python编程能力提升上去 今天晚上弄了一个，吴恩达的deep Learning Ai课程笔记，开始学习这个系列的课程了 笔记模板 英文：http://dl-notes.imshuai.com/#/](http://dl-notes.imshuai.com/#/c1w1) 什么都有的 https://redstonewill.com/category/deeplearning/ 中文笔记： 详细，相当于翻译： http://www.ai-start.com/dl2017/html/lesson1-week1.html 思考和总结： https://link.zhihu.com/?target=http%3A//kyonhuang.top/Andrew-Ng-Deep-Learning-notes/ https://zhuanlan.zhihu.com/p/35333489 http://imshuai.com/tag/deeplearning-ai-notes/ https://zhuanlan.zhihu.com/koalatree 上班族的学习时长： 整理笔记要明显消耗更多的时间，基本上10分钟的视频，做笔记至少要50分钟才能看完。每周的视频大概在2-3个小时，这就意味着看学习视频就要10-15个小时。编程作业3个小时左右，每周平均在15个小时，16周的课，净时间就花了240个小时！ video https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists 西瓜书的公式推导： https://datawhalechina.github.io/pumpkin-book/#/chapter1/chapter1 统计机器学习： https://github.com/SmirkCao/Lihang 2019.3.23-2019.3.24 今天（今天）是周末，两个早上都睡觉去了，处理一下，我弟弟的问题，和孩子交流的重要性，晚上什么都没有干，周日下午跑了步，学习了python sci-learn里面的交叉验证、超参数选择，集成学习库的用法，终于不再迷茫了，慢慢来 及时的记录学习过程 多去看别人的进展 去做别人没有做过的事情 只有你努力，努力的方向是正确的，就可以做出伟大的成就 https://zhuanlan.zhihu.com/p/29704017 2019.3.21 今天了解一下操盘，就是那个股票，感觉做数据科学家好吃香啊，加油，接下来有得忙了 2019.3.20 今天终于看了文献，想出了一个创新点子，可以发文章了，加油喔。 编写完了测试程序，加油 2019.3.19 今天早上看了关于许多灰色模型的现阶段文献，很受启发，感觉读文献真的对能力、思维的提高很大，也发现自己的潜力很大，加油，加油，加油，继续读，产生一些小点子，虽然不够好，但是也是突破 2019.3.18 今天看病去了，睡了好久，药物作用果然出乎意料， 2019.3.17 今天主要学习支持向量机的前世今生，怎么由来的 2019.3.16 今天周六，放松了一下自己，重新回归一下灰色预测模型，尤其是离散方程，其实去掉背景，抓住数学模型，才知道其实就是这样的，希望早日突破自己的界限 2019.3.14 今天改了论文，感觉快完了；学习了BP矩阵推导，人真的是越来越聪明和灵活 2019.3.13 今天晚上学完了回归树，好棒，虽然原理给人的感觉很直接，但是也是一种体现 2019.3.12 今天跑了步，早上改了毕业设计，下午配置了新手机，晚上写了日记 2019.3.11 今天早上听了听力，修改了毕业设计，核函数还是不是很懂；下午看了决策回归树，感觉很棒，过拟合才是该解决的关键问题！跑了步，感觉自己身体状况很不好啊！ 晚上听力电台，写了程序！ 慢慢的学习，慢慢的努力，慢慢的加油，慢慢的遇见自己的憧憬天空 2019.3.10 今天写了日记，说不上自己哪里郁闷，哪里开心！希望早点跑完程序，早点完事 2019.3.9 今天才发现，最近状态非常的不好，可能是无所事事吧，可是我有很多事情要做，加油，少女，加油，少女，以后一定要记得写了!总觉得自己逃不出自己的羁绊，被束缚 2019.2.28 今天调整自己的心态，回顾自己的生活，自己太急于求成了，心急吃不了热豆腐啊！！！！！ 中国有句老话说得对，积少成多，不积跬步无以至千里，不积小流无以成江河，慢慢来，弄透弄清楚 最后，英语+数学+编程+解决问题的能力 2019.2.27 今天早上，我读了同校同学写的简书文章，实在是感到好想笑，搜索了别人的解决方法，还是自己的知识量不足啊！！！！！！！！ 下午看了下假设检验的视频，再去跑了两个小时的步 晚上逛了一下午各位网站 2019.2.26 今天看了下某个计算机大佬的历程，深深地感到佩服。 《梦想小镇》又多了一块地盘了， 又重新学习了matplotlib,才发现,然后了玩了一下sklearn里面的带cross-validation的lasso的regression 再kaggle housr-prices 里面，rmse=$0.15386$,rank = 2903,不过做得也相当 2019.02.25 今天好像不在状态，可能是焦虑+迷茫，有动力，动力的方向在哪里啊！，还是好好的做好当下吧！ 阿西吧 2019.02.24 今天特别不想起床，有点小感冒，整理周志华的第一章笔记 下午总结日前学习的python库 顺便去kaggle做了小练习，数据的预处理工作。]]></content>
      <categories>
        <category>学习の历程(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
</search>
