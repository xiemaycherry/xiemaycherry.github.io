<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2020%2F09%2F06%2F%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%2FFeatureExtraction%2F</url>
    <content type="text"><![CDATA[Principal Component Analysis** : ä¸»æˆåˆ†åˆ†æå½¢è±¡ç†è§£å¦‚å›¾ï¼Œä¸‹é¢æ˜¯ä¸€å¼ 3dçš„å›¾ç‰‡ï¼Œä»ä¸åŒçš„æ–¹å‘æŠ•å½±å‡ºæ¥çš„äºŒç»´å›¾ï¼Œå¯ä»¥çœ‹å‡ºå³å¾€å·¦æŠ•å½±çš„å«æœ‰æ›´å¤šä¿¡æ¯ã€‚ å¦‚å›¾ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼ŒäºŒç»´ç‚¹å¾€ä¸¤ä¸ªæ­£äº¤çš„æ–¹å‘æŠ•å½±ï¼Œé•¿è½´å«æœ‰çš„ä¿¡æ¯æ›´å¤šã€‚ PCAçš„è¿‡ç¨‹ç¤ºæ„Step 1 : å»ä¸­å¿ƒã€‚ä¸­å¿ƒåœ¨åæ ‡è½´åœ¨ï¼ˆ0,0)ï¼Œå‡å€¼åœ¨åæ ‡è½´åŸç‚¹ Step 2 : Remove correlation(å»é™¤ç›¸å…³æ€§) é€šè¿‡åæ ‡å˜åŒ–ï¼Œåæ ‡æ—‹è½¬ï¼ŒçŸ©é˜µä½œç”¨ æ•°å­¦æ¨å¯¼ç›®æ ‡ï¼šå˜æ¢åçš„çŸ©é˜µï¼Œå¯¹è§’éé›¶ï¼Œéå¯¹è§’çº¿å…¨ä¸ºé›¶ã€‚S(Y)æœ‰éé›¶çš„å¯¹è§’å…ƒç´ ï¼Œæ‰€æœ‰éå¯¹è§’å…ƒç´ éƒ½æ˜¯é›¶ ç†è®ºæ¨å¯¼ PCA Examples PCA bias]]></content>
  </entry>
  <entry>
    <title><![CDATA[å¿ƒè·¯å†ç¨‹]]></title>
    <url>%2F2020%2F09%2F06%2Frecording%20of%20master%2FMyMain%2F</url>
    <content type="text"><![CDATA[From 2019-09-31 to 2019-11-10è¿‡å®Œäº†ç ”ä¸€çš„ç¬¬ä¸€ä¸ªåå‘¨ï¼Œå†…å¿ƒå¾ˆç©ºè™šï¼Œæåº¦çš„ç©ºè™šï¼Œä¸çŸ¥é“æ€ä¹ˆå›äº‹ï¼Ÿæˆ‘è§‰å¾—åŸå› æ˜¯ï¼šè‡ªå·±å¯¹è‡ªå·±çš„è¦æ±‚å¤ªé«˜äº†ï¼Œè¦æ±‚è‡ªå·±åšçš„äº‹æƒ…å¤ªå¤šäº†ï¼Ÿç»“æœä»€ä¹ˆéƒ½æ²¡æœ‰åšå¥½ã€‚ å¯¹äºè‡ªå·±çš„å»ºè®¾ï¼Œæˆ‘å°è¯•äº†å¾ˆå¤šçš„ä¸œè¥¿ï¼ŒåŒ–å¦†å’Œæ‰“æ‰®ã€‚æˆ‘è§‰å¾—æˆ‘è¿˜æ²¡æœ‰æ¼‚äº®çš„èµ„æœ¬ï¼Œæ²¡é’±ï¼Œæ²¡æˆ¿ã€‚æ‰€ä»¥ä¸€å®šè¦éå¸¸çš„åŠªåŠ›æ‰è¡Œã€‚æˆ‘åªå¸Œæœ›æˆ‘æœ€çˆ±çš„äººï¼Œé…å¾—ä¸Šæˆ‘ï¼Œæˆ‘å¸Œæœ›æˆ‘ä»¬æ˜¯å…±åŒå¥‹æ–—çš„çŠ¶æ€äº†ï¼Œè€Œä¸æ˜¯ä¾é ã€‚æ‰€ä»¥å°½é‡ä¸åŒ–å¦†å‡ºé—¨ï¼Œé™¤äº†é‡è¦åœºåˆã€‚ å¯¹äºå­¦ä¹ æ–¹é¢ï¼Œäº†è§£äº†é«˜é“èƒŒæ™¯ï¼Œè¿˜æ˜¯æ²¡æœ‰è¿›å…¥çŠ¶æ€ï¼Œæ‰€ä»¥è¦æ›´åŠªåŠ›æ‰è¡Œã€‚æœ€è¿‘çš„è¯¾ç¨‹å¤ªå¤šäº†ï¼Œå¹³è¡¡å•Šï¼æˆ‘å¿ƒæœ‰ä½™è€ŒåŠ›ä¸è¶³çš„ã€‚è¿˜æœ‰ä¸€å®šè¦ä¼šè¯´ï¼Œä¸å¥½è¯´ã€‚æ¥ä¸‹æ¥ä¸€å®šè¦é©¬åŠ›åè¶³çš„å‡ºå‘ã€‚ å¯¹äºäººï¼Œå¯èƒ½è¿™é‡Œåªæ˜¯ä¸‰å¹´çš„ä¸€æ®µæ—¶å…‰ï¼Œå¾ˆå¥½ç›¸å¤„å°±å¥½äº†ï¼Œæœ€é‡è¦çš„æ˜¯ç”·æœ‹å‹å’Œå®¤å‹ã€‚ å¯¹ä¸èµ·ï¼Œæˆ‘è¿˜æœ‰å¥‹æ–—ï¼Œæˆ‘è¦å¥‹æ–—ï¼Œæˆ‘è¦å¥‹æ–—ã€‚è¿˜æœ‰å¥èº«ã€‚ æˆ‘çš„æ—¶é—´éƒ½åˆ†æ•£åœ¨å…¶ä»–è§†é¢‘çš„äº‹æƒ…ä¸Šäº†ï¼Œæœç»å•Šï¼æ¯å¤©æœ€å¤šä¸¤å°æ—¶ã€‚å°½é‡ä¸ç©æ‰‹æœºäº†ï¼ï¼ï¼ï¼]]></content>
      <tags>
        <tag>æˆé•¿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å¯è§†åŒ–]]></title>
    <url>%2F2020%2F09%2F04%2F%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B9%8Borigin%2F</url>
    <content type="text"><![CDATA[æ­¤ç¯‡å°†è¯¦ç»†ç»™å‡ºå¦‚ä½•åˆ©ç”¨originç»˜åˆ¶å¸¸ç”¨çš„å›¾ï¼ŒåŒ…æ‹¬å•å˜é‡ï¼ŒåŒå˜é‡ï¼Œä»¥åŠå¤šå˜é‡ç›¸å…³çš„å›¾ã€‚åŒæ—¶ï¼Œä¹Ÿè¦è®²è§£å¦‚ä½•é…è‰²ï¼Œå­—ä½“è®¾ç½®ï¼Œå­å›¾è®¾ç½®ç­‰ç­‰æŠ€å·§ã€‚ [TOC] OriginOriginç»˜åˆ¶è¾¹é™…ç›´æ–¹å›¾plot-statistics-è¾¹é™…ç›´æ–¹å›¾ Originç»˜åˆ¶ç›¸å…³æ€§å›¾Step1: ç»˜åˆ¶æ•£ç‚¹å›¾ Step2ï¼šanalysis å¢åŠ çº¿æ€§å›å½’ å¯ä»¥å¾—åˆ°å›å½’æ›²çº¿ï¼Œå›å½’ç³»æ•°å’Œç›¸å…³æ€§ç³»æ•° å½“ç„¶ä¹Ÿå¯ä»¥é€šè¿‡è®¡ç®—ï¼Œç›´æ¥æ·»åŠ åˆ°å›¾é‡Œé¢ æ³¨æ„ï¼šå›å½’åˆ†æ+å›¾å½¢æ˜¯é€šè¿‡å¤šéƒ¨å®Œæˆçš„ã€‚å…ˆç»˜åˆ¶ä½ éœ€è¦çš„å›¾å½¢ï¼Œåœ¨åŠ å…¥ç»Ÿè®¡åˆ†æï¼Œä»¥åŠä¸€äº›è®¡ç®—æ•°æ®ã€‚ Originåˆ¶ä½œç›¸å…³ç³»æ•°çŸ©é˜µå›¾RRç»˜åˆ¶ç›¸å…³ç³»æ•°çŸ©é˜µRç»˜åˆ¶æ¡‘åŸºå›¾Arcgisæ„Ÿè§‰Arcgis æ˜¯ä¸“é—¨é’ˆå¯¹åœ°ç†ä¿¡æ¯ç»˜å›¾çš„ï¼Œæ˜æ˜¾ä½¿ç”¨èµ·æ¥æ–¹ä¾¿å¾ˆå¤šã€‚ Arcgisç»˜åˆ¶åœ°å›¾Arcgisç»˜åˆ¶å¾„å‘å›¾Global MapperEcharthttps://echarts.apache.org/examples/zh/index.html#chart-type-map ä¸Šæ‰‹ç¬¬ä¸€ä¸ª12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;ECharts&lt;/title&gt; &lt;!-- å¼•å…¥ echarts.js --&gt; &lt;script src="echarts.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- ä¸ºEChartså‡†å¤‡ä¸€ä¸ªå…·å¤‡å¤§å°ï¼ˆå®½é«˜ï¼‰çš„Dom --&gt; &lt;div id="main" style="width: 600px;height:400px;"&gt;&lt;/div&gt; &lt;script type="text/javascript"&gt; // åŸºäºå‡†å¤‡å¥½çš„domï¼Œåˆå§‹åŒ–echartså®ä¾‹ var myChart = echarts.init(document.getElementById('main')); // æŒ‡å®šå›¾è¡¨çš„é…ç½®é¡¹å’Œæ•°æ® var option = &#123; title: &#123; text: 'ECharts å…¥é—¨ç¤ºä¾‹' &#125;, tooltip: &#123;&#125;, legend: &#123; data:['é”€é‡'] &#125;, xAxis: &#123; data: ["è¡¬è¡«","ç¾Šæ¯›è¡«","é›ªçººè¡«","è£¤å­","é«˜è·Ÿé‹","è¢œå­"] &#125;, yAxis: &#123;&#125;, series: [&#123; name: 'é”€é‡', type: 'bar', data: [5, 20, 36, 10, 10, 20] &#125;] &#125;; // ä½¿ç”¨åˆšæŒ‡å®šçš„é…ç½®é¡¹å’Œæ•°æ®æ˜¾ç¤ºå›¾è¡¨ã€‚ myChart.setOption(option); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; é…ç½®éœ€è¦é…ç½®ä»€ä¹ˆæ‰¾åˆ°éœ€è¦çš„æ ‡ç­¾ï¼Œç„¶åè®¾ç½®æˆå¯¹åº”çš„å€¼å°±å¥½äº†ï¼ è‰²å½©æ­é…å­—ä½“å’Œå­—å·å¤„ç†AIæ¸²æŸ“â€”â€”åæœŸå¤„ç†]]></content>
      <categories>
        <category>æ•°æ®å¯è§†åŒ–</category>
      </categories>
      <tags>
        <tag>ç»˜å›¾</tag>
        <tag>origin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç›®å½•â€”â€”æ•°æ®åˆ†æ]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç›®å½•â€”â€”æ·±åº¦å­¦ä¹ ]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
      <categories>
        <category>æ·±åº¦å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç›®å½•â€”â€”æœºå™¨å­¦ä¹ ]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%9B%AE%E5%BD%95%E2%80%94%E2%80%94%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ç”Ÿæ´»æ”»ç•¥]]></title>
    <url>%2F2020%2F08%2F28%2F%E7%94%9F%E6%B4%BB%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[2020202008ç”µè„‘æ–‡ä»¶ç®¡ç†ç¬¬ä¸€æ¬¡å°±è¦æŠŠæ–‡ä»¶ä½ç½®ç¡®å®šã€‚ ä¸»è¦æ˜¯æ¢³ç†ç”µè„‘æ–‡ä»¶ç®¡ç†çš„æŠ€å·§ï¼Œæ–¹ä¾¿ä»¥åæé«˜å·¥ä½œæ•ˆç‡ã€‚ å‘½åæ–¹æ³•ã€‚é‡‡ç”¨3W1Xçš„ç†å¿µï¼Œwhen-work-who-X(å¤‡æ³¨)ï¼Œâ€œ3Wâ€åˆ†åˆ«æŒ‡ï¼šWhenæ—¶é—´â€”â€”20200630ï¼›Workäº‹é¡¹â€”â€”é”€å”®éƒ¨è¥é”€è®¡åˆ’ï¼›Whoä¸»ä½“â€”â€”å®¢æˆ·Aã€‚ â€œ1Xâ€æ˜¯æŒ‡ï¼šXå¤‡æ³¨â€”â€”ç¬¬ä¸‰ç‰ˆã€‚ åŒä¸€æ–‡ä»¶ï¼Œå¤šä¸ªä¿®æ”¹ç‰ˆæœ¬ã€‚æ–‡ä»¶åå‰é¢åŠ ä¸Šä¿®æ”¹äººï¼Œåœ¨æœ€ååŠ ä¸Šç‰ˆæœ¬å·ã€‚ åŒä¸€ä»»åŠ¡ï¼ˆä¸»é¢˜ï¼‰æ–‡ä»¶å¤¹ç®¡ç†ã€‚åŒçº§æœ€å¤š7ä¸ªæ–‡ä»¶å¤¹ï¼Œæœ€å¤š5å±‚ã€‚ åŠæ—¶å¤ç›˜å¾ˆå…³é”®ã€‚ 1. æ¯æ˜ŸæœŸè¦æ•´ç†ä¸€æ¬¡æ–‡ä»¶å¤¹ã€‚ 2. é‡è¦æ–‡ä»¶è¦åŒæ­¥ã€‚]]></content>
      <categories>
        <category>ç”Ÿæ´»æ”»ç•¥</category>
      </categories>
      <tags>
        <tag>æŠ€å·§</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BLOG ã® ç›®å½•]]></title>
    <url>%2F2020%2F08%2F28%2Fcategories%2F</url>
    <content type="text"><![CDATA[BLOG ã® ç›®å½•ç»Ÿä¸€ç”¨ä¸­æ–‡ æ•°å­¦ (Mathematics) æ•°å­¦çŸ¥è¯† æœºå™¨å­¦ä¹ ï¼ˆMachine Learning) æ€»ç›®å½• ç®—æ³•ï¼Œæ¨¡å‹ å®ç° æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰ 1. æ€»ç›®å½• ç®—æ³• å®ç° ç¼–ç¨‹è¯­è¨€ ï¼ˆProgram Languageï¼‰ æ€»ç›®å½• C Python è®¡ç®—æœºç›¸å…³çŸ¥è¯† æ•°æ®åˆ†æ æ€»ç›®å½• å¯è§†åŒ– ä¸šåŠ¡çŸ¥è¯† åˆ†ææ€ç»´ æ•°æ®åº“ æ•°æ®æŒ–æ˜ é¡¹ç›®å®æˆ˜ å­¦ä¹ æ—¥å¸¸ ï¼ˆStudying Diaryï¼‰ ä¸»è¦æ˜¯æ¯å¤©çš„å­¦ä¹ è®°å½• æ‚ä¸ƒæ‚å…«ï¼ˆMixed) å…¶ä»–é¢†åŸŸçš„çŸ¥è¯† ç”Ÿæ´»æ”»ç•¥ å­¦ä¹ å†ç¨‹ï¼ˆJourney of Studying) ä¸»è¦æ˜¯ä¹¦ç±èµ„æ–™çš„å­¦ä¹ ï¼ˆä¸€æœ¬ä¸€ç¯‡ï¼‰è¯¦ç»†çš„è®°å½•åœ¨æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ é‡Œé¢]]></content>
      <categories>
        <category>Categories</category>
      </categories>
      <tags>
        <tag>Categories</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ•°æ®åˆ†æä¹‹æ•°æ®åˆ†æèŒè´£]]></title>
    <url>%2F2020%2F08%2F27%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E8%B4%A3%2F</url>
    <content type="text"><![CDATA[æŠ€æœ¯+ä¸šåŠ¡ ä¸šåŠ¡+æŠ€æœ¯ï¼Œè‡³å°‘æ‡‚è¿™äº› æœ¯ä¸šæœ‰ä¸“æ”»ï¼ŒçŸ¥è¯†è¦å¹¿æ³›ï¼Œæ˜¯èŒä¸šå‘å±•çš„åŸºæœ¬å‡†åˆ™ã€‚ç‰¹åˆ«å¯¹æ•°æ®åˆ†æå¸ˆè¿™æ ·ä¸€ä¸ªå¤šé¢æ‰‹å‹è§’è‰²ã€‚é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥äº†è§£åˆ°ä»€ä¹ˆç¨‹åº¦å‘¢ï¼Ÿè¿™é‡Œæœ‰ä¸ªå»ºè®®ï¼š ä¸šåŠ¡æ–¹å‘åˆ†æå¸ˆï¼šæ•°æ®é‡‡é›†æ–¹å¼ã€æ•°æ®å­—æ®µæ ¼å¼ã€æŒ‡æ ‡çš„è®¡ç®—å£å¾„ä¸æ›´æ–°æ—¶é—´è¿™ä¸‰ä¸ªæ˜¯å¿…é¡»å¿…é¡»çŸ¥é“çš„ã€‚å› ä¸ºè¿™ä¸‰ç‚¹æ¶‰åŠåˆ°æ•°æ®çœŸå®æ€§ä¸å¯é æ€§ã€‚æ²¡æœ‰æ•°æ®è´¨é‡åšä¿è¯ï¼Œä»€ä¹ˆåˆ†æéƒ½æ˜¯ç©ºè°ˆã€‚å¯¹åŸºç¡€æ•°é‡è¶Šäº†è§£ï¼Œè¶Šèƒ½ä»ç»†èŠ‚ä¸­æ‰¾åˆ°æ€è·¯ï¼›ç®—æ³•æ¨¡å‹çš„ç§ç±»ä¸åº”ç”¨åœºæ™¯æ˜¯å¿…é¡»äº†è§£çš„ã€‚å› ä¸ºè¿™æ¶‰åŠåˆ°å¦‚ä½•é€‰æ‹©åˆ†ææ–¹æ³•ï¼Œå¦‚ä½•æå‡åˆ†æè´¨é‡ã€‚å…·ä½“ä»£ç æ€ä¹ˆå†™ï¼Œå¼„æ‡‚å°±æ‡‚ã€‚ æŠ€æœ¯æ–¹å‘åˆ†æå¸ˆï¼šä¸šåŠ¡éƒ¨é—¨åˆ†å·¥ã€èŒè´£ã€æµç¨‹å¿…é¡»è¦äº†è§£ã€‚è‡³å°‘èŒè´£æ¸…æ™°ï¼ŒçŸ¥é“è‡ªå·±è¦å¯¹æ¥çš„äººåˆ°åº•æ˜¯å¹²ä»€ä¹ˆã€‚è‡ªå·±å¯¹åº”éƒ¨é—¨å¸¸è§çš„ä¸šåŠ¡éœ€æ±‚ï¼Œå¦‚é”€å”®åˆ†æã€ç»è¥åˆ†æã€ä¿ƒé”€åˆ†æã€å•†å“ç®¡ç†çš„æ–¹æ³•è¦æœ‰æ‰€äº†è§£ã€‚åœ¨é¢å¯¹ä¸šåŠ¡éƒ¨é—¨éœ€æ±‚çš„æ—¶å€™ï¼Œå¤§æ¦‚çŸ¥é“ä»–ä»¬åœ¨æƒ³ä»€ä¹ˆï¼Œæœ‰ä»€ä¹ˆå¥—è·¯ã€‚å¸®åŠ©è‡ªå·±æ›´å¥½çš„ç†è§£éœ€æ±‚ï¼Œè§„é¿éœ€æ±‚å¤§å‘ã€‚]]></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>èŒä½è¦æ±‚</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ•°æ®åˆ†ææŠ€èƒ½]]></title>
    <url>%2F2020%2F08%2F25%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD%2F</url>
    <content type="text"><![CDATA[https://ask.hellobi.com/blog/qinlu/sitemap/ SQL å­¦ä¼šç›´æ¥æŠŠåˆ«äººçš„çŸ¥è¯†è£…è¿›è‡ªå·±çš„è„‘å­é‡Œhttps://www.zhihu.com/xen/market/personal-works-all/houziliaorenwu?zh_hide_tab_bar=true LeetCode &amp; NowCoderhttps://leetcode.com/problemset/database/ https://www.nowcoder.com/ta/sql å…³ç³»å‹æ•°æ®åº“MySQLæ•°æ®ç±»å‹ä¸»è¦æä¾›äº†ä¸‰ç§ç±»å‹ï¼Œåˆ†åˆ«æ˜¯æ–‡æœ¬ï¼Œæ•°å­—å’Œæ—¥æœŸã€‚ MySQL æ•°æ®ç±»å‹åœ¨ MySQL ä¸­ï¼Œæœ‰ä¸‰ç§ä¸»è¦çš„ç±»å‹ï¼šæ–‡æœ¬ã€æ•°å­—å’Œæ—¥æœŸ/æ—¶é—´ç±»å‹ã€‚ Text ç±»å‹ï¼š æ•°æ®ç±»å‹ æè¿° CHAR(size) ä¿å­˜å›ºå®šé•¿åº¦çš„å­—ç¬¦ä¸²ï¼ˆå¯åŒ…å«å­—æ¯ã€æ•°å­—ä»¥åŠç‰¹æ®Šå­—ç¬¦ï¼‰ã€‚åœ¨æ‹¬å·ä¸­æŒ‡å®šå­—ç¬¦ä¸²çš„é•¿åº¦ã€‚æœ€å¤š 255 ä¸ªå­—ç¬¦ã€‚ VARCHAR(size) ä¿å­˜å¯å˜é•¿åº¦çš„å­—ç¬¦ä¸²ï¼ˆå¯åŒ…å«å­—æ¯ã€æ•°å­—ä»¥åŠç‰¹æ®Šå­—ç¬¦ï¼‰ã€‚åœ¨æ‹¬å·ä¸­æŒ‡å®šå­—ç¬¦ä¸²çš„æœ€å¤§é•¿åº¦ã€‚æœ€å¤š 255 ä¸ªå­—ç¬¦ã€‚æ³¨é‡Šï¼šå¦‚æœå€¼çš„é•¿åº¦å¤§äº 255ï¼Œåˆ™è¢«è½¬æ¢ä¸º TEXT ç±»å‹ã€‚ TINYTEXT å­˜æ”¾æœ€å¤§é•¿åº¦ä¸º 255 ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚ TEXT å­˜æ”¾æœ€å¤§é•¿åº¦ä¸º 65,535 ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚ BLOB ç”¨äº BLOBs (Binary Large OBjects)ã€‚å­˜æ”¾æœ€å¤š 65,535 å­—èŠ‚çš„æ•°æ®ã€‚ MEDIUMTEXT å­˜æ”¾æœ€å¤§é•¿åº¦ä¸º 16,777,215 ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚ MEDIUMBLOB ç”¨äº BLOBs (Binary Large OBjects)ã€‚å­˜æ”¾æœ€å¤š 16,777,215 å­—èŠ‚çš„æ•°æ®ã€‚ LONGTEXT å­˜æ”¾æœ€å¤§é•¿åº¦ä¸º 4,294,967,295 ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚ LONGBLOB ç”¨äº BLOBs (Binary Large OBjects)ã€‚å­˜æ”¾æœ€å¤š 4,294,967,295 å­—èŠ‚çš„æ•°æ®ã€‚ ENUM(x,y,z,etc.) å…è®¸ä½ è¾“å…¥å¯èƒ½å€¼çš„åˆ—è¡¨ã€‚å¯ä»¥åœ¨ ENUM åˆ—è¡¨ä¸­åˆ—å‡ºæœ€å¤§ 65535 ä¸ªå€¼ã€‚å¦‚æœåˆ—è¡¨ä¸­ä¸å­˜åœ¨æ’å…¥çš„å€¼ï¼Œåˆ™æ’å…¥ç©ºå€¼ã€‚æ³¨é‡Šï¼šè¿™äº›å€¼æ˜¯æŒ‰ç…§ä½ è¾“å…¥çš„é¡ºåºå­˜å‚¨çš„ã€‚å¯ä»¥æŒ‰ç…§æ­¤æ ¼å¼è¾“å…¥å¯èƒ½çš„å€¼ï¼šENUM(â€˜Xâ€™,â€™Yâ€™,â€™Zâ€™) SET ä¸ ENUM ç±»ä¼¼ï¼ŒSET æœ€å¤šåªèƒ½åŒ…å« 64 ä¸ªåˆ—è¡¨é¡¹ï¼Œä¸è¿‡ SET å¯å­˜å‚¨ä¸€ä¸ªä»¥ä¸Šçš„å€¼ã€‚ Number ç±»å‹ï¼š æ•°æ®ç±»å‹ æè¿° TINYINT(size) -128 åˆ° 127 å¸¸è§„ã€‚0 åˆ° 255 æ— ç¬¦å·*ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚ SMALLINT(size) -32768 åˆ° 32767 å¸¸è§„ã€‚0 åˆ° 65535 æ— ç¬¦å·*ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚ MEDIUMINT(size) -8388608 åˆ° 8388607 æ™®é€šã€‚0 to 16777215 æ— ç¬¦å·*ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚ INT(size) -2147483648 åˆ° 2147483647 å¸¸è§„ã€‚0 åˆ° 4294967295 æ— ç¬¦å·*ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚ BIGINT(size) -9223372036854775808 åˆ° 9223372036854775807 å¸¸è§„ã€‚0 åˆ° 18446744073709551615 æ— ç¬¦å·*ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚ FLOAT(size,d) å¸¦æœ‰æµ®åŠ¨å°æ•°ç‚¹çš„å°æ•°å­—ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚åœ¨ d å‚æ•°ä¸­è§„å®šå°æ•°ç‚¹å³ä¾§çš„æœ€å¤§ä½æ•°ã€‚ DOUBLE(size,d) å¸¦æœ‰æµ®åŠ¨å°æ•°ç‚¹çš„å¤§æ•°å­—ã€‚åœ¨æ‹¬å·ä¸­è§„å®šæœ€å¤§ä½æ•°ã€‚åœ¨ d å‚æ•°ä¸­è§„å®šå°æ•°ç‚¹å³ä¾§çš„æœ€å¤§ä½æ•°ã€‚ DECIMAL(size,d) ä½œä¸ºå­—ç¬¦ä¸²å­˜å‚¨çš„ DOUBLE ç±»å‹ï¼Œå…è®¸å›ºå®šçš„å°æ•°ç‚¹ã€‚ * è¿™äº›æ•´æ•°ç±»å‹æ‹¥æœ‰é¢å¤–çš„é€‰é¡¹ UNSIGNEDã€‚é€šå¸¸ï¼Œæ•´æ•°å¯ä»¥æ˜¯è´Ÿæ•°æˆ–æ­£æ•°ã€‚å¦‚æœæ·»åŠ  UNSIGNED å±æ€§ï¼Œé‚£ä¹ˆèŒƒå›´å°†ä» 0 å¼€å§‹ï¼Œè€Œä¸æ˜¯æŸä¸ªè´Ÿæ•°ã€‚ Date ç±»å‹ï¼š æ•°æ®ç±»å‹ æè¿° DATE() æ—¥æœŸã€‚æ ¼å¼ï¼šYYYY-MM-DDæ³¨é‡Šï¼šæ”¯æŒçš„èŒƒå›´æ˜¯ä» â€˜1000-01-01â€™ åˆ° â€˜9999-12-31â€™ DATETIME() *æ—¥æœŸå’Œæ—¶é—´çš„ç»„åˆã€‚æ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSæ³¨é‡Šï¼šæ”¯æŒçš„èŒƒå›´æ˜¯ä» â€˜1000-01-01 00:00:00â€™ åˆ° â€˜9999-12-31 23:59:59â€™ TIMESTAMP() *æ—¶é—´æˆ³ã€‚TIMESTAMP å€¼ä½¿ç”¨ Unix çºªå…ƒ(â€˜1970-01-01 00:00:00â€™ UTC) è‡³ä»Šçš„æè¿°æ¥å­˜å‚¨ã€‚æ ¼å¼ï¼šYYYY-MM-DD HH:MM:SSæ³¨é‡Šï¼šæ”¯æŒçš„èŒƒå›´æ˜¯ä» â€˜1970-01-01 00:00:01â€™ UTC åˆ° â€˜2038-01-09 03:14:07â€™ UTC TIME() æ—¶é—´ã€‚æ ¼å¼ï¼šHH:MM:SS æ³¨é‡Šï¼šæ”¯æŒçš„èŒƒå›´æ˜¯ä» â€˜-838:59:59â€™ åˆ° â€˜838:59:59â€™ YEAR() 2 ä½æˆ– 4 ä½æ ¼å¼çš„å¹´ã€‚æ³¨é‡Šï¼š4 ä½æ ¼å¼æ‰€å…è®¸çš„å€¼ï¼š1901 åˆ° 2155ã€‚2 ä½æ ¼å¼æ‰€å…è®¸çš„å€¼ï¼š70 åˆ° 69ï¼Œè¡¨ç¤ºä» 1970 åˆ° 2069ã€‚ * å³ä¾¿ DATETIME å’Œ TIMESTAMP è¿”å›ç›¸åŒçš„æ ¼å¼ï¼Œå®ƒä»¬çš„å·¥ä½œæ–¹å¼å¾ˆä¸åŒã€‚åœ¨ INSERT æˆ– UPDATE æŸ¥è¯¢ä¸­ï¼ŒTIMESTAMP è‡ªåŠ¨æŠŠè‡ªèº«è®¾ç½®ä¸ºå½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ã€‚TIMESTAMP ä¹Ÿæ¥å—ä¸åŒçš„æ ¼å¼ï¼Œæ¯”å¦‚ YYYYMMDDHHMMSSã€YYMMDDHHMMSSã€YYYYMMDD æˆ– YYMMDDã€‚ Day Ox00 å…¥é—¨ï¼šhttps://www.w3school.com.cn/sql/sql_syntax.asp é€šè¿‡SQLä½¿å¾—æ•°æ®æ“ä½œå‘˜æœ‰èƒ½åŠ›æŸ¥è¯¢ï¼Œä¿®æ”¹æ•°æ®åº“ã€‚ WhatSQLï¼šç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€ã€‚SQLå¯¹å¤§å°å†™ä¸æ•æ„Ÿã€‚ SQLè¯­å¥åé¢çš„åˆ†å·ï¼Ÿæœ‰äº›æ•°æ®åº“ç³»ç»Ÿè¦æ±‚æ¯æ¡SQLå‘½ä»¤çš„æœ«ç«¯ä½¿ç”¨åˆ†å·ï¼Œæ¥è¡¨ç¤ºè¯­å¥çš„ç»“æŸã€‚ åˆ†ç±»ï¼š æ•°æ®æ“ä½œè¯­è¨€ï¼ˆDML) è¿™éƒ¨åˆ†åŒ…æ‹¬æŸ¥è¯¢å’Œæ›´æ–°æŒ‡ä»¤ã€‚ SELECT - ä»æ•°æ®åº“è¡¨ä¸­è·å–æ•°æ® UPDATE - æ›´æ–°æ•°æ®åº“è¡¨ä¸­çš„æ•°æ® DELETE - ä»æ•°æ®åº“è¡¨ä¸­åˆ é™¤æ•°æ® INSERT INTO - å‘æ•°æ®åº“è¡¨ä¸­æ’å…¥æ•°æ® æ•°æ®å®šä¹‰è¯­è¨€ (DDL) è¿™éƒ¨åˆ†åŒ…æ‹¬åˆ›å»ºå’Œåˆ é™¤è¡¨æ ¼ï¼Œè¿˜æœ‰å®šä¹‰ç´¢å¼•(é”®)ï¼Œè§„å®šè¡¨ä¹‹é—´çš„é“¾æ¥ï¼Œå’Œè¡¨é—´çš„çº¦æŸã€‚ SQL ä¸­æœ€é‡è¦çš„ DDL è¯­å¥: â€‹ CREATE DATABASE - åˆ›å»ºæ–°æ•°æ®åº“ â€‹ ALTER DATABASE - ä¿®æ”¹æ•°æ®åº“ â€‹ CREATE TABLE - åˆ›å»ºæ–°è¡¨ â€‹ ALTER TABLE - å˜æ›´ï¼ˆæ”¹å˜ï¼‰æ•°æ®åº“è¡¨ â€‹ DROP TABLE - åˆ é™¤è¡¨ â€‹ CREATE INDEX - åˆ›å»ºç´¢å¼•ï¼ˆæœç´¢é”®ï¼‰ â€‹ DROP INDEX - åˆ é™¤ç´¢å¼• Day Ox00 ç®€å•æŸ¥è¯¢ï¼šSELECT : æŸ¥è¯¢è¯­å¥ä¸å¸¦æ¡ä»¶æŸ¥è¯¢è¯­å¥ 123SELECT åˆ—åç§°1, åˆ—åç§°2 FROM è¡¨åç§°SELECT * FROM è¡¨åç§°SELECT DISTINCT åˆ—åç§° FROM è¡¨åç§° //å»é™¤é‡å¤å€¼ æœ‰æ¡ä»¶æŸ¥è¯¢è¯­å¥ 1SELECT åˆ—åç§° FROM è¡¨åç§° WHERE åˆ— è¿ç®—ç¬¦ å€¼ WHERE è¿‡æ»¤å•æ¡è®°å½• 12345678910æ“ä½œç¬¦ æè¿°= ç­‰äº&lt;&gt; ä¸ç­‰äº&gt; å¤§äº&lt; å°äº&gt;= å¤§äºç­‰äº&lt;= å°äºç­‰äºBETWEEN åœ¨æŸä¸ªèŒƒå›´å†…LIKE æœç´¢æŸç§æ¨¡å¼æ³¨é‡Šï¼šåœ¨æŸäº›ç‰ˆæœ¬çš„ SQL ä¸­ï¼Œæ“ä½œç¬¦ &lt;&gt; å¯ä»¥å†™ä¸º !=ã€‚ WHERE è¿‡æ»¤ä¸¤ä¸ªä»¥ä¸Šçš„æ¡ä»¶è®°å½• AND / OR ä¸šåŠ¡èƒ½åŠ›å¦‚ä½•ç†è§£ä¸šåŠ¡æ•°æ® æ¯åˆ—çš„å«ä¹‰ æ•°æ®åˆ†æ ç”¨æˆ·æ•°æ® ä¸»è¦æ˜¯æŒ‡ç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼ˆæ€§åˆ«ï¼Œå¹´é¾„) è¡Œä¸ºæ•°æ® æŒ‡ç”¨æˆ·åšäº†ä»€ä¹ˆï¼ˆåœç•™æ—¶é—´) åšäº†ä»€ä¹ˆï¼Œæ—¶é•¿ï¼Œç‚¹å‡»æ¬¡æ•°ç­‰ç­‰ äº§å“æ•°æ® äº§å“åç§°ï¼Œç±»åˆ«ç­‰ç­‰ å¸¸è§çš„ä¸šåŠ¡æŒ‡æ ‡ æŒ‡æ ‡çš„å«ä¹‰ï¼Ÿç»´åº¦çš„å«ä¹‰ï¼Ÿå¦‚æœä½ ä¸èƒ½è¡¡é‡å°±ä¸èƒ½å¢é•¿ ç”¨æˆ·çš„ç›¸å…³çš„æŒ‡æ ‡ æ´»è·ƒç”¨æˆ· å®šä¹‰ï¼šæ—¶é—´ï¼šæ—¥DAU(Daily Active User)ï¼›å‘¨WAU(Weekly Active User)ï¼›æœˆMAU(Monthly Active User)ï¼› åŠ¨ä½œï¼šæ‰“å¼€ï¼›æ”¯ä»˜ï¼› æ´»è·ƒç‡ï¼šæ´»è·ƒç”¨æˆ·/æ€»äººæ•° å»é‡ç”¨æˆ·(ç»Ÿè®¡ï¼Œè‡³å°‘) æ˜¯å¦ä¸ç”¨æˆ·ä¿æŒç²˜æ€§ ç•™å­˜ å®šä¹‰ï¼šå¦‚å…³æ³¨å…¬ä¼—å·ï¼›å–æ¶ˆå…³æ³¨ï¼› ç›¸åï¼šæµå¤± ç¬¬ä¸€å¤©æ–°å¢ç”¨æˆ·ï¼Œåœ¨ç¬¬Nå¤©ä½¿ç”¨è¿‡äº§ä¸šçš„ç”¨æˆ·æ•°/ç¬¬ä¸€å¤©æ–°å¢ç”¨æˆ·æ•° æ¬¡æ—¥ç•™å­˜ç‡ï¼›ç¬¬Næ—¥ç•™å­˜ç‡ã€‚ ä¸åŒæ—¶æœŸçš„æµå¤±æƒ…å†µï¼Œæ‰¾æµå¤±åŸå›  æ–°å¢ æ—¥æ–°å¢ç”¨æˆ· é€šè¿‡ä¸åŒæ¸ é“çš„åˆ†æï¼Œå¯ä»¥åˆ¤æ–­ä¸åŒæ¸ é“çš„æ¨å¹¿æ•ˆæœ è¡Œä¸ºæ•°æ® PVï¼šè®¿é—®æ¬¡æ•° Page Viewï¼›é¡µé¢æµè§ˆçš„å­—æ•°ï¼›çœ‹äº†å‡ ä¸ªé¡µé¢ çœ‹ç”¨æˆ·çš„å–œå¥½ UV: è®¿é—®äººæ•° Unique Visitorï¼› è½¬å‘ç‡ è½¬åŒ–ç‡ï¼šè½¬å‘æŸåŠŸèƒ½çš„ç”¨æˆ·æ•°/çœ‹è§è¯¥åŠŸèƒ½çš„ç”¨æˆ·æ•° è½¬åŒ–ç‡ å¦‚åº—é“ºè½¬åŒ–ç‡ å¹¿å‘Šè½¬åŒ–ç‡ Kå› å­ è¡¡é‡æ¨èæ•ˆæœ =å¹³å‡æŸä¸ªç”¨æˆ·å‘å¤šå°‘äººå‘å‡ºé‚€è¯·/æ¥å—åˆ°é‚€è¯·çš„äººè½¬åŒ–ä¸ºæ–°ç”¨æˆ·çš„è½¬åŒ–ç‡ äº§å“æŒ‡æ ‡ æ€»é‡ï¼šæˆäº¤é¢ï¼›æˆäº¤é‡ï¼›è®¿é—®æ—¶é•¿ äººå‡ï¼šäººå‡ä»˜è´¹ï¼›ä»˜è´¹ç”¨æˆ·ï¼›äººå‡è®¿é—®æ—¶é•¿ ä»˜è´¹ï¼šä»˜è´¹ç‡ï¼ˆä»˜è´¹äººæ•°ï¼‰ï¼›å¤è´­ç‡ï¼ˆæ¶ˆè´¹ä¸¤æ¬¡ä»¥ä¸Šçš„äººæ•°)ï¼› äº§å“ï¼šçƒ­é”€ï¼›å¥½è¯„ï¼›å·®è¯„äº§ï¼› å¦‚ä½•é€‰æ‹©æŒ‡æ ‡ å¥½çš„æŒ‡æ ‡æ˜¯æ¯”ç‡ åŒ—ææ˜ŸæŒ‡æ ‡ï¼šæ ¸å¿ƒæŒ‡æ ‡]]></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>æ•°æ®åˆ†ææŠ€èƒ½</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ•°æ®åˆ†æå®æˆ˜é¡¹ç›®]]></title>
    <url>%2F2020%2F08%2F25%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ç ”äºŒã®å­¦ä¹ ]]></title>
    <url>%2F2020%2F08%2F15%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[TOC] åˆ©ç”¨å¬åŠ›ææ–™å­¦è‹±è¯­æœ€é«˜æ•ˆæœ‰æ•ˆè¾“å‡ºåº”è¯¥æ˜¯ç¨é«˜äºç°æœ‰æ°´å¹³çš„ã€æ›´å‡†ç¡®ã€æ›´å¾—ä½“çš„è¡¨è¾¾è¾“å‡º å…ˆè®°ä½ä»¥ä¸‹ä¸¤ç‚¹ï¼Œä¸‹é¢æˆ‘ä»¬å†ä¸€ä¸€è§£æåº”è¯¥è¦æ€ä¹ˆåšåˆ°ã€‚ 1. å­¦ä¹ éœ€è¦åé¦ˆï¼Œæ¥å‘Šè¯‰æˆ‘ä»¬è¿™è¾“å‡ºæ˜¯æ­£ç¡®çš„ï¼Œå¯ä»¥ç»§ç»­ï¼›æˆ–è€…æ˜¯é”™è¯¯çš„ï¼Œéœ€è¦ä¿®æ­£ã€‚ 2. å°†è¾“å…¥å†…åŒ–ï¼Œå˜æˆè‡ªå·±çš„çŸ¥è¯†ã€‚ æˆ‘ä¸€èˆ¬ä¼šå¬å››éï¼Œä½†ä¸æ˜¯å…¨å¬åŸæ–‡ã€‚ ç¬¬ä¸€éï¼šæ³›å¬åŸæ–‡ï¼Œä¸è¦çœ‹å­—å¹•æˆ–è„šæœ¬ï¼Œæ¸…æ¥šå½•éŸ³çš„å†…å®¹ã€‚å¬ç¬¬ä¸€éçš„æ—¶å€™æˆ‘é€šå¸¸è¿ç¬”è®°éƒ½ä¸åšï¼Œç›®çš„æ˜¯ä¸ºäº†è®©è‡ªå·±æµç•…çš„å¬å®Œï¼Œå¯¹å¬åŠ›çš„å†…å®¹æœ‰ä¸€ä¸ªæ•´ä½“çš„æŒæ¡ã€‚ ç¬¬äºŒéï¼šå…ˆå¬åŸæ–‡ï¼Œæ ¹æ®å†…å®¹æ®µè½ï¼Œå¼€å§‹å¤è¿°å†…å®¹ï¼Œå¹¶å½•éŸ³ã€‚è¿™ä¸€æ­¥çš„ç›®çš„æ˜¯å¼ºè¿«è‡ªå·±è°ƒç”¨å·²ç»å­¦è¿‡çš„çŸ¥è¯†ï¼Œç»„ç»‡è¯­è¨€å’Œè¿›è¡Œç»ƒä¹ ã€‚ ç¬¬ä¸‰éï¼Œå¬è‡ªå·±çš„å½•éŸ³ï¼Œç„¶ååšå‡ºä¿®æ­£ã€‚è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œå¯ä»¥è®©ä½ äº†è§£è‡ªå·±çš„å‘éŸ³é—®é¢˜å’Œè¯­æ³•é—®é¢˜ï¼Œå¹¶æŠŠå¯å¬å‡ºæ¥çš„è¯­æ³•é—®é¢˜è¿›è¡Œä¿®æ”¹ã€‚é€šè¿‡è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠç®€å•é‡å¤è¾“å…¥çš„è¯­è¨€ææ–™ï¼Œè½¬åŒ–ä¸ºæœ‰æ•ˆè¾“å‡ºã€‚ ç¬¬å››éï¼Œå¬åŸæ–‡çœ‹å­—å¹•å’Œè„šæœ¬ï¼Œçœ‹æŠŠå¬ä¸æ‡‚çš„åœ°æ–¹æ ‡æ³¨ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆå¬ä¸æ‡‚ï¼ˆæ¯”å¦‚æ˜¯å› ä¸ºè‡ªå·±å‘éŸ³ä¸å‡†å¯¼è‡´çš„å¬ä¸å‡ºï¼Œæˆ–è€…å°±æ˜¯å› ä¸ºè¿™ä¸ªè¯æ²¡èƒŒè¿‡ã€ä¸ç†Ÿæ‚‰ï¼‰ã€‚ä¸ç†Ÿæ‚‰çš„ç”¨æ³•å’Œè‡ªå·±ç”¨é”™çš„åœ°æ–¹æ€»ç»“ï¼ŒèƒŒä¸‹æ¥ï¼Œä¸‹æ¬¡è¯•ç€ç”¨ã€‚ Tipsï¼š ä¸è¦é€‰æ‹©å¤ªéš¾çš„ææ–™ï¼Œå¤ªéš¾çš„ææ–™å®¹æ˜“ä½¿è‡ªå·±ä¸§å¤±å­¦ä¹ å…´è¶£ã€‚ ä¸€å¼€å§‹ï¼Œä¸è¦é€‰æ‹©å¤ªé•¿çš„å¬åŠ›ææ–™ã€‚10åˆ†é’Ÿå·¦å³æœ€ä½³ã€‚åœ¨è¿™é‡Œæ¨ètedï¼Œå¯ä»¥é€‰æ‹©æœ‰å­—å¹•æˆ–å…³é—­å­—å¹•ã€‚ åœ¨ä¸€ä¸ªç›¸è¿‘çš„æ—¶é—´æ®µå†…ï¼Œé€‰æ‹©ç›¸è¿‘é¢˜æçš„ææ–™ã€‚æ¯”å¦‚æˆ‘ä¼šåœ¨ä¸¤ä¸ªæ˜ŸæœŸå†…é€‰æ‹©â€œå¿ƒç†â€é¢˜æçš„å½•éŸ³ã€‚è¿™æ ·æˆ‘å°±ä¼šæœ‰æ›´å¤§çš„å‡ ç‡ç”¨ä¸Šåˆšå­¦è¿‡çš„ç»“æ„å’Œè¯æ±‡ã€‚ åŠæ—¶æ€»ç»“ï¼ŒåŠæ—¶å¤ä¹ å·²èƒŒè¿‡çš„ææ–™ï¼Œå¤ä¹ çš„é‡è¦æ€§å¤§å®¶éƒ½æ‡‚ï¼Œè¿™é‡Œå°±ä¸å¤šè¯´äº†ã€‚ çœŸé¢˜å¬å†™ ææ–™é€‰æ‹© èƒ½å¤Ÿå¬å¾—æ‡‚ 70%çš„ææ–™ 2 å…·ä½“æ‰§è¡Œæ–¹æ³• å…ˆæ³›å¬ä¸€ç¯‡ å†å¾ªç¯å¬å‡ é å†é€å¥é€å¥çš„å¬ ç¾å‰§ç²¾å¬ å…ˆçœ‹ä¸­æ–‡å¬ è‹±æ–‡ï¼ŒæŸ¥ å¬æ‰¾ å°è¯ï¼Œè·Ÿè¯» é‡å¤ä¸‰å››è‡³å°‘10]]></content>
      <categories>
        <category>å­¦ä¹ ã®å†ç¨‹(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç ”äºŒã®å­¦ä¹ ]]></title>
    <url>%2F2020%2F08%2F15%2F%E7%A0%94%E4%BA%8C%E3%81%AE%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[è®°å½•æ—¥å¸¸ï¼Œæ—¥å¸¸ç•™å¿µã€‚ é—­å…³ä¿®ç‚¼ï¼Œä¿®ç‚¼æˆé‡‘åˆšä¸åä¹‹èº«ï¼ ç«‹ä¸‹Flag, ä¸‰ä¸ªæœˆåï¼Œçœ‹çœ‹è‡ªå·±ï¼ŒåŠªåŠ›ğŸ˜€ğŸ˜€ æ¸…å•ğŸ˜€ğŸ˜€ what how æ—¥å¿— å…¬ä¼—å·ã€åšå®¢ã€CSDNã€Github ä¸»è¦è¾“å‡º æ¬ç –+é¡¹ç›® ä¸»è¦è¾“å…¥ æ•°æ®åˆ†æ+æ–°ç»æµ 8:00~11:20 2h 14:10-17:20 3h 19:00-22:00 3h æ¯å¤© æ¯å¤©çš„è§„åˆ’ï¼›æ¯å¤©åŠå°æ—¶ç‘œä¼½ï¼ˆå“‘é“ƒ)ï¼› æ¥ä¸‹æ¥æœ‰æ„ä¹‰çš„äº‹æƒ…ï¼Œè½¬è¿‡å»è½¬è¿‡æ¥åˆå›åˆ°æœ€åˆçš„èµ·ç‚¹ï¼š 1. @å¯è§†åŒ–ã€‚å°è£…ä¸€ä¸‹matplotlibä¿®æ”¹ä¸€äº›é»˜è®¤å‚æ•°ã€‚ä¸»è¦å°±æ˜¯ä¿®æ”¹å­—ä½“ï¼Œå­—å·ï¼Œä¸»é¢˜ï¼ŒèƒŒæ™¯ã€‚ 2. @å¡«å……ç®€å†ã€‚a)åŸºæœ¬ä¿¡æ¯ b) é¡¹ç›®ç»å†(ä¸‰å››ä¸ªå§) c)å®ä¹ ç»å† d) çŸ¥è¯†æŠ€èƒ½(è¦è¿›ä¸€æ­¥è¡¥å……)ã€‚è¾ƒå¼±çš„åœ°æ–¹:è½åœ°çš„é¡¹ç›®(å¥½æƒ³å¥½æƒ³å®ä¹ )ï¼›è‹±è¯­å•Šï¼› 3. @ç ”ç©¶ç”Ÿå®Œæ»¡çš„ç»“æŸã€‚æ¯•ä¸šè®¾è®¡æ¯ç« å¯¹åº”å‘ä¸€ç¯‡æ–‡ç« å§ï¼ˆäº§ä¸š)ã€‚åŠ æ²¹ï¼ŒåŠ æ²¹ï¼è¿™åŠå¹´è¦åšå®Œï¼Œå†æ‰¾æ•°æ® 4. @è‹±è¯­ã€‚æ–°æ¦‚å¿µè‹±è¯­äºŒå’Œæ–°æ¦‚å¿µè‹±è¯­ä¸‰å¤©å¤©å­¦ä¹ å–” 5. @åˆ»æ„ç»ƒä¹ ã€‚å¦‚æœç‹ ä¸ä¸‹å¿ƒï¼Œé‚£å°±æ¯æ—¶æ¯åˆ»çš„åˆ»æ„ï¼Œæ¯æ—¶æ¯åˆ»çš„æ®šç²¾ç«­è™‘ 6. @å…¬æ–‡å†™ä½œã€‚å—¯å—¯å—¯ã€‚åˆ»æ„çš„è®­ç»ƒè‡ªå·± æ¯å¤©è¿½è¸ªå…¬ä¼—å·æ–‡ç« ã€‚ çŒ´å­æ•°æ®åˆ†æã€‚ 20200905 åŠ æ²¹ï¼ˆé—­å…³ï¼‰ä»Šå¤©æ—©ä¸Šæ•´ç†æš‘å‡ä»»åŠ¡ ä»Šå¤©ä¸‹åˆçœ‹äº†ç»˜å›¾echart ä»Šå¤©æ™šä¸Šç»§ç»­time series(æ·»å µå•Š) æˆ‘åœ¨æƒ³åŸç”Ÿå®¶åº­ç»™ä½ ä»€ä¹ˆæ ·çš„æ„Ÿè§‰ï¼Œä½ ä¸å¾—ä¸æ¥å—ï¼Œç”šè‡³ä¸èƒ½åæŠ—ã€‚å¦‚æœåœ¨è¿™ä¸ªä¸–ç•Œä¸Šï¼Œè¿çˆ¶æ¯çš„æƒ…ï¼Œéƒ½æ˜¯è‡ªç§ä¸‘é™‹çš„ï¼Œæˆ‘è¿˜èƒ½å¾—åˆ°ä»€ä¹ˆå‘¢ï¼Ÿæ‰€ä»¥æˆ‘åŠªåŠ›çš„æƒ³é€ƒå‡ºæŸç¼šï¼Œæˆ‘ä¸æƒ³åœ¨è¿™ä¸ªä¸–ç•Œé ä»»ä½•æœ‰ç›®çš„ä¸œè¥¿ç”Ÿå­˜ä¸‹å»ã€‚æ‰€ä»¥å•Šï¼Œæˆ‘è¿˜èƒ½æ€ä¹ˆæ ·ï¼Œæˆ‘è¿˜èƒ½æ€ä¹ˆæ ·å‘¢ï¼Ÿå°±åƒã€Šéƒ½æŒºå¥½ã€‹é‡Œé¢çš„è‹æ˜ç‰ï¼Œè™½ç„¶æ²¡æœ‰é‚£ä¹ˆæƒ¨ï¼Œä½†æ˜¯ä¹Ÿè¦åƒå¥¹ä¸€æ ·ã€‚æˆ‘ä¸éœ€è¦ä»»ä½•äººçš„åŒæƒ…ã€‚ 20200904 æ–­èˆç¦»ä»Šå¤©æ—©ä¸Šæ‰”æ‰äº†è®¸å¤šä¸œè¥¿ï¼Œç¿»å‡ºæ¥ç‰¹åˆ«å¤šå¤§å­¦ä¹°çš„æ²¡æœ‰ç©¿çš„ä¸œè¥¿ ä»Šå¤©ä¸‹åˆç»˜å›¾çœ‹äº†1.3hï¼Œå­¦ä¹ äº†çŒ´å­çš„æ•°æ®åˆ†æçš„æŒ‡æ ‡ä½“ç³»çš„å»ºç«‹æ–¹æ³•ï¼æ„Ÿè§‰è¿˜æ˜¯å¥—è·¯. ä»Šå¤©æ™šä¸Šå¼„äº†æ—¶é—´åºåˆ— 20200903 ç»ˆäºè€ƒå®Œäº†å•Šé«˜é«˜å…´å…´ï¼Œè®¤è®¤çœŸçœŸæç§‘ç ”äº†ï¼ è¿™ä¸ªæœˆæŠŠé«˜é“é‡æ–°æ›´æ–°ä¸€ä¸‹ è¿™ä¸ªæœˆæŠŠæ—¶é—´åºåˆ—è·‘å‡ºæ¥ç»“æœ è¿™ä¸ªæœˆå¯è§†åŒ–èµ„æ–™å¼„ä¸€ä¸‹ è¿™ä¸ªæœˆè¿‡æ¸¡æœŸ(æ—©ä¸Šå¤šç¡ä¼šï¼Œæ™šä¸Šæ™šç‚¹ç¡) å¿…ä¿®ç¯èŠ‚ 6400006003 å­¦æœ¯æ´»åŠ¨ ç ”ç©¶ç”Ÿé™¢ 0 1 æ˜¥ä¸ç§‹ å…¶ä»– è€ƒæŸ¥ æ˜¯ å¿…ä¿®ç¯èŠ‚ 6400006009 è®ºæ–‡å¼€é¢˜æŠ¥å‘ŠåŠæ–‡çŒ®é˜…è¯»ç»¼è¿°II ç ”ç©¶ç”Ÿé™¢ 0 1 æ˜¥ä¸ç§‹ å…¶ä»– è€ƒæŸ¥ æ˜¯ å®è·µæ•™å­¦ç¯èŠ‚ï¼šè¿˜æœ‰äº”ä¸ªå­¦åˆ†ã€‚ å®è·µæ•™å­¦ç¯èŠ‚6ä¸ªå­¦åˆ†ä¸­ï¼ŒåŸºåœ°å®è·µå¿…é¡»å®Œæˆ2-4ä¸ªå­¦åˆ†ï¼ŒæŒ‰ç…§å®è·µæ—¶é—´1-3ä¸ªæœˆã€4-6ä¸ªæœˆã€7-12ä¸ªæœˆåŠä»¥ä¸Šä½œä¸ºå®è·µæ—¶é—´å•ä½ï¼Œåˆ†åˆ«è®¤å®šä¸º2å­¦åˆ†ã€3å­¦åˆ†å’Œ4å­¦åˆ†ã€‚è¦æ±‚æäº¤å®è·µæ€»ç»“æŠ¥å‘Šï¼Œå®è·µåŸºåœ°ï¼ˆå•ä½ï¼‰å°±å­¦ç”Ÿæäº¤çš„æŠ¥å‘Šç»™äºˆç›¸å…³æ”¯æ’‘ä¹¦é¢ææ–™è¯æ˜ï¼Œæ ¹æ®å®é™…å®è·µæ—¶é—´ï¼Œç»å¯¼å¸ˆå®¡æ ¸é€šè¿‡ï¼Œå¯è·å¾—2-4ä¸ªå­¦åˆ†ã€‚å®è·µæ•™å­¦è¯¾ç¨‹ä¸»è¦æŒ‡çªå‡ºå®è·µè®­ç»ƒçš„å®éªŒè¯¾ç¨‹ï¼Œå…¨æ ¡å¯é€šé€‰ï¼Œå®Œæˆè€…å–å¾—ç›¸åº”å­¦åˆ†ã€‚ 3ä¸ªå­¦åˆ†(å®ä¹ )+å­¦ä½è®ºæ–‡å†™ä½œè§„èŒƒ(2)ä¸ªå­¦åˆ† è™½ç„¶æˆ‘å¾ˆå–œæ¬¢å¤©å¤©ç¡å¤§è§‰ï¼Œèººåœ¨åºŠä¸Šç¡è§‰ã€‚ä½†æ˜¯å‘¢ï¼Ÿå¥½å¥½å·¥ä½œï¼Œè§„å¾‹çš„ç”Ÿæ´»ä½œæ¯ï¼Œè¿™è¿˜æ˜¯æˆ‘çš„è¿½æ±‚ã€‚ è™½ç„¶åœ¨æˆä¸ºé‚£ä¸ªç‹¬ç‰¹çš„è‡ªå·±çš„æ—¶å€™ï¼Œä¼šèµ°å¾ˆå¤šçš„å¼¯è·¯ï¼Œç„¶åæ‰çŸ¥é“æ€ä¹ˆæ ·çš„è‡ªå·±é€‚åˆè‡ªå·±ã€‚ä»€ä¹ˆçš„ä¸œè¥¿æ˜¯åº”è¯¥ä¸¢æ‰çš„ã€‚ ä¿®ç‚¼ï¼Œä¿®ç‚¼ï¼Œä¿®ç‚¼ ä¸èƒ½å†åƒå¤–å–äº†ï¼ 20200902 å¤ä¹ ä»Šå¤©å¤ä¹ è½¯ä»¶å®‰å…¨æ€§åˆ†æ 20200901 å¤ä¹ ä»Šå¤©æ—©ä¸Šå¤ä¹ èƒŒè¯µ ä»Šå¤©ä¸‹åˆæ•¢æŠ¥å‘Š ä»Šå¤©æ™šä¸ŠAndroidæ¼æ´ï¼Œå“ï¼Œè™½ç„¶å†™è¿‡android apk,ä½†æ˜¯å®‰å…¨é—®é¢˜å¥½éš¾å•Š 2020082020-831 å¤ä¹ +ç©è€ä»Šå¤©æ—©ä¸Šå¤ä¹ è½¯ä»¶å®‰å…¨æ€§åˆ†æ ä»Šå¤©ä¸‹åˆå’Œé¹å“¥å‡ºå»çœ‹ç”µå½±äº† ä»Šå¤©æ™šä¸Šå¤ä¹ è½¯ä»¶å®‰å…¨æ€§åˆ†æ 20200830 å¤ä¹ ingä»Šå¤©ç»§ç»­è½¯ä»¶å®‰å…¨æ€§åˆ†æï¼ˆæ— èŠï¼Œä½æ•ˆç‡) å†³å®šæ™šä¸ŠæŠŠæŠ¥å‘Šå®Œæˆäº† çªç„¶æƒ³çœ‹è®ºæ–‡äº†ï¼Œæˆ‘å‘ç°æ˜¯çš„çš„ç¡®ç¡®çˆ±ä¸Šç¤¾ä¼šç»æµå­¦çš„ä¸œè¥¿äº†ï¼Œç³Ÿäº†å•Šã€‚æ„Ÿè§‰è¦æ–­é€å¤šå¹´å»äº’è”ç½‘å…¬å¸çš„æ¢¦æƒ³äº†ï¼ˆå…¶å®è‡ªå·±å­¦çš„ä¹Ÿä¸å¥½)ï¼Œæ˜¯ä¸æ˜¯è¦å»ä½“åˆ¶å†…å·¥ä½œäº†å•Šï¼æ„Ÿè§‰å»ä½“åˆ¶å†…å·¥ä½œè¦æ··ä¸ªåšå£«å­¦ä½æ‰è¡Œå•Šã€‚çœ‹äº†å®éªŒå®¤åšå£«æ¯•ä¸šçš„æ¡ä»¶å’Œå¥–åŠ±è§„åˆ™ï¼Œçªç„¶å‘ç°è¯»åšå¥½éš¾å•Šï¼(ä¸»è¦æ˜¯æˆ‘æƒ³3-4å¹´è¾¾æ ‡å•Šï¼‰ã€‚é‚£æˆ‘æ–­ä¸æ–­é€å»äº’è”ç½‘å·¥ä½œçš„æƒ³æ³•å•Šï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ æŒ‰ç…§ç¡•å£«è¦æ±‚å¹²ï¼Ÿ 1**ï¼‰åšå£«ç”Ÿå››å¹´æ—¶é—´åº”è¯¥æœ‰ä¸€ä¸ªæ¯”è¾ƒå¥½çš„ç ”ç©¶è§„åˆ’ã€‚åšå£«å¤§è®ºæ–‡ä¸€èˆ¬åªéœ€è¦6-7ç« èŠ‚ï¼ŒåŸºæœ¬ä¸Šæ¯ä¸€å­¦æœŸå®Œæˆä¸€ç« èŠ‚å°±å¯ä»¥äº†ã€‚åšå£«ç”Ÿç¬¬ä¸€å¹´ï¼Œå­¦æ ¡å®‰æ’å¤§å®¶ä¸Šè¯¾ã€‚æœ‰å¾ˆå¤šå­¦ç”Ÿåœ¨è¿™ä¸€å¹´æ—¶é—´é‡Œé¢å»¶ç»­æœ¬ç§‘ç”Ÿå­¦ä¹ ä¹ æƒ¯ï¼Œå°†è€ƒè¯•æˆç»©æ”¾åœ¨ç¬¬ä¸€ä½ä¸Šã€‚å¯¹äºå–å¾—å¥½çš„å­¦ä¹ æˆç»©ã€æ‰“å¥½æ‰å®çš„å­¦ç§‘åŸºç¡€ï¼Œå›ºç„¶æœ‰å¿…è¦ï¼Œ ä½†åšå£«ç”Ÿç¬¬ä¸€å­¦å¹´ä¸€å®šä¸èƒ½å¤Ÿåªåšâ€œå°é•‡è¯»ä¹¦é’å¹´â€ï¼Œé™¤äº†ä¹¦æœ¬è€ƒè¯•ï¼Œä¸€å®šè¦å°½å¯èƒ½æ—©ç‚¹åŠ¨æ‰‹å¼€å±•ç ”ç©¶å·¥ä½œã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä¸€ç›´è§‰å¾—åšå£«ç”Ÿç¬¬ä¸€å­¦å¹´ç»“æŸæ—¶ï¼Œåº”è¯¥æ’°å†™å®Œæˆåšå£«è®ºæ–‡ç¬¬ä¸€ç« â€œç ”ç©¶èƒŒæ™¯å’Œå›½å†…å¤–ç ”ç©¶è¿›å±•â€95%ä»¥ä¸Šçš„å·¥ä½œï¼ŒåŒæ—¶ï¼Œæ’°å†™å®Œæˆåšå£«è®ºæ–‡ç¬¬äºŒç« â€œå®éªŒæ–¹æ³•ä¸åŸºæœ¬ç†è®ºâ€çš„åŸºæœ¬å†…å®¹ã€‚ åšå£«ç¬¬äºŒå­¦å¹´ï¼ŒåŠªåŠ›å®Œæˆç¬¬ä¸‰ã€å››ç« çš„ç ”ç©¶å†…å®¹ï¼Œå¹¶æ ¹æ®ç ”ç©¶å†…å®¹æ’°å†™1-2ç¯‡ä¸­ç­‰æ°´å‡†çš„å­¦æœ¯è®ºæ–‡ã€‚ åšå£«ç¬¬ä¸‰å­¦å¹´ï¼Œå®Œæˆåšå£«è®ºæ–‡ç¬¬äº”ç« ã€ç¬¬å…­ç« çš„ç ”ç©¶å†…å®¹ï¼Œæ ¹æ®ç ”ç©¶ç»“æœå‘è¡¨2-3ç¯‡è¾ƒé«˜æ°´å‡†çš„å­¦æœ¯è®ºæ–‡ã€‚ åšå£«ç¬¬å››å­¦å¹´ä¸ŠåŠå¹´ï¼Œè¡¥å……ã€å®Œå–„åšå£«è®ºæ–‡ç¬¬äºŒç« -ç¬¬å…­ç« ç ”ç©¶å†…å®¹ï¼Œæ’°å†™ç¬¬ä¸ƒç« ç»“è®ºéƒ¨åˆ†ã€‚é€šè¿‡å¯¹åšå£«ç ”ç©¶å†…å®¹è¿›è¡Œç³»ç»Ÿæ€§æ€»ç»“ï¼Œå‘è¡¨ä¸€ç¯‡é«˜æ°´å¹³çš„å­¦æœ¯è®ºæ–‡ã€‚ä¸æ­¤åŒæ—¶ï¼Œåšå£«ç”Ÿåœ¨ç¬¬å››å¹´ä¸ŠåŠå¹´å°†è‡ªå·±çš„åšå£«è®ºæ–‡ç¬¬ä¸€ç¨¿é€’äº¤ç»™å¯¼å¸ˆï¼Œè®©å…¶æœ‰å……è¶³çš„æ—¶é—´å¸®åŠ©ä½ ä¿®æ”¹ã€‚å¦‚æœå¯¼å¸ˆå‘ç°æœ‰ä¸é€‚åˆçš„éƒ¨åˆ†ï¼Œå¯ä»¥æŠ“ç´§æ—¶é—´è¿›è¡Œè¡¥å……å’Œå®Œå–„ã€‚åˆ°ç¬¬å››å­¦å¹´ä¸‹åŠå¹´ï¼Œå°±æ˜¯å®‰æ’é€å®¡ã€å‡†å¤‡ç­”è¾©ï¼Œè¿˜æœ‰è¶³å¤Ÿçš„æ—¶é—´æ‰¾å·¥ä½œã€‚ å¦‚æœåšå£«ç”Ÿèƒ½å¤ŸæŒ‰ç…§ä¸Šé¢çš„è¿™ä¸ªè®¡åˆ’å»å¼€å±•å·¥ä½œï¼Œåšå£«æœŸé—´å¯ä»¥å‘è¡¨5ç¯‡ä»¥ä¸Šå­¦æœ¯è®ºæ–‡ï¼Œåº”è¯¥éƒ½ä¼šè¶…è¿‡å­¦æ ¡çš„æ¯•ä¸šè¦æ±‚ï¼Œåšå£«ä¸æ­£å¸¸æ¯•ä¸šæ˜¯æ²¡æœ‰ç†ç”±çš„ã€‚** çªç„¶å‘ç°è¯»ç ”è¯»åšè·Ÿå·¥ä½œæ€§è´¨æ˜¯å·®ä¸å¤šçš„ï¼Œéƒ½æ˜¯é è‡ªå·±çš„æœ¬äº‹ç»™è€æ¿æœåŠ¡ã€‚å—¯å—¯ï¼Œå°±æ˜¯è¿™ç§ç›¸å¤„æ¨¡å¼ã€‚ 20200829 å¤ä¹ ingä»Šå¤©æ—©ä¸Šå’ŒåŒå­¦èŠå¤©ï¼Œå±…ç„¶å‡ºå»å®ä¹ äº† ä»Šå¤©æ™šä¸Šå’Œä¸‹åˆå¤ä¹ è½¯ä»¶å®‰å…¨æ€§åˆ†æï¼ˆéš¾ï¼‰ 202008028 å¯†ç å­¦è€ƒè¯•ä»Šå¤©æ—©ä¸Šé å¯†ç å­¦ ä»Šå¤©ä¸‹åˆæ”¶æ‹¾åšå®¢æ–‡ç«  ä»Šå¤©æ™šä¸Šï¼Œç”±äºä¸‹å¤§é›¨ï¼Œå›å¯å®¤çœ‹å‰§äº† 20200827 å·¥ç¨‹ä¼¦ç†ä»Šå¤©æ—©ä¸Šï¼Œæœç´¢å¾ˆå¤šæ•°æ®åˆ†æçš„èµ„æ–™ï¼Œæ„Ÿè§‰ä¸šåŠ¡å‹æ•°æ®åˆ†æå¸ˆè¦æ¥è§¦å¤ªå¤šä¸šåŠ¡ï¼ˆè½¬è¡Œçš„äººå¤šå•Šï¼Œå¤§å‚èƒ½å‘æŒ¥ä½œç”¨)ï¼ŒæŠ€æœ¯å‹æ•°æ®åˆ†æå¸ˆè¦ç®—æ³•å­¦çš„å¾ˆå¥½ï¼ˆæˆ‘åˆæ²¡æœ‰å¾ˆç‰¹åˆ«çš„å¤´è„‘ï¼Œé¡¹ç›®ç»å†ï¼‰ã€‚ä½†æ˜¯å‘¢ï¼Ÿæ•°æ®å¤„ç†ï¼Œæ•°æ®å»ºæ¨¡ï¼Œæ•°æ®å¯è§†åŒ–æ˜¯å¹²ä»€ä¹ˆéƒ½è¦ç”¨åˆ°çš„ã€‚è¿˜æ˜¯æˆ‘æœ¬ç§‘çš„æ°´å¹³ã€‚ä½†æ˜¯æˆ‘è¿˜æ˜¯æƒ³è·¨ç•Œå•Šï¼Œæœç„¶æ˜¯çˆ±ä¸€è¡Œï¼Œçˆ±ä¸Šä¸€è¡Œã€‚é±¼å’Œç†ŠæŒä¸å¯å…¼å¾—å•Šï¼Œè¦å–èˆã€‚ https://ask.hellobi.com/blog/qinlu/10261 ä»Šå¤©ä¸‹åˆï¼Œè€ƒå·¥ç¨‹ä¼¦ç†ã€‚å¿ƒå¡å¡ã€‚ ä»Šå¤©æ™šä¸Šï¼Œçœ‹äº†æˆ‘åœ¨é¢å’Œå›­ã€‚å†å²æ–‡ç‰©ï¼Œå›­æ—é£æ™¯å¤ªæ£’äº†ã€‚è‹±è¯­ï¼šã€Šbreakfast or lunchã€‹ã€‚åˆè¿›ä¸€æ­¥è¿›è¡Œäº†èŒä¸šè§„åˆ’ï¼› å¤ä¹ å¯†ç å­¦ï¼›å­¦ä¹ äº†tableauï¼Œæœç„¶æ¼‚äº®å•Šï¼ æˆ‘æƒ³äº†æƒ³ï¼ŒæŠŠæ¯•ä¸šè®¾è®¡åšå®Œäº†ï¼ŒæŠŠæ—¶é—´åºåˆ—é¡¹ç›®åšå¥½ï¼ŒæŠŠæ‰¾å®ä¹ ç›¸å…³å‡†å¤‡åšå¥½äº†ï¼Œçœ‹çœ‹å‰§ï¼Œå…»å…»èŠ±ï¼Œè¿™æ ·çš„ç ”ç©¶ç”Ÿå¤šå¥½å•Šï¼Œå¹²å˜›è¦ä¸è‡ªå·±æçš„é‚£ä¹ˆç´¯ã€‚åƒå¥½å–å¥½ï¼Œæ—¶ä¸æ—¶ç»™å®¶äººä¹°ç¤¼ç‰©ã€‚ å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦ã€‚ä¸è¦è¿½ä¸€åŒ¹é©¬ï¼Œä½ ç”¨è¿½é©¬çš„æ—¶é—´å»ç§è‰ï¼Œå¾…æ˜¥æš–èŠ±å¼€æ—¶ï¼Œèƒ½å¸å¼•ä¸€æ‰¹éªé©¬æ¥ä¾›ä½ é€‰æ‹©ï¼›æ‰€ä»¥åªè¦è‡ªå·±è¶³å¤Ÿä¼˜ç§€ï¼Œä½ å°±æœ‰å¤šå¤§çš„æƒåŠ›é€‰æ‹©è‡ªå·±çš„å–œå¥½ã€‚å°±è‡ªå·±åŠªåŠ›çš„åŠ¨åŠ›å•Šï¼ 202007826 Deadlineä»Šå¤©æ—©ä¸Šï¼Œå¤ä¹ äº†å…¨éƒ¨çš„å¯†ç å­¦ã€‚ ä»Šå¤©ä¸‹åˆï¼Œå¤ä¹ äº†å·¥ç¨‹ä¼¦ç†çš„åˆ†æé¢˜ã€‚ ä»Šå¤©æ™šä¸Šï¼Œå­¦ä¹ äº†æ•°æ®åˆ†æä¸­çš„é€»è¾‘æ€ç»´ï¼Œå¦‚ä½•ç²¾å‡†åŒ–äº§å“è®¾è®¡ï¼Œäº§ä¸šè¿è¥ã€‚ æˆ‘å·²ç»å—å¤Ÿäº†è¿™æ ·çš„ç”Ÿæ´»äº†ã€‚å°½æ—©å®ä¹ ï¼Œæœ‰äººå†…æ¨ï¼Œå°±çœ‹è‡ªå·±äº†ã€‚ @@@@@@@ æˆ‘ä¸æ˜¯ä¸€ä¸ªçƒ­è„¸ç‰¹å†·å±è‚¡çš„äººã€‚ 20200825 ä¸ƒå¤•å¿«ä¹ä»Šå¤©æ—©ä¸Šï¼Œèµ·åºŠå‘ç°è‡€éƒ¨å¥½ç–¼å•Š ä»Šå¤©ä¸‹åˆç»§ç»­å¤ä¹ å¯†ç å­¦ å¯è¯æ˜çš„åŠ å¯†å®‰å…¨æ€§ï¼›æ•°å­—ç­¾åå®‰å…¨æ€§ç›¸å…³æ¦‚å¿µã€‚å…¬é’¥ä½“åˆ¶çš„å®‰å…¨æ€§ ä»Šå¤©ä¸‹åˆå­¦ä¹ äº†A/B(whatï¼Œwhy, how)ï¼Œç”¨äºè¯„ä¼°æŸç§äº§å“å’Œè®¾è®¡æ˜¯å¦æœ‰æ•ˆçš„æä¾›äº†æŸé¡¹æŒ‡æ ‡ï¼Œè¿›è€Œæœ‰åŠ©äºè¾…åŠ©å†³ç­–ã€‚ æ— è®ºæ˜¯å…¬å¸ï¼ŒåŒçº§ï¼Œæ™®é€šæœ‹å‹ï¼Œç”·å¥³æœ‹å‹â€”â€”åˆ©ç›Šç¬¬ä¸€ï¼Œæ„Ÿæƒ…å€’æ•°ç¬¬ä¸€ã€‚èƒ½å®ç°åŒèµ¢æ˜¯æœ€å¥½ã€‚ è®ºèµšé’±çš„é‡è¦æ€§ï¼Œæˆ‘åˆä¸æ˜¯éä½ ä¸å¯ã€‚ä¸å–œæ¬¢çš„ä¸œè¥¿ï¼Œæˆ‘æ€ä¹ˆéƒ½ä¸ä¼šå°†å°±ã€‚ 20200824 å¤ä¹ ingä»Šå¤©æ—©ä¸Šåœ¨å¯å®¤å¤ä¹ æ§åˆ¶æµå®Œæ•´æ€§ ä»Šå¤©ä¸‹åˆå¤ä¹ æ¨¡ç³Šæµ‹è¯•ï¼Œfuzzingï¼Œå„ç§ç»†èŠ‚ ä»Šå¤©æ™šä¸Šä½æ•ˆç‡å¤ä¹ å¯†ç å­¦åˆ†ç»„å¯†ç å’ŒåŸºæœ¬æ¦‚å¿µï¼Œè¿˜å¯è¯æ˜å®‰å…¨æ€§ï¼Œç¬¬ä¸ƒç« çš„åŸºæœ¬æ¦‚å¿µï¼ŒåŒºåˆ«å…¬é’¥å¯†ç ä½“åˆ¶ï¼ˆä¸‰ç§ï¼‰ï¼Œ ã€Šåƒé±¼ã€‹å¥½å¬ 5W2Håˆ†ææ³•åœ¨æ•°æ®åˆ†æä¸­çš„åº”ç”¨ æœŸæœ«è€ƒè¯•å’‹å›äº‹èƒŒè¯µå‘¢ï¼Ÿè¿˜æ˜¯æ•°å­¦å¥½ï¼Œä¸€ä¸ªå®šç†åšå‡ åé“é¢˜ï¼Œè¿™ç§å­¦ç§‘å‡ ä¸ªç‚¹éƒ½ä¸ä¸€å®šè€ƒ ä¸‹å‘¨ï¼Œå…¨æ–°å…¨æ„çš„çœ‹è§†é¢‘ï¼Œçœ‹PPTï¼Œæ‰“å°è®ºæ–‡èƒŒè¯µ èƒŒè¯µï¼Œå®Œæˆè¯¾ç¨‹æŠ¥å‘Šã€‚ 20200823 å¤ä¹ ingä»Šå¤©æ—©ä¸Šå¯å®¤æ´—è¡£æœï¼ˆå‘¨æœ«å˜›ï¼Œå¤šç¡ä¼š) ä»Šå¤©ä¸‹åˆç»§ç»­å¤ä¹ å·¥ç¨‹ä¼¦ç†ï¼Œã€‚ã€‚ã€‚æ–‡ç§‘ã€‚ã€‚ã€‚è¿˜çœ‹äº†æˆ‘åœ¨é¢å’Œå›­ç­‰ä½ ã€‚æˆ‘è¿˜åœ¨æƒ³æ€ä¹ˆç”¨å·¥ç¨‹ä¼¦ç†åˆ†æç”Ÿæ´»ä¸­çš„å°ä¸‰ã€‚ ä»Šå¤©æ™šä¸Šå†™äº†å·¥ç¨‹ä¼¦ç†çš„è¯¾ä»¶ï¼Œ å›å¯å®¤å¥èº«ï¼Œå“‘é“ƒåˆ°äº† ååƒ»ä¹‹åœ°ï¼Œååƒ»ä¹‹åœ°ï¼Œååƒ»ä¹‹åœ° åˆ»æ„çš„ç»ƒä¹ ï¼ä¸ä¼šä»€ä¹ˆï¼Œå°±è¡¥å……ä»€ä¹ˆã€‚å›¢ç»“å°±æ˜¯åŠ›é‡ 20200822 å¹³æ·¡æ— å¥‡çš„ç”Ÿæ´»ä»Šå¤©æ—©ä¸Šä½æ•ˆç‡çš„å¤ä¹ äº†å¯†ç å­¦å’Œè½¯ä»¶å®‰å…¨æ€§åˆ†æï¼Œå¤ªéš¾è®°å¿†äº†ã€‚çœ‹å‰§æ—¥å¸¸ ä»Šå¤©ä¸‹åˆå¤ä¹ ç»§ç»­ ä»Šå¤©æ™šä¸Šç»§ç»­å¤ä¹ ï¼Œå•Šï¼Œä¸ºä»€ä¹ˆé‚£ä¹ˆå¤šè¦èƒŒçš„ä¸œè¥¿å•Š 20200821 æ— èŠçš„ç”Ÿæ´»æ˜¨å¤©æ™šä¸Šç¡ä¸å¥½ï¼Œç›–è¢«å­å¤ªçƒ­ï¼Œä¸ç›–åˆå¤ªå†·ï¼ŒæŠ˜è…¾ç€ç¡ä¸ç€ï¼Œæˆ‘çš„å¤©å•Šã€‚ ä»Šå¤©æ—©ä¸Šå¤‡ä»½èµ„æ–™ã€‚ ä»Šå¤©ä¸‹åˆå’Œæ™šä¸Šç»§ç»­å¤ä¹ ã€‚å¥½å¿ƒå¡å•Šï¼Œå¤ªéš¾èƒŒäº†ï¼Œæ„Ÿè§‰åœ¨è€ƒæ–‡ç§‘å•Šã€‚ä¸‹é¢æ—¶é—´å…¨éƒ¨å¤ä¹ äº†ã€‚ çœ‹ä¸‹å¦‚ä½•é€šè¿‡Pythonçˆ¬å–å¾®ä¿¡å…¬ä¼—å·ä¸Šçš„å…¨éƒ¨æ–‡ç«  å¯¹ä¸èµ·ï¼Œå…¶å®æ˜¯æœ€æ²¡æœ‰ç”¨çš„è¯è¯­äº†ã€‚ ä¸ºäº†æ¯å¤©å°‘å¾€è¿”å®éªŒå®¤ä¸€ä¸ªæ¥å›ï¼Œæˆ‘å†³å®šæ—©ä¸Šåœ¨å¯å®¤å­¦ä¹ äº†ï¼Œè¿™æ ·è¿˜å¯ä»¥åœ¨åºŠä¸Šèººåˆ°7:45ï¼Œä¹Ÿä¸æ‰“æ‰°å®¤å‹èµ·åºŠã€‚ 20200820 è¿”æ ¡è®°æƒ³ä¸åˆ°æˆ‘é©¬ä¸Šç ”äºŒäº†ï¼Œæ„Ÿè§‰è¿˜æ˜¯ä¸€äº‹æ— æˆçš„æ ·å­ã€‚å¾—ç»™è‡ªå·±é€‰å®šæ–¹å‘ï¼Œå¿«é€Ÿå‘å±•äº† 20200819 è·¯æ¼«æ¼«å…¶ä¿®è¿œå…®å†ä¸åŠªåŠ›ï¼Œä½ å°±ç”Ÿé”ˆäº†ã€‚äº²çˆ±çš„ï¼Œå¥³å­©å­ã€‚ ä½ è§ æˆ–è€…ä¸è§æˆ‘ æˆ‘å°±åœ¨é‚£é‡Œ ä¸æ‚²ä¸å–œ ä½ å¿µ æˆ–è€…ä¸å¿µæˆ‘ æƒ…å°±åœ¨é‚£é‡Œ ä¸æ¥ä¸å» ä½ çˆ± æˆ–è€…ä¸çˆ±æˆ‘ çˆ±å°±åœ¨é‚£é‡Œ ä¸å¢ä¸å‡ ä½ è·Ÿ æˆ–è€…ä¸è·Ÿæˆ‘ æˆ‘çš„æ‰‹å°±åœ¨ä½ æ‰‹é‡Œ ä¸èˆä¸å¼ƒ æ¥æˆ‘çš„æ€€é‡Œ æˆ–è€… è®©æˆ‘ä½è¿›ä½ çš„å¿ƒé‡Œ é»˜ç„¶ ç›¸çˆ± å¯‚é™ å–œæ¬¢]]></content>
      <categories>
        <category>å­¦ä¹ ã®å†ç¨‹(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ•°æ®åˆ†æä¸æœºå™¨å­¦ä¹ ä¹‹è¯­è¨€ç¯‡]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%AF%AD%E8%A8%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[ç¥ç»ç½‘ç»œPytorchåŸºç¡€è¯­æ³•å¸¸è§ç¥ç»ç½‘ç»œçš„å®ç°çº¿æ€§æ¨¡å‹å¤šå±‚æ„ŸçŸ¥æœºCNNLSTMGAN]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[æœºå™¨å­¦ä¹ ä¹‹æ¨¡å‹æ€§èƒ½]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½è¯„ä»·è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®è®­ç»ƒè¯¯å·®å³ç»éªŒè¯¯å·®ï¼›å­¦ä¹ å™¨åœ¨æ–°æ ·æœ¬ä¸Šçš„è¯¯å·®ç§°ä¸ºæ³›åŒ–è¯¯å·®ã€‚ æ¨¡å‹è¯„ä¼°çš„æ–¹æ³•ç•™å‡ºæ³• äº¤å‰éªŒè¯æ³• æ€§èƒ½åº¦é‡é¢„æµ‹åˆ†ç±»å‡†ç¡®åº¦å’Œé”™è¯¯ç‡å‡†ç¡®ç‡ï¼šæŒ‡çš„æ˜¯åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬æ•°é‡å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹ é”™è¯¯ç‡ï¼šæŒ‡åˆ†ç±»é”™è¯¯çš„æ ·æœ¬å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹ å‡†ç¡®ç‡å’Œå¬å›ç‡ç²¾ç¡®ç‡ï¼Œä¹Ÿè¢«ç§°ä½œæŸ¥å‡†ç‡ï¼Œæ˜¯æŒ‡æ‰€æœ‰é¢„æµ‹ä¸ºæ­£ç±»çš„ç»“æœä¸­ï¼ŒçœŸæ­£çš„æ­£ç±»çš„æ¯”ä¾‹ã€‚ å¬å›ç‡ï¼Œä¹Ÿè¢«ç§°ä½œæŸ¥å…¨ç‡ï¼Œæ˜¯æŒ‡æ‰€æœ‰æ­£ç±»ä¸­ï¼Œè¢«åˆ†ç±»å™¨æ‰¾å‡ºæ¥çš„æ¯”ä¾‹ã€‚ è¿‡æ‹Ÿåˆå­¦ä¹ å™¨åœ¨æœªçŸ¥æ•°æ®ä¸Šçš„è¡¨ç°å·® åŸå›  æ•°æ®ä¸Š å»ºæ¨¡æ ·æœ¬ã€‚æ ·æœ¬æ•°é‡å°‘ï¼› å™ªéŸ³å¹²æ‰°å¤§ æ¨¡å‹ å‚æ•°è¿‡å¾—ï¼Œæ¨¡å‹å¤ªå¤æ‚ è§£å†³æ–¹æ¡ˆ äº¤å‰éªŒè¯ æ·»åŠ æ­£åˆ™é¡¹ èŒƒæ•°ï¼›]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>æ­£åˆ™åŒ–</tag>
        <tag>äº¤å‰éªŒè¯</tag>
        <tag>ç‰¹å¾å·¥ç¨‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Book-Learning]]></title>
    <url>%2F2020%2F07%2F29%2FBook-Learning%2F</url>
    <content type="text"><![CDATA[åˆ†äº«çœ‹ä¹¦ç¬”è®° æ•°æ®æŒ–æ˜â€”â€”æ¦‚å¿µä¸æŠ€æœ¯æ•°æ®æŒ–æ˜çš„æ¦‚å¿µæ•°æ®æŒ–æ˜æ˜¯ä»å¤§é‡æ•°æ®ä¸­æå–æˆ–æŒ–æ˜çŸ¥è¯†ã€‚å¼ºè°ƒï¼šä»å¤§é‡çš„ï¼ŒæœªåŠ å·¥çš„ææ–™ä¸­å‘ç°å°‘é‡é‡‘å—è¿™ä¸€è¿‡ç¨‹ã€‚ åŸºæœ¬è¿‡ç¨‹ï¼š æ•°æ®æ¸…ç†ã€‚(æ¶ˆé™¤å™ªéŸ³æˆ–è€…ä¸ä¸€è‡´çš„æ•°æ®) æ•°æ®é›†æˆï¼ˆå¤šç§æ•°æ®é›†æˆå¯ä»¥ç»„åˆåœ¨ä¸€èµ·ï¼‰ æ•°æ®é€‰æ‹©ï¼ˆä»æ•°æ®åº“ä¸­æå–ä¸åˆ†æä»»åŠ¡ç›¸å…³çš„æ•°æ®) æ•°æ®å˜æ¢ã€‚(æ•°æ®å˜æ¢æˆ–ç»Ÿä¸€æˆé€‚åˆæŒ–æ˜å½¢å¼) æ•°æ®æŒ–æ˜(ä½¿ç”¨æ™ºèƒ½æ–¹æ³•æå–æ•°æ®) æ¨¡å¼è¯„ä¼° çŸ¥è¯†è¡¨ç¤ºï¼ˆå¯è§†åŒ–ç­‰æ‰‹æ®µï¼Œå±•ç¤ºæŒ–æ˜çš„çŸ¥è¯†) æ•°æ®é¢„å¤„ç†é—®é¢˜ï¼šç°å®ä¸­æ•°æ®ææ˜“å—å™ªéŸ³æ•°æ®ã€é—æ¼æ•°æ®å’Œä¸ä¸€è‡´æ€§æ•°æ®çš„å¹²æ‰°ã€‚ ä¸å®Œæ•´ï¼ˆå±æ€§å€¼ç¼ºå¤±ï¼‰ å™ªéŸ³(é”™è¯¯å±æ€§å€¼ï¼Œç¦»ç¾¤å€¼) ä¸ä¸€è‡´æ€§ï¼ˆç¼–ç ) æ•°æ®æ¸…ç†ã€‚åŒ…æ‹¬å¡«å†™é—æ¼å€¼ï¼Œå¹³æ»‘å™ªéŸ³æ•°æ®ï¼Œè¯†åˆ«ã€åˆ é™¤å±€å¤–è€…ï¼Œå¹¶è§£å†³ä¸ä¸€è‡´æ¥â€œæ¸…ç†æ•°æ®â€ã€‚è„æ•°æ®è½¬åŒ–ä¸ºå¹²å‡€æ•°æ®ã€‚ æ•°æ®é›†æˆã€‚ä¸åŒæ•°æ®æºçš„æ•°æ®é›†æˆã€‚ æ•°æ®æ¸…æ´—é—æ¼å€¼ å¿½ç•¥ äººå·¥å¡«å†™ å…¨å±€å˜é‡ å¹³å‡å€¼ åˆ†ç»„å¡«å…… å™ªéŸ³æ•°æ®å™ªéŸ³æ˜¯æŒ‡æµ‹é‡å˜é‡çš„éšæœºè¯¯å·®æˆ–åå·®ã€‚å¹³æ»‘æ•°æ®ã€‚ åˆ†ç®±ã€‚å­˜å‚¨å€¼è¢«åˆ†å¸ƒåˆ°ä¸€äº›ç®±å­ä¸­ï¼Œç„¶åå±€éƒ¨å¹³æ»‘ã€‚æŒ‰å¹³å‡å€¼å¹³æ»‘ã€‚æŒ‰ä¸­å€¼å¹³æ»‘ã€‚æŒ‰è¾¹ç•Œå¹³æ»‘ã€‚ èšç±»ã€‚ å›å½’ ä¸ä¸€è‡´æ•°æ®æ•°æ®é›†æˆå®ä½“è¯†åˆ«ã€‚ å†—ä½™ã€‚ æ•°æ®å˜æ¢å°†æ•°æ®è½¬æ¢æˆé€‚ç”¨äºæŒ–æ˜çš„å½¢å¼ å¹³æ»‘ã€‚ èšé›†ã€‚å¯¹æ•°æ®è¿›è¡Œæ±‡æ€»å’Œèšé›†ã€‚æ—¥ã€æœˆå’Œå¹´é”€å”®é¢ã€‚å¤šç²’åº¦æ•°æ®åˆ†ææ„é€ æ•°æ®æ–¹ æ•°æ®æ³›åŒ–ã€‚street-&gt;city; ageâ€”&gt;young, middle-age,senior è§„èŒƒåŒ–ã€‚ å±æ€§æ•°æ®æŒ‰æ¯”ä¾‹ç¼©æ”¾ï¼Œç¼©æ”¾åˆ°ç‰¹å®šåŒºé—´ã€‚ å±æ€§æ„é€ ã€‚ æœ€å°-æœ€å¤§è§„èŒƒåŒ– v = \frac{v-min}{max-min}(new_max-new_min)+new_minz-scoreè§„èŒƒåŒ– v = \frac{v-mean}{\delta}æ•°æ®å½’çº¦æ•°æ®æ–¹èšé›† ç»´å½’çº¦ æ•°æ®å‹ç¼© æ•°å€¼å‹ç¼© æ¦‚å¿µæè¿°ï¼šç‰¹å¾ä¸æ¯”è¾ƒæ•°æ®æŒ–æ˜åˆ†ä¸ºä¸¤ç±»: æè¿°å¼å’Œé¢„æµ‹å¼æŒ–æ˜ã€‚æè¿°å¼æä¾›æ•°æ®çš„æœ‰è¶£çš„ä¸€èˆ¬æ€§è´¨ã€‚å»ºç«‹ä¸€ä¸ªæˆ–ä¸€ç»„æ¨¡å‹ï¼Œå¹¶è¯•å›¾é¢„æµ‹æ–°æ•°æ®é›†çš„è¡Œä¸ºã€‚ æè¿°å¼æ•°æ®æŒ–æ˜ç§°ä¸ºæ¦‚å¿µæè¿°ã€‚ä¸åŒçš„ç²’åº¦å’Œè§’åº¦æè¿°æ•°æ®é›†ã€‚ åº¦é‡å¯ä»¥æ ¹æ®å…¶æ‰€ç”¨çš„èšé›†å‡½æ•°åˆ†æˆä¸‰ç±»ï¼š åˆ†å¸ƒçš„ï¼šä¸€ä¸ªèšé›†å‡½æ•°æ˜¯åˆ†å¸ƒçš„ï¼Œå¦‚æœå®ƒèƒ½ä»¥å¦‚ä¸‹åˆ†å¸ƒæ–¹å¼è¿›è¡Œè®¡ç®—ï¼šè®¾æ•°æ®è¢«åˆ’åˆ†ä¸º n ä¸ªé›†åˆï¼Œå‡½æ•°åœ¨æ¯ä¸€éƒ¨åˆ†ä¸Šçš„è®¡ç®—å¾—åˆ°ä¸€ä¸ªèšé›†å€¼ã€‚å¦‚æœå°†å‡½æ•°ç”¨äº n ä¸ªèšé›†å€¼å¾—åˆ°çš„ç»“æœï¼Œä¸å°†å‡½æ•°ç”¨äºæ‰€æœ‰æ•°æ®å¾—åˆ°çš„ç»“æœä¸€æ ·ï¼Œåˆ™è¯¥å‡½æ•°å¯ä»¥ç”¨åˆ†å¸ƒæ–¹å¼è®¡ç®—ã€‚ ä»£æ•°çš„ï¼šave(); æ•´ä½“çš„ï¼šrank(),median() æè¿°æ€§ç»Ÿè®¡åº¦é‡åº¦é‡ä¸­å¿ƒè¶‹åŠ¿å¹³å‡å€¼ åŠ æƒç®—æœ¯å¹³å‡ï¼ˆåŠ æƒå¹³å‡) ä¸­ä½æ•° åˆ†ä½æ•° æŒ–æ˜å¤§å‹æ•°æ®åº“ä¸­çš„å…³è”è§„åˆ™å…³è”è§„åˆ™æŒ–æ˜å‘ç°å¤§é‡æ•°æ®ä¸­é¡¹é›†çš„å…³è”æˆ–è€…ç›¸å…³è”ç³»ã€‚å¯ç”¨äºäºåˆ†ç±»è®¾è®¡ï¼Œäº¤å‰è´­ç‰©å’Œè´±å–åˆ†æã€‚ è´­ä¹°è®¡ç®—æœºä¹Ÿè¶‹å‘äºåŒæ—¶è´­ä¹°è´¢åŠ¡ç®¡ç†è½¯ä»¶çš„å…³è”è§„åˆ™ computer => finanical_management_software\\ [support = 2\%, confidence = 60\%]æ”¯æŒåº¦ï¼šæœ‰ç”¨æ€§ã€‚åŒæ—¶è´­ä¹°è®¡ç®—æœºå’Œè´¢åŠ¡ç®¡ç†è½¯ä»¶ã€‚ ç½®ä¿¡åº¦ï¼šç¡®å®šæ€§ã€‚è´­ä¹°è®¡ç®—æœºçš„é¡¾å®¢æœ‰å¤šå°‘è´­ä¹°è´¢åŠ¡ç®¡ç†è½¯ä»¶ã€‚ å¯æœ€å°æ”¯æŒåº¦é˜™å€¼å’Œæœ€å°ç½®ä¿¡åº¦é˜™å€¼ã€‚ Apriori ç®—æ³•ï¼š ä½¿ç”¨å€™é€‰é¡¹é›†æ‰¾é¢‘ç¹é¡¹é›†åˆ†ç±»å’Œé¢„æµ‹åˆ†ç±»å’Œé¢„æµ‹æ˜¯æ•°æ®åˆ†æçš„ä¸¤ç§å½¢å¼ï¼Œå¯ä»¥ç”¨äºæå–æè¿°é‡è¦æ•°æ®ç±»çš„æ¨¡å‹æˆ–é¢„æµ‹æœªæ¥çš„æ•°æ®è¶‹åŠ¿ã€‚ åˆ†ç±»é¢„æµ‹åˆ†ç±»æ ‡å·ï¼ˆç±»ï¼‰ï¼Œè€Œé¢„æµ‹å»ºç«‹è¿ç»­å€¼å‡½æ•°æ¨¡å‹ã€‚ é¢„æµ‹çš„å‡†ç¡®ç‡ã€è®¡ç®—é€Ÿåº¦ã€é²æ£’æ€§ã€å¯è§„æ¨¡æ€§å’Œå¯è§£é‡Šæ€§æ˜¯è¯„ä¼°åˆ†ç±»å’Œé¢„æµ‹æ–¹æ³•çš„äº”æ¡æ ‡å‡†ã€‚ èšç±»åˆ†ææ•°æ®å¯¹è±¡çš„é›†åˆè¿›è¡Œåˆ†æï¼Œä½†ä¸åˆ†ç±»ä¸åŒçš„æ˜¯ï¼Œèšç±»åˆ†æ (clustering) å±äºéç›‘ç£å­¦ä¹ ï¼Œä¹Ÿå°±æ˜¯ä¸çŸ¥é“è¦åˆ’åˆ†ç±»æ˜¯æœªçŸ¥çš„ã€‚èšç±»åˆ†æå°±æ˜¯è¦å°†æ•°æ®å¯¹è±¡åˆ†ç»„æˆä¸ºå¤šä¸ªç±»æˆ–ç°‡(cluster)ã€‚æ¯ä¸€ä¸ªç°‡ä¸­çš„å¯¹è±¡ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ç›¸ä¼¼åº¦ï¼Œè€Œä¸åŒç°‡å¯¹è±¡å·®åˆ«è¾ƒå¤§ã€‚å¸¸å¸¸é‡‡ç”¨è·ç¦»ä½œä¸ºç›¸å¼‚åº¦çš„è¡¡é‡ã€‚]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>æ•°æ®æŒ–æ˜</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å‘ç€æ°¸æ’å‡ºå‘]]></title>
    <url>%2F2020%2F07%2F28%2Fprepare-for-work%2F</url>
    <content type="text"><![CDATA[ç¼–ç¨‹è¯­è¨€çš„å­¦ä¹  ç¬¬ä¸€å‘¨ï¼šPythonåŸºç¡€çŸ¥è¯†https://github.com/jackfrued/Python-100-Days/tree/master/Day01-15 Day Ox00 åŸºæœ¬çš„æ•°æ®ç»“æ„ç±»å‹ï¼Œä»¥åŠæä¾›çš„å¸¸ç”¨æ–¹æ³•ã€‚ ç¼–ç çš„é£æ ¼å’Œè§„èŒƒæ€§ åˆè¯†python Pythonç®€ä»‹ - Pythonçš„å†å² / Pythonçš„ä¼˜ç¼ºç‚¹ / Pythonçš„åº”ç”¨é¢†åŸŸ æ­å»ºç¼–ç¨‹ç¯å¢ƒ - Windowsç¯å¢ƒ / Linuxç¯å¢ƒ / MacOSç¯å¢ƒ ä»ç»ˆç«¯è¿è¡ŒPythonç¨‹åº - Hello, world / printå‡½æ•° / è¿è¡Œç¨‹åº ä½¿ç”¨IDLE - äº¤äº’å¼ç¯å¢ƒ(REPL) / ç¼–å†™å¤šè¡Œä»£ç  / è¿è¡Œç¨‹åº / é€€å‡ºIDLE æ³¨é‡Š - æ³¨é‡Šçš„ä½œç”¨ / å•è¡Œæ³¨é‡Š / å¤šè¡Œæ³¨é‡Š ä»£ç æ³¨é‡Šé£æ ¼ 12345678910111213141516def func(arg1, arg2): &quot;&quot;&quot;åœ¨è¿™é‡Œå†™å‡½æ•°çš„ä¸€å¥è¯æ€»ç»“(å¦‚: è®¡ç®—å¹³å‡å€¼). è¿™é‡Œæ˜¯å…·ä½“æè¿°. å‚æ•° ---------- arg1 : int arg1çš„å…·ä½“æè¿° arg2 : int arg2çš„å…·ä½“æè¿° è¿”å›å€¼ ------- int è¿”å›å€¼çš„å…·ä½“æè¿° å˜é‡çš„å®šä¹‰ 12345678910æ¨¡å—å°½é‡ä½¿ç”¨å°å†™å‘½åï¼Œé¦–å­—æ¯ä¿æŒå°å†™ï¼Œå°½é‡ä¸è¦ç”¨ä¸‹åˆ’çº¿(é™¤éå¤šä¸ªå•è¯ï¼Œä¸”æ•°é‡ä¸å¤šçš„æƒ…å†µ)ç±»åä½¿ç”¨é©¼å³°(CamelCase)å‘½åé£æ ¼ï¼Œé¦–å­—æ¯å¤§å†™ï¼Œç§æœ‰ç±»å¯ç”¨ä¸€ä¸ªä¸‹åˆ’çº¿å¼€å¤´å‡½æ•°åä¸€å¾‹å°å†™ï¼Œå¦‚æœ‰å¤šä¸ªå•è¯ï¼Œç”¨ä¸‹åˆ’çº¿éš”å¼€å˜é‡åå°½é‡å°å†™, å¦‚æœ‰å¤šä¸ªå•è¯ï¼Œç”¨ä¸‹åˆ’çº¿éš”å¼€å¸¸é‡é‡‡ç”¨å…¨å¤§å†™ï¼Œå¦‚æœ‰å¤šä¸ªå•è¯ï¼Œä½¿ç”¨ä¸‹åˆ’çº¿éš”å¼€ è¯­è¨€å…ƒç´  ç¨‹åºå’Œè¿›åˆ¶ - æŒ‡ä»¤å’Œç¨‹åº / å†¯è¯ºä¾æ›¼æœº / äºŒè¿›åˆ¶å’Œåè¿›åˆ¶ / å…«è¿›åˆ¶å’Œåå…­è¿›åˆ¶ å˜é‡å’Œç±»å‹ - å˜é‡çš„å‘½å / å˜é‡çš„ä½¿ç”¨ / inputå‡½æ•° / æ£€æŸ¥å˜é‡ç±»å‹ / ç±»å‹è½¬æ¢ æ•°å­—å’Œå­—ç¬¦ä¸² - æ•´æ•° / æµ®ç‚¹æ•° / å¤æ•° / å­—ç¬¦ä¸² / å­—ç¬¦ä¸²åŸºæœ¬æ“ä½œ / å­—ç¬¦ç¼–ç  è¿ç®—ç¬¦ - æ•°å­¦è¿ç®—ç¬¦ / èµ‹å€¼è¿ç®—ç¬¦ / æ¯”è¾ƒè¿ç®—ç¬¦ / é€»è¾‘è¿ç®—ç¬¦ / èº«ä»½è¿ç®—ç¬¦ / è¿ç®—ç¬¦çš„ä¼˜å…ˆçº§ åˆ†æ”¯ç»“æ„ åˆ†æ”¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾ ifè¯­å¥ - ç®€å•çš„if / if-elseç»“æ„ / if-elif-elseç»“æ„ / åµŒå¥—çš„if å¾ªç¯ç»“æ„ å¾ªç¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾ whileå¾ªç¯ - åŸºæœ¬ç»“æ„ / breakè¯­å¥ / continueè¯­å¥ forå¾ªç¯ - åŸºæœ¬ç»“æ„ / rangeç±»å‹ / å¾ªç¯ä¸­çš„åˆ†æ”¯ç»“æ„ / åµŒå¥—çš„å¾ªç¯ / æå‰ç»“æŸç¨‹åº å‡½æ•°å’Œæ¨¡å—çš„ä½¿ç”¨ å‡½æ•°çš„ä½œç”¨ - ä»£ç çš„åå‘³é“ / ç”¨å‡½æ•°å°è£…åŠŸèƒ½æ¨¡å— å®šä¹‰å‡½æ•° - defè¯­å¥ / å‡½æ•°å / å‚æ•°åˆ—è¡¨ / returnè¯­å¥ / è°ƒç”¨è‡ªå®šä¹‰å‡½æ•° è°ƒç”¨å‡½æ•° - Pythonå†…ç½®å‡½æ•° / å¯¼å…¥æ¨¡å—å’Œå‡½æ•° å‡½æ•°çš„å‚æ•° - é»˜è®¤å‚æ•° / å¯å˜å‚æ•° / å…³é”®å­—å‚æ•° / å‘½åå…³é”®å­—å‚æ•° å‡½æ•°çš„è¿”å›å€¼ - æ²¡æœ‰è¿”å›å€¼ / è¿”å›å•ä¸ªå€¼ / è¿”å›å¤šä¸ªå€¼ ä½œç”¨åŸŸé—®é¢˜ - å±€éƒ¨ä½œç”¨åŸŸ / åµŒå¥—ä½œç”¨åŸŸ / å…¨å±€ä½œç”¨åŸŸ / å†…ç½®ä½œç”¨åŸŸ / å’Œä½œç”¨åŸŸç›¸å…³çš„å…³é”®å­— ç”¨æ¨¡å—ç®¡ç†å‡½æ•° - æ¨¡å—çš„æ¦‚å¿µ / ç”¨è‡ªå®šä¹‰æ¨¡å—ç®¡ç†å‡½æ•° / å‘½åå†²çªçš„æ—¶å€™ä¼šæ€æ ·ï¼ˆåŒä¸€ä¸ªæ¨¡å—å’Œä¸åŒçš„æ¨¡å—ï¼‰ Lambdaè¡¨è¾¾å¼ å­—ç¬¦ä¸²å’Œå¸¸ç”¨çš„æ•°æ®ç»“æ„è¿™ä¸€å¥éå¸¸é‡è¦ï¼Œpythonæä¾›çš„æ•°æ®ç»“æ„ï¼Œå’Œå†…ç½®çš„æ–¹æ³•å¾ˆå®ç”¨ã€‚ å­—ç¬¦ä¸²çš„ä½¿ç”¨ - è®¡ç®—é•¿åº¦ / ä¸‹æ ‡è¿ç®— / åˆ‡ç‰‡ / å¸¸ç”¨æ–¹æ³• åˆ—è¡¨åŸºæœ¬ç”¨æ³• - å®šä¹‰åˆ—è¡¨ / ç”¨ä¸‹è¡¨è®¿é—®å…ƒç´  / ä¸‹æ ‡è¶Šç•Œ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / ä¿®æ”¹å…ƒç´  / åˆ‡ç‰‡ / å¾ªç¯éå† åƒ insert ï¼Œremove æˆ–è€… sort æ–¹æ³•ï¼Œåªä¿®æ”¹åˆ—è¡¨ï¼Œæ²¡æœ‰æ‰“å°å‡ºè¿”å›å€¼â€”â€”å®ƒä»¬è¿”å›é»˜è®¤å€¼ None ã€‚è¿™æ˜¯Pythonä¸­æ‰€æœ‰å¯å˜æ•°æ®ç»“æ„çš„è®¾è®¡åŸåˆ™ã€‚ åˆ—è¡¨å¸¸ç”¨æ“ä½œ - è¿æ¥ / å¤åˆ¶(å¤åˆ¶å…ƒç´ å’Œå¤åˆ¶æ•°ç»„) / é•¿åº¦ / æ’åº / å€’è½¬ / æŸ¥æ‰¾ ç”Ÿæˆåˆ—è¡¨ - ä½¿ç”¨rangeåˆ›å»ºæ•°å­—åˆ—è¡¨ / ç”Ÿæˆè¡¨è¾¾å¼ / ç”Ÿæˆå™¨ å…ƒç»„çš„ä½¿ç”¨ - å®šä¹‰å…ƒç»„ / ä½¿ç”¨å…ƒç»„ä¸­çš„å€¼ / ä¿®æ”¹å…ƒç»„å˜é‡ / å…ƒç»„å’Œåˆ—è¡¨è½¬æ¢ é›†åˆåŸºæœ¬ç”¨æ³• - é›†åˆå’Œåˆ—è¡¨çš„åŒºåˆ« / åˆ›å»ºé›†åˆ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / æ¸…ç©º é›†åˆå¸¸ç”¨æ“ä½œ - äº¤é›† / å¹¶é›† / å·®é›† / å¯¹ç§°å·® / å­é›† / è¶…é›† å­—å…¸çš„åŸºæœ¬ç”¨æ³• - å­—å…¸çš„ç‰¹ç‚¹ / åˆ›å»ºå­—å…¸ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / å–å€¼ / æ¸…ç©º å­—å…¸å¸¸ç”¨æ“ä½œ - keys()æ–¹æ³• / values()æ–¹æ³• / items()æ–¹æ³• / setdefault()æ–¹æ³• 12list(d1.keys())in not in python list å¸¸ç”¨æ–¹æ³•æ€»ç»“ 12345678910111213141516171819201. åˆ›å»º 1.1 l = [1, 2] 1.2 list = []2. æ·»åŠ  2.1 æœ«å°¾å¢åŠ ä¸€ä¸ª append 2.2 æŒ‡å®šä½ç½®å¢åŠ ä¸€ä¸ª insert 2.3 å¢åŠ list extend +3. æŸ¥ [start: stop: step]4. æ”¹5. åˆ  1. pop 2. remove(å…ƒç´ ) 3. del åˆ—è¡¨6. æ’åºå’Œåè½¬ reverse(); sort(); sort(reverse = True)7. å±æ€§ len max/min8. å¤åˆ¶ python string 12345678910111213141516171819202122231. æ£€æµ‹ str æ˜¯å¦åŒ…å«åœ¨ mysträ¸­ï¼Œå¦‚æœæ˜¯ï¼Œè¿”å›å¼€å§‹çš„ç´¢å¼•å€¼ï¼›å¦åˆ™è¿”å›-1ã€‚ä¹Ÿå¯ä»¥æŒ‡å®šåœ¨ä¸€å®šçš„èŒƒå›´å†…ã€‚mystr.find(str, start=0, end=len(mystr))2. è·Ÿfind()æ–¹æ³•ä¸€æ ·ï¼Œåªä¸è¿‡å¦‚æœsträ¸åœ¨ mysträ¸­ä¼šæŠ¥ä¸€ä¸ªå¼‚å¸¸.mystr.index(str, start=0, end=len(mystr))3. æŠŠ mystr ä¸­çš„ str1 æ›¿æ¢æˆ str2,å¦‚æœ count æŒ‡å®šï¼Œåˆ™æ›¿æ¢ä¸è¶…è¿‡ count æ¬¡.mystr.replace(str1, str2, mystr.count(str1))4. ä»¥ str ä¸ºåˆ†éš”ç¬¦åˆ‡ç‰‡ mystrï¼Œå¦‚æœ maxsplitæœ‰æŒ‡å®šå€¼ï¼Œåˆ™ä»…åˆ†éš” maxsplit ä¸ªå­å­—ç¬¦ä¸²mystr.split(str=&quot; &quot;, 2)5. åˆ é™¤ mystr å·¦è¾¹çš„ç©ºç™½å­—ç¬¦mystr.lstrip()6. åˆ é™¤ mystr å­—ç¬¦ä¸²æœ«å°¾çš„ç©ºç™½å­—ç¬¦mystr.rstrip()7. åˆ é™¤mystrå­—ç¬¦ä¸²ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦ Day Ox01å®šä¹‰ç±»12classclass classname(object): __init__æ˜¯åˆ›å»ºå¯¹è±¡æ—¶è¿›è¡Œåˆå§‹åŒ–æ“ä½œ 12345678910111213141516171819202122232425262728 def __init__(self, name, age): self.name = name self.age = ageåˆ›å»ºå®åˆ—std = classname(&apos;xiemay&apos;,&apos;24&apos;)ç§æœ‰å’Œå…¬å¼€çš„å±æ€§å’Œå‡½æ•°ï¼šç”¨__å¼€å¤´@property è£…é¥°å™¨å¦‚æœæƒ³è®¿é—®å±æ€§å¯ä»¥é€šè¿‡å±æ€§çš„getterï¼ˆè®¿é—®å™¨ï¼‰å’Œsetterï¼ˆä¿®æ”¹å™¨ï¼‰æ–¹æ³•è¿›è¡Œå¯¹åº”çš„æ“ä½œã€‚ # è®¿é—®å™¨ - getteræ–¹æ³• @property def age(self): return self._ageé™æ€æ–¹æ³•å’Œç±»æ–¹æ³• # ä¿®æ”¹å™¨ - setteræ–¹æ³• @age.setter def age(self, age): self._age = age @staticmethod def is_valid(a, b, c): return a + b &gt; c and b + c &gt; a and a + c &gt; b## ç»§æ‰¿å’Œå¤šæ€class person(): class woman(person): super.__init__() æ–‡ä»¶æ“ä½œæ–‡ä»¶æ“ä½œåŸºæœ¬ä¸Šæ²¡ä»€ä¹ˆé—®é¢˜äº† æ“ä½œæ¨¡å¼ å…·ä½“å«ä¹‰ a+ æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ç”¨äºè¯»å†™ã€‚å¦‚æœè¯¥æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ–‡ä»¶æŒ‡é’ˆå°†ä¼šæ”¾åœ¨æ–‡ä»¶çš„ç»“å°¾ã€‚æ–‡ä»¶æ‰“å¼€æ—¶ä¼šæ˜¯è¿½åŠ æ¨¡å¼ã€‚å¦‚æœè¯¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶ç”¨äºè¯»å†™ã€‚ w+ æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ç”¨äºè¯»å†™ã€‚å¦‚æœè¯¥æ–‡ä»¶å·²å­˜åœ¨åˆ™æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶ä»å¼€å¤´å¼€å§‹ç¼–è¾‘ï¼Œå³åŸæœ‰å†…å®¹ä¼šè¢«åˆ é™¤ã€‚å¦‚æœè¯¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶ã€‚ &#39;r&#39; è¯»å– ï¼ˆé»˜è®¤ï¼‰ &#39;w&#39; å†™å…¥ï¼ˆä¼šå…ˆæˆªæ–­ä¹‹å‰çš„å†…å®¹ï¼‰ &#39;x&#39; å†™å…¥ï¼Œå¦‚æœæ–‡ä»¶å·²ç»å­˜åœ¨ä¼šäº§ç”Ÿå¼‚å¸¸ &#39;a&#39; è¿½åŠ ï¼Œå°†å†…å®¹å†™å…¥åˆ°å·²æœ‰æ–‡ä»¶çš„æœ«å°¾ &#39;b&#39; äºŒè¿›åˆ¶æ¨¡å¼ &#39;t&#39; æ–‡æœ¬æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ &#39;+&#39; æ›´æ–°ï¼ˆæ—¢å¯ä»¥è¯»åˆå¯ä»¥å†™ï¼‰ r+ æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ç”¨äºè¯»å†™ã€‚æ–‡ä»¶æŒ‡é’ˆå°†ä¼šæ”¾åœ¨æ–‡ä»¶çš„å¼€å¤´ã€‚ 12with open(filename, moder, encoding) as f1: for line in f1: è¯»å–æ–¹æ³•æŒ‰å­—èŠ‚12fileObject.read([count]); åœ¨è¿™é‡Œï¼Œè¢«ä¼ é€’çš„å‚æ•°æ˜¯è¦ä»å·²æ‰“å¼€æ–‡ä»¶ä¸­è¯»å–çš„å­—èŠ‚è®¡æ•°ã€‚è¯¥æ–¹æ³•ä»æ–‡ä»¶çš„å¼€å¤´å¼€å§‹è¯»å…¥ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥countï¼Œå®ƒä¼šå°è¯•å°½å¯èƒ½å¤šåœ°è¯»å–æ›´å¤šçš„å†…å®¹ï¼Œå¾ˆå¯èƒ½æ˜¯ç›´åˆ°æ–‡ä»¶çš„æœ«å°¾ã€‚ å•ç‹¬ä¸€è¡Œ123456readline()æ–¹æ³•f.readline() ä¼šä»æ–‡ä»¶ä¸­è¯»å–å•ç‹¬çš„ä¸€è¡Œã€‚æ¢è¡Œç¬¦ä¸º &apos;\n&apos;ã€‚f.readline() å¦‚æœè¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸², è¯´æ˜å·²ç»å·²ç»è¯»å–åˆ°æœ€åä¸€è¡Œã€‚with open() as f1: while True: lines = f.readline() if lines: å…¨éƒ¨è¡Œ12345readlines()æ–¹æ³• f.readlines() å°†ä»¥åˆ—è¡¨çš„å½¢å¼è¿”å›è¯¥æ–‡ä»¶ä¸­åŒ…å«çš„æ‰€æœ‰è¡Œï¼Œåˆ—è¡¨ä¸­çš„ä¸€é¡¹è¡¨ç¤ºæ–‡ä»¶çš„ä¸€è¡Œã€‚å¦‚æœè®¾ç½®å¯é€‰å‚æ•° sizehint, åˆ™è¯»å–æŒ‡å®šé•¿åº¦çš„å­—èŠ‚, å¹¶ä¸”å°†è¿™äº›å­—èŠ‚æŒ‰è¡Œåˆ†å‰²ã€‚with open() as f1: lines = f1.readlines() json æ–‡ä»¶è¯»å–12345678910jsonæ¨¡å—ä¸»è¦æœ‰å››ä¸ªæ¯”è¾ƒé‡è¦çš„å‡½æ•°ï¼Œåˆ†åˆ«æ˜¯ï¼šdump - å°†Pythonå¯¹è±¡æŒ‰ç…§JSONæ ¼å¼åºåˆ—åŒ–åˆ°æ–‡ä»¶ä¸­dumps - å°†Pythonå¯¹è±¡å¤„ç†æˆJSONæ ¼å¼çš„å­—ç¬¦ä¸² infor = json.dumps(neww) f.write(infor+&apos;\n&apos;)load - å°†æ–‡ä»¶ä¸­çš„JSONæ•°æ®ååºåˆ—åŒ–æˆå¯¹è±¡loads - å°†å­—ç¬¦ä¸²çš„å†…å®¹ååºåˆ—åŒ–æˆPythonå¯¹è±¡ b = json.loads(lines) excelå•ç‹¬æ“ä½œexcelçš„åº“ åˆ›å»º/æ‰“å¼€(å¯¹è±¡)ï¼Œå®šä½(sheet)ï¼Œå®šä½è¡Œåˆ—, ä¿å­˜ å°±æ˜¯è¿™å‡ ä¸ªæ–¹æ³• xlrd12345678910111213141516171819202122232425262728293031323334353637383940### å¯¼å…¥ xlrd åº“import xlrd### æ‰“å¼€åˆšæ‰æˆ‘ä»¬å†™å…¥çš„ test_w.xls æ–‡ä»¶wb = xlrd.open_workbook(&quot;test_w.xls&quot;)### è·å–å¹¶æ‰“å° sheet æ•°é‡print( &quot;sheet æ•°é‡:&quot;, wb.nsheets)### è·å–å¹¶æ‰“å° sheet åç§°print( &quot;sheet åç§°:&quot;, wb.sheet_names())### æ ¹æ® sheet ç´¢å¼•è·å–å†…å®¹sh1 = wb.sheet_by_index(0)### æˆ–è€…### ä¹Ÿå¯æ ¹æ® sheet åç§°è·å–å†…å®¹### sh = wb.sheet_by_name(&apos;æˆç»©&apos;)### è·å–å¹¶æ‰“å°è¯¥ sheet è¡Œæ•°å’Œåˆ—æ•°print( u&quot;sheet %s å…± %d è¡Œ %d åˆ—&quot; % (sh1.name, sh1.nrows, sh1.ncols))### è·å–å¹¶æ‰“å°æŸä¸ªå•å…ƒæ ¼çš„å€¼print( &quot;ç¬¬ä¸€è¡Œç¬¬äºŒåˆ—çš„å€¼ä¸º:&quot;, sh1.cell_value(0, 1))### è·å–æ•´è¡Œæˆ–æ•´åˆ—çš„å€¼rows = sh1.row_values(0) # è·å–ç¬¬ä¸€è¡Œå†…å®¹cols = sh1.col_values(1) # è·å–ç¬¬äºŒåˆ—å†…å®¹### æ‰“å°è·å–çš„è¡Œåˆ—å€¼print( &quot;ç¬¬ä¸€è¡Œçš„å€¼ä¸º:&quot;, rows)print( &quot;ç¬¬äºŒåˆ—çš„å€¼ä¸º:&quot;, cols)### è·å–å•å…ƒæ ¼å†…å®¹çš„æ•°æ®ç±»å‹print( &quot;ç¬¬äºŒè¡Œç¬¬ä¸€åˆ—çš„å€¼ç±»å‹ä¸º:&quot;, sh1.cell(1, 0).ctype)### éå†æ‰€æœ‰è¡¨å•å†…å®¹for sh in wb.sheets(): for r in range(sh.nrows): # è¾“å‡ºæŒ‡å®šè¡Œ print( sh.row(r)) xlwt123456789101112131415161718192021222324252627### excel_w.py### å¯¼å…¥ xlwt åº“import xlwt### åˆ›å»º xls æ–‡ä»¶å¯¹è±¡wb = xlwt.Workbook()### æ–°å¢ä¸¤ä¸ªè¡¨å•é¡µsh1 = wb.add_sheet(&apos;æˆç»©&apos;)sh2 = wb.add_sheet(&apos;æ±‡æ€»&apos;)### ç„¶åæŒ‰ç…§ä½ç½®æ¥æ·»åŠ æ•°æ®,ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¡Œï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯åˆ—### å†™å…¥ç¬¬ä¸€ä¸ªsheetsh1.write(0, 0, &apos;å§“å&apos;)sh1.write(0, 1, &apos;æˆç»©&apos;)sh1.write(1, 0, &apos;å¼ ä¸‰&apos;)sh1.write(1, 1, 88)sh1.write(2, 0, &apos;æå››&apos;)sh1.write(2, 1, 99.5)### å†™å…¥ç¬¬äºŒä¸ªsheetsh2.write(0, 0, &apos;æ€»åˆ†&apos;)sh2.write(1, 0, 187.5)### æœ€åä¿å­˜æ–‡ä»¶å³å¯wb.save(&apos;test_w.xls&apos;) pandas ä¹Ÿå¯ä»¥æ“ä½œ 123456789101112ExcelWriter: Class for writing DataFrame objects into excel sheets.with ExcelWriter(&apos;path_to_file.xlsx&apos;, mode=&apos;a&apos;) as writer: df.to_excel(writer, sheet_name=&apos;Sheet3&apos;) writer = pd.ExcelWriter(&apos;exam.xlsx&apos;) for i in all_grad_pair: inflowdata = pd.read_csv(newfiledir+i+precitypair+&apos;.txt&apos;,\ sep = &apos;\t&apos;,header = 0, index_col = 0,encoding = &apos;utf-8&apos;) inflowdata.to_excel(writer,sheet_name = CityName[j])writer.save() â€‹12345678910111213import pandas as pd #è¯»å–ä¸¤ä¸ªè¡¨æ ¼data1=pd.read_excel('æ–‡ä»¶è·¯å¾„')data2=pd.read_excel('æ–‡ä»¶è·¯å¾„') #å°†ä¸¤ä¸ªè¡¨æ ¼è¾“å‡ºåˆ°ä¸€ä¸ªexcelæ–‡ä»¶é‡Œé¢writer=pd.ExcelWriter('D:æ–°è¡¨.xlsx')data1.to_excel(writer,sheet_name='sheet1')data2.to_excel(writer,sheet_name='sheet2') #å¿…é¡»è¿è¡Œwriter.save()ï¼Œä¸ç„¶ä¸èƒ½è¾“å‡ºåˆ°æœ¬åœ°writer.save() ç¬¬äºŒå‘¨ï¼šnumpyhttps://cloudxlab.com/blog/numpy-pandas-introduction/ å¯¹è±¡Numpy æä¾›äº†nç»´æ•°ç»„å¯¹è±¡ï¼ˆndarray, A multidimensional array object) åˆ›å»º 1234np.arange(6)array([0,1, 2, 3, 4, 5])np.zeros(10) # 1-nnp.zeros((3, 6)) # 2-n types123arr1 = np.array([1, 2, 3], dtype=np.float64)arr1.dtypefloat_arr = arr.astype(np.float64) ç´¢å¼•å°±æ˜¯ç”¨ä¸­æ‹¬å·ï¼Œæ³¨æ„åˆ‡ç‰‡æ˜¯ä¸€ç»´æ•°ç»„è¿˜æ˜¯å¤šå°‘ç»´æ•°ç»„ï¼[, ], å¦‚æœï¼Œåé¢çœç•¥è¡¨ç¤ºå…¨éƒ¨ç´¢å¼•ã€‚ å¸ƒå°”ç±»å‹ç´¢å¼• 12345data[names == &apos;Bob&apos;]è¡¨ç¤ºç´¢å¼•è¡Œdata[names == &apos;Bob&apos;, 2:]è¡¨ç¤ºè¡Œåˆ—ç´¢å¼• å¢æ”¹1result = np.where(cond, xarr, yarr) ç´¢å¼•å€¼åˆ è®¡ç®—å‡½æ•°+-/ *éƒ½æ˜¯å…ƒç´ å¯¹é½ np.sqrt() np.exp() pandaså¯¹è±¡åˆ›å»ºç´¢å¼•å¢æ”¹ç´¢å¼•å€¼åˆ è®¡ç®—å‡½æ•°matplotlibseabornç¬¬ä¸‰å‘¨ï¼šsklearnç¬¬äº”å‘¨ï¼šsqlç¬¬å…­å‘¨ï¼š Linuxç¬¬ä¸ƒå‘¨å’Œå…«å‘¨ï¼šæœºå™¨å­¦ä¹ ç®—æ³•å’Œæ•°æ®æŒ–æ˜]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æœºå™¨å­¦ä¹ ]]></title>
    <url>%2F2020%2F07%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[çº¿æ€§å›å½’é€»è¾‘æ–¯ç‰¹å›å½’å†³ç­–æ ‘]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>ç›‘ç£å­¦ä¹ ä¸éç›‘ç£å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data-Analysis]]></title>
    <url>%2F2020%2F07%2F25%2FData-Analysis%2F</url>
    <content type="text"></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>æ•°æ®åˆ†æ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç”Ÿæ´»å¿ƒå¾—]]></title>
    <url>%2F2020%2F07%2F20%2F%E7%94%9F%E6%B4%BB%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[æå‡è‡ªå·± 20200824å®‰å®‰é™é™è·Ÿç€å¯¼å¸ˆå¹²äº”å¹´ï¼Œè¯»åšä¹Ÿæ˜¯å¾ˆå¥½çš„ï¼ä½†æ˜¯è‡ªå·±æŠŠè‡ªå·±æ¯’æ­»äº†ï¼Œç°åœ¨åªèƒ½å°½å¿«æ‰¾å·¥ä½œäº†ï¼Œæ—©å®ä¹ å§! æŠŠè€ƒè¯•è¿‡äº† è”ç³»æ¶›å“¥ï¼Œå½“é¢äº¤æµ å®ä¹ æˆ–è€…æ¯•ä¸šè®ºæ–‡ æ¸æ¸çš„å‘ç°ï¼Œååˆ©å¾ˆé‡è¦å—ï¼Ÿå°‘å‘ä¸€ç¯‡è®ºæ–‡ï¼Œå¹²é¡¹ç›®é‡è¦å—ï¼Ÿæˆ‘æ— æ‰€è°“å•Šï¼ 20200808å·¥ä½œå§ï¼Œæˆ‘è¿˜æ˜¯å»èµšé’±å§ï¼æˆ‘çš„æŠ€èƒ½å·®ä¸å¤šå¯ä»¥å»å·¥ä½œäº†ï¼Œå¯¹äºé¡¹ç›®ç»éªŒï¼ˆå¯èƒ½å·®ä¸€ç‚¹ï¼‰ï¼›èµšé’±å»äº†ï¼å·¥ä½œäº†ï¼ æ—©ç‚¹å®Œæˆæ¯•ä¸šè®¾è®¡ï¼ å‡†å¤‡å·¥ä½œäº†ï¼ 20200730https://mp.weixin.qq.com/s?__biz=MzU5Nzg5ODQ3NQ==&amp;mid=2247493071&amp;idx=3&amp;sn=07e73bb37e1bafb8f5c2ac9bdba20948&amp;chksm=fe4ec04bc939495d1d1e28e5883d83b90d9e50eaa00bd398bf192693edc066055d2e0de0ff09&amp;scene=0&amp;xtrack=1#rd è¦æ˜¯ä»æ•°æ®åˆ†ææŒæ¡çš„æŠ€èƒ½æ¥åˆ†é—¨æ´¾çš„è¯ï¼Œæ¥çœ‹çœ‹ä½ ä¼šæ˜¯å“ªä¸ªé—¨æ´¾çš„æŒé—¨äººã€‚ 1ã€ä¸å¸®æŒé—¨äººï¼šæ”¶å…¥ï¼š10K å·¦å³ï¼›å¤„å¢ƒï¼šå°å…¬å¸èŒå‘˜ï¼Œæ€¥åˆ‡æƒ³è¦æ‘†è„±â€œäººè‚‰å–æ•°æœºå™¨â€ã€‚å·¥ä½œå†…å®¹ï¼šå–æ•°ã€ç»Ÿè®¡ã€åˆ¶ä½œæŠ¥è¡¨ï¼›æŒæ¡æŠ€èƒ½ï¼šExcel ã€SQLå–æ•°ã€åŸºæœ¬çš„æ•°æ®åº“æ“ä½œâ€¦â€¦ 2ã€å°‘æ—æŒé—¨äººï¼šæ”¶å…¥ï¼š15K å·¦å³ï¼›å¤„å¢ƒï¼šä¸­å°å‹å…¬å¸èŒå‘˜ï¼Œæ€¥åˆ‡æƒ³è¦æå‡èŒåœºç«äº‰åŠ›ï¼Œçªç ´è–ªèµ„ç“¶é¢ˆã€‚å·¥ä½œå†…å®¹ï¼šå—å°‘æ—è´Ÿè´£æ•°æ®æ¸…æ´—ã€å»ºæ¨¡ï¼Œ åŒ—å°‘æ—è´Ÿè´£ç ”ç©¶ç®—æ³•ã€ç»“åˆä¸šåŠ¡éœ€æ±‚ä¼˜åŒ–ç®—æ³•ï¼›æŒæ¡æŠ€èƒ½ï¼šç»Ÿè®¡å­¦ã€pythonã€æ•°æ®åº“æ“ä½œâ€¦â€¦ 3ã€æ˜æ•™æŒé—¨äººï¼šæ”¶å…¥ï¼šä¸åˆ° 20 Kï¼›åœ°ä½ï¼šä¸­å¤§å‹å…¬å¸èŒå‘˜/ leader ï¼Œæ€¥åˆ‡æƒ³è¦æ„å»ºæ»¡è¶³å¤§å‚æ•°æ®åˆ†æèƒ½åŠ›æ¨¡å‹ï¼Œæ–©è·é«˜è–ªofferã€‚å·¥ä½œå†…å®¹ï¼šæ ¹æ®æ•°æ®æ‰¾åŸå› ã€ç»™ç»“è®ºï¼ŒæŠ“ä½ä¸šåŠ¡æ ¸å¿ƒæœ¬è´¨ï¼›æŒæ¡æŠ€èƒ½ï¼šç»Ÿè®¡å­¦ã€æ•°æ®åº“ã€pythonã€æ•°æ®åˆ†ææ€ç»´ä¸æ–¹æ³•â€¦â€¦ 4ã€æ­¦å½“æŒé—¨äººï¼šæ”¶å…¥ï¼š25K+ ï¼›åœ°ä½ï¼šå¤§å‚èŒå‘˜/ ladder ï¼Œéšæ—¶æœŸå¾…å…¬å¸å…¥è‚¡ã€‚å·¥ä½œå†…å®¹ï¼šå¯¹ä¼ä¸šç°çŠ¶åšåˆ†æï¼Œä¸ºä¼ä¸šé¢„æµ‹æœªæ¥ã€å¸ƒå±€æˆ˜ç•¥ï¼›æŒæ¡æŠ€èƒ½ï¼šæ•°æ®åº“ã€æ•°æ®æŒ–æ˜ã€pythonã€æ•°æ®åˆ†ææ€ç»´ä¸æ–¹æ³•ã€SPSSç­‰å·¥å…·â€¦â€¦ 20200728 é™Œä¸ŠèŠ±å¼€ï¼Œæ…¢æ…¢å½’çŸ£5w2hæ˜¯æœ€å¥½çš„ç²¾ç»†åŒ–æ–¹æ³•ã€‚ å¯¹ä¸èµ·ï¼Œæˆ‘æ˜¯ä¸æ˜¯æ¬ºéª—åˆ«äººçš„æ„Ÿæƒ…äº†ã€‚ä»é•¿è¿œçœ‹ï¼Œæˆ‘æ˜¯ä¸æ˜¯ä¸æˆç†Ÿå•Šï¼è€æ˜¯ç»™åˆ«äººé€ æˆéº»çƒ¦ã€‚æ²¡æœ‰è·Ÿåˆ«äººæ²Ÿé€šæˆ‘çš„çœŸå®æƒ³æ³•å•Šã€‚æµªè´¹åˆ«äººçš„æ—¶é—´å’Œç²¾åŠ›å•Šï¼ æˆ‘ç°åœ¨æ˜¯å¾ˆæ¸…æ¥šè‡ªå·±çš„èŒä¸šè§„åˆ’äº†ã€‚å…¶å®ï¼Œæˆ‘ä¸€ç›´æ¸…æ¥šè‡ªå·±çš„èŒä¸šè§„åˆ’ï¼Œä½†æ˜¯å°±æ˜¯æ²¡æœ‰æ²Ÿé€šå¥½ã€‚ æ—¢ç„¶çŸ¥é“è‡ªå·±å†…å¿ƒéœ€è¦ä»€ä¹ˆï¼Œé‚£å°±å»è¡ŒåŠ¨å•Šï¼æˆ‘è¦çš„ä¸è¿‡æ˜¯è¿™ä¸ªå­¦å†ç½¢äº†ï¼Œè¿™ä¸ªæ•²é—¨ç –ã€‚ from 201509-201909 ç¾å¥½çš„å¤§å­¦æ—¶å…‰ï¼Œæˆ‘äº²çˆ±çš„è¥¿ç§‘ã€‚è¿™é‡Œçš„å››å¹´ï¼Œæ˜¯æˆ‘æœ€å¿«ä¹å’Œå¹¸ç¦çš„æ—¶å…‰äº†ã€‚å¦‚æœå¯ä»¥æˆ‘æ„¿æ„æ”¾å¼ƒå¾ˆå¤šï¼Œåªæ±‚å¤šåœ¨é‚£é‡Œå¤šå‘†ä¸€å¤©ã€‚æˆ‘æ°¸è¿œæŠŠåœ¨è¥¿å—ç§‘æŠ€å¤§å­¦çš„æ—¶å…‰è§†ä¸ºæˆ‘æœ€å®è´µçš„ç»å†ã€‚æ¯æ¬¡æƒ³èµ·çš„æ—¶å€™ï¼Œæ³ªæ°´æ„Ÿè§‰å°±è¦å‡ºæ¥äº†ï¼Œå°±åƒç¦»å¼€è¥¿ç§‘å¤§å»ç”µå­ç§‘æŠ€å¤§å­¦çš„è½¦ä¸Šã€‚çœ‹ç€æ¨¡ç³Šçš„è¥¿ç§‘å¤§ï¼Œæˆ‘å“­äº†ã€‚å››å¹´å¯¹æˆ‘å¤ªé‡è¦äº†ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å­¦ä¼šäº†ç§‘ç ”ã€‚ from 201909-202007 ç ”ä¸€æ—¶å…‰ã€‚ä¸Šè¯¾ï¼Œç§‘ç ”ï¼Œå®éªŒå®¤è¿˜æ˜¯ä¸‰ç‚¹ä¸€çº¿ã€‚ç§‘ç ”åšçš„è¿˜æ˜¯é¡ºåˆ©ï¼Œåªæ˜¯è‡ªå·±æ²¡æœ‰æ²Ÿé€šè‡ªå·±çš„éœ€æ±‚ã€‚æˆ‘å°±æƒ³åšä¸¤å¹´çš„ç§‘ç ”ï¼Œåˆä½œä¸€ç¯‡è®ºæ–‡ï¼Œç„¶åå»å·¥ä½œã€‚å½“ç„¶æœ‰ç‚¹æƒ³è¯»åšï¼Œä»”ç»†æƒ³æƒ³ï¼Œè¯»åšå®Œå…¨æ²¡æœ‰ä»»ä½•æ„ä¹‰çš„ã€‚æˆ‘åŠªåŠ›çš„æ„ä¹‰åªæ˜¯æƒ³ä¸è¾œè´Ÿè‡ªå·±ï¼Œå¹¶ä¸æ˜¯è¦è¯»åšã€‚è¿™ä¸ªç‹¬ç«‹çš„ç§‘ç ”è¿‡ç¨‹ï¼Œè‡ªå·±å­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ï¼Œè¿™ä¹Ÿæ˜¯å¢é•¿è§è¯†ï¼ŒçŸ¥è¯†å’Œé˜…å†çš„äº‹æƒ…ã€‚å¦‚æœæ˜¯å› ä¸ºç¼ºé’±è¯»åšï¼Œæ€ä¹ˆå¯èƒ½å‘¢ï¼Ÿå®Œå…¨æ˜¯å› ä¸ºæ²¡æœ‰æ„ä¹‰ï¼Œå¦‚æœè¯»äº†å››å¹´ï¼Œè¿˜è·Ÿç°åœ¨å·®ä¸å¤šï¼Œå°±æ˜¯å¢é•¿äº†ç‚¹çŸ¥è¯†ï¼Œå¯¹æˆ‘æ¥è¯´ï¼Œå®Œå…¨æ²¡æœ‰æ„ä¹‰ã€‚è¯»ç ”çš„ç»å†ç¾å¥½åœ¨äºè®¤è¯†äº†æˆ‘äº²çˆ±çš„å®¤å‹ï¼Œæ‰æ‰ï¼›å’Œå®éªŒå®¤çš„è€å¸ˆå’ŒåŒå­¦ï¼Œä»–ä»¬éƒ½å¾ˆå‰å®³å’Œä¼˜ç§€ã€‚å¢åƒå¢å–äº†ä¸å°‘ã€‚å•¦å•¦å•¦å•¦å•¦ï¼æˆ‘è‡ªå·±ä¹Ÿæ²¡æœ‰æƒ³åˆ°ï¼Œæƒ³æƒ³è‡ªå·±å½“åˆçš„ç®€å†ï¼Œè¦èŠ±ä¸‰å¹´è¾¾æˆçš„ç›®æ ‡ï¼Œå±…ç„¶ä¸€å¹´å°±å®Œæˆäº†ã€‚å•¦å•¦å•¦å•¦å•¦ï¼åœ¨è¿™é‡Œï¼Œæˆ‘ç‹¬ç«‹äº†ç§‘ç ”ã€‚ å­¦ç”Ÿç”Ÿæ¶¯ç»“æŸäº†ï¼ å¾€åï¼Œå‡†å¤‡å»æ±‚èŒäº†ï¼ äººç”Ÿæ²¡æœ‰ç™½èµ°çš„è·¯ï¼Œæ¯ä¸€æ®µæ—…ç¨‹éƒ½æ˜¯æ”¶è·æ…¢æ…¢ï¼ åˆ·é¢˜å‡†å¤‡å“ˆã€‚ 20200727å‘ç€æ°¸æ’å‡ºå‘ã€‚ç»§ç»­åŠ æ²¹ï¼Œ æŠŠå†…å¿ƒè®¸å¤šçš„æ‰§å¿µæŠ›å¼ƒä»¥åï¼Œä½ å°±ä¼šå‘ç°ä½ å–œæ¬¢çš„ä¸œè¥¿ï¼Œè‡ªç„¶è€Œç„¶çš„æµéœ²å‡ºäº†ï¼ä»é•¿è¿œçœ‹ï¼Œè‡ªå·±æƒ³è¦çš„ï¼Œå·²ç»åœ¨è·¯ä¸Šäº†ï¼ä½ æƒ³å¾—åˆ°çš„ä¸œè¥¿ä¹Ÿåœ¨å¿ƒé‡Œäº†ã€‚ ä¸è¿‡å°±æ˜¯ç”Ÿæ´»ä¸­çš„å°æ’æ›²ç½¢äº†ï¼ŒæƒŠå–œç½¢äº† ã€‚å°±åƒæ”¾å¼ƒä¿ç ”çš„ï¼Œæ”¾å¼ƒç ”ä¸€çš„ç¡•åšè¿è¯»ï¼Œæˆ‘ä¸€ç›´çš„çœ‹æ¸…è‡ªå·±çš„å†…å¿ƒï¼Œä¹‹æ‰€ä»¥è¿˜è¦ç•™æ‹ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œå¯èƒ½å°±æ˜¯æƒ³åˆä½œä¸€ä¸¤æ¬¡å§ï¼å¯¹ä¸èµ·ï¼Œæˆ‘æ˜¯ä¸æ˜¯è€æ˜¯æ¬ºéª—åˆ«äººçš„æ„Ÿæƒ…å•Šï¼ ç²¾é€šä¸€ä¸ªé¢†åŸŸå…¶å®å¾ˆç®€å•ï¼Œ 20200725åŠªåŠ›ä¿®ç‚¼è‡ªå·±ï¼çªç„¶å‘ç°ä»€ä¹ˆéƒ½å¾ˆåƒåœ¾äº†ï¼ åŠªåŠ›æå‡è‡ªå·±ä¸€ã€è‡ªæˆ‘æŠ•èµ„ é˜…è¯»ï¼å½±éŸ³å­¦ä¹ ï¼å†™æ—¥è®°ï¼è®¤è¯†æ–°æœ‹å‹ï¼å­¦ä¹ ä¸“ä¸šçŸ¥è¯†ï¼è€ƒèµ„æ ¼è¯ï¼å‚åŠ ç ”è®¨ä¼šã€è¯»ä¹¦ä¼šï¼æŠŠåœ¨è·¯ä¸Šçš„æ—¶é—´è½¬å˜ä¸ºå­¦ä¹ æ—¶é—´ï¼åˆ©ç”¨åšå®¢ã€ç”µå­æŠ¥å‘å¸ƒä¿¡æ¯ï¼è®¢é˜…åˆŠç‰©ï¼é‡æ–°æ£€è§†äººç”Ÿè®¡åˆ’ï¼æŠŠä¸€å¹´çš„ç›®æ ‡å†™åœ¨çº¸ä¸Š äºŒã€é‡‘é’± å­˜é’±ï¼èŠ‚çº¦ï¼æŠ•èµ„ï¼å¡«å†™å®¶åº­æ”¶æ”¯ç°¿ï¼ä¸èµŒåšï¼è¯·ä»–äººåƒé¥­ï¼ææ¬¾ ä¸‰ã€å¿ƒçµæˆé•¿ï¼ˆå‹åŠ›ã€åŠ¨åŠ›ï¼‰ æ¯å¤©è¦è¯´ç§¯æå‘ä¸Šçš„è¯ï¼å†¥æƒ³ï¼æ¯å¤©å†™ä¸€ä»¶æ„Ÿæ©çš„äº‹ï¼æ—©ä¸Šæ³¡æ¾¡ï¼æ¯å¤©éƒ½æœ‰ä¸€ä»¶æœŸå¾…çš„äº‹ï¼æ¯å‘¨åšä¸€ä»¶æœ‰è¶£çš„äº‹ï¼æ•´ç†ï¼ä¸€å¤©åšä¸‰æ¬¡æ·±å‘¼å¸ï¼å¬å–œæ¬¢çš„éŸ³ä¹ï¼é—®æœ‰å»ºè®¾æ€§çš„é—®é¢˜ï¼ä¸€å¤©å°‘åšä¸€ä»¶äº‹ï¼ˆå·¥ä½œæ¸…å•æˆ–å¤‡å¿˜å½•ï¼‰ å››ã€è¿ç”¨æ—¶é—´ ä¸çœ‹ç”µè§†ï¼æ‹Ÿå®šç¬¬äºŒå¤©çš„è®¡åˆ’ï¼é™å®šçœ‹ç”µå­é‚®ä»¶çš„æ¬¡æ•°ï¼æ‹’ç»èšé¤çš„é‚€çº¦ï¼æ‚äº‹ç»Ÿä¸€å¤„ç†ï¼å…ˆå¤„ç†æœ€é‡è¦çš„ä¸‰ä»¶äº‹ï¼åˆ—å·¥ä½œæ¸…å•ï¼ä¸¥å®ˆä¸‹ç­æ—¶é—´ï¼ææ—©è¿›å…¬å¸ï¼ä¸€æ¬¡åªé›†ä¸­åœ¨ä¸€ä»¶äº‹ä¸Šï¼ä¸æ–­æ”¹å–„å¯¹æ—¶é—´çš„è¿ç”¨ äº”ã€äººé™…å…³ç³» ç»å¸¸ç§°å‘¼å¯¹æ–¹çš„åå­—ï¼æ¯å¤©éƒ½è¦ç§°èµä»–äººï¼ä¸€å¤©æœ‰40ï¼…çš„æ—¶é—´ä¿æŒç¬‘å®¹ï¼å¤§å£°åœ°ä¸äººæ‰“æ‹›å‘¼ï¼æˆä¸ºå€¾å¬çš„äººï¼åŸè°…ä»–äººï¼å†™äº¤æ¢æ—¥è®°ï¼æ¯å¤©ä¸é‡è¦çš„äººäº¤è°ˆ10åˆ†é’Ÿä»¥ä¸Šï¼ä¸è¯´æŠ±æ€¨ã€ä¸æ»¡çš„è¯ï¼å…ˆè¯´ç»“è®ºï¼ä»¥åŒèµ¢çš„ç›®æ ‡æ€è€ƒ å…­ã€å¥åº·ã€ç¾ åƒå¥åº·é£Ÿå“ï¼æŠŠç™½ç±³æ¢æˆç³™ç±³ï¼æ¯å¤©åˆ·3æ¬¡ç‰™ï¼åƒå¤©ç„¶é£Ÿç‰©ï¼æ¯å¤©ç¡æ»¡7ä¸ªå°æ—¶ï¼ä¸€å¤©å–2å‡æ°´ï¼æ¯å¤©æ™’å¤ªé˜³30åˆ†é’Ÿï¼ä¸å–é…’ï¼è®²ç©¶ç©¿ç€ï¼å‡è¡¡æ‘„å–è¥å…»â˜…ï¼é¥®é£Ÿä»¥è”¬æœä¸ºä¸»â˜…ï¼æˆ’çƒŸâ˜…ï¼è‚ŒåŠ›è®­ç»ƒâ˜…ï¼åšæœ‰æ°§è¿åŠ¨â˜…ï¼é™åˆ¶çƒ­é‡æ‘„å–â˜…ï¼æŒ‰æ‘©ï¼åšä¼¸å±•è¿åŠ¨ åˆ—è¡¨ä¸­å‡ºç°â˜…è€…ï¼Œä¸ºéœ€è¦ä¸‰ä¸ªæœˆæ—¶é—´åŸ¹å…»çš„èº«ä½“ä¹ æƒ¯ã€‚ åŸåˆ™æ²¡ä»€ä¹ˆåŠæ³•ï¼Œæˆ‘å°±æ˜¯è¿™æ ·å¯¹æœªæ¥æ²¡æœ‰è¦æ±‚ï¼Œè¿˜åœ¨ç§¯æåŠªåŠ›çš„è‡ªå·±ï¼ è¦æ‹’ç»ç¤¾äº¤ã€‚æˆ‘ç°åœ¨è§‰å¾—è¿˜æ˜¯ä¸ªä¸ªäººç”Ÿæ´»å¥½ï¼Œæˆ‘å†ä¹Ÿä¸æƒ³å»è®¤è¯†æˆ‘çš„äººç¾¤ä¸­äº†ï¼Œæˆ‘åªæƒ³å»ä¸è®¤è¯†çš„äººç¾¤ä¸­ã€‚å¦‚æœæ²¡æœ‰äººè®¤è¯†æˆ‘å¤šå¥½å•Šï¼æ„Ÿè§‰å¾—äº†äººç¾¤å¯†é›†ç—‡ã€‚ è¦çŸ¥ä¸–æ•…ã€‚æˆ‘ä¹Ÿæ˜¯æœ€è¿‘æ‰å‘ç°ï¼Œæˆ‘ä¸€ç‚¹ä¹Ÿå’Œåˆ«äººåˆä¸æ¥ï¼Œè™½ç„¶æˆ‘ç°åœ¨è§‰å¾—æˆ‘æ²¡æœ‰ä»€ä¹ˆé”™ï¼Œä¹Ÿä¸åœ¨æ„ä»€ä¹ˆã€‚ä½†æ˜¯æ„Ÿè§‰è¿™æ ·ä¸å¥½ï¼Œé‚£æ˜¯è¢«äººçŒœå¿Œï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿæœ‰æ—¶å€™å¤ªè¿‡äºåšè‡ªå·±äº†ï¼Œå¥½åƒä¸å¤ªå¥½å•Šï¼ ä¹Ÿä¸çŸ¥é“æ˜¯åˆ«äººæ”¹å˜äº†æˆ‘ï¼Œè¿˜æ˜¯æˆ‘åˆ»æ„çš„ï¼Œé‡å¡‘è‡ªå·±çš„è¿‡ç¨‹ï¼Œå¾ˆéš¾ã€‚]]></content>
      <categories>
        <category>æ—¥å¿—</category>
      </categories>
      <tags>
        <tag>ç”Ÿæ´»æ—¥å¿—</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¥¿ç“œä¹¦]]></title>
    <url>%2F2020%2F07%2F17%2F%E5%AD%A6%E4%B9%A0%E3%81%AE%E5%8E%86%E7%A8%8B-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E5%91%A8%E5%BF%97%E5%8D%8E%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[é˜…è¯»ç›®å½•[TOC] ç¬¬ä¸€ç«  What is the machine learning?éå¸¸å®˜æ–¹çš„å®šä¹‰ï¼š Tom mitchell(1998) Well-posed LearningProblem:A compute program is said to learn from experience E with respect to same task T and some performance measure P,if its performance on T,as measured by P, improves with experience Eã€‚ï¼ˆè¿™ä¸ªæˆ‘è«æ³•ç¿»è¯‘å–”ï¼‰å¤§æ¦‚æ„æ€æ˜¯å¼ºå¤§çš„è®¡ç®—æœºèƒ½å¤Ÿäº‹å…ˆåœ°å®Œæˆäººä¸ºéæ˜¾ç¤ºç¼–ç¨‹å¥½çš„ä»»åŠ¡ï¼Œæ€ä¹ˆå®Œæˆå‘¢ï¼Ÿå¯¹äºæŸä¸ªä»»åŠ¡T,ç»™å®šä¸€ä¸ªæ€§èƒ½åº¦é‡æ–¹æ³•P,åœ¨ç»éªŒEçš„å½±å“ä¸‹ï¼Œå¦‚æœPå¯¹Tçš„æµ‹é‡ç»“æœå¾—åˆ°äº†æ”¹è¿›ï¼Œåˆ™è¯´æ˜è¯¥ç¨‹åºä»Eä¸­å­¦ä¹ äº†æœºå™¨å­¦ä¹ çš„è¿‡ç¨‹å¤§è‡´å¦‚æ­¤ï¼šè®©è®¡ç®—æœºä»æ•°æ®ä¸­äº§ç”Ÿæ¨¡å‹(model)ï¼Œé¦–å…ˆæä¾›ç»éªŒæ•°æ®ï¼Œç»™å®šå­¦ä¹ ç®—æ³•(learning algorithm)å’Œæ€§èƒ½æµ‹é‡æ–¹æ³•ï¼Œå®ƒå°±èƒ½æ ¹æ®æ•°æ®äº§ç”Ÿæ¨¡å‹ã€‚æ¨¡å‹ï¼š æ³›æŒ‡ä»æ•°æ®ä¸­å­¦å¾—çš„ç»“æœæ¨¡å¼ï¼š å±€éƒ¨æ€§çš„ç»“æœ åŸºæœ¬æœ¯è¯­æ•°æ®é›†: data setæ ·æœ¬ï¼š sampleå±æ€§ï¼ˆç‰¹å¾ï¼‰ï¼š attributeï¼ˆfeature)å±æ€§å€¼ï¼š attribute valueå±æ€§ç©ºé—´ï¼ˆç‰¹å¾ç©ºé—´ï¼‰ï¼š attribute space ï¼ˆ sample spaceï¼‰ç‰¹å¾å‘é‡ï¼š feature vectorå­¦ä¹ ï¼ˆè®­ç»ƒï¼‰ï¼šlearningï¼ˆtrainingï¼‰è®­ç»ƒæ•°æ®ï¼š training dataè®­ç»ƒé›†ï¼š training setå‡è®¾ï¼šhypothesis å­¦å¾—æ¨¡å‹å¯¹åº”äº†å…³äºæ•°æ®çš„æŸç§æ½œåœ¨è§„å¾‹æ³›å‡½èƒ½åŠ›: generalization å‡è®¾ç©ºé—´å½’çº³ï¼ˆinductionï¼‰ï¼š ä»ç‰¹æ®Šåˆ°ä¸€èˆ¬çš„â€œæ³›åŒ–â€(generalization)è¿‡ç¨‹æ¼”ç»ï¼ˆdeduction)ï¼š ä»ä¸€èˆ¬åˆ°ç‰¹æ®Šçš„â€œç‰¹åŒ–â€(specialization)è¿‡ç¨‹æœºå™¨å­¦ä¹ æ˜¾ç„¶æ˜¯å½’çº³å­¦ä¹ ï¼ˆinductive learning)å½’çº³å­¦ä¹ åˆ†ç‹­ä¹‰ä¸å¹¿ä¹‰ï¼Œç‹­ä¹‰æ˜¯æŒ‡è¦æ±‚ä»training set ä¸­å­¦å¾—æ¦‚å¿µï¼Œå¹¿ä¹‰æ˜¯æŒ‡ä»sampleä¸­å­¦ä¹  å­¦ä¹ è¿‡ç¨‹ï¼ˆè®­ç»ƒè¿‡ç¨‹ï¼‰çœ‹ä½œæ˜¯åœ¨æ‰€ä»¥å‡è®¾ç»„æˆçš„ç©ºé—´ä¸­è¿›è¡Œæœç´¢çš„è¿‡ç¨‹ï¼Œæœç´¢ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸training setåŒ¹é…çš„å‡è®¾ã€‚å¦‚æœå‡è®¾çš„è¡¨ç¤ºä¸€æ—¦ç¡®å®šï¼Œå‡è®¾ç©ºé—´ä¸å…¶è§„æ¨¡å°±ç¡®å®šäº†ã€‚æƒ³æ›´è¯¦ç»†äº†è§£å‡è®¾ç©ºé—´ï¼Œæˆ³æˆ‘å•¦5.2ç°å®é—®é¢˜ä¸­å¸¸é¢ä¸´å¾ˆå¤§çš„å‡è®¾ç©ºé—´ï¼Œæˆ‘ä»¬å¯ä»¥å¯»æ‰¾ä¸€ä¸ªä¸è®­ç»ƒé›†ä¸€è‡´çš„å‡è®¾é›†åˆï¼Œç§°ä¹‹ä¸ºç‰ˆæœ¬ç©ºé—´ã€‚ç‰ˆæœ¬ç©ºé—´ä»å‡è®¾ç©ºé—´å‰”é™¤äº†ä¸æ­£ä¾‹ä¸ä¸€è‡´å’Œä¸åä¾‹ä¸€è‡´çš„å‡è®¾ï¼Œå®ƒå¯ä»¥çœ‹æˆæ˜¯å¯¹æ­£ä¾‹çš„æœ€å¤§æ³›åŒ–ã€‚å½’çº³åå¥½æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¯¹æŸç§ç±»å‹å‡è®¾çš„åå¥½ï¼Œç§°ä¸ºâ€œå½’çº³åå¥½â€ï¼ˆinductive bias),ä¹Ÿå°±æ˜¯å­¦ä¹ ç®—æ³•åœ¨ä¸€ä¸ªå¯èƒ½å¾ˆåºå¤§çš„å‡è®¾ç©ºé—´ä¸­å¯¹å‡è®¾è¿›è¡Œé€‰æ‹©çš„å¯å‘å¼æˆ–è€…â€œä»·å€¼è§‚â€å¥¥å¡å§†å‰ƒåˆ€å®šå¾‹ï¼š è‹¥æœ‰å¤šä¸ªå‡è®¾ä¸è§‚æµ‹ä¸€è‡´ï¼Œåˆ™é€‰æ‹©åšç®€å•çš„å“ªä¸ªã€‚æ²¡æœ‰å…è´¹çš„æ— é¤å®šç†ï¼ˆNo Free Lunch Theorem[NFL]) åœ¨æ‰€ä»¥é—®é¢˜å‡ºç°çš„æœºä¼šç›¸åŒï¼Œæˆ–è€…æ‰€ä»¥é—®é¢˜åŒç­‰é‡è¦ä¸‹ï¼Œæ‰€æœ‰ç®—æ³•çš„æœŸæœ›ä¸€æ ·ã€‚ä½†åœ¨å®é™…é—®é¢˜ä¸­ï¼Œé’ˆå¯¹å…·ä½“çš„é—®é¢˜ï¼Œä¸åŒçš„ç®—æ³•æ‰ä¼šå‡ºç°ç›¸å¯¹ä¼˜åŠ£ã€‚ å‘å±•å†ç¨‹æ¨ç†æœŸï¼šäºŒåä¸–çºªäº”åå¹´ä»£åˆ°ä¸ƒåå¹´ä»£åˆï¼ŒAIå¤„äºæ¨ç†åŒºï¼Œä»£è¡¨æ€§å·¥ä½œä¸»è¦æ˜¯A.Newell å’ŒH.Simonçš„â€œé€»è¾‘ç†è®ºå®¶â€ç¨‹åºå’Œæ­¤åçš„â€œé€šç”¨é—®é¢˜æ±‚è§£â€ç¨‹åºç­‰ã€‚â€œé€»è¾‘ç†è®ºå®¶â€ç¨‹åºè¯æ˜äº†æ•°å­¦å®¶ç½—ç´ å’Œæ€€ç‰¹æµ·çš„ã€Šæ•°å­¦åŸç†ã€‹é‡Œé¢çš„æŸäº›å®šç†ï¼Œè·å¾—å›¾çµå¥–ã€‚çŸ¥è¯†æœŸï¼šä»äºŒåä¸–çºªä¸ƒåå¹´ä»£ä¸­æœŸå¼€å§‹ï¼ŒAIçš„ç ”ç©¶è¿›å…¥äº†â€œçŸ¥è¯†æœŸâ€ï¼Œå¤§é‡çš„ä¸“å®¶ç³»ç»Ÿå‡ºç°ï¼ŒE.A.Feigenbaumï¼ˆçŸ¥è¯†å·¥ç¨‹ä¹‹çˆ¶ï¼‰åœ¨1994è·å¾—å›¾çµå¥–ã€‚äººä»¬æ„è¯†åˆ°ï¼Œä¸“å®¶ç³»ç»Ÿé¢ä¸´â€œçŸ¥è¯†å·¥ç¨‹ç“¶é¢ˆâ€,åœ¨é‚£ä¸ªæ—¶å€™ï¼Œæœ‰äººæŠŠçŸ¥è¯†æ€»ç»“å‡ºæ¥å†æ•™ç»™è®¡ç®—æœºæ˜¯ç›¸å½“å›°éš¾çš„ã€‚1950å¹´ï¼Œå›¾çµå†å…³äºå›¾çµæµ‹è¯•çš„æ–‡ç« ä¸­ï¼Œæ›¾æåˆ°æœºå™¨å­¦ä¹ çš„å¯èƒ½äºŒåä¸–çºªäº”åå¹´ä»£åˆï¼ŒA.Samuelè‘—åè·³æ£‹ç¨‹åºã€‚äº”åå¹´ä»£ä¸­åæœŸï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„â€è¿æ¥ä¸»ä¹‰â€œå­¦ä¹ ï¼Œå¦‚F.Rosenblattçš„æ„ŸçŸ¥å™¨ï¼ˆPerceptroï¼‰ï¼ŒB.Widremçš„Adaline,å…­ä¸ƒåå¹´ä»£ï¼ŒåŸºäºé€»è¾‘è¡¨ç¤ºçš„â€ç¬¦å·ä¸»ä¹‰å­¦ä¹ æŠ€æœ¯è“¬å‹ƒå‘å±•å­¦ä¹ æœŸï¼šäºŒåä¸–çºªå…«åå¹´ä»£æ˜¯æœºå™¨å­¦ä¹ ç™¾èŠ±åˆæ”¾çš„æ—¶æœŸã€‚ä¸€å¤§ä¸»æµæ˜¯ç¬¦å·ä¸»ä¹‰å­¦ä¹ ï¼Œä»£è¡¨å†³ç­–æ ‘ï¼ˆdecision tree).äºŒåä¸–çºªä¹åå¹´ä»£ä¸­æœŸä¹‹å‰ï¼Œå¦å¤–ä¸€å¤§ä¸»æµæŠ€æœ¯æ˜¯åŸºäºç¥ç»ç½‘ç»œçš„è¿æ¥ä¸»ä¹‰å­¦ä¹ ã€‚äºŒåä¸–çºªä¹åå¹´ä»£ä¸­æœŸï¼Œâ€ç»Ÿè®¡å­¦ä¹ â€œå æ®ä¸»æµï¼Œä»£è¡¨æ”¯æŒå‘é‡æœºã€‚äºŒåä¸€ä¸–çºªåˆï¼Œè¿æ¥ä¸»ä¹‰å­¦ä¹ æ€èµ·äº†â€æ·±åº¦å­¦ä¹ â€œä¸ºåçš„çƒ­æ½®ã€‚ ç¬¬äºŒç«  ï¼š æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©ç»éªŒè¯¯å·®ä¸è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆè®­ç»ƒè¯¯å·®ï¼ˆtraining error) or ç»éªŒè¯¯å·®ï¼ˆempirical error): å­¦ä¹ å™¨åœ¨è®­ç»ƒé›†ä¸Šçš„è¾“å‡ºä¸è®­ç»ƒé›†ä¹‹é—´çš„å·®å¼‚è¿‡æ‹Ÿåˆï¼ˆover fittingï¼‰ï¼šåœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°éå¸¸å¥½ï¼Œæ³›åŒ–èƒ½åŠ›å¤ªå·®ï¼Œæœ€å¸¸è§çš„æƒ…å†µæ˜¯å­¦ä¹ èƒ½åŠ›å¤ªå¼ºå­¦ä¹ åˆ°ä¸å¤ªä¸€èˆ¬çš„ç‰¹æ€§ï¼Œæ— æ³•å½»åº•é¿å…ï¼Œåªèƒ½â€œç¼“è§£â€æ¬ æ‹Ÿåˆï¼ˆunder fittingï¼‰ï¼šè¿™ç§æƒ…å†µå®¹æ˜“å…‹æœæ¨¡å‹é€‰æ‹©(model selection): ä¸åŒçš„å‚æ•°é…ç½®ï¼Œäº§ç”Ÿä¸åŒçš„æ¨¡å‹ã€‚ç†è®ºä¸Šæœ€å¥½çš„æ¨¡å‹æ˜¯å¯¹æ³›åŒ–èƒ½åŠ›è¿›è¡Œè¯„ä¼°ï¼Œæœ€å¥½çš„å°±æ˜¯æ³›åŒ–è¯¯å·®æœ€å°çš„ï¼Œæ³›åŒ–è¯¯å·®æ˜¯æ— æ³•ç›´æ¥è·å–çš„ è¯„ä¼°æ–¹æ³•è®¾ç½®ä¸€ä¸ªâ€æµ‹è¯•é›†ï¼ˆtesting set)â€æ¥æµ‹è¯•å­¦ä¹ å™¨åœ¨æ–°æ ·æœ¬çš„åˆ¤æ–­èƒ½åŠ›ï¼Œç”¨æµ‹è¯•è¯¯å·®è¿‘ä¼¼æ³›åŒ–è¯¯å·®è¦æ±‚ï¼š æµ‹è¯•æ ·æœ¬ä¸è®­ç»ƒæ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒçš„ æµ‹è¯•é›†åº”è¯¥å°½å¯èƒ½ä¸è®­ç»ƒé›†äº’æ–¥ï¼Œæµ‹è¯•æ ·æœ¬å°½é‡ä¸å‡ºç°åœ¨è®­ç»ƒé›†ä¸­å¦‚ä½•äº§ç”Ÿtraining set å’Œ testing set ç•™å‡ºæ³•ï¼ˆhold-out)è¦æ±‚ï¼šæ•°æ®é›†($D$)åˆ’åˆ†æˆä¸¤ä¸ªäº’æ–¥çš„é›†åˆï¼ˆè®­ç»ƒé›†($S$,æµ‹è¯•é›†$T$),éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåˆ’åˆ†åï¼Œå°½é‡å¯èƒ½çš„ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ã€‚ä¸åŒçš„åˆ’åˆ†ç»“æœï¼Œå¾—åˆ°ä¸åŒçš„æµ‹è¯•è¯¯å·®ã€‚å•æ¬¡ä½¿ç”¨ç•™å‡ºæ³•å¾—åˆ°çš„ç»“æœæ˜¯ä¸å¤Ÿç¨³å®šçš„ï¼Œæ‰€ä»¥ä¸€èˆ¬é‡‡ç”¨è‹¥å¹²æ¬¡çš„éšæœºåˆ’åˆ†ï¼Œé‡å¤è¿›è¡Œå®éªŒè¯„ä¼°åå»å¹³å‡å€¼ äº¤å‰éªŒè¯æ³•ï¼ˆcross validation)I. å°†æ•°æ®($D$)åˆ’åˆ†æˆ$k$ä¸ªå¤§å°ç›¸ä¼¼çš„äº’æ–¥å­é›†ï¼Œæ¯ä¸ªå­é›†$D_i$éƒ½å°½å¯èƒ½ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§II. æ¯æ¬¡éƒ½ç”¨$k-1$ä½œä¸ºè®­ç»ƒé›†ï¼Œä½™ä¸‹çš„å“ªä¸ªå­é›†ä½œä¸ºæµ‹è¯•é›†ï¼Œäºæ˜¯ä¹éƒ½åˆ°äº†kä¸ªæµ‹è¯•ç»“æœçš„å‡å€¼å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ$k$çš„å–å€¼å¯¹ç»“æœçš„ç¨³å®šæ€§å’Œä¿çœŸæ€§æœ‰å¾ˆå¤§çš„å½±å“ï¼Œå› æ­¤ä¹Ÿå«kè€…äº¤å‰éªŒè¯ï¼ˆk-flold cross validation) kçš„é€šå¸¸å–å€¼æ˜¯10åŒæ ·çš„ï¼Œæ•°æ®é›†$D$åˆ’åˆ†ä¸º$k$ä¸ªå­é›†æœ‰å¾ˆå¤šçš„åˆ’åˆ†æ–¹å¼ï¼Œå¯é‡å¤$P$æ¬¡$k$æŠ˜äº¤å‰éªŒè¯ã€‚ è‡ªåŠ©æ³• (bootstrapping)æ³¨æ„çš„æ˜¯æˆ‘ä»¬å¸Œæœ›é€šè¿‡æ‰€ä»¥çš„è®­ç»ƒé›†ï¼ˆ$D$)è®­ç»ƒå‡ºæ¨¡å‹ï¼Œä½†æ˜¯æµå‡ºæ³•å’Œäº¤å‰éªŒè¯çš„æ–¹æ³•ï¼Œéƒ½ä¿ç•™ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†ï¼Œå› æ­¤å®é™…è¯„ä¼°çš„æ¨¡å‹æ‰€ä½¿ç”¨çš„è®­ç»ƒé›†æ›´ä¸‹ï¼Œè¿™ä¹Ÿè®¸ä¼šå¯¼è‡´ä¼°è®¡åå·®ã€‚è‡ªåŠ©æ³•ï¼š å¯é‡å¤é‡‡æ ·æˆ–è€…æœ‰æ”¾å›é‡‡æ · è®°é‡‡æ ·äº§ç”Ÿçš„æ•°æ®é›†ï¼ˆ$Dâ€™$),æ¯æ¬¡ä»$D$ä¸­æŒ‘é€‰åº”è¯¥æ ·æœ¬ï¼Œå°†å…¶æ‹·è´è‡³($Dâ€™$),å¹¶å†å°†é‡‡æ ·çš„æ ·æœ¬æ”¾å›æ•°æ®é›†($D$),é‡å¤($m$)æ¬¡ä»¥åï¼Œå¾—åˆ°äº†åŒ…å«($m$)ä¸ªæ ·æœ¬çš„æ•°æ®é›†($Dâ€™$) å¯¹äºå¯é‡å¤é‡‡æ ·ï¼Œæ ·æœ¬å§‹ç»ˆä¸é‡‡åˆ°çš„æ¦‚ç‡æ˜¯$(1-\frac{1}{m})^m$,å–æé™å¾—åˆ°ï¼šåˆå¼æ•°æ®é›†ä¸­$36.8%$ä¸ºå‡ºç°åœ¨é‡‡æ ·æ•°æ®é›†ä¸­ï¼Œå› æ­¤å¯å°†($D$)ä½œä¸ºè®­ç»ƒé›†ï¼Œ($D\Dâ€™$)ä½œä¸ºæµ‹è¯•é›†ï¼Œåˆç§°å¤–åŒ…ä¼°è®¡(out-of-bag estimate)è‡ªåŠ©æ³•é€‚ç”¨äºæ•°æ®é‡å°‘ï¼Œéš¾åŒºåˆ«æµ‹è¯•é›†å’Œè®­ç»ƒé›†æ—¶ï¼Œè‡ªåŠ©æ³•ä¼šæ”¹å˜åˆå§‹æ•°æ®çš„åˆ†å¸ƒï¼Œåœ¨åˆå§‹æ•°æ®è¶³å¤Ÿçš„æƒ…å†µä¸‹ï¼Œæµå‡ºæ³•å’Œäº¤å‰éªŒè¯æ›´å¸¸ç”¨ä¸€äº› è°ƒå‚å’Œæœ€ç»ˆçš„æ¨¡å‹å­¦ä¹ ç®—æ³•éƒ½æœ‰å‚æ•°(parameter),ä¸åŒçš„å‚æ•°é…ç½®ï¼Œå­¦å¾—æ¨¡å‹çš„æ€§èƒ½ä¹Ÿå¾€å¾€ä¸åŒéªŒè¯é›†(validation set): æ¨¡å‹è¯„ä¼°å’Œé€‰æ‹©ä¸­ç”¨äºä¼°è®¡æµ‹è¯•çš„æ•°æ®é›†ç§°ä¸ºçš„æ•°æ®é›†å¾€å¾€å°†è®­ç»ƒé›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ŒåŸºäºéªŒè¯é›†ä¸Šçš„æ€§èƒ½æ¥è¿›è¡Œæ¨¡å‹é€‰æ‹©å’Œè°ƒå‚ æ€§èƒ½åº¦é‡(performance measure)å‡è®¾æ£€éªŒï¼ˆå…¶å®æˆ‘ä¸€ç›´éƒ½å¹¶ä¸æ˜¯ç‰¹åˆ«äº†è§£ï¼‰ å‡è®¾æ£€éªŒçš„åŸºæœ¬åŸç†æ˜¯é‡è¦çš„ç»Ÿè®¡æ¨æ–­é—®é¢˜ä¹‹ä¸€ï¼Œæ ¹æ®æ ·æœ¬æä¾›çš„ä¿¡æ¯ï¼Œæ£€éªŒå…³äºæ€»ä½“æŸä¸ªå‡è®¾æ˜¯å¦æ­£ç¡®ã€‚åŒ…æ‹¬å‚æ•°çš„å‡è®¾æ£€éªŒï¼ˆå‡å€¼ã€æ–¹å·®ç­‰ï¼‰å’Œéå‚æ•°ï¼ˆåˆ†å¸ƒå•Šï¼‰çš„å‡è®¾æ£€éªŒã€‚ å‚æ•°æ£€éªŒï¼š æå‡ºå‡è®¾Hâ€”-&gt;åœ¨æ„é€ ç»Ÿè®¡é‡ï¼Œç¡®å®šç»Ÿè®¡é‡çš„åˆ†å¸ƒâ€”-&gt; ç¡®å®šæ‹’ç»åŸŸå’Œæ¥å—åŸŸçš„åˆ†ç•Œçº¿â€”-&gt; åœ¨æ ¹æ®æ ·æœ¬è®¡ç®—ç»Ÿè®¡é‡çš„å€¼u â€”-&gt; æ¨æ–­ åˆ†å¸ƒæ‹Ÿåˆæ£€éªŒ åå·®å’Œæ–¹å·®é€šè¿‡æ¦‚ç‡è®ºåˆ†æå¯¹å­¦ä¹ ç®—æ³•çš„æœŸæœ›æ³›åŒ–é”™è¯¯ç‡è¿›è¡Œæ‹†è§£$x$: æµ‹è¯•æ ·æœ¬$y_D$ï¼š $x$åœ¨æ•°æ®é›†ä¸­çš„æ ‡è®°$y$: $x$çš„çœŸå®æ ‡è®°$f(x:D)$: åœ¨è®­ç»ƒé›†ä¸Šå­¦å¾—çš„æ¨¡å‹$f$åœ¨$x$ä¸Šé¢„æµ‹è¾“å‡ºä»¥å›å½’ä»»åŠ¡ä¸ºä¾‹å­ï¼šå­¦ä¹ ç®—æ³•çš„æœŸæœ›é¢„æµ‹ä¸ºï¼š \hat{f}(x) = E_D[f(x;D)]æ–¹å·®ï¼šåº¦é‡åŒæ ·çš„æ ·æœ¬å¤§å°çš„è®­ç»ƒé›†çš„å˜åŠ¨æ‰€å¯¼è‡´çš„å­¦ä¹ æ€§èƒ½çš„å˜åŒ–ï¼Œå³åˆ»ç”»æ•°æ®æ‰°åŠ¨æ‰€é€ æˆçš„å½±å“ var(x)= E_D[(f(x;D)-\hat{f}(x))^2]å™ªå£°ï¼š è¡¨è¾¾äº†å½“å‰ä»»åŠ¡ä¸Šä»»åŠ¡å­¦ä¹ ç®—æ³•æ‰€èƒ½è¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œå³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ã€‚ \epsilon^2=E_D[(y_D-y)^2]æœŸæœ›è¾“å‡ºå’ŒçœŸå®æ ‡è®°çš„å·®åˆ«ç§°ä¸ºåå·®(bias): åº¦é‡äº†å­¦ä¹ ç®—æ³•çš„æœŸæœ›é¢„æµ‹ä¸çœŸå®ç»“æœçš„åç¦»ç¨‹åº¦ï¼Œå³åˆ»ç”»äº†å­¦ä¹ ç®—æ³•æœ¬èº«çš„æ‹Ÿåˆèƒ½åŠ› bias^2(x)=(f(x)-y)^2è‹¥å‡è®¾å™ªå£°æœŸæœ›ä¸ºé›¶ï¼Œé‚£ä¹ˆç®—æ³•çš„æœŸæœ›æ³›åŒ–è¯¯å·®ï¼š E(f;D)=E_D[(f(x;D)-y)^2]\\ =....=E_D[(f(x;D)-\hat{f}(x))^2]+(\hat{f}(x)-y)^2+E_D[(y_D-y)^2]E(f;D)=bias^2(x)+var(x)+\epsilon^2ç”±ä¸Šå¼å¯çŸ¥ï¼Œæ³›åŒ–èƒ½åŠ›ç”±å­¦ä¹ ç®—æ³•çš„èƒ½åŠ›ã€æ•°æ®çš„å……åˆ†æ€§ã€å­¦ä¹ ä»»åŠ¡æœ¬èº«çš„éš¾åº¦å…±åŒå†³å®šçš„ã€‚underfitting: åå·®ä¸»å¯¼æ³›åŒ–è¯¯å·®over fittingï¼š è®­ç»ƒæ•°æ®å‘ç”Ÿçš„æ‰°åŠ¨æ¸æ¸è¢«å­¦ä¹ åˆ°ï¼Œæ–¹å·®ä¸»å¯¼äº†æ³›åŒ–è¯¯å·® ç¬¬ä¸‰ç«  çº¿æ€§æ¨¡å‹æˆ‘è‡ªå·±å…¶å®æ˜¯ä¸€ç›´åœç•™åœ¨çº¿æ€§æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ï¼Œå› ä¸ºæ¯æ¬¡å¼€å¤´éƒ½æ˜¯è¿™ä¸€å¼ ï¼Œæ‰€ä»¥æˆ‘å°±å­¦ä¹ äº†å¾ˆå¤šæ¬¡ã€‚è¿™æ¬¡ä¸å‡†å¤‡å†ç»†çœ‹äº†ã€‚ çº¿æ€§åˆ¤åˆ«åˆ†æ Linear Discriminant Analysis (LDA)åŸºæœ¬æ€æƒ³ï¼š åœ¨è®­ç»ƒæ ·ä¾‹é›†ä¸Šï¼Œè®¾æ³•å°†æ ·æœ¬ä¾‹å­æŠ•å½±åˆ°ä¸€æ¡ç›´çº¿ä¸Šä½¿å¾—åŒç±»æ ·ä¾‹çš„æŠ•å½±å°½å¯èƒ½æ¥è¿‘ã€å¼‚ç±»æŠ•å½±ç‚¹å°½å¯èƒ½è¿œç¦»ã€‚æ•°å­¦è¡¨è¾¾ï¼š$D={(x_i,y_i)}_{i=1}^{m}$: data set$X_i$: ç¬¬$i$ç±»é›†åˆ$u_i$: ç¬¬$i$ç±»é›†åˆå‡å€¼å‘é‡$\sum{i}$: ç¬¬$i$ç±»é›†åˆåæ–¹å·®çŸ©é˜µ$ w^Tu_i$ï¼š ç¬¬$i$ç±»é›†åˆåœ¨ç›´çº¿ä¸Šçš„æŠ•å½±$ w^T\sum_{i}w$: æ ·æœ¬ç‚¹çš„åœ¨ç›´çº¿ä¸Šçš„æŠ•å½±å­¦ä¹ ç®—æ³•ï¼šåŒç±»æ›´è¿‘ï¼š$\min \sum_{i=1}^{n}(w^T\sum_{i}w)$ç±»ä¸­å¿ƒè¶Šå¤§ï¼š$\max ||w^{T}u_1-(\sum_{i=2}(w^{T}u_i))||_2^2$å› æ­¤ï¼Œæƒ³æœ€å¤§åŒ–çš„ç›®æ ‡è€ƒè™‘$i = 2$çš„æƒ…å†µ J = \frac{||w^Tu_0-w^Tu_1||_2^2}{w^T\sum_{i=1}w+w^T\sum_{i=2}w} =\frac{w^T(u_0-u_1)(u_0-u_1)^Tw}{w^T(\sum_1+\sum_2)w} åº”ç”¨ç©ºé—´å‡ ä½•å’ŒçŸ©é˜µçš„å…³ç³»æè¿° ç±»å†…æ•£åº¦çŸ©é˜µ($S_W$)\sum_1+\sum_2 ç±»é—´æ•£åº¦çŸ©é˜µï¼š(u_0-u_1)(u_0-u_1)^T æ‰€ä»¥ï¼Œæˆ‘ä»¬æƒ³ä¼˜åŒ–ç›®æ ‡å¦‚ä¸‹ï¼šJ = \frac{w^T_Sbw}{w^TS_ww}å¦‚ä½•ç¡®å®š$w$å‘¢ï¼Ÿæ³¨æ„åˆ°åˆ†å­åˆ†æ¯éƒ½æ˜¯å…³äº$w$çš„äºŒæ¬¡å‹ï¼Œå› æ­¤è§£è¿™å’Œwçš„æ–¹å‘æœ‰å…³ç³»ï¼Œå› æ­¤ï¼Œå¯ä»¤ $w^TS_ww=1$,ä¼˜åŒ–é—®é¢˜å¯æ˜¯å¦‚ä¸‹ï¼š \min -w^TS_bw \\ s.t. w^TS_ww = 1æ„é€ lagrange å‡½æ•° L = -w^TS_bw+r(w^TS_ww-1)å¯¹$w$æ±‚å¯¼å¯å¾—ï¼š S_bw =rS_ww$S_b w$å’Œ$ u_0 - u_1 $ æ–¹å‘æ˜¯$u_0-u_1$,ä¸å¦¨è®¾ S_nw=r(u_0-u_1)so,w = s_w^{-1}(u_0-u_1)è¿™é‡Œè€ƒè™‘åˆ°æ•°å€¼è§£çš„ç¨³å®šæ€§ï¼Œå› æ­¤å¾€å¾€æŠŠ$S_w$è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ ç¬¬å››ç«  å†³ç­–æ ‘å†³ç­–æ ‘æ˜¯ä¸€ç§ç‰¹åˆ«æ™®é€šçš„ç¬¦åˆç”Ÿæ´»åšå†³ç­–çš„è¿‡ç¨‹ã€‚ ç¬¬äº”ç«  ç¥ç»ç½‘ç»œç¥ç»ç½‘ç»œæœ€å¼€å§‹å‡ºç°æ˜¯æ ¹æ®ç”Ÿç‰©ç¥ç»ç½‘ç»œæ¥çš„ã€‚ æœ€ç®€å•çš„ç¥ç»ç½‘ç»œï¼šç¥ç»å…ƒæ¨¡å‹(neuron|unit)McCulloch and PittsæŠ½è±¡å‡ºâ€œM-Pç¥ç»å…ƒæ¨¡å‹â€ æ„ŸçŸ¥å™¨ï¼ˆPerceptron)è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ï¼Œè¾“å‡ºå±‚ï¼šM-Pç¥ç»å…ƒæ„ŸçŸ¥å™¨çš„å­¦ä¹ è¿‡ç¨‹ä¸€å®šæ˜¯æ”¶æ•›çš„ å¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œ ï¼ˆmulti-layer feddforward neural networks)å‰é¦ˆï¼šç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ä¸å­˜åœ¨ç¯æˆ–è€…å›è·¯ç¥ç»å…ƒçš„å­¦ä¹ è¿‡ç¨‹ï¼šå°±æ˜¯æ ¹æ®è®­ç»ƒæ•°æ®æ¥è°ƒæ•´ç¥ç»å…ƒä¹‹é—´çš„â€è¿æ¥æƒâ€(connection weight),ä»¥åŠæ¯ä¸ªåŠŸèƒ½ç¥ç»å…ƒçš„é˜™å€¼ è¯¯å·®é€†ä¼ æ’­ç®—æ³•ï¼š error BackPropagation (BP)å…¨å±€æœ€å°å’Œå±€éƒ¨æœ€å°ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹å…¶å®ä¹Ÿå°±æ˜¯å‚æ•°å¯»ä¼˜çš„è¿‡ç¨‹ï¼ŒåŸºäºæ¢¯åº¦çš„æœç´ æ˜¯ä½¿ç”¨æœ€ä¸ºå¹¿æ³›çš„å‚æ•°å¯»ä¼˜æ–¹æ³•ï¼Œä½†æ˜¯å¦‚æœè¯¯å·®å‡½æ•°åœ¨å½“å‰ç‚¹çš„æ¢¯åº¦ä¸ºé›¶ï¼Œåˆ™å¾ˆæœ‰å¯èƒ½è¾¾åˆ°å±€éƒ¨æå°ã€‚ ç¬¬å…­ç«  æ”¯æŒå‘é‡æœºæ”¯æŒå‘é‡æœºçš„å­¦ä¹ åŸç†å¾ˆç®€å•ä¹Ÿå¾ˆæœ‰è¶£ï¼Œä»åˆ†ç±»é—®é¢˜ï¼Œæ€ä¹ˆä¸€æ­¥ä¸€æ­¥å»ºç«‹çš„ä¼˜åŒ–é—®é¢˜ï¼Œä¸€æ­¥ä¸€æ­¥çš„å®Œå–„ä¼˜åŒ–é—®é¢˜ä»¥åŠæ±‚è§£ï¼Œä»ç¡¬é—´éš”åˆ°è½¯é—´éš”ï¼Œåˆ†ç±»é—®é¢˜æ˜¯è€ƒè™‘åˆ†å¯¹ï¼Œè€Œå›å½’é—®é¢˜å¸Œæœ›é¢„æµ‹å€¼å’ŒåŸå§‹å€¼å°½å¯èƒ½çš„æ¥è¿‘ï¼Œè¿™æ ·å°±é€ æˆäº†çº¦æŸæ¡ä»¶ï¼Œç›®æ ‡æ€§çš„ä¸åŒã€‚ æœ€é‡è¦çš„æ˜¯å¼•å…¥äº†æ ¸æ–¹æ³•ï¼Œä½ç»´ç©ºé—´çš„éçº¿æ€§å…³ç³»æ˜ å°„æˆäº†é«˜ç»´ç©ºé—´çº¿æ€§å…³ç³»ï¼Œè¿™æ˜¯ç‰¹åˆ«é‡è¦çš„æ€æƒ³ ç¬¬å…«ç«  é›†æˆå­¦ä¹ åŸºæœ¬æ€æƒ³æ„å»ºä¸€ç»„åŸºå­¦ä¹ å™¨ï¼ˆbase learner)ï¼Œåœ¨ç»“åˆ a. å¦‚æœé›†æˆä¸­æ˜¯ç›¸åŒç±»å‹çš„ä¸ªä½“å­¦ä¹ å™¨ï¼Œå¦‚å†³ç­–æ ‘ï¼Œå…¨æ˜¯ç¥ç»ç½‘ç»œçš„é›†æˆâ€œåŒè´¨â€ï¼ˆhomogeneous),ä¸ªä½“å­¦ä¹ å™¨å«åŸºå­¦ä¹ å™¨ b. ä¸åŒçš„å­¦ä¹ å™¨ï¼Œå¼‚è´¨ï¼ˆheterogeneous)ï¼Œä¸ªä½“å­¦ä¹ å™¨å«ç»„ä»¶å­¦ä¹ å™¨ ä¸ºä»€ä¹ˆæœ‰æ•ˆ å¤šæ ·æ€§çš„åŸºå­¦ä¹ å™¨ ä¸åŒçš„æ¨¡å‹å–é•¿è¡¥çŸ­ æ¯ä¸ªåŸºå­¦ä¹ å™¨éƒ½çŠ¯é”™è¯¯ï¼Œç»¼åˆèµ·æ¥å¯èƒ½æ€§ä¸å¤§ ä¸¾ä¸ªæ —å­ ä¹Ÿè®¸ä¸€ä¸ªçº¿æ€§æ¨¡å‹ä¸èƒ½ç®€å•åˆ†ç±»ï¼Œä½†æ˜¯å¤šä¸ªçº¿æ€§æ¨¡å‹ç»¼åˆï¼Œå¯å°†æ•°æ®é›†æˆåŠŸåˆ†ç±» æ„å»ºä¸åŒçš„æœºå™¨å­¦ä¹ Q 1: å¦‚ä½•å»ºç«‹åŸºå­¦ä¹ å™¨ å°½é‡æ»¡è¶³å¤šæ ·æ€§ M1: ä¸åŒçš„å­¦ä¹ ç®—æ³• M2: ç›¸åŒå­¦ä¹ ç®—æ³•ã€ä¸åŒçš„å‚æ•° M3: ä¸åŒçš„æ•°æ®é›†ï¼ˆä¸åŒçš„æ ·æœ¬å­é›†ã€æ•°æ®é›†ä¸Šä¸åŒçš„ç‰¹å¾ï¼‰ homogenous ensemble é‡‡ç”¨ç›¸åŒçš„å­¦ä¹ ç®—æ³•ã€ä¸åŒçš„è®­ç»ƒé›† Bagging Boosting ç›¸åŒç®—æ³•ï¼Œä¸åŒçš„å‚æ•°è®¾ç½® ç›¸åŒçš„è®­ç»ƒé›†ï¼Œä¸åŒçš„å­¦ä¹ ç®—æ³• Q2: å¦‚ä½•ç»¼åˆå‘¢ï¼Ÿ tæŠ•ç¥¨æ³•ï¼šmajority voting weighted voting è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹ç¡®å®šå¦‚ä½•ç»¼åˆ Stacking åå¥½çš„ç®€å•æ¨¡å‹ ç»¼åˆBagging = Boostrap AGGregatINGæœ‰æ”¾å›é‡‡æ ·ï¼ŒåŒè´¨å­¦ä¹ å™¨ ç®—æ³•1234567891011Input : è®­ç»ƒé›† D=&#123;(x1,y1)&#125; åŸºå­¦ä¹ ç®—æ³•A è®­ç»ƒè½®æ•° Tè¿‡ç¨‹ for t = 1,2,...,T do h_t= A(D,Dt) // Dtç¬¬tæ¬¡é‡‡æ ·çš„åˆ†å¸ƒ end forè¾“å‡º å›å½’ï¼šAverage åˆ†ç±»ï¼šæŠ•ç¥¨æ³• ä¼˜ç‚¹æ²¡æœ‰ç”¨äºå»ºæ¨¡çš„æ ·æœ¬ï¼Œå¯ä»¥ç”¨ä½œéªŒè¯é›†æ¥å¯¹æ³›åŒ–èƒ½åŠ›è¿›è¡ŒåŒ…å¤–ä¼°è®¡ï¼Œå¯ä»¥å¾—å‡ºBaggingæ³›åŒ–è¯¯å·®çš„åŒ…å¤–ä¼°è®¡ random forestï¼ˆRF)è¾“å…¥ä¸ºæ ·æœ¬é›†$D={(x,y1),(x2,y2),â€¦(xm,ym)}$ï¼Œå¼±åˆ†ç±»å™¨è¿­ä»£æ¬¡æ•°Tã€‚ è¾“å‡ºä¸ºæœ€ç»ˆçš„å¼ºåˆ†ç±»å™¨f(x)f(x) 1ï¼‰å¯¹äºt=1,2â€¦,T: a)å¯¹è®­ç»ƒé›†è¿›è¡Œç¬¬tæ¬¡éšæœºé‡‡æ ·ï¼Œå…±é‡‡é›†mæ¬¡ï¼Œå¾—åˆ°åŒ…å«mä¸ªæ ·æœ¬çš„é‡‡æ ·é›†$Dt$ b)ç”¨é‡‡æ ·é›†$Dt$è®­ç»ƒç¬¬tä¸ªå†³ç­–æ ‘æ¨¡å‹$Gt(x)$ï¼Œåœ¨è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹çš„èŠ‚ç‚¹çš„æ—¶å€™ï¼Œ åœ¨èŠ‚ç‚¹ä¸Šæ‰€æœ‰çš„æ ·æœ¬ç‰¹å¾ä¸­é€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬ç‰¹å¾ï¼Œ åœ¨è¿™äº›éšæœºé€‰æ‹©çš„éƒ¨åˆ†æ ·æœ¬ç‰¹å¾ä¸­é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„ç‰¹å¾æ¥åšå†³ç­–æ ‘çš„å·¦å³å­æ ‘åˆ’åˆ† 2) å¦‚æœæ˜¯åˆ†ç±»ç®—æ³•é¢„æµ‹ï¼Œåˆ™Tä¸ªå¼±å­¦ä¹ å™¨æŠ•å‡ºæœ€å¤šç¥¨æ•°çš„ç±»åˆ«æˆ–è€…ç±»åˆ«ä¹‹ä¸€ä¸ºæœ€ç»ˆç±»åˆ«ã€‚å¦‚æœæ˜¯å›å½’ç®—æ³•ï¼ŒTä¸ªå¼±å­¦ä¹ å™¨å¾—åˆ°çš„å›å½’ç»“æœè¿›è¡Œç®—æœ¯å¹³å‡å¾—åˆ°çš„å€¼ä¸ºæœ€ç»ˆçš„æ¨¡å‹è¾“å‡ºã€‚ å‚æ•°è®¾ç½® åˆ©ç”¨00Bæ ·æœ¬è¯„ä¼°å˜é‡çš„é‡è¦æ€§ Boosting æé«˜é¡ºæ¬¡å»ºç«‹å­¦ä¹ å™¨ï¼Œå°±æ˜¯å…ˆä»è®­ç»ƒé›†ä¸Šè®­ç»ƒä¸€ä¸ªåŸºå­¦ä¹ å™¨ï¼Œå†æ ¹æ®å­¦ä¹ å™¨çš„è¡¨ç°å¯¹è®­ç»ƒé›†åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œè®©å…ˆå­¦ä¹ å™¨é”™è¯¯è®­ç»ƒçš„æ ·æœ¬åœ¨åç»­æ”¶åˆ°æ›´å¤šçš„å…³æ³¨ï¼Œç„¶ååŸºäºè°ƒæ•´çš„åˆ†å¸ƒè®­ç»ƒä¸‹ä¸€ä¸ªå­¦ä¹ å™¨ï¼Œæœ€åï¼Œåœ¨å°†è¿™Tä¸ªå­¦ä¹ å™¨è¿›è¡ŒåŠ æƒç»“åˆ åŸºå­¦ä¹ å™¨çš„çº¿æ€§ç»„åˆ H_N(x;P)=\sum_{t=1}^{N}\alpha_th_t(x;a_t)$a_t$æ˜¯ç¬¬$i$ä¸ªå¼±å­¦ä¹ å™¨çš„æœ€ä¼˜å‚æ•°ï¼Œ$\alpha_t$æ˜¯åœ¨å¼ºåˆ†ç±»å™¨ä¸­çš„æ¯”é‡ï¼Œ$P$æ˜¯$a_t$å’Œ$\alpha_t$çš„ç»„åˆ æœ€å°åŒ–æŒ‡æ•°æŸå¤±å‡½æ•° l_{exp}(H|D)=E_{x~D}[e^{-f(x)H(x)}] H_n(x)=H_{n-1}(x)+\alpha_{n}h_{n}(x,a_n)l(h_i(x,a_t)|D)=E_{x~D}(exp(-f(x)h_i(x)))\\=p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))\frac{\partial l(h_i(x,a_t)|D)}{\partial h_i(x,a_t)}=\\ -p(f(x)=1)exp(-h_i(x))+p(f(x)=-1)exp(h_i(x))=0h(x)=\frac{1}{2}ln\frac{P(f(x)=1)}{P(f(x)=-1)}é‡‡å–ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œå¾—åˆ°ä¸åŒçš„ç±»å‹ https://blog.csdn.net/luanpeng825485697/article/details/79383492 GBDTStacking ä¸åŒå­¦ä¹ å™¨ï¼Œç›¸åŒæ•°æ®é›† ç¬¬ä¸€å±‚ ç¬¬äºŒå±‚ï¼šä¸ç”¨ç¬¬ä¸€å±‚çš„æ•°æ® å¯ç”¨äº¤å‰éªŒè¯ æ³¨æ„äº‹é¡¹ï¼š è¿‡æ‹Ÿåˆé—®é¢˜ï¼šç¬¬äºŒå±‚çº¿æ€§å›å½’ ç¬¬ä¸€å±‚å°½å¯èƒ½çš„å¤šæ ·æ€§ï¼š ç»¼åˆå¥½çš„æ¨¡å‹ é˜²æ­¢è¿‡æ‹Ÿåˆ 1. éšæœºæ€§ 2. Bagging Boosting Stacking æå¤§ä¼¼ç„¶ä¼°è®¡ä¼¼ç„¶ï¼š ç›¸ä¼¼çš„æ ·å­ å¯¹äºä¸€ç»„æ•°æ®ï¼Œå‡è®¾ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œå¸Œæœ›å·²çŸ¥ç‚¹åœ¨è¿™ä¸ªæ­£æ€åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰ç‚¹å¯¹äºçš„æ¦‚ç‡ä¹‹å’Œæˆ–è€…ç§¯æœ€å¤§ï¼Œ ï¼Œè“è‰²è¡¨ç¤ºæ•°æ®ï¼Œçº¢è‰²å°±æ˜¯åšå¾—æ­£æ€åˆ†å¸ƒ ç¬¬åç«  é™ç»´ä¸åº¦é‡å­¦ä¹ kè¿‘é‚»å­¦ä¹ k-Nearest Neighbor åŸç†ï¼š åŸºäºæŸç§è·ç¦»åº¦é‡æ‰¾å‡ºè®­ç»ƒé›†ä¸­ä¸å…¶æœ€é è¿‘çš„kä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ ¹æ®kä¸ªé‚»å±…çš„ä¿¡æ¯è¿›è¡Œé¢„æµ‹ã€‚ ç»™å®šæµ‹è¯•æ ·æœ¬$x$,å¦‚æœæœ€é‚»è¿‘æ ·æœ¬$z$,æœ€é‚»è¿‘åˆ†ç±»å™¨å‡ºé”™çš„æ¦‚ç‡å°±æ˜¯$x$ä¸$z$ä¸å†åŒä¸€ç±» p(err) = 1-\sum_{c \in y}p(c|x)P(c|z)ä½ç»´åµŒå…¥ç¼“è§£ç»´æ•°ç¾éš¾çš„é‡è¦é€”ç»ä¹‹ä¸€æ˜¯é™ç»´ï¼ˆdimension reductionï¼‰è¿™æ ·ä½¿å¾—å­ç©ºé—´ä¸­æ ·æœ¬å¯†åº¦å¤§å¹…åº¦æé«˜ï¼Œè·ç¦»è®¡ç®—å˜å¾—æ›´å®¹æ˜“ï¼Œ å¤šç»´ç¼©æ”¾ï¼ˆMultiple Dimensional,Scalingï¼‰MDS å‡å®šmä¸ªæ ·æœ¬åœ¨åŸå§‹ç©ºé—´çš„è·ç¦»çŸ©é˜µ$D$,åœ¨ä½ç»´ç©ºé—´ä¸­ï¼Œä¸¤ä¸ªæ ·æœ¬æ¬§å¼è·ç¦»ç­‰äºåŸç©ºé—´çš„è·ç¦»ï¼Œ$||z_i-z_j|| = dist_{ij}$, ä»¤$B=Z^TZ$ä¸ºé™ç»´åæ ·æœ¬çš„å†…ç§¯çŸ©é˜µ, dist_{ij}^2=||z_i||^2+||z_j||^2-2z_iz_j=b_{ii}+b_{jj}-2b_{ij}å¯¹é™ç»´åæ•°æ®ä¸­å¿ƒåŒ–ï¼Œå‡å€¼ä¸º0,$\sum_{i=1}^{m}z_i$,äºæ˜¯ä¹å°±æœ‰$\sum_{i=1}^{M}b_{ij}=z_j(z_1+z_2+â€¦+z_m)=0=\sum_{j=1}^{m}x_{ij}$ ,å¯å¾— \sum_{i=1}^{m}dist_{ij}^2=\sum_{i=1}^{m}(b_{ii}+b_{jj}-2b_{ij})=tr(B)_mb_{jj}\\ \sum_{i=1}^{m}\sum_{j=1}^{m}dist_{ij}^2 = 2m tr(B)\\ tr(B)=\sum_{i=1}^{m}||z_i||^2å¯å¾— b_{ij}=-\frac{1}{2}(dist_{ij}^2-dist_{i.}^2-dist_{.j}^2+dist{..}^2)å¯¹çŸ©é˜µBåšç‰¹å¾å€¼åˆ†è§£(eigenvalue decomposition)ï¼Œ$B = V \land V$,åˆ™ Z = \land_{*}^{1/2}V_{*}æ¬²è·å¾—ä½ç»´å­ç©ºé—´ï¼Œæœ€ç®€å•æ˜¯å¯¹åŸå§‹é«˜ç»´ç©ºé—´è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œ$Z = W^TX$,ç‰¹åˆ«çš„ï¼Œ$W$å–æ­£äº¤å˜æ¢ï¼Œ$W={w_1,w_2,â€¦,w_{dâ€™}}$Wæ˜¯dâ€™ä¸ªdç»´åŸºå‘é‡ï¼Œ ä¸»æˆåˆ†åˆ†æPrincipal Component Analysis ï¼šPCA åœ¨æ­£äº¤ç©ºé—´é‡Œé¢çš„æ ·æœ¬ï¼Œç”¨ä¸€ä¸ªè¶…å¹³é¢å¯¹æ ·æœ¬è¿›è¡Œæ°å½“çš„è¡¨è¾¾ï¼Œè‡³å°‘è¿™ä¸ªæ ·æœ¬ç‚¹æ»¡è¶³ æœ€è¿‘é‡æ„æ€§ï¼š æ ·æœ¬ç‚¹åˆ°è¿™ä¸ªè¶…å¹³é¢çš„è·ç¦»è¶³å¤Ÿè¿‘ æœ€å¤§å¯åˆ†æ€§ï¼š æ ·æœ¬ç‚¹åœ¨è¿™è¶…å¹³é¢ä¸Šçš„æŠ•å½±å°½å¯èƒ½åˆ†å¼€ å¯¹äºæœ€è¿‘é‡æ„æ€§ï¼š å‡è®¾æ ·æœ¬å»ä¸­å¿ƒåŒ–ï¼Œå†å‡è®¾æŠ•å½±å˜æ¢åå¾—åˆ°æ¬£çš„æ­£äº¤åæ ‡ç³»${w_1,w_2,â€¦,w_d}$,dç»´ç©ºé—´é‡Œé¢çš„ä¸€ç»„å•ä½æ­£äº¤åŸºï¼Œ$||w_i||_2=0$,$||w_i^Tw_j||=0$,å¦‚æœå†æ–°åæ ‡ç³»ä¸­ä¸¢æ‰ä¸€éƒ¨åˆ†åæ ‡ï¼Œæ ·æœ¬ç‚¹åœ¨æ–°åæ ‡çš„æŠ•å½±æ˜¯$z_i={w_1^Tx_{i1}},..,w_{dâ€™}^Tx_{i}$,äºæ˜¯åˆ$z_{ij} =w_{j}^Tx_i$,$\hat{x_i}=\sum_{j}^{dâ€™}w_jx_i$ \sum_{i=1}^{m}||\sum_{j=1}^{d'}z_{ij}w_j-x_i||_2^2=\sum_{i=1}^{m}z_i^Tz_i-2\sum_{i=1}^{m}z_i^TW^Tx_i+x_i^Tx_i\\ =\sum_{i=1}^{m}x_i^TWW^Tx_i-2\sum_{i=1}^{m}x_i^TWW^Tx_i+x_i^Tx_i\\ min -\sum_{i=1}^{m}z_i^Tz_i=-tr(Z^TZ)\\ min -tr(\sum_{i=1}^{m}W^Tx_ix_i^TW)=-tr(W^T(\sum_{i=1}^{m}x_i^Tx_i)Wï¼‰=-tr(W^TXX^TW)\\ s.t W^TW = Iå¯¹äºæœ€å¤§å¯åˆ†æ€§$(W^T\hat{X}=0)$ max tr(W^TXX^TW)\\s.t W^TW = Iæ ¹æ®lagrange L(W,\lambda)=-tr(W^TXX^TW)-\lambda(W^TW-I)\\ \frac{\partial L}{\partial w_i}=-2w_iXX^T-2\lambda_i w_i=0\\ XX^Tw_i = \lambda w_i$XX^T$æ˜¯åæ–¹å·®çŸ©é˜µ,$\lambda$æ˜¯ç‰¹å¾å€¼ï¼Œ$w_i$æ˜¯ç‰¹å¾å‘é‡ ç‰¹åˆ«æç¤ºï¼Œ$x$éœ€è¦ä¸­å¿ƒåŒ– å¯¹äºçº¿æ€§PCAé™ç»´æ–¹æ³•æ˜¯ä»é«˜ç»´ç©ºé—´æ˜ å°„åˆ°ä½ç»´ç©ºé—´ï¼Œ$Z= W^TX$,ç„¶è€Œä¸å°‘æƒ…å†µï¼Œåˆ™éœ€è¦éçº¿æ€§æ˜ å°„æ‰èƒ½æ‰¾åˆ°æ°å½“çš„ä½ç»´åµŒå…¥ï¼Œ $\phi(x)$ \max tr(\phi(X)\phi(X)^T)=tr( W^T\varphi(x)\varphi(x)^TW)\\ W^TW = Iäºæ˜¯æœ‰ \varphi(x)^T\varphi(x)w_i=\lambda_iw_i\\ w_i=\frac{tr(\varphi(x)^T\varphi(x))}{\lambda_iw_i} z_j = \frac{\sum_{i=1}^{m}\varphi(x)^T\varphi(x)}{\lambda_iw_i}\varphi(x_i)\ =\frac{\sum_{i=1}^{m}\varphi(x_i)K(x_i,x)}{\lambda_iw_i}æµå½¢å­¦ä¹ ï¼ˆè¡¨ç¤ºå­¦ä¹ æœ‰ç‚¹å›°éš¾)ç¬¬åä¸€ç«  ç‰¹å¾é€‰æ‹©ä¸ç¨€ç–å­¦ä¹ å¯¹äºä¸€ä¸ªå­¦ä¹ ä»»åŠ¡ï¼Œå¯¹ä»»åŠ¡æœ‰ç”¨çš„ç‰¹å¾,ç§°ä¸ºâ€relevant featureâ€ï¼Œå¯¹äºæ²¡æœ‰ç”¨çš„å±æ€§â€irrelevant featureâ€,å› æ­¤ä»ç»™å®šç‰¹å¾é›†é€‰æ‹©å‡ºç›¸å…³ç‰¹å¾å­é›†çš„è¿‡ç¨‹ï¼Œç‰¹å¾é€‰æ‹©ï¼ˆfeature selection),åŸå› ä¸€ï¼Œé™ç»´ï¼›åŸå› äºŒï¼šé™ä½å­¦ä¹ çš„ä»»åŠ¡ã€‚ æ— å…³ç‰¹å¾ï¼ŒåŒ…æ‹¬ä¸€ç±»å†—ä½™ç‰¹å¾ï¼ˆredundant featureï¼‰ï¼Œèƒ½å¤Ÿä»å…¶ä»–ç‰¹å¾é‡Œé¢æ¨æ¼”å‡ºæ¥ã€‚ ç‰¹å¾æœç´¢å‰å‘ï¼ˆforward)æœç´¢å¯¹äºç‰¹å¾é›†åˆ$\{a_1,a_2,â€¦,a_d \}$,æ¯ä¸ªç‰¹å¾çœ‹ä½œä¸€ä¸ªå€™é€‰é›†ï¼Œå¯¹è¿™$d$å€™é€‰çš„å•ç‰¹å¾å­é›†è¿›è¡Œè¯„ä»·ï¼Œå¯é€‰å‡ºæœ€ä¼˜å­é›†ï¼Œç„¶åï¼Œå†ä¸‹ä¸€è½®å­é›†ä¸­ï¼Œæ„æˆäº†ä¸¤ä¸ªç‰¹å¾å€™é€‰çš„å­é›†ï¼Œ åå‘ (backward) æœç´¢æ¯æ¬¡å°è¯•å»æ‰ä¸€ä¸ªæ— å…³ç‰¹å¾ åŒå‘(bidirectional)æœç´¢ä¸Šè¿°æ“ä½œåªæ˜¯è´ªå¿ƒç­–ç•¥ï¼Œä»…ä»…è€ƒè™‘äº†æœ¬è½®é€‰å®šé›†åˆæœ€ä¼˜ â€‹ å­é›†è¯„ä»·ï¼ˆsubset evaluation)å·²çŸ¥ä¸€ä¸ªæ•°æ®é›†$D$,å‡å®šç¬¬$i$ç±»æ ·æœ¬æ‰€å æ¯”ä¾‹$p_i$,å¯¹äºå±æ€§å­é›†$A$,å‡è®¾æ ¹æ®å–å€¼Dåˆ†æˆVä¸ªå­é›†$\{D^1,D^2,â€¦,D^V\}$,åˆ™å­é›†Açš„ä¿¡å¿ƒ å¢ç›Š Gain(A) = Ent(D)-\sum_{i=1}^V\frac{|D^i|}{|D|}Ent(D^i)\\ Ent(D)=\sum_{i=1}^{|y|}p_ilog^{-p_i}â€‹ ä¿¡æ¯å¢ç›ŠGain(A)è¶Šå¤§ï¼Œè¯´æ˜ç‰¹å¾å­é›†AåŒ…å«çš„æœ‰åŠ©äºåˆ†ç±»çš„ä¿¡æ¯è¶Šå¤šï¼Œç‰¹å¾å­é›†Aæ˜¯å¯¹æ•°æ®é›†Dçš„ä¸€ä¸ªåˆ’åˆ†ï¼Œæ ·æœ¬Dçš„æ ‡è®°ä¿¡æ¯Yåˆ™å¯¹åº”ç€Dçš„çœŸå®åˆ’åˆ†ï¼Œå°±èƒ½å¯¹Aè¿›è¡Œè¯„ä»·ï¼Œå¯¹Yå¯¹åº”çš„åˆ’åˆ†çš„å·®å¼‚è¶Šå°ï¼Œåˆ™è¯´æ˜Aè¶Šå¥½ï¼Œ è¿‡æ»¤å¼é€‰æ‹©Relief ï¼ˆRelevant Featureï¼‰ è®¾è®¡ä¸€ä¸ªâ€œç›¸å…³ç»Ÿè®¡é‡â€æ¥æè¿°åº¦é‡ç‰¹å¾çš„é‡è¦æ€§ï¼Œè¯¥ç»Ÿè®¡é‡æ˜¯ä¸€ä¸ªå‘é‡ï¼Œæ¯ä¸ªåˆ†é‡å¯¹åº”ä¸€ä¸ªåˆå¼ç‰¹å¾ï¼Œè€Œç‰¹å¾å­é›†çš„é‡è¦æ€§åˆ™æ˜¯æ¯ä¸ªç‰¹å¾å¯¹åº”ç»Ÿè®¡é‡åˆ†é‡ä¹‹å’Œæ¥å†³å®šï¼Œæœ€ç»ˆåªéœ€æŒ‡å®šä¸€ä¸ªé˜™å€¼ï¼Œæ ¹æ®é˜™å€¼é€‰æ‹©ç»Ÿè®¡é‡åˆ†é‡å¯¹åº”çš„ç‰¹å¾å³å¯ å¦‚ä½•ç¡®å®šç›¸å…³ç»Ÿè®¡é‡ ç»™å®šè®­ç»ƒé›†$(x_i,y_i)$,å¯¹äºå®ä¾‹$x_i$,åœ¨å…¶åŒç±»æ ·æœ¬ä¸­æ‰¾æœ€è¿‘é‚»ï¼ˆnear-hit),åœ¨ä»å¼‚ç±»æ ·æœ¬ä¸­å¯»æ‰¾å…¶æœ€è¿‘é‚»$x_{x,nm}$ç§°ä¸ºâ€œçŒœé”™è¿‘é‚»â€ï¼Œ \delta^j =\sum_i-diff(x_i^j,x_{i.nh}^j)^2+diff(x_i^j,x_{i,nm}^j)^2åˆ†å€¼è¶Šå¤§ï¼Œè¯´æ˜å¯¹åº”å±æ€§çš„åˆ†ç±»èƒ½åŠ›è¶Šå¼º å¯¹äºå¤šåˆ†ç±»é—®é¢˜ \delta^j = \sum_i-diff(x_i^j,x_{i,nh}^j)^2+\sum_{l \neq k}p_l\ diff(x_i^j,x_{i,l,nm}^j)è¿™ç§æ–¹æ³•çœ‹ä¸€ä¸ªå±æ€§ï¼ˆç‰¹å¾ï¼‰é‡ä¸é‡è¦ï¼Œå…ˆè®¡ç®—å‡ºæ¯ä¸ªå±æ€§çš„ç»Ÿè®¡åˆ†é‡ï¼ŒæŒ‰ç…§å…¬å¼ï¼Œå­é›†çš„è¯„ä»·å°±æ˜¯å¯¹äºåˆ†é‡çš„å’Œ åŒ…è£¹å¼é€‰æ‹©ç›´æ¥æŠŠæœ€ç»ˆå°†è¦ä½¿ç”¨çš„å­¦ä¹ å™¨çš„æ€§èƒ½ä½œä¸ºç‰¹å¾å­é›†çš„è¯„ä»·å‡†åˆ™ï¼Œç‰¹å¾é€‰æ‹©çš„ç›®çš„å°±æ˜¯ä¸ºç»™å®šå­¦ä¹ æœŸé€‰æ‹©æœ‰åˆ©å…¶æ€§èƒ½çš„ç‰¹å¾å­é›†ã€‚ LVWï¼ˆLas Vegas Wrapperï¼‰æ˜¯å…¸å‹çš„åŒ…è£¹å¼ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œæ‹‰æ–¯ç»´åŠ æ–¯æ–¹æ³•ï¼ˆLas Vegas methodï¼‰æ¡†æ¶ä¸‹ä½¿ç”¨éšæœºç­–ç•¥æ¥è¿›è¡Œå­é›†æœç´¢ï¼Œå¹¶ä»¥æœ€ç»ˆåˆ†ç±»å™¨çš„è¯¯å·®ä¸ºç‰¹å¾å­é›†è¯„ä»·å‡†åˆ™ ç®—æ³• åµŒå…¥å¼é€‰æ‹©å­¦ä¹ å™¨è‡ªåŠ¨åœ°è¿›è¡Œç‰¹å¾é€‰æ‹© L-PèŒƒæ•° L_P = ||X||_P = p\sqrt{\sum_{i=1}^{n}x_i^p} L0èŒƒæ•° ||X||_0=å‘é‡ä¸­éé›¶å…ƒç´ çš„ä¸ªæ•°L1èŒƒæ•° ||x||_1 = \sum|x_i|L2èŒƒæ•°ï¼Œæœ€å¸¸ç”¨ ||X||_2=\sqrt{x_i^2}æ— ç©·èŒƒæ•° ||x||=max|x_i|å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¦‚æœä½¿ç”¨L2,ç§°ä¸ºå²­å›å½’(ridge regression),å¦‚æœé‡‡å–L1èŒƒæ•°ï¼Œåˆ™æœ‰ç§°ä¸ºLASSOï¼ŒL1æ¯”L2æ›´æ˜“äºç¨€ç–è§£ï¼Œå¯ä»¥çœ‹å¾—å‡ºL1èŒƒæ•°æ­£åˆ™åŒ–çš„è¿‡ç¨‹å¾—åˆ°äº†ä»…é‡‡ç”¨ä¸€éƒ¨åˆ†åˆå§‹åŒ–ç‰¹å¾çš„æ¨¡å‹ã€‚ L1æ­£åˆ™åŒ–æ±‚è§£å¯ä½¿ç”¨è¿‘ç«¯æ¢¯åº¦ä¸‹é™æ³•(Proximal Gradient Descent)PGD L-Lipschitzæ¡ä»¶ è®¾å‡½æ•°$Î¦(x)$åœ¨æœ‰é™ åŒºé—´$[a,b]$ä¸Šæ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š (1) å½“$xâˆˆ[a,b]$æ—¶ï¼Œ$Î¦(x)âˆˆ[a,b]$ï¼Œå³$aâ‰¤Î¦(x)â‰¤b$. (2) å¯¹ä»»æ„çš„$x1ï¼Œx2âˆˆ[a,b]$ï¼Œ æ’æˆç«‹ï¼š$|Î¦(x1)-Î¦(x2)|â‰¤L|x1-x2|$. å¦‚æœ$f(x)$å¯å¯¼ï¼Œå¹¶ä¸”$\nabla f$æ»¡è¶³L-Lipschitzæ¡ä»¶ï¼Œ ||\nabla f(x')-\nabla f(x)||_2^2]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>è¥¿ç“œä¹¦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç»Ÿè®¡å­¦]]></title>
    <url>%2F2020%2F07%2F17%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[ç»Ÿè®¡å­¦ ç»Ÿè®¡å­¦ day Ox00day Ox00 é¦–å…ˆä»‹ç»éšæœºå®éªŒçš„åŸºæœ¬æ¦‚å¿µï¼ŒåŒ…æ‹¬éšæœºå®éªŒï¼Œæ ·æœ¬ç‚¹ï¼Œæ ·æœ¬ç©ºé—´ï¼ŒåŸºæœ¬äº‹ä»¶ï¼Œéšæœºäº‹ä»¶ï¼›å…¶æ¬¡ä»‹ç»æ¦‚ç‡è®ºçš„åŸºæœ¬æ¦‚å¿µï¼ŒåŒ…æ‹¬æ¦‚ç‡çš„å…¬ç†åŒ–å®šä¹‰ï¼Œå¤å…¸æ¦‚ç‡ï¼Œæ¡ä»¶æ¦‚ç‡ï¼Œå…¨æ¦‚ç‡ï¼Œè´å¶æ–¯å…¬å¼ç­‰ç­‰ã€‚ç‰¹åˆ«æ³¨æ„ä¸¤ä¸ªå®¹æ˜“æ··æ·†çš„æ¦‚å¿µï¼šäº‹ä»¶çš„ç‹¬ç«‹æ€§å’Œäº’æ–¥ã€‚ day Ox01 é¦–å…ˆå¼• å‡ºéšæœºå˜é‡çš„å®šä¹‰ï¼Œä»ç¦»æ•£éšæœºå˜é‡å’Œè¿ç»­éšæœºå˜é‡ä¸¤ä¸ªç»´åº¦ï¼Œä»‹ç»å…¸å‹çš„åˆ†å¸ƒå‡½æ•°ã€‚å…¶ä¸­æ¦‚ç‡å‡½æ•°å’Œåˆ†å¸ƒå‡½æ•°æ˜¯éå¸¸é‡è¦çš„æ¦‚å¿µã€‚ åŸºæœ¬æ¦‚å¿µéšæœºè¯•éªŒï¼šè®°ä½œ$E$ æ ·æœ¬ç‚¹ï¼š éšæœºè¯•éªŒä¸­å‡ºç°çš„å¯èƒ½ç»“æœç§°ä¸ºæ ·æœ¬ç‚¹ï¼Œè®°ä½œ $\omega$ æ ·æœ¬ç©ºé—´ï¼š æ‰€æœ‰æ ·æœ¬ç‚¹ç»„æˆçš„é›†åˆç§°ä¸ºæ ·æœ¬ç©ºé—´ï¼Œéšæœºå®éªŒæ‰€æœ‰çš„ç»“æœçš„é›†åˆï¼Œè®°ä½œ$\Omega$ äº‹ä»¶ï¼š æ ·æœ¬ç©ºé—´çš„å­é›†ï¼Œå«åšéšæœºäº‹ä»¶ï¼Œè®°ä½œA,B,Cã€‚ â€‹ åˆ†ç±»ï¼šåŸºæœ¬äº‹ä»¶ï¼ˆç”±ä¸€ä¸ªæ ·æœ¬ç‚¹æ„æˆï¼‰ï¼Œä¸å¯èƒ½äº‹ä»¶ï¼ˆä¸åŒ…å«ä»»ä½•æ ·æœ¬ç‚¹ï¼‰ï¼Œå¿…ç„¶äº‹ä»¶ï¼ˆæ ·æœ¬ç©ºé—´çš„æ‰€æœ‰æ ·æœ¬ç‚¹ç»„æˆï¼‰ äº‹ä»¶çš„å…³ç³»å’Œè¿ç®— â€‹ Aä¸Bäº’æ–¥ï¼ˆäº’ä¸ç›¸å®¹ï¼‰ï¼Œå¹¶ä¸ºç©ºé›†ã€‚ä¸å¯èƒ½åŒæ—¶å‘ç”Ÿã€‚ â€‹ å¯¹ç«‹ï¼ˆäº’é€†ï¼‰ï¼šA,Båœ¨ä¸€æ¬¡å®éªŒä¸­æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªå‘ç”Ÿã€‚ äº‹ä»¶é—´çš„å…³ç³»åŒ…å« ç›¸ç­‰ äº’ä¸ç›¸å®¹æ€§ï¼šä¸å¯èƒ½åŒæ—¶å‘ç”Ÿï¼Œæ²¡æœ‰äº¤é›† äº‹ä»¶çš„æ¦‚ç‡æ¦‚ç‡çš„å…¬ç†åŒ–å®šä¹‰è®¡ç®—æ–¹æ³•å¤å…¸æ–¹æ³•éšæœºäº‹ä»¶çš„è¦æ±‚ï¼š(1). æ¶‰åŠçš„éšæœºç°è±¡åªæœ‰æœ‰é™ä¸ªåŸºæœ¬ç»“æœï¼ˆ2). æ¯ä¸ªåŸºæœ¬ç»“æœå‡ºç°çš„å¯èƒ½æ€§æ˜¯ç›¸åŒçš„ï¼ˆç­‰å¯èƒ½æ€§ï¼‰ äº‹ä»¶çš„åŸºæœ¬ç»“æœï¼š P(A) = \frac{k}{n} = \frac{äº‹ä»¶åŒ…å«çš„åŸºæœ¬äº‹ä»¶çš„ä¸ªæ•°}{å…¨ç©ºé—´åŒ…å«çš„åŸºæœ¬ç»“æœæ€»æ•°}äº‹ä»¶çš„ç‹¬ç«‹æ€§ä¸¤ä¸ªäº‹ä»¶çš„ç‹¬ç«‹æ€§æ˜¯æŒ‡ä¸€ä¸ªäº‹ä»¶çš„å‘ç”Ÿä¸å½±å“å¦ä¸€ä¸ªäº‹ä»¶çš„å‘ç”Ÿï¼Œ P(AB) = P(A)P(B)å¤šä¸ªäº‹ä»¶çš„ç‹¬ç«‹æ€§ P(A_iA_j) = P(A_i)P(A_j)\\ P(A_iA_jA_k) = P(A_i)P(A_j)P(A_k)\\ \vdots P(A_1A_2\cdots A_n) = P(A_1)P(A_2)\cdots P(A_n)å®éªŒçš„ç‹¬ç«‹æ€§å®éªŒ$E_1$çš„ä»»æ„ä¸€ä¸ªç»“æœï¼ˆäº‹ä»¶ï¼‰ä¸å®éªŒ$E_2$çš„ä»»ä¸€ä¸ªç»“æœéƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„äº‹ä»¶ï¼Œåˆ™ç§°å®éªŒç›¸äº’ç‹¬ç«‹ æ¡ä»¶æ¦‚ç‡ P(A|B) = \frac{P(AB)}{P(B)}ä¹˜æ³•å…¬å¼ P(A_1A_2A_3) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)å…¨æ¦‚ç‡å…¬å¼ P(A) = P(A|B)P(B)+P(A|\hat{B})P(\hat{B}) P(A) = \sum_{i = 1}^nP(A|B_i)P(B_i)è´å¶æ–¯å…¬å¼ P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i = 1}^nP(A|B_k)P(B_k)}éšæœºå˜é‡ day Ox01éšæœºå˜é‡è¡¨ç¤ºéšæœºç°è±¡ç»“æœï¼Œä¸€èˆ¬å¤§å†™å­—æ¯X,Y,Z, éšæœºå˜é‡å–å€¼ç”¨å°å†™å­—æ¯x,y,zç­‰è¡¨ç¤ºã€‚ ç”¨ç­‰å·æˆ–è€…ä¸ç­‰å·æŠŠXä¸xè”ç³»èµ·æ¥å°±å¾ˆå¤šæœ‰è¶£çš„äº‹ä»¶ï¼ŒX=x,Y&lt;y,ç­‰ç­‰æ„æˆäº†äº‹ä»¶ã€‚ éšæœºå˜é‡å®šä¹‰åœ¨åŸºæœ¬ç©ºé—´$\Omega$ä¸Šçš„å®å€¼å‡½æ•°$X = X(w)$æˆä¸ºéšæœºç©ºé—´ X: w->å®æ•°åŸŸï¼ˆæ˜ å°„)éšæœºå˜é‡çš„åˆ†å¸ƒå‡½æ•°åˆ†å¸ƒå‡½æ•°çš„å®šä¹‰ F(x) = P(X]]></content>
      <categories>
        <category>æ•°å­¦</category>
      </categories>
      <tags>
        <tag>ç»Ÿè®¡å­¦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PageRankç®—æ³•]]></title>
    <url>%2F2020%2F07%2F15%2FPageRank%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[PageRankæ˜¯ä¸€ç§ç½‘é¡µæ’åºç®—æ³•ï¼ŒåŸºäºé¡µé¢çš„è´¨é‡å’Œæ•°é‡ã€‚å¯åº”ç”¨äºè¯„ä¼°ç½‘é¡µèŠ‚ç‚¹é‡è¦æ€§ã€‚ PageRankç®—æ³•PageRank,å³\ç½‘é¡µæ’å**ï¼Œåˆç§°ç½‘é¡µçº§åˆ«ã€Googleå·¦ä¾§æ’åæˆ–ä½©å¥‡æ’åã€‚PageRankæ˜¯Googleç”¨äºç”¨æ¥æ ‡è¯†ç½‘é¡µçš„ç­‰çº§/é‡è¦æ€§çš„ä¸€ç§æ–¹æ³•ï¼Œæ˜¯Googleç”¨æ¥è¡¡é‡ä¸€ä¸ªç½‘ç«™çš„å¥½åçš„å”¯ä¸€æ ‡å‡†ã€‚ å‡è®¾ æ•°é‡å‡è®¾: å¦‚æœä¸€ä¸ªé¡µé¢èŠ‚ç‚¹å…¥é“¾æ•°é‡è¶Šå¤šï¼Œåˆ™è¿™ä¸ªé¡µç è¶Šé‡è¦ã€‚ è´¨é‡å‡è®¾ï¼šæŒ‡å‘é¡µé¢Açš„å…¥é“¾è´¨é‡ä¸åŒï¼Œè€ƒè™‘æƒé‡çš„å½±å“ï¼Œåˆ™è¿™ä¸ªé¡µé¢è¶Šæ˜¯é‡è¦ã€‚ ç®—æ³•æ±‚è§£ ç¬¬ä¸€é˜¶æ®µï¼šé€šè¿‡ç½‘é¡µé“¾æ¥å…³ç³»æ„å»ºèµ·Webå›¾ï¼Œåˆå§‹æ¯ä¸ªé¡µé¢ç›¸åŒçš„PageRankå€¼ï¼Œå†é€šè¿‡è‹¥å¹²è½®å¾—åˆ°æ¯ä¸ªé¡µé¢çš„æœ€ç»ˆpagerank. æ¯ä¸€è½®æ›´æ–°é¡µé¢PageRankå¾—åˆ†çš„è®¡ç®—æ–¹æ³• æƒé‡ PR(T)/L(T)\\ where PR(T)çš„PageRankå€¼ï¼ŒL(T)ä¸ºTçš„å‡ºé“¾æ•°ç›®ä¿®æ­£$L(T)$ä¸º0çš„æƒ…å†µï¼Œå­¤ç«‹ç½‘é¡µï¼Œä½¿å¾—å¾ˆå¤šç½‘é¡µèƒ½è¢«è®¿é—®åˆ°ã€‚$q = 0.85$ PR(A) = (\frac{PR(B)}{L(B)}+\frac{PR(C)}{L(C)}+\dots)q+1-qå…¶ä»–ç½‘ç»œå±æ€§åº¦é‡æ–¹æ³•Centrality indices: degree, betweenness, and closeness. referenceæå‡ºè€…ï¼š The anatomy of a large-scale hypertextual Web search engine https://en.wikipedia.org/wiki/PageRank]]></content>
      <categories>
        <category>ç§‘ç ”</category>
      </categories>
      <tags>
        <tag>ç®—æ³•</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rè¯­è¨€]]></title>
    <url>%2F2020%2F07%2F03%2FR%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[https://bookdown.org/qiyuandong/intro_r/-r-basics-2.html#section-3.3 å…¥é—¨ï¼š https://rc2e.com/ http://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/intro.html å…¨é¢ï¼š https://github.com/harryprince/R-Tutor è§†é¢‘ï¼š ä¸­æ–‡ï¼š https://www.youtube.com/watch?v=rPj5FsTRboE è‹±æ–‡ï¼šhttps://www.youtube.com/watch?v=32o0DnuRjfg è¿™ä¸ªæ•™ç¨‹å¥½ï¼š https://sites.google.com/site/econometricsacademy/econometrics-models/linear-regression https://www.youtube.com/watch?v=YMt5K68ZvjQ&amp;list=PLRW9kMvtNZOh7Xt1m5Mlhhz2wtr0tCUEE]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Xgboost]]></title>
    <url>%2F2020%2F07%2F03%2FXgboost%2F</url>
    <content type="text"><![CDATA[ç†è®ºéƒ¨åˆ†è¯¥ç®—æ³•æ€æƒ³å°±æ˜¯ä¸æ–­åœ°æ·»åŠ æ ‘ï¼Œä¸æ–­åœ°è¿›è¡Œç‰¹å¾åˆ†è£‚æ¥ç”Ÿé•¿ä¸€æ£µæ ‘ï¼Œæ¯æ¬¡æ·»åŠ ä¸€ä¸ªæ ‘ï¼Œå…¶å®æ˜¯å­¦ä¹ ä¸€ä¸ªæ–°å‡½æ•°ï¼Œå»æ‹Ÿåˆä¸Šæ¬¡é¢„æµ‹çš„æ®‹å·®ã€‚å½“æˆ‘ä»¬è®­ç»ƒå®Œæˆå¾—åˆ°kæ£µæ ‘ï¼Œæˆ‘ä»¬è¦é¢„æµ‹ä¸€ä¸ªæ ·æœ¬çš„åˆ†æ•°ï¼Œå…¶å®å°±æ˜¯æ ¹æ®è¿™ä¸ªæ ·æœ¬çš„ç‰¹å¾ï¼Œåœ¨æ¯æ£µæ ‘ä¸­ä¼šè½åˆ°å¯¹åº”çš„ä¸€ä¸ªå¶å­èŠ‚ç‚¹ï¼Œæ¯ä¸ªå¶å­èŠ‚ç‚¹å°±å¯¹åº”ä¸€ä¸ªåˆ†æ•°ï¼Œæœ€ååªéœ€è¦å°†æ¯æ£µæ ‘å¯¹åº”çš„åˆ†æ•°åŠ èµ·æ¥å°±æ˜¯è¯¥æ ·æœ¬çš„é¢„æµ‹å€¼ã€‚ boosting: https://zhuanlan.zhihu.com/p/38329631 Xgboost å°±æ˜¯å›å½’æ ‘çš„é›†æˆ https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/ https://blog.csdn.net/github_38414650/article/details/76061893?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare https://blog.csdn.net/qq_24519677/article/details/81809157 æœ‰ç©ºå†æ¨å¯¼äº† è°ƒç”¨åº“Python æä¾›äº†ä¸¤ç§åº“ xgboost xgboost sklearnæ¥å£ æ­å»ºæ¨¡å‹ å‚æ•°è®¾ç½® GridSearchCV è°ƒå‚(ç½‘æ ¼æ³•) è°ƒå‚æ­¥éª¤ï¼Œå‚æ•°èŒƒå›´ https://blog.csdn.net/han_xiaoyang/article/details/52665396 12345678import xgboost as xgbfrom xgboost import XGBRegressorfrom sklearn.metrics import mean_absolute_error,make_scorerfrom sklearn.grid_search import GridSearchCVfrom sklearn.cross_validation import KFold, train_test_splitfrom sklearn.datasets import load_boston https://blog.csdn.net/s09094031/article/details/94871596?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.compare 1sklearn.model_selection.``train_test_split test_size train_sizeï¼š â€‹ ä¸‰ç§ç±»å‹ã€‚floatï¼Œintï¼ŒNoneã€‚ floatï¼š0.0-1.0ä¹‹é—´ï¼Œä»£è¡¨è®­ç»ƒæ•°æ®é›†å æ€»æ•°æ®é›†çš„æ¯”ä¾‹ã€‚ intï¼šä»£è¡¨è®­ç»ƒæ•°æ®é›†å…·ä½“çš„æ ·æœ¬æ•°é‡ã€‚ Noneï¼šè®¾ç½®ä¸ºtest_sizeçš„è¡¥ã€‚ defaultï¼šé»˜è®¤ä¸ºNoneã€‚ random_stateï¼šä¸‰ç§ç±»å‹ã€‚intï¼Œrandomstate instanceï¼ŒNoneã€‚ intï¼šæ˜¯éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ã€‚æ¯æ¬¡åˆ†é…çš„æ•°æ®ç›¸åŒã€‚ randomstateï¼šrandom_stateæ˜¯éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ã€‚ï¼ˆè¿™é‡Œæ²¡å¤ªç†è§£ï¼‰ Noneï¼šéšæœºæ•°ç”Ÿæˆå™¨æ˜¯ä½¿ç”¨äº†np.randomçš„randomstateã€‚ ç§å­ç›¸åŒï¼Œäº§ç”Ÿçš„éšæœºæ•°å°±ç›¸åŒã€‚ç§å­ä¸åŒï¼Œå³ä½¿æ˜¯ä¸åŒçš„å®ä¾‹ï¼Œäº§ç”Ÿçš„ç§å­ä¹Ÿä¸ç›¸åŒã€‚ shuffleï¼šå¸ƒå°”å€¼ï¼Œå¯é€‰å‚æ•°ã€‚é»˜è®¤æ˜¯Noneã€‚åœ¨åˆ’åˆ†æ•°æ®ä¹‹å‰å…ˆæ‰“ä¹±æ•°æ®ã€‚å¦‚æœshuffle=FALSEï¼Œåˆ™stratifyå¿…é¡»æ˜¯Noneã€‚ stratifyï¼šarray-likeæˆ–è€…Noneï¼Œé»˜è®¤æ˜¯Noneã€‚å¦‚æœä¸æ˜¯Noneï¼Œå°†ä¼šåˆ©ç”¨æ•°æ®çš„æ ‡ç­¾å°†æ•°æ®åˆ†å±‚åˆ’åˆ†ã€‚ è‹¥ä¸ºNoneæ—¶ï¼Œåˆ’åˆ†å‡ºæ¥çš„æµ‹è¯•é›†æˆ–è®­ç»ƒé›†ä¸­ï¼Œå…¶ç±»æ ‡ç­¾çš„æ¯”ä¾‹ä¹Ÿæ˜¯éšæœºçš„ã€‚ è‹¥ä¸ä¸ºNoneæ—¶ï¼Œåˆ’åˆ†å‡ºæ¥çš„æµ‹è¯•é›†æˆ–è®­ç»ƒé›†ä¸­ï¼Œå…¶ç±»æ ‡ç­¾çš„æ¯”ä¾‹åŒè¾“å…¥çš„æ•°ç»„ä¸­ç±»æ ‡ç­¾çš„æ¯”ä¾‹ç›¸åŒï¼Œå¯ä»¥ç”¨äºå¤„ç†ä¸å‡è¡¡çš„æ•°æ®é›†ã€‚ x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.23, random_state=2) https://blog.csdn.net/qq_43288098/article/details/105407204?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.compare å‚æ•°ï¼šåˆ†å¼€è°ƒ https://blog.csdn.net/zc02051126/article/details/46711047 https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn æ¨¡å‹ä¿å­˜https://www.fatrabbids.com/2018/10/19/xgboost%e7%9a%84%e4%bf%9d%e5%ad%98%e6%a8%a1%e5%9e%8b%e3%80%81%e5%8a%a0%e8%bd%bd%e6%a8%a1%e5%9e%8b%e3%80%81%e7%bb%a7%e7%bb%ad%e8%ae%ad%e7%bb%83/#more-235 XGBoostçš„ç‰¹æ€§é‡è¦æ€§å’Œç‰¹æ€§é€‰æ‹© æ¨¡å‹å¤æ‚åº¦ ç‰¹å¾æ•°é‡è¡¡é‡ï¼šç‰¹å¾é‡è¦æ€§é˜™å€¼çš„å¢åŠ ï¼Œé€‰æ‹©ç‰¹å¾æ•°é‡å‡å°‘ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡ä¼šä¸‹é™ã€‚å½“ç„¶ï¼Œç‰¹å¾æ•°é‡çš„å‡å°‘åè€Œä¼šæ˜¯å‡†ç¡®ç‡å‡é«˜ï¼Œå› ä¸ºè¿™äº›è¢«å‰”é™¤ç‰¹å¾æ˜¯å™ªå£°ã€‚]]></content>
      <tags>
        <tag>æœºå™¨å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[English-Daily]]></title>
    <url>%2F2020%2F06%2F23%2FEnglish-Daily%2F</url>
    <content type="text"><![CDATA[2020-7-6coincide with v. ä¸â€¦ç›¸ç¬¦ stalk v. æ½œè¿‘ï¼ˆçŒç‰©æˆ–äººï¼‰ï¼›ï¼ˆéæ³•ï¼‰è·Ÿè¸ªï¼›æ€’å†²å†²åœ°èµ°ï¼›è¶¾é«˜æ°”æ‰¬åœ°èµ° n. ç§†ï¼›æŸ„ï¼›ï¼ˆå¶ï¼‰æŸ„ï¼›ï¼ˆèŠ±ï¼‰æ¢— verge Bella was on the verge of tears when she heard the news. å¬åˆ°è¿™ä¸ªæ¶ˆæ¯æ—¶ï¼Œè´æ‹‰å·®ç‚¹å°±è¦å“­äº†ã€‚ resistant adj. æŠµåˆ¶çš„ï¼ŒåæŠ—çš„ï¼ŒæŠ—æ‹’çš„ï¼›æœ‰æŠµæŠ—åŠ›çš„ï¼›æŠµæŠ—â€¦çš„ï¼›ä¸å—â€¦â€¦æŸå®³çš„ People are usually resistant to change. äººä»¬é€šå¸¸æŠ—æ‹’æ”¹å˜ã€‚ liar The tall guy was a notorious liar. é‚£ä¸ªé«˜ä¸ªå­æ˜¯ä¸ªè‡­åæ˜­è‘—çš„éª—å­ã€‚ politics n. æ”¿æ²»ï¼›æ”¿æ²»äº‹ç‰©ï¼ˆæ´»åŠ¨ï¼‰ï¼›æ”¿è§ï¼›æƒæœ¯ oblige (ä»¥æ³•å¾‹ã€ä¹‰åŠ¡ç­‰)å¼ºè¿«, è¿«ä½¿; å¸®å¿™, æ•ˆåŠ³; [å¸¸ç”¨è¢«åŠ¨]ä½¿æ„Ÿæ¿€; ä½¿(è¡Œä¸ºç­‰)æˆä¸ºå¿…è¦ phrase. (feel obliged to do sth.)è§‰å¾—æœ‰ä¹‰åŠ¡åšï¼›ä¸å¾—ä¸åš I felt obliged to leave after such an unpleasant quarrel. å‘ç”Ÿäº†è¿™æ ·ä¸æ„‰å¿«çš„äº‰åµä¹‹åï¼Œæˆ‘è§‰å¾—æœ‰å¿…è¦ç¦»å¼€ã€‚ 2020-7-1jelly n. æœå†»ï¼›è‚‰å†»ï¼›æœé…±ï¼›èƒ¶çŠ¶ç‰©ï¼Œèƒ¶å‡ç‰©ï¼›è½»ä¾¿å¡‘æ–™é‹ oval adj. æ¤­åœ†å½¢çš„ï¼›åµå½¢çš„ n. æ¤­åœ†å½¢ï¼›åµå½¢ rigorous /â€˜rÉªÉ¡É™rÉ™s/ adj. è°¨æ…çš„ï¼Œç»†è‡´çš„ï¼›ä¸¥æ ¼çš„ï¼Œä¸¥å‰çš„ He makes a rigorous study of the plants in the area. ä»–å¯¹è¯¥åœ°çš„æ¤ç‰©è¿›è¡Œäº†ç¼œå¯†çš„ç ”ç©¶ã€‚ ultimately UK/â€˜ÊŒltÉªmÉ™tli/ adv. æœ€ç»ˆ, æœ€å, å½’æ ¹ç»“åº•, ç»ˆç©¶ Everything will ultimately depend on what is said at the meeting. ä¸€åˆ‡å°†æœ€ç»ˆå–å†³äºä¼šè®®çš„å†…å®¹ã€‚ sturdy UK/â€˜stÉœËdi/ adj. ç»“å®çš„ï¼Œåšå›ºçš„ï¼›å¼ºå£®çš„ï¼›å¥å£®çš„ï¼›åšå†³çš„ï¼Œé¡½å¼ºçš„ broaden UK/â€˜brÉ”Ëdn/ You should broaden your experience by travelling more. ä½ åº”è¯¥å¤šåˆ°å„åœ°èµ°èµ°ä»¥å¢å¹¿è§è¯†. broaden the horizon å¼€æ‹“è§†é‡ propel UK/prÉ™â€™pel/ v. æ¨è¿›ï¼Œæ¨åŠ¨ï¼›é©±ä½¿ï¼›è¿«ä½¿ voyage UK/â€˜vÉ”ÉªÉªdÊ’/ n. èˆªè¡Œ, ï¼ˆå°¤æŒ‡ï¼‰èˆªæµ· v. èˆªè¡Œ, è¿œè¡Œ, ï¼ˆå°¤æŒ‡ï¼‰è¿œèˆª ä¾‹å¥ The voyage from England to India used to take 3 weeks. ä»è‹±æ ¼å…°åˆ°å°åº¦çš„èˆªè¡Œæ›¾ç»éœ€è¦ä¸‰å‘¨ã€‚ 2020-6-28moist UK/mÉ”Éªst/ adj. å¾®æ¹¿çš„, æ¹¿æ¶¦çš„ insult UK/Éªnâ€™sÊŒlt/v. ä¾®è¾±ï¼Œè¾±éª‚ n. ä¾®è¾±ï¼Œè¾±éª‚ spontaneous UK/spÉ’nâ€™teÉªniÉ™s/ They greeted him with spontaneous applause. ä»–ä»¬è‡ªå‘åœ°é¼“èµ·æŒæ¥æ¬¢è¿ä»–ã€‚ slender UK/â€˜slendÉ™(r)/ perimeter UK/pÉ™â€™rÉªmÉªtÉ™(r)/ n. å‘¨é•¿ï¼›å¤–ç¼˜ï¼Œè¾¹ç¼˜ blouse UK/blaÊŠz/ He pointed out a woman passing by who was wearing a skirt and blouse. ä»–æŒ‡å‡ºäº†ä¸€ä¸ªç©¿ç€è£™å­å’Œè¡¬è¡«çš„è¿‡è·¯å¥³å­ã€‚ perfume UK/â€˜pÉœËfjuËm/ n. é¦™æ°´, é¦™æ–™, èŠ³é¦™ v. ä½¿â€¦å‘å‡ºé¦™æ°”, æ´’é¦™æ°´ 2020-6-272020-6-26Functional foods are food products that have a potentially positive effect on health beyond basic nutritional benefits. Functional foods aim to solve not only all the needs that regular foods provide, but also to address functional needs, which can range from maintaining and improving physical or mental health to adjusting energy levels and moods. Food has been historically used as preventive medicine in many cultures around the world, but the recent rise of functional foods can be directly linked to the rise of the wellness economy, which, in turn, is largely driven by influencer marketing and social media use. 2020-6-25IT IS A truth universally acknowledged that inequalityï¼ˆä¸å¹³ç­‰ï¼‰in the rich worldï¼ˆå‘è¾¾å›½å®¶ï¼‰is high and rising. Or, at least, it used to be. A growing band of economists are challenging the receivedï¼ˆè¢«å…¬è®¤çš„ï¼‰wisdom, pointing out that trends in the distributionï¼ˆåˆ†å¸ƒï¼Œåˆ†é…ï¼‰of income and wealth may not be as bad as is often thought. ä¼—æ‰€å‘¨çŸ¥ï¼Œå¯Œè£•å›½å®¶çš„ä¸å¹³ç­‰ç°è±¡éå¸¸ä¸¥é‡ï¼Œè€Œä¸”è¿˜åœ¨åŠ å‰§ã€‚æˆ–è€…è¯´ï¼Œè‡³å°‘æ›¾ç»æ˜¯è¿™æ ·çš„ã€‚è¶Šæ¥è¶Šå¤šçš„ç»æµå­¦å®¶å¼€å§‹è´¨ç–‘æ—¢æœ‰çš„è§‚ç‚¹ï¼Œä»–ä»¬æŒ‡å‡ºæ”¶å…¥å’Œè´¢å¯Œçš„åˆ†å¸ƒè¶‹åŠ¿å¯èƒ½ä¸æ˜¯åƒé€šå¸¸è¢«è®¤ä¸ºçš„é‚£ä¹ˆç³Ÿç³•ã€‚ 2020-6-24imaginary adj. æƒ³è±¡ä¸­çš„, å¹»æƒ³çš„, è™šæ„çš„ carriage n. è¿è¾“ï¼›è¿è´¹ï¼Œï¼ˆæ—§æ—¶ï¼‰é©¬è½¦ï¼›ç«è½¦è½¦å¢ï¼›ä»ªæ€ï¼Œå§¿æ€ï¼Œä¸¾æ­¢ message messenger n. ä¿¡ä½¿, é€ä¿¡äºº, é€šä¿¡å‘˜, é‚®é€’å‘˜ pavement n. äººè¡Œé“ postpone v. å»¶æœŸ, å»¶è¿Ÿ, æš‚ç¼“ Weâ€™ll have to postpone the meeting until next week. æˆ‘ä»¬å°†ä¸å¾—ä¸æŠŠä¼šè®®æ¨è¿Ÿåˆ°ä¸‹å‘¨ä¸¾è¡Œã€‚ velocity n. é€Ÿåº¦ï¼Œé€Ÿç‡ï¼›é«˜é€Ÿ reconcile v. ä½¿å’Œè°ä¸€è‡´ï¼Œè°ƒå’Œï¼›ä½¿å’Œè§£ï¼›å°†å°±ï¼Œå¦¥å Itâ€™s difficult to reconcile these two different points of view. å¾ˆéš¾å…¼é¡¾è¿™ä¸¤ç§ä¸åŒçš„è§‚ç‚¹ã€‚ 2020-6-23ï¿¼The success of the brand wasnâ€™t built through big marketing campaigns, but through a savvy digital marketing strategy that increased brand awareness and generated high engagement, traffic, and conversions. è¯¥å“ç‰Œçš„æˆåŠŸå¹¶ä¸å»ºç«‹äºå¤§å‹è¥é”€æ´»åŠ¨ï¼Œè€Œæ˜¯å»ºç«‹äºç²¾å‡†çš„æ•°å­—è¥é”€ç­–ç•¥ï¼Œè¯¥ç­–ç•¥æé«˜äº†å“ç‰Œçš„çŸ¥ååº¦ï¼Œè·å¾—äº†å¾ˆé«˜çš„å‚ä¸åº¦ã€æµé‡å’Œè½¬åŒ–ç‡ã€‚ traffic: ä¿¡æ¯æµé‡ï¼Œé€šä¿¡é‡ With only 40 physical stores, which are mostly used to drive consumers to e-commerce portals, Perfect Diary maintains momentum primarily through its digital footprint. Currently, it has a powerful presence on Little Red Book, Bilibili, Weibo, WeChat, Tmall, and Douyin. Thereafter she wrote articles for papers and magazines for a living. æ­¤åå¥¹ç»™æŠ¥çº¸å’Œæ‚å¿—æ’°ç¨¿è°‹ç”Ÿã€‚ adv. æ­¤å, ä¹‹å, ä»¥å spur n. åˆºæ¿€, æ¿€åŠ±, é­ç­–; è¸¢é©¬åˆº, é´åˆº; éª¨åˆº; å±±å˜´, å°–å¡ v. åˆºæ¿€, æ¿€åŠ±, ä¿ƒè¿›, é­ç­– stick adj. é»ï¼ˆæ€§ï¼‰çš„, ä¸€é¢å¸¦é»èƒ¶çš„, é—·çƒ­çš„, æ„Ÿåˆ°çƒ­å¾—éš¾å—çš„ n. å‘Šäº‹è´´ I have to take a shower before going out because the sweat had made my skin sticky. å‡ºé—¨å‰æˆ‘å¾—å†²ä¸ªæ¾¡ï¼Œå› ä¸ºæ±—æ°´è®©æˆ‘çš„çš®è‚¤é»ä¹ä¹çš„ devotion n. å…³çˆ±ï¼Œå…³ç…§ï¼›å¥‰çŒ®ï¼›å¿ è¯šï¼›å®—æ•™ç¤¼æ‹œ The career needs our devotion for all our lives. è¿™é¡¹äº‹ä¸šéœ€è¦æˆ‘ä»¬æ¯•ç”Ÿçš„å¥‰çŒ®ã€‚ reckless adj. é²è½çš„ï¼›ä¸è®¡åæœçš„ï¼›æ— æ‰€é¡¾å¿Œçš„ wag v. æ‘‡åŠ¨ï¼›æ‘†ï¼ˆå°¾å·´ï¼‰ï¼Œï¼ˆå°¾å·´ï¼‰æ‘‡ï¼Œæ‘†åŠ¨ n. æ‘‡æ‘†ï¼Œæ‘†åŠ¨ï¼›è€å¼€ç©ç¬‘çš„äººï¼Œçˆ±é—¹ç€ç©çš„äºº keen adj. çƒ­è¡·çš„, çƒ­æƒ…çš„; æ¸´æœ›çš„; æ•æ·çš„; çµæ•çš„; é”‹åˆ©çš„; å¼ºçƒˆçš„ n. æ¸å“­; æŒ½æ­Œ v. (ä¸ºæ­»è€…)æ¸å“­ be keen on sthå¯¹ æ„Ÿå…´è¶£ be keen to do æ¸´æœ›åšæŸäº‹ offspring n. å­å¥³ï¼Œåä»£ï¼›å¹¼å´½ï¼›å¹¼è‹— receipt n. æ”¶æ®ï¼Œæ”¶å…¥]]></content>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day]]></title>
    <url>%2F2020%2F06%2F22%2Ftime-series-01%2F</url>
    <content type="text"><![CDATA[æ—¶é—´åºåˆ—åŠå…¶åˆ†è§£ æ—¶é—´åºåˆ—åˆ†ç±»å¹³ç¨³åºåˆ—ï¼ˆstationary series)åºåˆ—ä¸­çš„å„è§‚å¯Ÿå€¼åŸºæœ¬ä¸Šåœ¨æŸä¸ªå›ºå®šçš„æ°´å¹³ä¸Šæ³¢åŠ¨ï¼Œåœ¨ä¸åŒæ—¶Fé—´æ®µæ³¢åŠ¨ç¨‹åº¦ä¸åŒï¼Œä½†ä¸å­˜åœ¨æŸç§è§„å¾‹ã€‚å¹³ç¨³æ€§æ—¶é—´åºåˆ—çš„å‡å€¼å’Œæ–¹å·®éƒ½æ˜¯å¸¸æ•°ã€‚ æ–¹æ³•ï¼ša) çœ‹åŸå›¾ã€‚æ˜¯å¦åœ¨æŸä¸ªå¸¸æ•°é™„è¿‘æ³¢åŠ¨ï¼Œä¸”æ³¢åŠ¨èŒƒå›´æœ‰ç•Œã€‚å¦‚æœæœ‰æ˜æ˜¾çš„è¶‹åŠ¿æ€§æˆ–è€…å‘¨æœŸæ€§ï¼Œåˆ™ä¸æ˜¯ã€‚b) ADFå•ä½æ ¹æ£€æµ‹ã€‚på€¼ã€‚ éå¹³ç¨³åºåˆ—ï¼ˆnon-stationary series)æ¶‰åŠè¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œå‘¨æœŸä¸‰ç§ç‰¹æ€§ï¼ŒåŒ…å«å…¶ä¸­ä¸€ç§æˆ–è€…å¤šç§æˆåˆ†ã€‚ è¶‹åŠ¿(trend)æ—¶é—´åºåˆ—åœ¨é•¿æ—¶æœŸå†…å‘ˆç°å‡ºæ¥çš„æŸç§ä¸Šå‡æˆ–è€…ä¸‹é™çš„è¶‹åŠ¿ã€‚åˆ†ä¸ºçº¿æ€§å’Œéçº¿æ€§ã€‚ å­£èŠ‚æ€§ï¼ˆseasonality)æ˜¯æŒ‡æ—¶é—´åºåˆ—åœ¨ä¸€å¹´å†…é‡å¤å‡ºç°çš„å‘¨æœŸæ³¢åŠ¨ã€‚å› å­£èŠ‚ä¸åŒè€Œå‘ç”Ÿå˜åŒ–ï¼Œå¦‚æ—…æ¸¸æ—ºå­£ï¼Œæ—…æ¸¸æ·¡å­£ã€‚ å‘¨æœŸæ€§ï¼ˆcyclicityï¼‰æ˜¯æŒ‡æ—¶é—´åºåˆ—å‘ˆç°å‡ºçš„é•¿æœŸè¶‹åŠ¿ã€‚å‘¨æœŸæ€§ä¸åŒäºè¶‹åŠ¿å˜åŠ¨ï¼Œå®ƒæ˜¯æ¶¨è½ç›¸é—´çš„äº¤æ›¿æ³¢åŠ¨ã€‚ä¸åŒæ„å­£èŠ‚å˜åŠ¨ï¼Œå®ƒæ— å›ºå®šè§„å¾‹ï¼Œå˜åŠ¨å‘¨æœŸå¤šåœ¨ä¸€å¹´ä»¥ä¸Šï¼Œä¸”å‘¨æœŸé•¿çŸ­ä¸ä¸€ã€‚å‘¨æœŸæ€§é€šå¸¸æ˜¯ç”±ç»æµç¯å¢ƒçš„å˜åŒ–å¼•èµ·çš„ã€‚ å¶ç„¶æ€§å› ç´ å…¶å¯¼è‡´æ—¶é—´åºåˆ—å‘ˆç°å‡ºæŸç§éšæœºæ³¢åŠ¨ã€‚ æ—¶é—´åºåˆ—çš„æˆåˆ†å¯åˆ†ä¸ºï¼šè¶‹åŠ¿ï¼ˆT),å­£èŠ‚æ€§ï¼ˆS),å‘¨æœŸæ€§ï¼ˆC),éšæœºæ€§ï¼ˆI)ã€‚ å¹³ç¨³æ—¶é—´åºåˆ—åˆ†æARæ¨¡å‹ è‡ªå›å½’æ¨¡å‹AR è‡ªå›å½’æ¨¡å‹æè¿°å½“å‰å€¼ä¸å†å²å€¼ä¹‹é—´çš„å…³ç³»ï¼Œç”¨å˜é‡è‡ªèº«çš„å†å²æ—¶é—´æ•°æ®å¯¹è‡ªèº«è¿›è¡Œé¢„æµ‹ã€‚è‡ªå›å½’æ¨¡å‹å¿…é¡»æ»¡è¶³å¹³ç¨³æ€§çš„è¦æ±‚ã€‚ ç§»åŠ¨å¹³å‡æ¨¡å‹MA ç§»åŠ¨å¹³å‡æ¨¡å‹å…³æ³¨çš„æ˜¯è‡ªå›å½’æ¨¡å‹ä¸­çš„è¯¯å·®é¡¹çš„ç´¯åŠ  è‡ªå›å½’ç§»åŠ¨å¹³å‡æ¨¡å‹ARMA è‡ªå›å½’æ¨¡å‹ARå’Œç§»åŠ¨å¹³å‡æ¨¡å‹MAæ¨¡å‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†è‡ªå›å½’ç§»åŠ¨å¹³å‡æ¨¡å‹ARMA(p,q) å·®åˆ†è‡ªå›å½’ç§»åŠ¨å¹³å‡æ¨¡å‹ARIMA å°†è‡ªå›å½’æ¨¡å‹ã€ç§»åŠ¨å¹³å‡æ¨¡å‹å’Œå·®åˆ†æ³•ç»“åˆï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†å·®åˆ†è‡ªå›å½’ç§»åŠ¨å¹³å‡æ¨¡å‹ARIMA(p,d,q) å‚æ•°ç¡®å®šæ‹–å°¾å’Œæˆªå°¾æ‹–å°¾æŒ‡åºåˆ—ä»¥æŒ‡æ•°ç‡å•è°ƒé€’å‡æˆ–éœ‡è¡è¡°å‡ï¼Œè€Œæˆªå°¾æŒ‡åºåˆ—ä»æŸä¸ªæ—¶ç‚¹å˜å¾—éå¸¸å°ã€‚ ARIMAå»ºæ¨¡è¿‡ç¨‹ å°†åºåˆ—å¹³ç¨³ï¼ˆå·®åˆ†æ³•ç¡®å®šdï¼‰ på’Œqé˜¶æ•°ç¡®å®šï¼šACFä¸PACF ARIMAï¼ˆp,d,qï¼‰ æ¨¡å‹ ACF PACF ARï¼ˆpï¼‰ è¡°å‡è¶‹äºé›¶ï¼ˆå‡ ä½•å‹æˆ–æŒ¯è¡å‹ï¼‰ pé˜¶åæˆªå°¾ MAï¼ˆqï¼‰ qé˜¶åæˆªå°¾ è¡°å‡è¶‹äºé›¶ï¼ˆå‡ ä½•å‹æˆ–æŒ¯è¡å‹ï¼‰ ARMAï¼ˆp,qï¼‰ qé˜¶åè¡°å‡è¶‹äºé›¶ï¼ˆå‡ ä½•å‹æˆ–æŒ¯è¡å‹ï¼‰ pé˜¶åè¡°å‡è¶‹äºé›¶ï¼ˆå‡ ä½•å‹æˆ–æŒ¯è¡å‹ï¼‰ å‚æ•° p,q çš„è‡ªåŠ¨ç¡®å®šæ–¹å¼ä¿¡æ¯å‡†åˆ™åœ¨å‚æ•°ä¼°è®¡çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨ä¼¼ç„¶å‡½æ•°ä½œä¸ºç›®æ ‡å‡½æ•°ã€‚å¯ä»¥é€šè¿‡åŠ å…¥æ¨¡å‹å¤æ‚åº¦çš„æƒ©ç½šé¡¹é¿å…è¿‡æ‹Ÿåˆé—®é¢˜ã€‚æ¯”å¦‚èµ¤æ± ä¿¡æ¯å‡†åˆ™ï¼ˆAIC)å’Œè´å¶æ–¯ä¿¡æ¯å‡†åˆ™(BIC) AIC=2kâˆ’2ln(L)ä¸€æ–¹é¢å¼•å…¥æƒ©ç½šé¡¹ï¼Œä½¿å¾—æ¨¡å‹å‚æ•°å°½å¿«å°‘ï¼Œå‡å°‘è¿‡æ‹Ÿåˆã€‚å¦ä¸€æ–¹é¢ï¼Œä¹Ÿå¸Œæœ›æé«˜æ¨¡å‹çš„æ‹Ÿåˆåº¦ï¼ˆæå¤§ä¼¼ç„¶ï¼‰ BIC=kLn(n)âˆ’2ln(L)kä¸ºæ¨¡å‹å‚æ•°ä¸ªæ•°ï¼Œnä¸ºæ ·æœ¬æ•°é‡ï¼ŒLä¸ºä¼¼ç„¶å‡½æ•°ã€‚å¼•å…¥$Kln(n)$æƒ©ç½šé¡¹åœ¨ç»´åº¦è¿‡å¤§ä¸”æ ·æœ¬æ•°æ®ç›¸å¯¹è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥æœ‰æ•ˆé¿å…å‡ºç°ç»´åº¦ç¾éš¾ã€‚ æ—¶é—´åºåˆ—çš„åˆ†è§£åŠ æ³•æ¨¡å‹ X_t = T_t + C_t+S_t + I_t ,t = 1,2,..,næ¯ä¸ªæ—¶é—´åºåˆ—çœ‹æˆæ˜¯ä¸‰ä¸ªéƒ¨åˆ†çš„å åŠ ï¼Œåˆ†åˆ«æ˜¯è¶‹åŠ¿é¡¹ã€å¾ªç¯é¡¹ï¼Œå­£èŠ‚é¡¹ï¼Œéšæœºé¡¹ ä¹˜æ³•æ¨¡å‹ X_t = T_t*C_t*S_t*I_tè¶‹åŠ¿åˆ†æè¶‹åŠ¿æ‹Ÿåˆæ³•å°±æ˜¯æŠŠæ—¶é—´ä½œä¸ºè‡ªå˜é‡ï¼Œç›¸åº”çš„åºåˆ—è§‚å¯Ÿå€¼ä½œä¸ºå› å˜é‡ï¼Œå»ºç«‹åºåˆ—å€¼éšæ—¶é—´å˜åŒ–çš„å›å½’æ¨¡å‹ã€‚å¯åˆ†ä¸ºçº¿æ€§æ‹Ÿåˆå’Œæ›²çº¿æ‹Ÿåˆã€‚ çº¿æ€§æ‹Ÿåˆå¦‚æœé•¿æœŸè¶‹åŠ¿å‘ˆç°å‡ºçº¿æ€§ç‰¹å¾ï¼Œå¯ç”¨çº¿æ€§æ¨¡å‹æ‹Ÿåˆï¼Œ \left\{\begin{array}{c} x_t = a+bt+I_t\\ E(I_t) = 0,Var(I_t) = \sigma^2 \end{array} \right.å…¶ä¸­ï¼Œ$T_t = a+bt$å°±æ˜¯æ¶ˆé™¤éšæœºæ³¢åŠ¨å½±å“åçš„è¯¥åºåˆ—çš„é•¿æœŸè¶‹åŠ¿ã€‚ æ›²çº¿æ‹Ÿåˆå¦‚æœé•¿æœŸè¶‹åŠ¿å‘ˆç°å‡ºçº¿æ€§ç‰¹å¾ï¼Œå¯ç”¨æ›²çº¿æ¨¡å‹æ¥æ‹Ÿåˆ \left\{ \begin{array}{c|c|c} äºŒæ¬¡å‹& T_t = a+bt+ct^2& å˜æ¢åï¼Œçº¿æ€§æœ€å°äºŒä¹˜æ³•\\ æŒ‡æ•°å‹&T_t = ab^t& å¯¹æ•°å˜åŒ– & æœ€å°äºŒä¹˜æ³•\\ ä¿®æ­£æŒ‡æ•°å‹&T_t = a+bc^t& &è¿­ä»£æ³•\\ Gompertzå‹& T_t = e^{a+bc^t}& & è¿­ä»£æ³•\\ Logistic & T_t = \frac{1}{a+bc^t}& è¿­ä»£æ³• \end{array} \right.å¹³æ»‘æ³•ç§»åŠ¨å¹³å‡æ³•å‡è®¾åœ¨æ¯”è¾ƒçŸ­çš„æ—¶é—´é—´éš”é‡Œï¼Œåºåˆ—çš„å–å€¼æ˜¯è¾ƒç¨³å®šçš„ï¼Œè¿™ç§å·®å¼‚æ˜¯ç”±éšæœºæ³¢åŠ¨é€ æˆçš„ã€‚ç”±æ­¤ï¼Œå¯ç”¨ä¸€å®šæ—¶é—´é—´éš”å†…çš„å¹³å‡å€¼ä½œä¸ºæŸä¸€æœŸçš„ä¼°è®¡å€¼ã€‚ næœŸä¸­å¿ƒç§»åŠ¨å¹³å‡ \widetilde{x_t} = \frac{1}{n}(\frac{1}{2}x_{t-\frac{n}{2}}+x_{t-\frac{n}{2}+1}+\dots+x_{t+\frac{n}{2}-1}+\frac{1}{2}x_{t+\frac{n}{2}})næœŸç§»åŠ¨å¹³å‡ \widetilde{x_t} = \frac{1}{n}(x_t+x_{t-1}+\dots+x_{t-n+1})æŒ‡æ•°å¹³æ»‘æ³•ç®€å•æŒ‡æ•°å¹³æ»‘ \widetilde{x_t} = \alpha x_t+\alpha (1-\alpha )x_{t-1}+\dots)å­£èŠ‚æ•ˆåº”å­£èŠ‚æ€§æ•ˆåº”çš„å­˜åœ¨ï¼Œä½¿å¾—æ°”æ¸©ä¼šåœ¨ä¸åŒå¹´ä»½çš„ç›¸åŒæœˆä»½å‘ˆç°å‡ºç›¸ä¼¼çš„æ€§è´¨ã€‚ å¦‚æœåªæ˜¯å­˜åœ¨å­£èŠ‚æ€§å’Œéšæœºæ³¢åŠ¨æ€§ x_{ij} = \hat{x}S_j+I_{ij}å…¶ä¸­$S_j$è¡¨ç¤ºç¬¬jä¸ªæœˆçš„å­£èŠ‚æŒ‡æ•°ï¼Œ$\hat{x}$ä¸ºå„æœˆå¹³å‡æ°”æ¸©ã€‚ å­£èŠ‚æŒ‡æ•°çš„è®¡ç®—: Step1: è®¡ç®—å‘¨æœŸå†…å„æœŸçš„å¹³å‡æ•° \hat{x}_k = \frac{\sum_{i= 1}^{n}x_{ik}}{n}ï¼ˆk = 1,2,...,m)å…¶ä¸­ï¼Œmè¡¨ç¤ºå‘¨æœŸï¼Œnè¡¨ç¤ºå‘¨æœŸçš„æ•°é‡ Step2: è®¡ç®—æ€»å¹³å‡æ•° \hat{x} = \frac{\sum_{i = 1}^{n}\sum_{k = 1}^{m}x_{ik}}{nm}Step3: è®¡ç®—å­£èŠ‚æŒ‡æ•° S_k = \frac{\hat{x}_k}{\hat{x}}æ··åˆæ•ˆåº”åŠ æ³•æ¨¡å‹ x_t = T_t + S_t + I_tä¹˜æ³•æ¨¡å‹ x_t = T_t*S_t*I_tæ··åˆæ¨¡å‹ x_t = S_t*T_t+I_t\\ x_t = S_t*(T_t+I_t)å¦‚æœå­£èŠ‚æ³¢åŠ¨çš„æŒ¯å¹…ä¸å—è¶‹åŠ¿å˜åŠ¨çš„å½±å“ï¼Œåˆ™è¯´æ˜å­£èŠ‚æ€§ä¸è¶‹åŠ¿ä¹‹é—´æ²¡æœ‰ç›¸äº’ä½œç”¨å…³ç³»ï¼Œå¯åŠ ã€‚å¦‚æœå­£èŠ‚æ³¢åŠ¨çš„æŒ¯å¹…éšè¶‹åŠ¿çš„å˜åŒ–è€Œå˜åŒ–ï¼Œæ˜¯ç›¸äº’ä½œç”¨çš„å…³ç³»ï¼Œå¯å°è¯•æ··åˆæ¨¡å‹å’Œä¹˜æ³•æ¨¡å‹ã€‚ Tool in Python: xfreshç‰¹å¾æå–å®˜ç½‘ï¼š https://tsfresh.readthedocs.io/en/latest/text/quick_start.html ä¸­æ–‡ï¼š https://github.com/SimaShanhe/tsfresh-feature-translation Data Formatscolumn_id: Features will be extracted individually for each entity(id); one row per id. column_sort: sorting the time series. ç‰¹å¾æå–: å¯ä»¥ä¸€æ¬¡æ€§æå–å®Œï¼›ä¹Ÿå¯ä»¥å•ç‹¬æå–kind_to_parameters è®¾ç½®å‚æ•°ï¼›è¿˜å¯ä»¥æå– å¯åˆ†å¸ƒå¼è®¡ç®— the rolling mechanism é¦–å…ˆç¡®å®šæ»‘åŠ¨çª—å£ Step1 : å®ç°å•å˜é‡ç‰¹å¾çš„æå– Step2 : å®ç°å¤šå˜é‡ç‰¹å¾çš„æå– Day Ox 01çŸ¥è¯†æ¸…å•: ç‰¹å¾æå–ï¼šå¤§æ¦‚ä¸Šåƒç§ç‰¹å¾ï¼ˆå‡ åç§æ–¹æ³•ï¼‰ tsfresh.feature_extraction.extraction.extract_features(timeseries_container,default_fc_parameters=None, kind_to_fc_parameters=None**, column_id=None, column_sort=None, column_kind=None, column_value=None, chunksize=None, n_jobs=1, show_warnings=False, disable_progressbar=False, impute_function=None, profile=False, profiling_filename=â€™profile.txtâ€™, profiling_sorting=â€™cumulativeâ€™, distributor=None)** pandas.DataFrame containing the different time series column_id (str) â€“ The name of the id column to group by. column_sort (str) â€“ The name of the sort column. n_jobs (int) â€“ The number of processes to use for parallelization. æ—¶é—´åºåˆ—çš„æ»‘åŠ¨çª—å£ï¼ˆå•åºåˆ—åˆ’åˆ†æˆå¤šåºåˆ—ï¼‰ tsfresh.utilities.dataframe_functions.``roll_time_series(*df_or_dict*, column_id**, column_sort=None, column_kind=None, rolling_direction=1, max_timeshift=None, min_timeshift=0, chunksize=None, n_jobs=1, show_warnings=False, disable_progressbar=False, distributor=None)** max_timeshift (int) â€“ If not None, the cut-out window is at maximum max_timeshift large. If none, it grows infinitely. min_timeshift (int) â€“ Throw away all extracted forecast windows smaller or equal than this. Must be larger than or equal 0. n_jobs (int) â€“ The number of processes to use for parallelization. If zero, no parallelization is used. show_warnings=False ï¼ˆæŒ‡å®šï¼‰ç‰¹å¾æå– æ˜¾è‘—æ€§æ£€æµ‹ https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_selection.html?highlight=select_features#tsfresh.feature_selection.selection.select_features ç›¸å…³æ€§æ£€æµ‹ https://tsfresh.readthedocs.io/en/latest/text/parallelization.html#parallelization-of-feature-selection 123456789101112131415161718192021222324252627282930313233from tsfresh import extract_features, select_features,extract_relevant_featuresfrom tsfresh.utilities.dataframe_functions import imputefrom tsfresh.utilities.dataframe_functions import roll_time_series, make_forecasting_frameimport pandas as pdimport tsfresh as tsf fc_parameters_value1 = &#123;"length": None, "sum_values": None&#125;fc_parameters_value2 = &#123;"maximum": None, "minimum": None&#125;kind_to_fc_parameters = &#123; "value1": fc_parameters_value1, "value2": fc_parameters_value2&#125;if __name__ == '__main__': # ceate data rawdata = &#123;'id1': [0,0,0,0,0,1,1,1,1,1],'time': [1,2,3,4,5,10,11,12,13,14],\ 'value1': [1,2,3,4,5,6,7,8,9,10], 'value2': [1,2,3,4,5,6,7,8,9,10] &#125; df = pd.DataFrame(rawdata)# è®¾ç½®é•¿åº¦+1 = çœŸå®é•¿åº¦,æ˜¯å½“å‰ç¼–å·å¾€ä¸Šæ•°. df_rolled = roll_time_series(df, column_id="id1", column_sort="time", max_timeshift=1, min_timeshift=0)# roll_time_seriesçš„è¿”å›å€¼ print(df_rolled) df_rolled = df_rolled.drop('id1',axis = 1)# column_id: èšåˆåˆ— column_sort:æ’åºï¼Œä¸€ä¸ªcolumn_idå°±å¯¹åº”ä¸€ä¸ªç‰¹å¾ extracted_features = extract_features(df_rolled, column_id='id', column_sort='time', kind_to_fc_parameters = kind_to_fc_parameters, show_warnings=False) print(extracted_features) Day Ox 02 æŸ¥çœ‹æå–ç‰¹å¾å¯æ ¹æ®æ­¤æå–è‡ªåŠ¨æå–çš„ç‰¹å¾ï¼Œç”¨äºé¢„æµ‹æ—¶å€™çš„æå–ç‰¹å¾ 1kind_to_fc_parameters = tsf.feature_extraction.settings.from_columns(extracted_features) 1234# 5. ç‰¹å¾æŠ½å–ä¸è¿‡æ»¤åŒæ—¶è¿›è¡Œï¼ˆä¸€æ­¥åˆ°ä½ï¼Œçœå»å¤šä½™è®¡ç®—ï¼‰# column_id: group by #features_filtered_direct = extract_relevant_features(timeseries, y, column_id='id', column_sort='time')#print(features_filtered_direct.head()) å­¦ä¹ è·¯å¾„ï¼š 1. æ•°æ®æ ¼å¼ 2. æ»‘åŠ¨çª—å£è®¾ç½® 3. ç‰¹å¾æå– 4. ç‰¹å¾é€‰æ‹© ä¸“é¢˜ æ—¶é—´åºåˆ—çš„ç«èµ›æ–¹æ¡ˆhttps://mp.weixin.qq.com/s?__biz=MzU1Nzc1NjI0Nw==&amp;mid=2247485604&amp;idx=1&amp;sn=6283ec080344665bfad90570bf1504a4&amp;chksm=fc31b29ccb463b8acac7acf4d89494aaad0c76620becb2b07c370ccbfaff850edc3c1ad4e0fd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1593390448780&amp;sharer_shareid=fb5716a8ad12ea6329433df53d4cbf64#rd https://www.zhihu.com/question/21229371/answer/533770345 Prophet å·¥å…·]]></content>
  </entry>
  <entry>
    <title><![CDATA[å›å½’åˆ†æ]]></title>
    <url>%2F2020%2F06%2F20%2F%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[[TOC] å›å½’åˆ†ææœ€ç®€å•çš„çº¿æ€§å›å½’ï¼Œé¿å…å¤šé‡å…±çº¿æ€§ï¼Œè¿‡æ‹Ÿåˆï¼Œå¼•å…¥æ­£åˆ™é¡¹çš„çº¿æ€§å›å½’æ¨¡å‹ã€‚æ¶‰åŠåˆ°çš„æ•°å­¦çŸ¥è¯†ï¼šä¸€èŒƒæ•°ï¼ŒäºŒèŒƒæ•°ï¼Œå¤šå…ƒå‡½æ•°æ±‚æå€¼ã€‚æ¨¡å‹çš„å«ä¹‰ï¼Œå‚æ•°æ±‚è§£ç®—æ³•ï¼Œç›®æ ‡å‡½æ•°ï¼Œä»¥åŠå„ç§æ¨¡å‹çš„ä¼˜ç¼ºç‚¹ã€‚ å®šä¹‰å›å½’åˆ†ææ˜¯å¯»æ‰¾è‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´çš„æ•°é‡å…³ç³»ï¼Œç”¨äºé¢„æµ‹å»ºæ¨¡çš„æ–¹æ³•ã€‚å…¶ä¸€ï¼Œå®ƒå¯ä»¥æ­ç¤ºè‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´çš„æ˜¾è‘—æ€§æ£€æµ‹ã€‚å…¶äºŒï¼Œæ­ç¤ºå¤šä¸ªè‡ªå˜é‡å¯¹ä¸€ä¸ªå› å˜é‡çš„å½±å“ç¨‹åº¦å¤§å°ã€‚ å›å½’ç±»å‹1ï¼‰ç‹¬ç«‹å˜é‡çš„æ•°é‡ 2ï¼‰åº¦é‡å˜é‡çš„ç±»å‹ 3ï¼‰å›å½’çº¿çš„å½¢çŠ¶ 1. çº¿æ€§å›å½’ï¼ˆLinear Regression)å› å˜é‡ï¼šè¿ç»­ï¼› è‡ªå˜é‡ï¼šè¿ç»­æˆ–è€…ç¦»æ•£ æ¨¡å‹çš„å½¢å¼ Y = a+bX+ğœ€\\ \left(\begin{array}{c} y_{1} \\ y_{2} \\ \vdots \\ y_{n} \end{array}\right)=\left(\begin{array}{cccc} 1 & x_{11} & \cdots & x_{1(p-1)} \\ 1 & x_{21} & \cdots & x_{2(p-1)} \\ \vdots & \vdots & \vdots & \vdots \\ 1 & x_{n 1} & \cdots & x_{n(p-1)} \end{array}\right) \beta+\left(\begin{array}{c} e_{1} \\ e_{2} \\ \vdots \\ e_{n} \end{array}\right)\\ Y_{n*1} = X_{n*p}\beta+ğœ€where $a$ and $b$ are the regression coefficients, and ğœ€ is the random error. ç›®æ ‡å‡½æ•° min SSR = \sum_{i}(y_i-f(x_i))^2\\ min_{w}||Xw-y||_2^2å‚æ•°ä¼°è®¡æœ€å°äºŒä¹˜æ³•ï¼ˆLease Square Method)ï¼ˆOLS) This approach is called the method of ordinary least squares. æ¨¡å‹è¯„ä¼°æ‹Ÿåˆä¼˜åº¦ R-square , coefficient of determinationLarger $R^2$ indicates a better fit and means that the model can better explain the variation of the output with different inputs. https://realpython.com/linear-regression-in-python/ è¦æ±‚ è‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´å¿…é¡»æ»¡è¶³çº¿æ€§å…³ç³»ã€‚ å¤šå…ƒå›å½’å­˜åœ¨å¤šé‡å…±çº¿æ€§ï¼Œè‡ªç›¸å…³æ€§å’Œå¼‚æ–¹å·®æ€§ã€‚ çº¿æ€§å›å½’å¯¹å¼‚å¸¸å€¼éå¸¸æ•æ„Ÿã€‚å¼‚å¸¸å€¼ä¼šä¸¥é‡å½±å“å›å½’çº¿å’Œæœ€ç»ˆçš„é¢„æµ‹å€¼ã€‚ å¤šé‡å…±çº¿æ€§ä¼šå¢åŠ ç³»æ•°ä¼°è®¡çš„æ–¹å·®ï¼Œå¹¶ä¸”ä½¿å¾—ä¼°è®¡å¯¹æ¨¡å‹ä¸­çš„å¾®å°å˜åŒ–éå¸¸æ•æ„Ÿã€‚ç»“æœæ˜¯ç³»æ•°ä¼°è®¡ä¸ç¨³å®šã€‚ åœ¨å¤šä¸ªè‡ªå˜é‡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨æ­£å‘é€‰æ‹©ã€å‘åæ¶ˆé™¤å’Œé€æ­¥é€‰æ‹©çš„æ–¹æ³•æ¥é€‰æ‹©æœ€é‡è¦çš„è‡ªå˜é‡ã€‚ é€»è¾‘å›å½’ï¼ˆLogistic Regression)Logistic å›å½’çš„æœ¬è´¨æ˜¯ï¼šå‡è®¾æ•°æ®æœä»è¿™ä¸ªåˆ†å¸ƒï¼Œç„¶åä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡åšå‚æ•°çš„ä¼°è®¡ã€‚ Logistic åˆ†å¸ƒ F(x) = P(X]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>å›å½’åˆ†æ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[çŸ¥è¯†æ¸…å•]]></title>
    <url>%2F2020%2F06%2F19%2F%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[ä¸»è¦æ˜¯åˆ—å‡ºå…³äºæ—¥å¸¸ä¸­é‡åˆ°çš„å¾ˆå¥½çš„èµ„æ–™ï¼Œè‡ªå·±ä¸æ¸…æ¥šçš„æ–‡ç« å’Œèµ„æ–™ã€‚ 2020-8-24 5W2H5W2Håˆ†åˆ«å¯¹åº”ç€7ä¸ªå…³é”®é—®å·ï¼š Whatï¼šä½•äº‹ï¼Ÿ Whoï¼šä½•äººï¼Ÿ Whenï¼šä½•æ—¶ï¼Ÿ Whereï¼šä½•åœ°ï¼Ÿ Whyï¼šä½•å› ï¼Ÿ Howï¼šæ€ä¹ˆåšï¼Ÿ How muchï¼šå¤šå°‘é’±ï¼Ÿ 5W2Hæ¢³ç†é”€å”®ä¸‹é™é—®é¢˜ æ–‡ç« æœ€å¼€å¤´ï¼Œå°Pè€æ¿æäº†ä¸€ä¸ªæå…¶æ¨¡ç³Šçš„é—®é¢˜ï¼š â€œæœ€è¿‘é”€å”®é¢ä¸ºä»€ä¹ˆä¸‹é™äº†ï¼Ÿâ€ å¦‚æœç”¨5W2Hæ³•ï¼Œåº”è¯¥æ€ä¹ˆç†æ¸…å¤´ç»ªå‘¢ï¼Ÿ å¾ˆç®€å•ï¼Œè·Ÿç€é—®å°±å®Œäº‹å„¿äº†ï¼ Whatï¼ˆä½•äº‹-é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼‰ é—®é¢˜æ˜¯è€æ¿æŠ›å‡ºçš„é”€å”®é¢ä¸‹é™åŸå› åˆ†æï¼Œä½†è¿™ä¸ªéœ€æ±‚å¤ªè¿‡ç¬¼ç»Ÿï¼Œæˆ‘ä»¬éœ€è¦è¿›ä¸€æ­¥è¯¢é—®æ¥ç•Œå®šå’Œè§£æ„é—®é¢˜ã€‚ Whenï¼ˆä»€ä¹ˆæ—¶å€™ï¼Ÿï¼‰ æ˜¯ä»€ä¹ˆæ—¶é—´æ®µé”€å”®å¼€å§‹ä¸‹æ»‘ï¼Ÿä¸‹æ»‘æ˜¯ç¯æ¯”è¿˜æ˜¯åŒæ¯”ï¼Œäº¦æˆ–æ˜¯å’Œå¹³å‡ç›¸æ¯”ï¼Ÿä»è¶‹åŠ¿ä¸Šçœ‹ï¼Œæ˜¯æŒç»­æ€§ä¸‹æ»‘ï¼Œè¿˜æ˜¯æŸäº›æ—¶é—´èŠ‚ç‚¹çš„çªç„¶ä¸‹è·Œï¼Ÿ Whereï¼ˆä»€ä¹ˆåœ°æ–¹ï¼Ÿï¼‰ æ˜¯æ‰€æœ‰æ¸ é“çš„æ™®éä¸‹è·Œè¿˜æ˜¯æŸä¸ªé‡ç‚¹æ¸ é“çš„æŠ˜æˆŸï¼Ÿæ˜¯å…¨å›½å„åœ°æ™®éé”€å”®ä¸‹é™ï¼Œè¿˜æ˜¯æŸä¸ªåœ°åŒºé”€å”®ä¸‹é™çš„å‰å®³ï¼Ÿ Whoï¼ˆæ˜¯å“ªç¾¤äººï¼Ÿï¼‰ æ˜¯æ–°å®¢æˆ·è¿˜æ˜¯è€å®¢æˆ·çš„é”€å”®è´¡çŒ®ä¹åŠ›ï¼Ÿæ˜¯æ™®é€šå®¢æˆ·çš„å‡å°‘ï¼Œè¿˜æ˜¯å“ç‰Œå¿ è¯šå®¢æˆ·çš„æµå¤±ï¼Ÿ Whyï¼ˆä¸ºä»€ä¹ˆï¼Ÿï¼‰ å›ç­”å®Œä¸Šé¢4ä¸ªWï¼Œç»¼åˆèµ·æ¥åŸºæœ¬èƒ½å¤Ÿå›ç­”ä¸ºä»€ä¹ˆé”€å”®ä¸‹è·Œè¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯è¿™æ ·è¿˜ä¸å¤Ÿï¼Œæ•°æ®åˆ†ææ›´é‡è¦çš„æ˜¯æŒ‡å¯¼è¯¥æ€ä¹ˆåš Howï¼ˆæ€ä¹ˆåšï¼Ÿï¼‰ å¦‚æœæ˜¯æŸä¸ªæ¸ é“è€å®¢æµå¤±ä¸¥é‡ï¼Œåº”è¯¥å¿«é€Ÿåšå®¢æˆ·åŸå› å®šä½ï¼Œä»¥åŠç”¨CRMå…³æ€€æ¥æŒ½å›å®¢æˆ·ã€‚ å¦‚æœæ˜¯å„æ¸ é“ã€å…¨å›½æ€§æ™®éé”€å”®ä¸‹è·Œï¼Œå¸‚åœºä»½é¢è¢«å¯¹æ‰‹ä¾µèš€ï¼Œé‚£åº”è¯¥ç´§å¯†è§‚å¯Ÿå¸‚åœºï¼Œç´§ç›¯ç«å“åŠ¨ä½œã€‚ How muchï¼ˆé‡åŒ–åšå¤šå°‘ï¼Ÿï¼‰ ç»“åˆä¸Šä¸€æ­¥çš„è¡ŒåŠ¨ï¼Œå…·ä½“è¡¡é‡é€šè¿‡çŸ­ä¿¡æˆ–è€…å…¶ä»–æ–¹å¼è§¦è¾¾èŠ±è´¹å¤šå°‘ï¼Œéœ€è¦æŠ•å…¥å¤šå°‘æŠ˜æ‰£ï¼Œé¢„è®¡å”¤å›å¤šå°‘å®¢æˆ·ï¼Œæå‡å¤šå°‘é”€å”®é¢ï¼Œè¿™äº›éƒ½å¯ä»¥åŸºäºå†å²æ•°æ®é‡åŒ–ã€‚ æ€ä¹ˆæ ·ï¼Ÿ å¯¹äºä¸€ä¸ªæ¨¡ç³Šçš„é”€å”®ä¸‹è·Œé—®é¢˜ï¼Œé€šè¿‡è¿™7æ­¥çš„æ‹†è§£ï¼Œå¾ˆå¿«å°±æ‰“å¼€äº†åˆ†ææ€è·¯ã€‚ä¸è¿‡ï¼Œè¦å®Œå…¨ç²¾å‡†çš„å®šä½é—®é¢˜ï¼Œæ‰¾åˆ°æœ¬è´¨è§£å†³åŠæ³•ï¼Œè¿˜éœ€è¦è¿›ä¸€æ­¥çš„å®šä½ã€å‡è®¾å’ŒéªŒè¯ã€‚ 2020-6-29 Zæ£€æµ‹å’ŒTæ£€æµ‹https://mp.weixin.qq.com/s?__biz=MzI4MjkzNTUxMw==&amp;mid=2247485455&amp;idx=1&amp;sn=857066158bf8c2de38939f3037416035&amp;chksm=eb9321b9dce4a8afd68d764c295f8bcc69c62f2b1d000f3e1c5e61a7d9b6e2ec3de8df068174&amp;mpshare=1&amp;scene=24&amp;srcid=&amp;sharer_sharetime=1593403964973&amp;sharer_shareid=0e2d0ffe45c3a6dfb66aa422c3a1381d#rd 2020-6-28è§†é¢‘ï¼š http://www.julyedu.com/video/play/58/405 2020-6-19SQL ä¸­æ–‡: https://www.liaoxuefeng.com/wiki/1177760294764384 è‹±æ–‡ï¼š https://www.codecademy.com/courses/learn-sql/lessons/manipulation/exercises/sql è§†é¢‘ï¼š https://www.jikexueyuan.com/course/sql/ åŸºç¡€ https://study.163.com/course/courseMain.htm?courseId=215012&amp;_trace_c_p_k2_=f68f3d2867a343789ac2d3cfa92dd308 https://www.nowcoder.com/discuss/95812?type=2 https://www.cnblogs.com/zsh-blogs/category/1413021.html]]></content>
      <categories>
        <category>è§„åˆ’</category>
      </categories>
      <tags>
        <tag>æŠ€èƒ½</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data-Science]]></title>
    <url>%2F2020%2F06%2F11%2FData-Science%2F</url>
    <content type="text"><![CDATA[CourseTsinghua Dr. Yuan Data Mining: Theories and Algorithms for Tackling Big Data ToolsStata: https://www.stata.com/why-use-stata/ https://www.youtube.com/watch?v=AyXeh7iojuA BOOOOOOKhttps://www-users.cs.umn.edu/~kumar001/dmbook/index.php]]></content>
      <categories>
        <category>æ•°æ®ç§‘å­¦(Data Science)</category>
      </categories>
      <tags>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ¯å¤©äº†è§£å¤šä¸€ç‚¹]]></title>
    <url>%2F2020%2F06%2F11%2F%E6%AF%8F%E5%A4%A9%E4%BA%86%E8%A7%A3%E5%A4%9A%E4%B8%80%E7%82%B9%2F</url>
    <content type="text"><![CDATA[ç§‘æ™® 2020-728æˆ‘å°†èå…¥å‰§çƒˆäº‰æ–—çš„å¤§äººä¸–ç•Œï¼Œè¦åœ¨é‚£è¾¹å­¤å†›å¥‹æˆ˜ï¼Œå¿…é¡»å˜å¾—æ¯”ä»»ä½•äººéƒ½åšä¸å¯æ‘§ã€‚â€”â€”ã€Šæµ·è¾¹çš„å¡å¤«å¡ã€‹ ä½ è¿˜è¦ä»€ä¹ˆé—®é¢˜å—ï¼Ÿä¸€æ–¹é¢æƒ³çœ‹çœ‹ä½ å¯¹è¿™ä»½å·¥ä½œçš„æ€åº¦å’Œé‡è§†ç¨‹åº¦ï¼Œå³ä½ é¢è¯•æ˜¯å¦å¸¦æœ‰ç›®çš„æ€§åœ°æƒ³è¦äº†è§£å…¬å¸çš„æƒ…å†µï¼Œè¿˜æ˜¯åªæ˜¯å•çº¯çš„æ‰¾ä¸€ä»½å·¥ä½œï¼› å¦ä¸€æ–¹é¢ï¼Œä¹Ÿæƒ³è¦è¿›ä¸€æ­¥è€ƒå¯Ÿä½ çš„æ€§æ ¼ï¼Œååº”èƒ½åŠ›ç­‰ï¼Œæ¯”å¦‚ï¼Œä½ ä¼šé—®å“ªæ–¹é¢çš„é—®é¢˜ï¼Œæ˜¯å¦åœé¡¿ä¸çŸ¥é“é—®ä»€ä¹ˆï¼Œæ˜¯å¦åº”ä»˜å¼çš„å›ç­”è€Œä¸æ˜¯æ ¹æ®å‰é¢è°ˆåŠåˆ°çš„å†…å®¹æ¥æé—®ç­‰ç­‰ã€‚ 1.å²—ä½ç›¸å…³æ–¹é¢ ç›®å‰è¯¥å²—ä½å…¬å¸æœ‰å¤šå°‘äººï¼Ÿè¿™ä¸ªå²—ä½æ‰€åœ¨çš„å›¢é˜Ÿè§„æ¨¡æ˜¯å¤šå°‘ï¼Ÿè¿™ä¸ªå²—ä½æ–°å¼€è®¾çš„å—ï¼Ÿè¿˜æ˜¯åŸå²—ä½ä¸Šçš„äººç¦»èŒäº†ï¼Ÿè¿™ä¸ªå²—ä½çš„å·¥ä½œå°†ä¸å“ªäº›éƒ¨é—¨å·¥ä½œã€å“ªäº›å…³é”®äººç‰©äº’åŠ¨æ¯”è¾ƒå¤šï¼Ÿè¿™ä¸ªå²—ä½ï¼Œæ‚¨è§‰å¾—æœ€é‡è¦çš„å·¥ä½œå†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ 2.åˆ©ç›Šç›¸å…³æ–¹é¢ æ‚¨å¸Œæœ›è¿™ä¸ªå²—ä½äº§ç”Ÿä»€ä¹ˆæ ·çš„ä»·å€¼ï¼Œèµ·åˆ°ä»€ä¹ˆä½œç”¨ï¼Ÿè¿™ä¸ªå²—ä½çš„KPIæ˜¯ä»€ä¹ˆï¼Ÿå¦‚æœæš‚æ—¶æ²¡æœ‰KPIï¼Œé‚£èƒœä»»è¿™ä»½å·¥ä½œï¼Œæœ€å…³é”®åˆ¤æ–­åŸå› æœ‰å“ªäº›ï¼Ÿæ‚¨è®¤ä¸ºè¿™ä¸ªå²—ä½åœ¨å…¬å¸å†…éƒ¨çš„å‘å±•å¦‚ä½•ï¼Ÿ 3.ä¸Šå¸ä¸è€æ¿ç›¸å…³æ–¹é¢ å¦‚æœæœ‰å¹¸åŠ å…¥åˆ°å…¬å¸ï¼Œæˆ‘æœ€å…ˆå¼€å±•çš„å·¥ä½œæ˜¯ä»€ä¹ˆï¼Ÿæ‚¨å¯¹è¿™ä¸ªå²—ä½éƒ½æœ‰ç€å…·ä½“ä»€ä¹ˆæ ·çš„æœŸæœ›ï¼Ÿæ‚¨è®¤ä¸ºå›¢é˜Ÿã€å…¬å¸ç°åœ¨é¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨åœ¨å…¬å¸çš„ä¸€å¤©æ˜¯å¦‚ä½•åº¦è¿‡çš„ï¼Ÿæ‚¨æ¯”è¾ƒå–œæ¬¢å…·æœ‰ä»€ä¹ˆç‰¹è´¨çš„ä¸‹å±ï¼Ÿæ‚¨å¯¹è¿™ä¸ªè¡Œä¸šæœªæ¥å‘å±•æœ‰ä»€ä¹ˆçœ‹æ³•å‘¢ï¼Ÿè´µå…¬å¸æœ€è®©æ‚¨è‡ªè±ªçš„ä¼ä¸šæ–‡åŒ–æ˜¯ä»€ä¹ˆï¼Ÿ é€šè¿‡è¿™äº›é—®é¢˜å’Œå¯¹æ–¹çš„å›ç­”ï¼Œä¹Ÿå¯ä»¥çœ‹å‡ºé¢è¯•å®˜çš„æ€§æ ¼ä»¥åŠåšäº‹æ€åº¦ï¼Œç‰¹åˆ«å¦‚æœå¯¹æ–¹æ˜¯ç”¨äººéƒ¨é—¨ï¼Œå¾ˆæœ‰å¯èƒ½å°±æ˜¯ä½ å…¥èŒåçš„ç›´å±ä¸Šå¸ï¼Œé€šè¿‡äº¤æµçš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥è®©è‡ªå·±ä½“ä¼šä¸€ä¸‹ï¼Œæ˜¯å¦å–œæ¬¢å’Œå¯¹æ–¹ä¸€èµ·å…±äº‹ã€‚ ç®¡ç†è®©äººä¿¡æœé¦–å…ˆï¼Œä½ å¿…é¡»æ˜ç™½ä¸€ç‚¹ï¼š å¸¦å›¢é˜Ÿï¼Œé™¤äº†è®©ä¸‹å±æ„Ÿè§‰åˆ°â€œä»·å€¼æ„Ÿâ€ä¹‹å¤–ï¼Œè¿˜è¦è®©ä»–æ„è¯†åˆ°â€œå·®è·æ„Ÿâ€ï¼Œè¿™æ ·æ‰èƒ½è®©ä»–ä¿æŒæŒç»­çš„è¿›æ­¥ã€‚ æ€ä¹ˆä½“ç°å·®è·æ„Ÿå‘¢ï¼Ÿä»ä¸¤ä¸ªç»´åº¦ï¼š 1ã€çºµå‘å’Œä½ æ¯” ä½œä¸ºä¸‹å±çš„é¢†å¯¼ï¼Œä½ çš„èƒ½åŠ›è®©ä»–ä¿¡æœå—ï¼Ÿä½ æ˜¯ä»–æƒ³è¦æˆä¸ºç›®æ ‡å—ï¼Ÿ ä½ è¦æŠŠè‡ªå·±çš„èƒ½åŠ›å±•ç°å‡ºæ¥ã€‚ æ¯”å¦‚åŒæ ·æ˜¯å†™ä¸€ç¯‡æ–‡ç« ï¼Œä»–èŠ±äº†ä¸€å¤©æ‰å†™ä¸€ç‰ˆï¼Œäº¤ç»™ä½ ä¿®æ”¹ï¼Œä½ åªèŠ±äº†åŠä¸ªå°æ—¶è®©æ–‡ç« è„±èƒæ¢éª¨ã€‚ ä»–å°±ä¼šä½©æœä½ ï¼šé¢†å¯¼çœŸå‰å®³ï¼Œä»–æ˜¯æ€ä¹ˆæƒ³çš„ï¼Ÿæˆ‘èƒ½ä¸èƒ½åšåˆ°ï¼Ÿ 2ã€æ¨ªå‘è·ŸåŒçº§æ¯” è¥é€ å‡ºä¸€ç§ç›¸äº’æ¯”è¾ƒçš„æ°›å›´ï¼Œè®©ä¸‹å±çŸ¥é“ï¼Œå’Œå…¶ä»–å›¢é˜Ÿæˆå‘˜æ¯”ï¼Œè‡ªå·±å¤„äºä¸€ä¸ªæ€æ ·çš„ä½ç½®ï¼Ÿå’Œåˆ«äººçš„æœ‰å¤šå¤§çš„å·®è·ï¼Ÿ è¯´å®Œâ€œä»·å€¼æ„Ÿâ€å’Œâ€œå·®è·æ„Ÿâ€è¿™ä¸¤ä¸ªå¸¦å›¢é˜ŸåŸåˆ™ï¼Œä¸‹é¢å†ä»¥æˆ‘10æ¥å¹´çš„ç®¡ç†ç»éªŒå‡ºå‘ï¼Œè¯´è¯´æ€ä¹ˆæŠŠå®ƒä»¬èå…¥æŒ‡å¯¼å›¢é˜Ÿçš„åšäº‹æ–¹æ³•ä¸­ å¸¦å›¢é˜Ÿæœ€æ ¸å¿ƒæ˜¯ä¸¤ä¸ªåŸåˆ™ï¼š 1ã€\ä»·å€¼æ„Ÿï¼šè®©ä¸‹å±åœ¨å·¥ä½œä¸­çœŸæ­£æœ‰æ”¶è·ã€‚ 2ã€\å·®è·æ„Ÿï¼šé€šè¿‡æ¯”è¾ƒè®©ä¸‹å±æ„è¯†åˆ°å·®è·ä»¥æŒç»­è¿›æ­¥ã€‚ äº”ä¸ªåšäº‹æ­¥éª¤ï¼š 1ã€\å®šç›®æ ‡ï¼šç»™ä¸‹å±å®šä¸€ä¸ªæ¸…æ™°ã€ä¸”æœ‰æŒ‘æˆ˜çš„ç›®æ ‡ï¼Œè¿™ä¸ªç›®æ ‡å¾—å’Œä»–çš„è‡ªæˆ‘ç›®æ ‡ç›¸å…³ï¼ŒåŒæ—¶ä¹Ÿå¾—å’Œä½ çš„ç›®æ ‡å¼ºç›¸å…³ã€‚ 2ã€\ç»™æ–¹æ³•ï¼šç»™ä¸‹å±å®Œæˆç›®æ ‡çš„æ–¹æ³•æŒ‡å¯¼ï¼Œæœ‰ä¹¦é¢ç‰ˆæœ€ä½³ã€‚ 3ã€\åšè®¡åˆ’ï¼šè¯•ç€è®©ä¸‹å±è‡ªå·±åšå·¥ä½œè®¡åˆ’ã€‚ 4ã€\å¤šç›‘æ§ï¼šåšå¥½æ£€æŸ¥è°ƒæ•´ï¼Œå¾—åŠæ—¶å‘ç°å¼‚å¸¸æƒ…å†µã€‚ 5ã€\å‹¤æ²‰æ·€ï¼šå®Œæˆå·¥ä½œåç£ä¿ƒä¸‹å±åšå†…å®¹èµ„äº§çš„æ²‰æ·€ æˆ‘è§‰å¾—æˆ‘ç¼ºå°‘çš„ä¸œè¥¿ï¼šä¸äººç›¸å…³çš„æ´»åŠ¨ï¼Œæˆ‘éƒ½ä¸å–œæ¬¢å‚ä¸ã€‚æˆ‘åªèƒ½åšå¥½è‡ªå·±ã€‚ ç®¡ç†ä»–äººçš„èƒ½åŠ›ã€‚ ç®¡ç†è€…å¦‚ä½•æå‡ç»„ç»‡æ•ˆèƒ½ï¼š å…¶ä¸€ï¼Œ5w2h(ä¸ºä»€ä¹ˆåšï¼Ÿè°å»åšï¼Ÿåšä»€ä¹ˆï¼Ÿå“ªé‡Œåšï¼Ÿä»€ä¹ˆæ—¶å€™åšï¼Ÿæ€ä¹ˆåšï¼Ÿåšå¤šå°‘ï¼Ÿï¼‰ã€‚ å…¶äºŒï¼Œäººå¯¹è®¡åˆ’æ‰§è¡Œçš„å½±å“ï¼ˆæ¥å—åº¦å¦‚ä½•ï¼Œåä½œåº¦å¦‚ä½•ï¼Œæ‰§è¡Œåº¦å¦‚ä½•ï¼‰ã€‚ å…¶ä¸‰ï¼Œå¯èƒ½ä¼šå‡ºç°çš„é—®é¢˜ï¼Œä»¥åŠç›¸åº”é—®é¢˜çš„å¤„ç†é¢„æ¡ˆã€‚ å…¶å››ï¼Œè®¡åˆ’è¿‡ç¨‹çš„é¢„æ¼” æ€»ç»“ç®¡ç†è€…è¦å–„äºå»å­¦ä¹ ï¼Œå»ä¸¾ä¸€åä¸‰ã€‚æ—¢å¯ä»¥é€šè¿‡å¯¹ä»–äººçš„å·¥ä½œï¼Œç®¡ç†æ–¹å¼å»è§‚å¯Ÿæ€»ç»“ï¼Œé€è¿‡ä»–äººçš„æ¡ˆä¾‹æ¥å‡å°‘ç®¡ç†æˆæœ¬ï¼Œæå‡ç®¡ç†æ•ˆèƒ½ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å¯¹è‡ªå·±çš„ç®¡ç†å·¥ä½œè¿›è¡Œâ€œæ—¥äº‹æ—¥æ¯•ï¼Œæ—¥æ¸…æ—¥ç»“â€,åšå¥½ç®¡ç†æ—¥å¿—ï¼Œåšå¥½æ€»ç»“ï¼Œä¸æ–­å­¦ä¹ ï¼Œæˆé•¿ã€‚ å›¢é˜Ÿç®¡ç†èƒ½åŠ›èšç„¦ä¸‰ä¸ªæ–¹é¢ï¼Œç›®æ ‡è®¾å®šã€æˆå‘˜åˆ†å·¥ã€èµ„æºåˆ†é…ã€‚ ä¼˜ç§€ç®¡ç†è€…éœ€è¦å…·å¤‡çš„æ°”è´¨ï¼Ÿ ç»“æœå¯¼å‘ï¼Œèšç„¦ç›®æ ‡ã€åˆ¶å®šè®¡åˆ’ï¼› ç§¯æè¿›å–ï¼Œè§£å†³é—®é¢˜ã€æ¨åŠ¨æ‰§è¡Œï¼› å­¦ä¹ æ€»ç»“ï¼Œä¸æ–­ç§¯ç´¯ã€åŠ æ·±ç†è§£ï¼› è‡ªæˆ‘è¶…è¶Šï¼Œæ‰¿è®¤é”™è¯¯ã€æ‰¿æ‹…è´£ä»»ã€‚ 20200727linuxæºç å®‰è£…æ•™ç¨‹ https://blog.csdn.net/u010509774/article/details/50593231 2020-7-252020-7-18è¯»ä¸‡å·ä¹¦ï¼Œä¸å¦‚è¡Œä¸‡é‡Œè·¯ã€‚ä¹¦ä¸­å†å¤šçš„é“ç†ï¼Œä¸å¦‚è‡ªå·±é—¯ä¸€é—¯ã€‚ 2020-7-17 excelç ´è§£pandas Nanç›¸åŠ è¿˜æ˜¯nan alt+F11, æ’å…¥-æ¨¡å— 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151 Option Explicit Public Sub AllInternalPasswords()&apos; Breaks worksheet and workbook structure passwords. Bob McCormick&apos; probably originator of base code algorithm modified for coverage&apos; of workbook structure / windows passwords and for multiple passwords&apos;&apos; Norman Harker and JE McGimpsey 27-Dec-2002 (Version 1.1)&apos; Modified 2003-Apr-04 by JEM: All msgs to constants, and&apos; eliminate one Exit Sub (Version 1.1.1)&apos; Reveals hashed passwords NOT original passwordsConst DBLSPACE As String = vbNewLine &amp; vbNewLineConst AUTHORS As String = DBLSPACE &amp; vbNewLine &amp; _&quot;Adapted from Bob McCormick base code by&quot; &amp; _&quot;Norman Harker and JE McGimpsey&quot;Const HEADER As String = &quot;AllInternalPasswords User Message&quot;Const VERSION As String = DBLSPACE &amp; &quot;Version 1.1.1 2003-Apr-04&quot;Const REPBACK As String = DBLSPACE &amp; &quot;Please report failure &quot; &amp; _&quot;to the microsoft.public.excel.programming newsgroup.&quot;Const ALLCLEAR As String = DBLSPACE &amp; &quot;The workbook should &quot; &amp; _&quot;now be free of all password protection, so make sure you:&quot; &amp; _DBLSPACE &amp; &quot;SAVE IT NOW!&quot; &amp; DBLSPACE &amp; &quot;and also&quot; &amp; _DBLSPACE &amp; &quot;BACKUP!, BACKUP!!, BACKUP!!!&quot; &amp; _DBLSPACE &amp; &quot;Also, remember that the password was &quot; &amp; _&quot;put there for a reason. Don&apos;t stuff up crucial formulas &quot; &amp; _&quot;or data.&quot; &amp; DBLSPACE &amp; &quot;Access and use of some data &quot; &amp; _&quot;may be an offense. If in doubt, don&apos;t.&quot;Const MSGNOPWORDS1 As String = &quot;There were no passwords on &quot; &amp; _&quot;sheets, or workbook structure or windows.&quot; &amp; AUTHORS &amp; VERSIONConst MSGNOPWORDS2 As String = &quot;There was no protection to &quot; &amp; _&quot;workbook structure or windows.&quot; &amp; DBLSPACE &amp; _&quot;Proceeding to unprotect sheets.&quot; &amp; AUTHORS &amp; VERSIONConst MSGTAKETIME As String = &quot;After pressing OK button this &quot; &amp; _&quot;will take some time.&quot; &amp; DBLSPACE &amp; &quot;Amount of time &quot; &amp; _&quot;depends on how many different passwords, the &quot; &amp; _&quot;passwords, and your computer&apos;s specification.&quot; &amp; DBLSPACE &amp; _&quot;Just be patient! Make me a coffee!&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND1 As String = &quot;You had a Worksheet &quot; &amp; _&quot;Structure or Windows Password set.&quot; &amp; DBLSPACE &amp; _&quot;The password found was: &quot; &amp; DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; _&quot;Note it down for potential future use in other workbooks by &quot; &amp; _&quot;the same person who set this password.&quot; &amp; DBLSPACE &amp; _&quot;Now to check and clear other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGPWORDFOUND2 As String = &quot;You had a Worksheet &quot; &amp; _&quot;password set.&quot; &amp; DBLSPACE &amp; &quot;The password found was: &quot; &amp; _DBLSPACE &amp; &quot;$$&quot; &amp; DBLSPACE &amp; &quot;Note it down for potential &quot; &amp; _&quot;future use in other workbooks by same person who &quot; &amp; _&quot;set this password.&quot; &amp; DBLSPACE &amp; &quot;Now to check and clear &quot; &amp; _&quot;other passwords.&quot; &amp; AUTHORS &amp; VERSIONConst MSGONLYONE As String = &quot;Only structure / windows &quot; &amp; _&quot;protected with the password that was just found.&quot; &amp; _ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACKDim w1 As Worksheet, w2 As WorksheetDim i As Integer, j As Integer, k As Integer, l As IntegerDim m As Integer, n As Integer, i1 As Integer, i2 As IntegerDim i3 As Integer, i4 As Integer, i5 As Integer, i6 As IntegerDim PWord1 As StringDim ShTag As Boolean, WinTag As Boolean Application.ScreenUpdating = FalseWith ActiveWorkbookWinTag = .ProtectStructure Or .ProtectWindowsEnd WithShTag = FalseFor Each w1 In WorksheetsShTag = ShTag Or w1.ProtectContentsNext w1If Not ShTag And Not WinTag ThenMsgBox MSGNOPWORDS1, vbInformation, HEADERExit SubEnd IfMsgBox MSGTAKETIME, vbInformation, HEADERIf Not WinTag ThenMsgBox MSGNOPWORDS2, vbInformation, HEADERElseOn Error Resume NextDo &apos;dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126With ActiveWorkbook.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; _Chr(i3) &amp; Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If .ProtectStructure = False And _.ProtectWindows = False ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND1, _&quot;$$&quot;, PWord1), vbInformation, HEADERExit Do &apos;Bypass all for...nextsEnd IfEnd WithNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfIf WinTag And Not ShTag ThenMsgBox MSGONLYONE, vbInformation, HEADERExit SubEnd IfOn Error Resume NextFor Each w1 In Worksheets&apos;Attempt clearance with PWord1w1.Unprotect PWord1Next w1On Error GoTo 0ShTag = FalseFor Each w1 In Worksheets&apos;Checks for all clear ShTag triggered to 1 if not.ShTag = ShTag Or w1.ProtectContentsNext w1If ShTag ThenFor Each w1 In WorksheetsWith w1If .ProtectContents ThenOn Error Resume NextDo &apos;Dummy do loopFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If Not .ProtectContents ThenPWord1 = Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; Chr(l) &amp; _Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)MsgBox Application.Substitute(MSGPWORDFOUND2, _&quot;$$&quot;, PWord1), vbInformation, HEADER&apos;leverage finding Pword by trying on other sheetsFor Each w2 In Worksheetsw2.Unprotect PWord1Next w2Exit Do &apos;Bypass all for...nextsEnd IfNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextLoop Until TrueOn Error GoTo 0End IfEnd WithNext w1End IfMsgBox ALLCLEAR &amp; AUTHORS &amp; VERSION &amp; REPBACK, vbInformation, HEADEREnd Sub 2020-6-20å½“ä½ é€šè¿‡æ•°æ®å¯è§†åŒ–æ¥è¡¨è¾¾è§‚ç‚¹ï¼Œé¦–å…ˆè‡ªå·±è¦æœ‰ä¸€ä¸ªæ¸…æ™°çš„ç»“è®ºï¼Œç„¶åæœ‰é’ˆå¯¹æ€§åœ°çªå‡ºè‡ªå·±æƒ³è¦è¡¨è¾¾çš„è¦ç‚¹ï¼Œé€šè¿‡è§†è§‰åŒ–çš„å…ƒç´ ï¼Œå¼•å¯¼è§‚ä¼—æ­£ç¡®åœ°ç†è§£è‡ªå·±çš„è§‚ç‚¹ï¼Œè€Œä¸è¦è®©è§‚ä¼—è‡ªè¡Œå¾—å‡ºç»“è®ºã€‚ æœ€åï¼Œåˆ†äº«ä¸€ä¸‹æˆ‘åœ¨çŸ¥è¯†æ˜Ÿçƒä¸Šé¢å‘çš„å…³äºåˆ†ææ•°æ®çš„ 5 ç‚¹æ€è€ƒã€‚ 1. åˆ†ææ•°æ®çš„å¹³å‡å€¼å’Œä¸­ä½æ•° æ¯”å¦‚è¯´ï¼Œå®¢æˆ·çš„å¹´é¾„ã€è´­ä¹°é‡‘é¢çš„å¹³å‡å€¼å’Œä¸­ä½æ•°åˆ†åˆ«æ˜¯å¤šå°‘ï¼Ÿä¸­ä½æ•°å¾€å¾€æ¯”å¹³å‡å€¼æ›´å…·æœ‰åˆ†æä»·å€¼ã€‚ 2. åˆ†ææ•°æ®çš„æå€¼å’Œåˆ†å¸ƒ æ¯”å¦‚è¯´ï¼Œåœ¨æ‰€æœ‰çš„è´­ä¹°è€…ä¸­ï¼Œå¹´é¾„æœ€å¤§çš„æ˜¯è°ï¼Ÿå¹´é¾„æœ€å°çš„æ˜¯è°ï¼Ÿæ˜¯å¦æœä»æ­£æ€åˆ†å¸ƒï¼Ÿ 3. åˆ†ææ•°æ®çš„ç›¸å…³æ€§ æ¯”å¦‚è¯´ï¼Œå¹´é¾„ä¸è´­ä¹°é‡‘é¢æ˜¯å¦æœ‰ç›¸å…³æ€§ï¼Ÿç›¸å…³ç³»æ•°æ˜¯å¤šå°‘ï¼Ÿ 4. åˆ†ææ•°æ®èƒŒåçš„åŸå›  æ¯”å¦‚è¯´ï¼Œå®¢æˆ·ä¸ºä»€ä¹ˆä¼šè´­ä¹°ï¼Ÿé”€å”®ä¸‹é™çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ 5. æå‡ºæ•°æ®åˆ†æçš„å»ºè®® æ¯”å¦‚è¯´ï¼Œç»è¿‡å‰æœŸçš„åˆ†æï¼ŒçŸ¥é“é”€å”®ä¸‹é™çš„åŸå› ï¼Œä¸»è¦æ˜¯å› ä¸ºè€å¹´å®¢æˆ·ç¾¤ä½“çš„è®¤çŸ¥åº¦åä½ï¼Œæ•…æå‡ºå»ºè®®ï¼šé’ˆå¯¹è€å¹´å®¢æˆ·ç¾¤ä½“å¼€å±•å®£ä¼ æ´»åŠ¨ã€‚ æ€»ä¹‹ï¼Œä¸è¦å½“ä¸€ä¸ªçº¯ç²¹çš„ã€Œç»Ÿè®¡è€…ã€ï¼Œè¦åšæ•°æ®çš„åˆ†æè€…ï¼Œæœ€å¥½æ˜¯é—®é¢˜çš„è§£å†³è€…ã€‚ 2020-6-19 è®ºæ•°æ®çš„é‡è¦æ€§ï¼ï¼ï¼ï¼ï¼ è®ºæ•°æ®çš„é‡è¦æ€§ï¼ï¼ï¼ï¼ï¼ 2020-6-18 et-alæ ¼å¼çš„å‚è€ƒæ–‡çŒ®çš„è®¾ç½®æ–¹æ³• å‚è€ƒæ–‡çŒ®ç±»å‹ 2020-6-17 ç»Ÿè®¡å­¦èµ„æ–™æ”¶é›†ï¼š è§†é¢‘ å“ˆä½›å¤§å­¦ https://www.bilibili.com/video/av455440626/?p=2 2020-6-16 ä¸€é¢ 1h 1.è‡ªæˆ‘ä»‹ç» 2.ç»Ÿè®¡ 1ï¼‰å‡è®¾æ£€éªŒï¼ŒAåŸå¸‚å¹³å‡å·¥èµ„X1ï¼Œæ–¹å·®sigma1ï¼ŒBåŸå¸‚å¹³å‡å·¥èµ„X2ï¼Œæ–¹å·®sigma2. è®¾è®¡å‡è®¾æ£€éªŒï¼ŒéªŒè¯X1æ˜¾è‘—å¤§äºX2ï¼Œè¦æ±‚H0ï¼ŒH1ï¼Œå‡è®¾æ£€éªŒç»Ÿè®¡é‡åŠå…¶åˆ†å¸ƒ 2ï¼‰æ¦‚ç‡è®ºï¼Œç”²ä¹™ä¸¤äººåŒæ—¶ç©ä¸€ä¸ªæ¸¸æˆï¼ŒæŠ•è‡³å‡åŒ€éª°å­ï¼Œä¸¤ä¸ªäººè½®æµæŠ•æ·ï¼Œè°å…ˆæŠ•åˆ°6è°èµ¢ï¼Œ é—®ç”²å…ˆæŠ•ï¼Œè·èƒœçš„æ¦‚ç‡ 3.æœºå™¨å­¦ä¹  1ï¼‰100ä¸‡ä¸ªæ ·æœ¬é‡ï¼Œ70ä¸ªfeatureï¼Œå¦‚æœä½ ç”¨random forestï¼Œä½ ä¼šé€‰æ‹©å¤šæ·±çš„æ ‘ 2ï¼‰ç®€è¿°baggingï¼Œrfï¼Œboostingçš„åŒºåˆ« 4.äº§å“ 1ï¼‰å¿«æ‰‹å†…éƒ¨ç”Ÿæ€åˆ†ä¸ºç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ï¼Œä½ å¦‚ä½•é€‰æ‹©ä¸€ä¸ªæŒ‡æ ‡ï¼Œç”¨äºè¯„åˆ¤å°½å¯èƒ½å¤šçš„äººå‘ä½œå“ 2ï¼‰ç›´æ’­é—´ä»·å€¼ç”¨è§‚çœ‹æ—¶é•¿æ¥è¯„åˆ¤ï¼Œé€‰æ‹©ä¸€ä¸ªæŒ‡æ ‡å»è¯„åˆ¤ç›´æ’­é—´çš„ä»·å€¼ 5.python ä¸€ä¸ªç®€å•ç¼–ç¨‹ï¼Œlist a = [10,20,30,40,50,60,70,80,90] åœ¨list ä¸­å…ˆå–å‡º20çš„å€æ•°ï¼Œi.e., 20,40,60,80ï¼Œå†å–å‡º30çš„å€æ•°ï¼Œä¾æ­¤ç±»æ¨ä¸€ç›´åˆ°90ï¼Œæœ€åå–å‡º10çš„å€æ•° 6.Sql leetcode, top three department salary å˜ç§ äºŒé¢ 30mins éš”å¤© 1.å¾—åˆ°ä¸€ä¸ªAB testç»“æœï¼Œä½ æ€ä¹ˆåˆ†æ 2.ç»å…¸producté¢˜ç›®ï¼Œä¸€ä¸ªæŒ‡æ ‡ä¸‹é™äº†ï¼Œå¦‚ä½•åˆ†æ 3.å®è§‚é—®é¢˜ï¼Œæ€ä¹ˆåˆ†æå—åŒ—æ–¹ç”¨æˆ·å·®å¼‚ 2020-6-13 å¤§æ•°æ®æŒ–æ˜ä¸åˆ†æå®ä¹ ç”Ÿä¸€é¢é¢ç» è‡ªæˆ‘ä»‹ç» sqlæ€ä¹ˆæ · pythonæ€ä¹ˆè‡ªå­¦çš„ è®²ä¸€ä¸ªæ•°æ®æŒ–æ˜ä¸åˆ†æå®ä¹ æˆ–é¡¹ç›®ã€‚ 5.è®²å®ä¹ ç»å† https://www.nowcoder.com/contestRoom å°½ç®¡æˆ‘çœ‹äº†å¾ˆå¤§è¿™æ–¹é¢çš„ä¸œè¥¿ï¼Œ 2020-6-12 ä¸€ä¸ªæ•°æ®åˆ†ææŠ¥å‘Šçš„å†…å®¹ æˆ‘å¯¹è¿™ä¸ªå¾ˆæ„Ÿå…´è¶£å•Šï¼ï¼ï¼ï¼ éµå¾ªçš„æ ‡å‡†å±•ç¤ºåˆ†æç»“æœ-ã€‹éªŒè¯åˆ†æè´¨é‡-ã€‹æä¾›å†³ç­–å‚è€ƒ éœ€æ±‚å±‚ï¼šç›®çš„ï¼Œç›®æ ‡ æ•°æ®å±‚ï¼šæ•°æ®æ¸…æ´— åˆ†æå±‚ï¼šæè¿°åˆ†æå’Œå»ºæ¨¡åˆ†æï¼Œå‰è€…æ˜¯æ´å¯Ÿç»“è®ºï¼Œåè€…æ˜¯æ¨¡å‹æµ‹è¯•ï¼Œ è¾“å‡ºå±‚ï¼šæ¨¡å‹+æŠ¥å‘Šæ’°å†™ã€‚ ç®€å•ç‰ˆæœ¬ é¡¹ç›®èƒŒæ™¯ï¼šç®€è¿°é¡¹ç›®ç›¸å…³èƒŒæ™¯ï¼Œä¸ºä»€ä¹ˆåšï¼Œç›®çš„æ˜¯ä»€ä¹ˆ é¡¹ç›®è¿›åº¦ï¼šç»¼è¿°é¡¹ç›®çš„æ•´ä½“è¿›ç¨‹ï¼Œä»¥åŠç›®å‰çš„æƒ…å†µ åè¯è§£é‡Šï¼šå…³é”®æ€§æŒ‡æ ‡å®šä¹‰æ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆå®šä¹‰ åè¯è§£é‡Šï¼šå…³é”®æ€§æŒ‡æ ‡çš„å®šä¹‰æ˜¯è¯´æ˜ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆå®šä¹‰ã€‚æœ‰ä½•ä¸åŒã€‚ æ•°æ®è·å–æ–¹æ³•ï¼šå¦‚ä½•å–æ ·ï¼Œæ€ä¹ˆè·å–åˆ°çš„æ•°æ®ï¼Œä¼šæœ‰å“ªäº›é—®é¢˜ æ•°æ®è·å–æ–¹æ³•ï¼šå¦‚ä½•å–æ ·ï¼Œç›¸å…³é—®é¢˜ã€‚åŒ…æ‹¬å¼‚å¸¸å€¼è¡¥å……ï¼Œå¦‚ä½•å¡«å……ã€‚æ•°æ®æ¸…æ´—å’Œæ•°æ®è¡¥å…¨ã€‚ æ•°æ®æ¦‚è§ˆï¼šé‡è¦æŒ‡æ ‡çš„è¶‹åŠ¿ï¼Œå˜åŒ–æƒ…å†µï¼Œé‡è¦æ‹ç‚¹æˆå› è§£é‡Š å¯è§†åŒ–æˆ–è€…è¡¨æ ¼å±•ç¤º æ•°æ®æ‹†åˆ†ï¼šæ ¹æ®éœ€è¦æ‹†åˆ†ä¸åŒçš„ç»´åº¦ï¼Œä½œä¸ºç»†èŠ‚è¡¥å…… ç»“è®ºæ±‡æ€»ï¼šæ±‡æ€»ä¹‹å‰æ•°æ®åˆ†æçš„ä¸»è¦ç»“è®ºï¼Œä½œä¸ºæ¦‚è§ˆ åç»­æ”¹è¿›ï¼šåˆ†æç›®å‰å­˜åœ¨çš„é—®é¢˜ï¼Œå¹¶ç»™å‡ºè§£å†³æ”¹è¿›é˜²èŒƒ è‡´è°¢ é™„ä»¶ï¼šè¯¦ç»†æ•°æ® ä¸“ä¸šç‰ˆæœ¬ æ ‡é¢˜ä¸š ç›®æ ‡ å‰è¨€ a. å…¶å¯¹èƒ½å¦è§£å†³ä¸šåŠ¡é—®é¢˜ï¼Œèµ·åˆ°å†³ç­–æ€§ä½œç”¨ã€‚åŒ…æ‹¬åˆ†æèƒŒæ™¯ã€ç›®çš„ä»¥åŠæ€è·¯ã€‚ æ­£æ–‡ a. æŠ¥å‘Šçš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿç”±å“ªäº›å­è§‚ç‚¹ç»„æˆï¼Œæ”¯æŒæ¯ä¸ªå­è§‚ç‚¹çš„æ•°æ®ï¼Œå±•ç¤ºæ–¹å¼ï¼Œé‡åŒ–ç»“æœï¼ˆéµå¾ªé‡‘å­—å¡”åŸç†) ç°çŠ¶æè¿°ï¼›2ï¼Œ ä»€ä¹ˆé‡åŒ–æŒ‡æ ‡ï¼›3ï¼ŒåŒæ¯”ã€ç¯æ¯”ç­‰ç­‰ 4. é€‰æ‹©åŸå›  ç»“è®º a. æ ¹æ®åˆ†æç»“æœï¼Œé€šå¸¸ä»¥ç»¼è¿°æ€§æ–‡å­—æ¥è¯´æ˜ï¼Œè¦ç´§å¯†ç»“åˆä¸šåŠ¡ã€‚ é™„å½• a. èµ„æ–™ï¼Œé‡è¦æ•°æ®ï¼Œåœ°å›¾ å…³é”®è¯ï¼š æŒ‡æ ‡ï¼›æ•°æ®ï¼›å¯è§†åŒ–ï¼›é€»è¾‘ï¼›å®äº‹æ±‚æ˜¯ éš¾ç‚¹ï¼š å»ºæ¨¡åˆ†æï¼›è®¡é‡ é‡ç‚¹ï¼š ç»´åº¦ï¼›æŒ‡æ ‡ æœ€å¿Œè®³çš„å°±æ˜¯åˆ†æå‡ºä¸€å¤§æ¨æ˜¾è€Œæ˜“è§çš„ç»“è®ºï¼Œå°±åƒæ•°æ®æŒ–æ˜ä¸€æ ·ã€‚]]></content>
      <categories>
        <category>ç§‘æ™®</category>
      </categories>
      <tags>
        <tag>æ—¥å¸¸</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å¯†ç å­¦]]></title>
    <url>%2F2020%2F06%2F11%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[ç§‘æ™® Day1ç°ä»£ä¿¡æ¯å®‰å…¨çš„åŸºæœ¬è¦æ±‚ï¼š ä¿¡æ¯çš„ä¿å¯†æ€§ Confidentialityï¼šé˜²æ­¢ä¿¡æ¯æ³„æ¼ç»™æœªç»æˆæƒçš„äººï¼ˆåŠ å¯†è§£å¯†æŠ€æœ¯ï¼‰æœºå¯†æ€§ ä¿¡æ¯çš„å®Œæ•´æ€§ Integrityï¼šé˜²æ­¢ä¿¡æ¯è¢«æœªç»æˆæƒçš„ç¯¡æ”¹ï¼ˆæ¶ˆæ¯è®¤è¯ç ï¼Œæ•°å­—ç­¾åï¼‰ è®¤è¯æ€§ Authenticationï¼šä¿è¯ä¿¡æ¯æ¥è‡ªæ­£ç¡®çš„å‘é€è€…ï¼ˆæ¶ˆæ¯è®¤è¯ç ï¼Œæ•°å­—ç­¾åï¼‰è®¤ä¸º å…¶ä»– ä¸å¯å¦è®¤æ€§ Non-repudiationï¼šä¿è¯å‘é€è€…ä¸èƒ½å¦è®¤ä»–ä»¬å·²å‘é€çš„æ¶ˆæ¯ï¼ˆæ•°å­—ç­¾åï¼‰ ç¬¬ä¸€ç«  å¼•è¨€æ¶‰åŠçš„çŸ¥è¯†ç‚¹åŒ…æ‹¬ä¿¡æ¯å®‰å…¨çš„è¦æ±‚ï¼ˆä¸»è¦å››ä¸ªæ–¹é¢ï¼‰ï¼Œå¯†ç å­¦åŸºæœ¬æ¦‚å¿µï¼Œå®‰å…¨çš„å®šä¹‰ï¼Œå¯†ç ç®—æ³•çš„è®¾è®¡è¦æ±‚ï¼Œå¤å…¸å¯†ç ï¼ˆæ›¿æ¢ï¼Œä»£æ›¿ï¼‰ oå¯†ç å­¦åŸºæœ¬æ¦‚å¿µ**,**å¦‚å¯†ç ç¼–ç å­¦ã€å¯†ç åˆ†æå­¦ã€æ˜æ–‡ã€å¯†æ–‡ã€åŠ å¯†ã€è§£å¯† oå¯¹ç§°å¯†ç ä½“åˆ¶å’Œéå¯¹ç§°å¯†ç ä½“åˆ¶ oå¤å…¸å¯†ç ä½“åˆ¶ï¼Œå¦‚ç½®æ¢å¯†ç ã€å•è¡¨ä»£æ¢å¯†ç ã€å¤šè¡¨ä»£æ¢å¯†ç ï¼ˆè¦ä¼šè®¡ç®—ï¼‰ ç°ä»£ä¿¡æ¯å®‰å…¨çš„åŸºæœ¬è¦æ±‚ï¼š ä¿¡æ¯çš„ä¿å¯†æ€§ Confidentialityï¼šé˜²æ­¢ä¿¡æ¯æ³„æ¼ç»™æœªç»æˆæƒçš„äººï¼ˆåŠ å¯†è§£å¯†æŠ€æœ¯ï¼‰ ä¿¡æ¯çš„å®Œæ•´æ€§ Integrityï¼šé˜²æ­¢ä¿¡æ¯è¢«æœªç»æˆæƒçš„ç¯¡æ”¹ï¼ˆæ¶ˆæ¯è®¤è¯ç ï¼Œæ•°å­—ç­¾åï¼‰ è®¤è¯æ€§ Authenticationï¼šä¿è¯ä¿¡æ¯æ¥è‡ªæ­£ç¡®çš„å‘é€è€…ï¼ˆæ¶ˆæ¯è®¤è¯ç ï¼Œæ•°å­—ç­¾åï¼‰ ä¸å¯å¦è®¤æ€§ Non-repudiationï¼šä¿è¯å‘é€è€…ä¸èƒ½å¦è®¤ä»–ä»¬å·²å‘é€çš„æ¶ˆæ¯ï¼ˆæ•°å­—ç­¾åï¼‰ http://yuqiangcoder.com/2019/10/07/%E5%AF%86%E7%A0%81%E5%AD%A6%E6%A6%82%E8%BF%B0.html å¯†ç å­¦å°±æ˜¯è¦é€šè¿‡ç®—æ³•å’Œåè®®å®ç°ç›¸åº”çš„åŠŸèƒ½ å‡¯æ’’å¯†ç ï¼šç§»åŠ¨2ä½ï¼ŒH K æºæ’’å¯†ç  å®‰å…¨pæ— æ¡ä»¶å®‰å…¨çš„(ä¸å¯ç ´è¯‘çš„)ï¼š pæ— è®ºæˆªè·å¤šå°‘å¯†æ–‡ï¼Œéƒ½æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯æ¥å”¯ä¸€ç¡®å®šæ˜æ–‡ï¼Œåˆ™è¯¥å¯†ç æ˜¯æ— æ¡ä»¶å®‰å…¨çš„ï¼Œå³å¯¹ç®—æ³•çš„ç ´è¯‘ä¸æ¯”çŒœæµ‹æœ‰ä¼˜åŠ¿ pè®¡ç®—ä¸Šå®‰å…¨çš„ï¼š pä½¿ç”¨æœ‰æ•ˆèµ„æºå¯¹ä¸€ä¸ªå¯†ç ç³»ç»Ÿè¿›è¡Œåˆ†æè€Œæœªèƒ½ç ´è¯‘ï¼Œåˆ™è¯¥å¯†ç æ˜¯å¼ºçš„æˆ–è®¡ç®—ä¸Šå®‰å…¨çš„ å¯†ç ç®—æ³•è¦æ±‚å¯†ç ç®—æ³•åªè¦æ»¡è¶³ä»¥ä¸‹ä¸¤æ¡å‡†åˆ™ä¹‹ä¸€å°±è¡Œï¼š ï¼ˆ1ï¼‰ ç ´è¯‘å¯†æ–‡çš„ä»£ä»·è¶…è¿‡è¢«åŠ å¯†ä¿¡æ¯çš„ä»·å€¼ã€‚ ï¼ˆ2 ) ç ´è¯‘å¯†æ–‡æ‰€èŠ±çš„æ—¶é—´è¶…è¿‡ä¿¡æ¯çš„æœ‰ç”¨æœŸã€‚ æ»¡è¶³ä»¥ä¸Šä¸¤ä¸ªå‡†åˆ™çš„å¯†ç ç®—æ³•åœ¨å®é™…ä¸­æ˜¯å¯ç”¨çš„ã€‚ å•è¡¨ä»£æ›¿å¯†ç å•è¡¨ä»£æ›¿å¯†ç å¯åˆ†ä¸º â€¢ åŠ æ³•å¯†ç  â€¢ ä¹˜æ³•å¯†ç  â€¢ ä»¿å°„å¯†ç  å¤å…¸å¯†ç ç½®æ¢å¯†ç  å•è¡¨ä»£æ›¿å¯†ç ç®—æ³• å¤šè¡¨ä»£æ›¿å¯†ç ç®—æ³• ç¬¬äºŒç«  æµå¯†ç ä¸€æ¬¡ä¸€å¯†ï¼Œæµå¯†ç ï¼Œå¯†é’¥æµä¸‰ä¸ªæ¦‚å¿µã€‚ oæµå¯†ç åŸºæœ¬æ¦‚å¿µã€ç‰¹ç‚¹ oçº¿æ€§åé¦ˆç§»ä½å¯„å­˜å™¨ oRC4 ä¸€æ¬¡ä¸€å¯†ï¼ˆç†æƒ³ï¼‰ â€¢ä¼˜ç‚¹ï¼š â€¢å¯†é’¥éšæœºäº§ç”Ÿï¼Œä»…ä½¿ç”¨ä¸€æ¬¡ â€¢æ— æ¡ä»¶å®‰å…¨ â€¢åŠ å¯†å’Œè§£å¯†ä¸ºåŠ æ³•è¿ç®—ï¼Œæ•ˆç‡è¾ƒé«˜ â€¢ç¼ºç‚¹ï¼š â€¢å¯†é’¥é•¿åº¦è‡³å°‘ä¸æ˜æ–‡é•¿åº¦ä¸€æ ·é•¿ï¼Œå¯†é’¥å…±äº«å›°éš¾ï¼Œä¸å¤ªå®ç”¨ æµå¯†ç å¯†ç ä½“åˆ¶ åºåˆ—å¯†ç  â€¢æµå¯†ç çš„åŸºæœ¬æ€æƒ³ â€¢åˆ©ç”¨å¯†é’¥käº§ç”Ÿä¸€ä¸ªå¯†é’¥æµ â€¢å¯†é’¥æµ â€¢ç”±å¯†é’¥æµå‘ç”Ÿå™¨ f äº§ç”Ÿï¼š Ã˜å†…éƒ¨è®°å¿†å…ƒä»¶çš„çŠ¶æ€Ïƒiç‹¬ç«‹äºæ˜æ–‡å­—ç¬¦çš„å«åšåŒæ­¥æµå¯†ç ï¼Œå¦åˆ™å«åšè‡ªåŒæ­¥æµå¯†ç ã€‚ å¯†ç åˆ†æå­¦çš„ç›®æ ‡åœ¨äºç ´è¯‘ï¼ˆ BC ï¼‰ A. æ˜æ–‡ B. å¯†æ–‡ C. å¯†é’¥ D. ç®—æ³•ç»“æ„ ä¿å¯†é€šä¿¡ç³»ç»Ÿçš„å®‰å…¨å¨èƒ ä¿å¯†é€šä¿¡çš„å®‰å…¨å¨èƒï¼š è¢«åŠ¨æ”»å‡»ï¼šçªƒå¬ï¼Œå—…æ¢æµé‡åˆ†æç­‰ï¼Œä¸»è¦æ˜¯ç ´åæ¶ˆæ¯çš„æœºå¯†æ€§ï¼› ä¸»åŠ¨æ”»å‡»ï¼šä¸­æ–­ï¼Œç¯¡æ”¹ï¼Œå‡å†’ç­‰ã€‚ ä¸­æ–­ç ´åäº†ä¿¡æ¯çš„å¯ç”¨æ€§ ç¯¡æ”¹ç ´åäº†ä¿¡æ¯çš„å®Œæ•´æ€§ å‡å†’ç ´åäº†çœŸå®æ€§ï¼ˆè®¤è¯ï¼‰ æ‰€ä»¥ä¿å¯†é€šä¿¡ç³»ç»Ÿçš„å®‰å…¨éœ€æ±‚æœ‰ï¼š æœºå¯†æ€§â€”â€”é‡‡ç”¨åŠ å¯†æœºåˆ¶ å®Œæ•´æ€§â€”â€”é‡‡ç”¨å®Œæ•´æ€§éªŒè¯æœºåˆ¶ï¼Œå¦‚Hashå‡½æ•°ï¼Œæ¶ˆæ¯è®¤è¯ç  çœŸå®æ€§â€”â€”é‡‡ç”¨è®¤è¯æœºåˆ¶ï¼Œå¦‚æ•°å­—ç­¾åï¼Œè®¤è¯åè®® ä¸­æ–­â€”â€”ç”¨å¯†ç å­¦çš„æŠ€æœ¯æ²¡æœ‰å¤ªå¥½çš„åŠæ³•ï¼ˆè¿™æ˜¯æˆ‘ä¸ªäººçš„ç†è§£ï¼‰ å¤å…¸å¯†ç å­¦ ç½®æ¢å¯†ç ï¼šåˆç§°æ¢ä½å¯†ç ï¼ŒåŠ å¯†è¿‡ç¨‹ä¸­æ˜æ–‡çš„å­—æ¯ä¿æŒç›¸åŒï¼Œä½†æ˜¯é¡ºåºè¢«æ‰“ä¹±ã€‚åªè¦æŠŠä½ç½®æ¢å¤ï¼Œå°±èƒ½å¾—åˆ°æ˜æ–‡ã€‚ ä»£æ¢å¯†ç ï¼šæ˜æ–‡ä¸­çš„æ¯ä¸€ä¸ªå­—ç¬¦è¢«æ›¿æ¢æˆå¯†æ–‡ä¸­çš„å¦ä¸€ä¸ªå­—ç¬¦ã€‚æ¥æ”¶è€…å¯¹å¯†æ–‡åšåå‘æ›¿æ¢å°±å¯ä»¥æ¢å¤æ˜æ–‡ã€‚ å¤šåæˆ–åŒéŸ³ä»£æ›¿å¯†ç  å¤šå­—æ¯ä»£æ›¿å¯†ç  å¤šè¡¨ä»£æ›¿å¯†ç  æ€»ç»“å¤å…¸å¯†ç å­¦çš„ç‰¹ç‚¹ï¼šåŠ å¯†å¯¹è±¡ï¼›æ–¹æ³•ï¼›ä¿å¯†å†…å®¹ï¼›ç ´è§£ï¼› è®¡ç®—å¼ºåº¦å° å‡ºç°åœ¨ DES ä¹‹å‰ æ•°æ®å®‰å…¨åŸºäºç®—æ³•çš„ä¿å¯†ã€‚è¿™å’Œç°ä»£å¯†ç æœ‰å¾ˆå¤§çš„å·®è·ï¼Œåªè¦çŸ¥é“åŠ å¯†æ–¹æ³•ï¼Œå°±èƒ½è½»æ˜“çš„è·å–æ˜æ–‡ã€‚ç°ä»£çš„å¯†ç åŸºäºç§˜é’¥çš„åŠ å¯†ï¼Œç®—æ³•éƒ½æ˜¯å…¬å¼€çš„ï¼Œè€Œä¸”å…¬å¼€çš„å¯†ç ç®—æ³•å®‰å…¨æ€§æ›´é«˜ï¼Œèƒ½è¢«æ›´å¤šäººè¯„è®ºå’Œä½¿ç”¨ï¼ŒåŠ å¼ºæ¼æ´çš„ä¿®è¡¥ã€‚ ä»¥å­—æ¯è¡¨ä¸ºä¸»è¦åŠ å¯†å¯¹è±¡ã€‚å¤å…¸å¯†ç å¤§å¤šæ•°æ˜¯å¯¹æœ‰æ„ä¹‰çš„æ–‡å­—è¿›è¡ŒåŠ å¯†ï¼Œè€Œç°ä»£å¯†ç æ˜¯å¯¹æ¯”ç‰¹åºåˆ—è¿›è¡ŒåŠ å¯†ã€‚è¿™ä¹Ÿæ˜¯ç°ä»£å¯†ç å’Œå¤å…¸å¯†ç çš„åŒºåˆ«ï¼Œè€Œä¸”å¤å…¸å¯†ç çš„åˆ†ææ–¹æ³•ä¹Ÿæ˜¯ç”¨å­—æ¯é¢‘ç‡åˆ†æè¡¨æ¥ç ´è§£çš„ã€‚ æ›¿æ¢å’Œç½®æ¢æŠ€æœ¯ å¯†ç åˆ†ææ–¹æ³•åŸºäºå­—æ¯ä¸å­—æ¯ç»„åˆçš„é¢‘ç‡ç‰¹æ€§ä»¥åŠæ˜æ–‡çš„å¯è¯»æ€§ ç°ä»£å¯†ç å­¦ 1976ï¼šç”± Diffie å’Œ Hellman åœ¨ã€Š å¯†ç å­¦çš„æ–°æ–¹å‘ã€‹ï¼ˆã€ŠNew Directions in Cryptographyã€‹ï¼‰æå‡ºäº†å…¬é’¥å¯†ç å­¦ä½“åˆ¶çš„æ€æƒ³ 1977å¹´ï¼šç¾å›½å›½å®¶æ ‡å‡†å±€é¢å¸ƒæ•°æ®åŠ å¯†æ ‡å‡† DESï¼ˆData Encryption Standardï¼‰ 1978å¹´ï¼šç¬¬ä¸€ä¸ªå…¬é’¥ç®—æ³• RSA ç®—æ³•ï¼ˆç”± Ron Rivestã€Adi Shamir å’Œ Leonard Adleman çš„å§“æ°é¦–å­—æ¯ç»„æˆï¼‰ ç°ä»£å¯†ç å­¦ä¸»è¦æœ‰ä¸‰ä¸ªæ–¹å‘ï¼šç§é’¥å¯†ç ï¼ˆå¯¹ç§°å¯†ç ï¼‰ã€å…¬é’¥å¯†ç ï¼ˆéå¯¹ç§°å¯†ç ï¼‰ã€å®‰å…¨åè®®ã€‚ ç§é’¥å¯†ç ä¹Ÿç§°å¯¹ç§°å¯†ç ï¼Œæ˜¯å¯¹æ–‡å­—çš„åŠ å¯†è½¬æ¢æˆå¯¹æ¯”ç‰¹åºåˆ—çš„åŠ å¯†ï¼ˆç›¸å¯¹äºå¤å…¸å¯†ç ï¼‰ï¼Œç”¨åŒä¸€ä¸ªå¯†é’¥è¿›è¡ŒåŠ å¯†å’Œè§£å¯†æ“ä½œï¼Œè¿™ä¸ªå¯†é’¥å‘é€æ–¹å’Œæ¥æ”¶æ–¹éƒ½æ˜¯è¦ä¿å¯†çš„ï¼Œæ‰€ä»¥ç§°ä¸ºç§é’¥å¯†ç ã€‚å®ƒçš„ä¸¤ä¸ªåŸºæœ¬æ“ä½œå°±æ˜¯ä»£æ¢å’Œç½®æ¢å°±æ˜¯æ¥æºäºå¤å…¸å¯†ç å­¦çš„ã€‚ å¯¹ç§°å¯†ç æœ‰ä¸¤ä¸ªè®¾è®¡åŸåˆ™ï¼Œä¸€ä¸ªæ˜¯æ‰©æ•£ï¼ˆDiffusionï¼‰ï¼šæ˜æ–‡çš„ç»Ÿè®¡ç»“æ„è¢«æ‰©æ•£æ¶ˆå¤±åˆ°å¯†æ–‡çš„é•¿ç¨‹ç»Ÿè®¡ç‰¹æ€§ï¼Œä½¿å¾—æ˜æ–‡å’Œå¯†æ–‡ä¹‹é—´çš„ç»Ÿè®¡å…³ç³»å°½é‡å¤æ‚ã€‚ å¦ä¸€ä¸ªæ˜¯æ··ä¹±ï¼ˆconfusionï¼‰ï¼šä½¿å¾—å¯†æ–‡çš„ç»Ÿè®¡ç‰¹æ€§ä¸å¯†é’¥çš„å–å€¼ä¹‹é—´çš„å…³ç³»å°½é‡å¤æ‚ã€‚ å¯¹ç§°å¯†ç çš„ä»£è¡¨æœ‰ DES ç®—æ³•å’Œ AES ç®—æ³•ï¼Œ å…¬é’¥å¯†ç  DH å¯†é’¥äº¤æ¢åè®® RSA ç®—æ³•æ˜¯ç¬¬ä¸€ä¸ªå…¬é’¥å¯†ç ç®—æ³•ï¼Œä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªæ•°å­—ç­¾åç®—æ³•ã€‚ p q pi(n) =(p-1)(q-1);ä¸näº’è´¨çš„ä¹¦&lt;=n é€‰e ä¸pi(n)æœ€å¤§å…¬çº¦æ•°1ï¼Œäº’è´¨ï¼Œ æ‰¾dï¼Œe*d/pi(n)=1 (n,e)å…±ï¼ˆn,d)ç§é’¥ a^emod n =b b^d mod n=c æ ¹æ®ä»¥ä¸Šå¯†é’¥å¯¹çš„ç”Ÿæˆè¿‡ç¨‹ï¼š å¦‚æœæƒ³çŸ¥é“ d éœ€è¦çŸ¥é“æ¬§æ‹‰å‡½æ•° Ï†(n) å¦‚æœæƒ³çŸ¥é“æ¬§æ‹‰å‡½æ•° Ï†(n) éœ€è¦çŸ¥é“ P å’Œ Q è¦çŸ¥é“ P å’Œ Q éœ€è¦å¯¹ n è¿›è¡Œå› æ•°åˆ†è§£ã€‚ å¯¹äºæœ¬ä¾‹ä¸­çš„ 4757 ä½ å¯ä»¥è½»æ¾è¿›è¡Œå› æ•°åˆ†è§£ï¼Œä½†å¯¹äºå¤§æ•´æ•°çš„å› æ•°åˆ†è§£ï¼Œæ˜¯ä¸€ä»¶å¾ˆå›°éš¾çš„äº‹æƒ…ï¼Œç›®å‰é™¤äº†æš´åŠ›ç ´è§£ï¼Œè¿˜æ²¡æœ‰æ›´å¥½çš„åŠæ³•ï¼Œå¦‚æœä»¥ç›®å‰çš„è®¡ç®—é€Ÿåº¦ï¼Œç ´è§£éœ€è¦50å¹´ä»¥ä¸Šï¼Œåˆ™è¿™ä¸ªç®—æ³•å°±æ˜¯å®‰å…¨çš„ æ¤­åœ†æ›²çº¿åŠ å¯†ç®—æ³•ï¼Œç®€ç§°ECCï¼Œæ˜¯åŸºäºæ¤­åœ†æ›²çº¿æ•°å­¦ç†è®ºå®ç°çš„ä¸€ç§éå¯¹ç§°åŠ å¯†ç®—æ³•ã€‚ç›¸æ¯”RSAï¼ŒECCä¼˜åŠ¿æ˜¯å¯ä»¥ä½¿ç”¨æ›´çŸ­çš„å¯†é’¥ï¼Œæ¥å®ç°ä¸RSAç›¸å½“æˆ–æ›´é«˜çš„å®‰å…¨ï¼ŒRSAåŠ å¯†ç®—æ³•ä¹Ÿæ˜¯ä¸€ç§éå¯¹ç§°åŠ å¯†ç®—æ³• é‡åˆ å››ã€åŒä½™è¿ç®—åŒä½™å°±æ˜¯æœ‰ç›¸åŒçš„ä½™æ•°ï¼Œä¸¤ä¸ªæ•´æ•° aã€ bï¼Œè‹¥å®ƒä»¬é™¤ä»¥æ­£æ•´æ•° mæ‰€å¾—çš„ä½™æ•°ç›¸ç­‰ï¼Œåˆ™ç§° aï¼Œ bå¯¹äºæ¨¡måŒä½™ã€‚ ä¹˜æ³•é€†å…ƒï¼› å…­ã€ä¹˜æ³•é€†å…ƒåœ¨æ¨¡7ä¹˜æ³•ä¸­ï¼š 1çš„é€†å…ƒä¸º1 (1*1)%7=1 2çš„é€†å…ƒä¸º4 (2*4)%7=1 3çš„é€†å…ƒä¸º5 (3*5)%7=1 4çš„é€†å…ƒä¸º2 (4*2)%7=1 5çš„é€†å…ƒä¸º3 (5*3)%7=1 6çš„é€†å…ƒä¸º6 (6*6)%7=1 https://zhuanlan.zhihu.com/p/101907402 ç¬¬ä¸‰ç« ç°ä»£å¯†ç oåˆ†ç»„å¯†ç åŸºæœ¬æ¦‚å¿µã€ç‰¹ç‚¹ oFeistel ç½‘ç»œ oDESï¼Œå¯†é’¥é•¿åº¦ã€åˆ†ç»„é•¿åº¦ã€Sç›’ã€å¤šé‡DES oåˆ†ç»„å¯†ç çš„å››ç§è¿è¡Œæ¨¡å¼ oAESï¼Œå¯†é’¥é•¿åº¦ã€åˆ†ç»„é•¿åº¦ å¤ªéš¾è®°ä½äº†ï¼ŒåŸç†ä¹Ÿå¤ªéš¾äº† Day 2 ç°ä»£å¯†ç ä¸€æ¬¡æ€§å¯†ç Frank Miller åœ¨1882 å¹´æå‡ºäº†ä¸€æ¬¡æ€§å¯†ç ï¼ˆOne-time padï¼‰çš„æ¦‚å¿µâ€”â€”åŠ å¯†ï¼šå°†æ¶ˆæ¯å’Œç§é’¥è¿›è¡Œå¼‚æˆ–è¿ç®—å¾—åˆ°å¯†æ–‡ï¼›è§£å¯†ï¼šå°†å¯†é’¥å’Œå¯†æ–‡è¿›è¡Œå¼‚æˆ–è¿ç®—å¾—åˆ°åŸæ¶ˆæ¯ï¼Œè¿™ä¸ªè¿‡ç¨‹ç±»ä¼¼äºå‰é¢æåˆ°çš„ a âŠ• b âŠ• a = b ã€‚ä¸€æ¬¡æ€§å¯†ç çš„å®šä¹‰å¦‚ä¸‹æ‰€ç¤ºï¼š æ— æ¡ä»¶å®‰å…¨ å¯†é’¥éšæœºäº§ç”Ÿçš„ï¼Œåªèƒ½ç”¨ä¸€æ¬¡ å¼‚æˆ– 1+1 =0 ï¼Œ0+1 = 1 å…±äº«å¯†é’¥éš¾ æµå¯†ç ä½“åˆ¶å¯†é’¥k,äº§ç”Ÿå¯†é’¥æµï¼ˆå‘ åŒæ­¥æµå¯†ç ï¼ˆçŠ¶æ€æ— å…‰ï¼‰ ä¸€.åŠ å¯†æ–¹æ³•çš„åˆ†ç±»ï¼šæŒ‰ç…§ä¸åŒçš„æ ‡å‡†æœ‰ä¸åŒçš„åˆ†ç±»æ ‡å‡†ï¼š1.æŒ‰ç…§å¯†é’¥çš„ç‰¹å¾ä¸åŒï¼Œå¯ä»¥åˆ†ä¸ºå¯¹ç§°å¯†ç ä¸éå¯¹ç§°å¯†ç ã€‚2.æŒ‰ç…§åŠ å¯†æ–¹å¼çš„ä¸åŒï¼Œå¯ä»¥åˆ†ä¸ºæµå¯†ç å’Œåˆ†ç»„å¯†ç ã€‚3.éå¯¹ç§°å¯†ç å‡å±äºåˆ†ç»„å¯†ç ã€‚ 1.æµå¯†ç ã€‚åˆååºåˆ—å¯†ç ã€‚æ˜æ–‡ç§°ä¸ºæ˜æ–‡æµï¼Œä»¥åºåˆ—çš„æ–¹å¼è¡¨ç¤ºã€‚åŠ å¯†æ—¶å€™ï¼Œå…ˆç”±ç§å­å¯†é’¥ç”Ÿæˆä¸€ä¸ªå¯†é’¥æµã€‚ç„¶ååˆ©ç”¨åŠ å¯†ç®—æ³•æŠŠæ˜æ–‡æµå’Œå¯†é’¥æµè¿›è¡ŒåŠ å¯†ï¼Œäº§ç”Ÿå¯†æ–‡æµã€‚æµå¯†ç æ¯æ¬¡åªé’ˆå¯¹æ˜æ–‡æµä¸­çš„å•ä¸ªæ¯”ç‰¹ä½è¿›è¡ŒåŠ å¯†å˜æ¢ï¼ŒåŠ å¯†è¿‡ç¨‹æ‰€éœ€è¦çš„å¯†é’¥æµç”±ç§å­å¯†é’¥é€šè¿‡å¯†é’¥æµç”Ÿæˆå™¨äº§ç”Ÿã€‚æµå¯†ç çš„ä¸»è¦åŸç†æ˜¯é€šè¿‡éšæœºæ•°å‘ç”Ÿå™¨äº§ç”Ÿæ€§èƒ½ä¼˜è‰¯çš„ä¼ªéšæœºåºåˆ—ï¼Œä½¿ç”¨è¯¥åºåˆ—åŠ å¯†æ˜æ–‡æµï¼ˆæŒ‰æ¯”ç‰¹ä½åŠ å¯†ï¼‰ï¼Œå¾—åˆ°å¯†æ–‡æµã€‚ç”±äºæ¯ä¸€ä¸ªæ˜æ–‡éƒ½å¯¹åº”ä¸€ä¸ªéšæœºçš„åŠ å¯†å¯†é’¥ï¼Œæ‰€ä»¥æµå¯†ç åœ¨ç»å¯¹ç†æƒ³çš„æ¡ä»¶ä¸‹åº”è¯¥æ˜¯ç®—ä¸€ç§æ— æ¡ä»¶å®‰å…¨çš„ä¸€æ¬¡ä¸€å¯†å¯†ç ã€‚æœºå¯†æµç¨‹ï¼šç§å­å¯†ç -&gt;éšæœºæ•°å‘ç”Ÿå™¨-&gt;å¯†é’¥æµæ˜æ–‡æµ-&gt;(é€šè¿‡å¯†é’¥æµ)-&gt;åŠ å¯†å˜æ¢-&gt;å¯†æ–‡æµè®¾æ˜æ–‡æµä¸ºï¼šm=m1m2Â·Â·Â·Â·Â·miÂ·Â·Â·Â·Â·ï¼Œå¯†é’¥æµç”±å¯†é’¥æµå‘ç”Ÿå™¨fäº§ç”Ÿï¼šzi=fï¼ˆkï¼Œaiï¼‰ï¼ŒaiæŒ‡åŠ å¯†å™¨å­˜å‚¨å™¨åœ¨iæ—¶åˆ»çš„çŠ¶æ€ï¼Œfæ˜¯ç”±ç§å­å¯†é’¥kå’Œaiäº§ç”Ÿçš„å‡½æ•°ï¼Œè®¾æœ€ç»ˆçš„å¯†é’¥æµä¸ºk=k1k2Â·Â·Â·kiÂ·Â·Â·Â·Â·ï¼ŒåŠ å¯†ç»“æœä¸ºc=c1c2Â·Â·Â·Â·ciÂ·Â·Â·Â·Â·=Ek1ï¼ˆm1ï¼‰.ã€‚ã€‚ã€‚Ekiï¼ˆmiï¼‰ï¼Œè§£å¯†ç»“æœä¸ºm=Dk1ï¼ˆc1ï¼‰Dk2ï¼ˆc2ï¼‰Â·Â·Â·Dkiï¼ˆciï¼‰=m1m2Â·Â·Â·miï¼Œæ— è®ºåŠ å¯†è§£å¯†ï¼Œå…¶å…³é”®éƒ½æ˜¯å¯†é’¥æµã€‚ 2.æµå¯†ç çš„åˆ†ç±»åˆ†ä¸ºåŒæ­¥æµå¯†ç å’Œè‡ªåŒæ­¥æµå¯†ç 3.æµå¯†ç çš„ç‰¹æ€§ï¼šæå¤§çš„å‘¨æœŸï¼Œè‰¯å¥½çš„ç»Ÿè®¡ç‰¹æ€§ï¼ŒæŠ—çº¿æ€§åˆ†æã€‚4.æµå¯†ç çš„å®‰å…¨æ€§å–å†³äºå¯†é’¥æµçš„å®‰å…¨æ€§ï¼Œè¦æ±‚å¯†é’¥æµåºåˆ—æœ‰è¾ƒå¥½çš„éšæœºæ€§ã€‚5.ä¸æ˜å¯†é’¥çš„äººå¦‚ä½•å¯¹æµå¯†ç è¿›è¡Œåˆ†æã€‚è¿™ç§å¯†é’¥æµä¸€èˆ¬éƒ½æ˜¯å‘¨æœŸçš„ï¼Œåšåˆ°å®Œå…¨éšæœºæ˜¯å›°éš¾çš„ï¼Œè¿™æ ·ä¼ªéšæœºåºåˆ—ï¼Œç†è®ºä¸Šæ˜¯å¯ä»¥åˆ†æå‡ºæ¥çš„ã€‚ä¸¾ä¸ªä¾‹å­ã€‚æ•Œæ–¹æˆªè·äº†å¯†æ–‡ä¸²ï¼š101101011110010æ˜æ–‡ä¸²ï¼š011001111111001å¯†é’¥æµï¼š110100100001011å¯ä»¥æ ¹æ®å‰10ä¸ªæ¯”ç‰¹å»ºç«‹å¦‚ä¸‹æ–¹ç¨‹ å¯†é’¥æµç”Ÿæˆå™¨ï¼š é«˜è¦æ±‚å…³é”® è¦æ±‚ï¼š æ¸¸ç¨‹ï¼šå‘¨æœŸ 0.1 å‘è©å‡½æ•° äº§ç”Ÿå¯†é’¥æµçš„è¦æ±‚ï¼Œæ–¹æ³•ã€è®¾è®¡ åé¦ˆç§»ä½å¯„å­˜å™¨ â€‹ ï¼šå¯„å­˜å™¨ â€‹ ï¼š è¿”å›å‡½æ•° åˆå§‹çŠ¶æ€ çº¿æ€§åé¦ˆç§»ä½å¯„å­˜å™¨ å¿« å‘¨æœŸâ€œ è¾“å‡ºå½¢çŠ¶ï¼šå‘è©å‡½æ•° ç®—æ³• RC4 æµå¯†ç æ˜¯ä¸€æ¬¡ä¸€å¯†å—ï¼Ÿä¸æ˜¯ RC4æ²¡æœ‰å®ç°çš„m-åºåˆ—ä¸å¯çº¦ã€Š2^n-1 å……è¦ æœ¬åŸå¤šé¡¹å¼ åé¦ˆå‡½æ•°å½¢å¼ ä¼ªéšæœºæ€§ æ±‚ä½ 12 Day 3 3_13 åˆ†ç»„å¯†ç åº”ç”¨è®¾è®¡ç»“æ„åŸç†å®‰å…¨æ€§åŸåˆ™æ··æ·†åŸåˆ™ æ‰©æ•£åŸåˆ™ ç®—æ³•è¦æ±‚åˆ†ç»„é•¿åº¦è¶³å¤Ÿå¤§ å¯†é’¥é‡è¶³å¤Ÿå¤§ DESç®—æ³•56-64 IBMç¬¬ä¸€ä¸ªå•†ä¸š åé¢å‡ºç°äº†AES ç®—æ³•æ¡†å›¾ IP åˆå§‹ç½®æ¢ è®ºå‡½æ•° 16è®º åˆ†å·¦å³32bit å…¬å¼ï¼šå‡½æ•°ï¼ˆR,è½®å¯†é’¥ï¼‰ Sç›’ è¾“å…¥å…­ä½ï¼Œ8ä¸ªç›’å­ è¾“å‡º32bit step1; 32bit-48bit() é€‰æ‹©æ‰©å±•è¿ç®— E 8*4-ã€‹ä¸¤ç«¯ ç½®æ¢ Sç›’ 4*16 é€‰æ‹©å‹ç¼©è¿ç®— â€‹ è¾“å…¥è¾“å‡º â€‹ è¾“å…¥ï¼š6bit äºŒè¿›åˆ¶-ã€‹åè¿›åˆ¶ ç¡®å®šä½ç½® Pç›’ç½®æ¢ 32 -32 å¯†é’¥ç¼–æ’ ç½®æ¢-ã€‹ä¸¤ç»„-ã€‹å¾ªç¯å·¦ç§»ã€‹16è½®å¯†é’¥ æ€§è´¨ï¼šäº’è¡¥æ€§å’Œå¼±å¯†é’¥æ€§ 2DES 56+1 = 57 ä¸­é—´äººç›¸é‡å·¥å…· 3DES åˆ†ç»„å¯†ç çš„å·¥ä½œæ¨¡å¼ ä¸ºä»€ä¹ˆï¼Ÿåˆ†ç»„é•¿åº¦æ˜¯å›ºå®šï¼Œè€Œæ•°æ®é•¿åº¦å’Œæ ¼å¼æ˜¯ä¸åŒçš„ï¼Œ ç”µç æœ¬æ¨¡å¼ å¯†ç åˆ†ç»„é“¾æ¥æ¨¡å¼ â€‹ CBCåŠ å¯† å®Œæ•´æ€§ï¼ˆè®¤è¯ç ç”Ÿæˆï¼‰åŠ å¯†ï¼Œå¯¹æ¯” æ˜æ–‡æ ¡éªŒç -ã€‹CBC(M.r)&gt;å¯¹æ¯” è§£å†³ï¼šæ˜æ–‡ç»Ÿè®¡è§„å¾‹éšè— å·¥ä½œæ¨¡å¼ 2 æ•°æ®æ ¼å¼ï¼š â€‹ å­—èŠ‚ã€æ¯”ç‰¹ã€ç­‰ç­‰æ•…äº‹ åˆ†ç»„å¯†ç æ¦‚è¿°å…±äº«å¯†é’¥ IV æœ‰é™åŸŸçš„åŸºæœ¬æ¦‚å¿µå•ä½å…ƒï¼šåŠ æ³• é€†å…ƒï¼šä¹˜æ³• AESå­—èŠ‚ä¸ºå¤„ç†å•å…ƒ 8bits åŠ æ³•ï¼šmod 2 å¤šé¡¹å¼é™¤æ³• 8 4 3 1 0 çš„æœ«å¤šé¡¹å¼å–æ¨¡ å¤šé¡¹å¼è¿ç®— 128 128ï¼Œ192ï¼Œ256 S-æŒ‰åˆ— å››ä¸ªåŸºæœ¬åšå‡º 10 12 14 s:16 å­—èŠ‚ä»£æ¢ She 16*16 Sé‡Œé¢æŸ¥è¡¨ä»£æ¢ äºŒè¿›åˆ¶ åå…­è¿›å±• æ±‚é€† æ··æ·†æ•ˆåº” ä¹±äº† è¡Œç§»ä½ â€‹ å¾ªç¯å·¦ç§» åˆ—æ··æ·† â€‹ æ¯ä¸€åˆ—çŸ©é˜µç°åœº â€‹ çœ‹æˆå¤šé¡¹å¼ â€‹ çŸ©é˜µé€‰æ‹© è½®å¯†é’¥åŠ  å¼‚æˆ–ï¼šå­å¯†é’¥ å±…ä½ â€‹ åˆå§‹å¯†é’¥ï¼Œ AES â€‹ å››ä¸ªä½-ã€‹ä¸€ä¸ªå­—èŠ‚-ã€‹16è¿›åˆ¶ ä¸€ä¸ªå­—èŠ‚=ã€‹ä¸¤ä¸ªåå…­è¿›æ•° å¯†é’¥æ‰©å±•ç®—æ³• é€†Sç›’ Day 4 ç°ä»£å¯†ç å­¦ 3-27å…¬é’¥ï¼šå¯†é’¥ç®¡ç†ï¼Œ éå¯¹ç§°å¯†ç ä½“åˆ¶ å¯†é’¥å¯¹ pk sk åŠ å¯†ï¼šå…¬é’¥ ä¼˜åŠ¿ï¼š â€‹ å¯†é’¥åˆ†å‘ â€‹ å¯†é’¥ç®¡ç† ï¼š1 N-1 â€‹ å¼€æ”¾ç³»ç»Ÿ RSAåŠ å¯†ç®—æ³•æ•°å­¦çŸ¥è¯† â€‹ ç®—æ³• å¤§æ•°æ®åˆ†è§£ å¯†é’¥ç”Ÿæˆ æœ€å¤§å…¬å› å­å’Œä¹˜æ³•é€†å…ƒçš„è®¡ç®—æ–¹æ³•ã€‚ https://blog.csdn.net/boksic/article/details/7014386 https://blog.csdn.net/a745233700/article/details/102341542?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5 https://blog.csdn.net/weixin_34138377/article/details/92199465?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4 https://blog.csdn.net/weixin_41482303/article/details/85417302?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-3 ç­¾å è¯ä¹¦ https://blog.csdn.net/weixin_34007879/article/details/85528967?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2]]></content>
      <categories>
        <category>ç§‘æ™®</category>
      </categories>
      <tags>
        <tag>æ—¥å¸¸</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[or]]></title>
    <url>%2F2019%2F12%2F01%2For%2F</url>
    <content type="text"><![CDATA[è¿ç­¹å­¦ç›®çš„æ˜¯åœ¨å†³ç­–æ—¶ä¸ºç®¡ç†äººå‘˜æä¾›ç§‘å­¦ä¾æ®ã€‚ åˆ©ç”¨ç»Ÿè®¡å­¦ï¼Œæ•°å­¦æ¨¡å‹å’Œç®—æ³•ç­‰æ–¹æ³•ï¼Œå¯»æ‰¾å¤æ‚é—®é¢˜ä¸­çš„æœ€ä½³æˆ–è€…è¿‘ä¼¼æœ€ä½³çš„è§£ç­”ã€‚ è§£å†³é—®é¢˜çš„ä¼˜åŒ–ç®—æ³•ã€‚ æ¨¡å‹å»ºç«‹å®é™…é—®é¢˜ å†³ç­–å˜é‡ å½±å“æ‰€è¦åˆ°è¾¾ç›®çš„çš„å› ç´ æ‰¾åˆ°å†³ç­–å˜é‡ ç›®æ ‡å‡½æ•° çº¦æŸæ¡ä»¶ çº¿æ€§è§„åˆ’æ•´æ•°è§„åˆ’1ã€çº¯æ•´æ•°è§„åˆ’ï¼šæ‰€æœ‰å†³ç­–å˜é‡å‡è¦æ±‚ä¸ºæ•´æ•°çš„æ•´æ•°è§„åˆ’2ã€æ··åˆæ•´æ•°è§„åˆ’ï¼šéƒ¨åˆ†å†³ç­–å˜é‡å‡è¦æ±‚ä¸ºæ•´æ•°çš„æ•´æ•°è§„åˆ’3ã€çº¯0ï¼1æ•´æ•°è§„åˆ’ï¼šæ‰€æœ‰å†³ç­–å˜é‡å‡è¦æ±‚ä¸º0ï¼1çš„æ•´æ•°è§„åˆ’4ã€æ··åˆ0ï¼1è§„åˆ’ï¼šéƒ¨åˆ†å†³ç­–å˜é‡å‡è¦æ±‚ä¸º0ï¼1çš„æ•´æ•°è§„åˆ’ åˆ†æ”¯å®šç•Œæ³• : ç²¾ç¡®ç®—æ³•â€”åˆ†æ”¯å®šç•Œæ³•(Branch and Bound Algorithm, B&amp;B) è¿™å°±æ„å‘³ç€ï¼Œè¦ä¹ˆèŠ±é’±ä¹°ä»¥ä¸Šæ±‚è§£å™¨çš„ä½¿ç”¨æƒï¼Œè¦ä¹ˆå°±è‡ªå·±å†™B&amp;Bç®—æ³•çš„Codeï¼Œç„¶åå¿å—Cplex 1åˆ†é’Ÿå¯ä»¥æ±‚è§£çš„é—®é¢˜å´è¦èŠ±1å¤©æ—¶é—´çš„æ±‚è§£ã€‚ï¼ˆå¾ˆå¤šé—®é¢˜æ—¶é—´å°±æ˜¯é‡‘é’±ï¼Œä¾‹å¦‚èˆªç­å»¶è¯¯åå‰©ä½™èˆªç­é‡æ–°æ’ç­çš„é—®é¢˜ï¼Œé€šå¸¸éœ€è¦åœ¨10åˆ†é’Ÿå†…æ±‚è§£ï¼‰ æƒ³æ³•ï¼š é¦–å…ˆï¼Œå¯ä»¥ç¡®å®šçš„æ˜¯è¿™æ˜¯ä¸ªèˆªç­é‡æ–°æ’ç­çš„é—®é¢˜ï¼Œæ•°å­¦ä¸Šï¼Œèˆªç­å®‰æ’å±äºè¿ç­¹å­¦çš„é—®é¢˜ä¹‹ä¸€ï¼Œéœ€è¦åº”ç”¨å»ºç«‹ä¼˜åŒ–æ¨¡å‹è§£å†³ã€‚å»ºç«‹æœ€ä¼˜åŒ–é—®é¢˜ï¼Œæœ€é‡è¦çš„ä¸¤æ­¥æ˜¯æ¨¡å‹å»ºç«‹å’Œæ¨¡å‹æ±‚è§£ã€‚æ¨¡å‹çš„å»ºç«‹ï¼šéœ€è¦ç¡®å®šå†³ç­–å˜é‡ï¼ˆæ•´æ•°è§„åˆ’ï¼Œæ··åˆæ•´æ•°è§„åˆ’)ï¼Œç›®æ ‡å‡½æ•°ï¼ˆå¤šç›®æ ‡ï¼‰ï¼Œçº¦æŸæ¡ä»¶ã€‚ æ¨¡å‹çš„æ±‚è§£ï¼š åˆ†å±‚åºåˆ—æ³• ã€‚ è¯¾å ‚èƒŒæ™¯èˆªç­çš„é‡æ’ç­é—®é¢˜ï¼Œæœ€ä¼˜åŒ–é—®é¢˜ï¼Œè¿ç­¹å­¦èŒƒç•´çš„é—®é¢˜ã€‚ çº¦æŸï¼šç®—æ³•èƒ½å¤Ÿåœ¨æ»¡è¶³å¤šç§å®é™…çº¦æŸæ¡ä»¶çš„å‰æä¸‹ï¼Œå¯ä»¥å¯¹èˆªç­è®¡åˆ’è¿›è¡Œæ¢å¤ï¼Œå¹¶å¿«é€Ÿç»™å‡ºæœ€ä¼˜çš„èˆªç­è°ƒæ•´æ›¿æ¢æ–¹æ¡ˆ ï¼› èˆªç­è¿è¡Œä¸æœºç»„ç¼–æ’çš„å„ç±»çº¦æŸæ¡ä»¶ ï¼› æ ¹æ®èˆªç­è®¡åˆ’å¯¹æœºç»„æ’ç­è®¡åˆ’è¿›è¡Œè°ƒæ•´ï¼Œä½¿å¾—æœºç»„çš„èµ„è´¨ç­‰ä¸èˆªç­è®¡åˆ’å¯ä»¥åŒ¹é…ï¼Œ å·èˆªä¸€ä¸ªæœˆå†…çš„å…¨éƒ¨èˆªç­è®¡åˆ’ä¸æœºç»„æ’ç­è®¡åˆ’ å¤‡ç”¨é£æœº æœ‰é™ è°ƒæ•´åˆ†æœºé£è¡Œé¡ºåº èˆªç­å»¶è¿Ÿ ä¸èƒ½æå‰èµ·é£ ä¸èƒ½è¶…è¿‡å»¶è¯¯æ—¶é—´ èˆªç­å–æ¶ˆ å¦‚æœè¶…è¿‡äº†å»¶è¯¯æ—¶é—´ï¼Œç›®æ ‡å‡½æ•°å¢åŠ è°ƒæ•´æˆæœ¬ æ—…å®¢è½¬ç­¾ åªèƒ½ä¸€æ¬¡è½¬ï¼Œè¿˜æœ‰åº§ä½é™åˆ¶ èˆªç­ç›´é£ èˆªç­ç”±äºå¤©æ°”æˆ–æµæ§ç­‰åŸå› æ— æ³•é¡ºç•…è¿è¡Œæ—¶ï¼Œå°†è”ç¨‹èˆªç­ä¸­æ®µå–æ¶ˆç›´é£æœ€ç»ˆç›®çš„åœ°ï¼Œå¹¶å¦¥å–„å¤„ç½®æ—…å®¢æ˜¯èˆªç­è°ƒæ•´æ–¹æ³•ä¹‹ä¸€ã€‚ï¼ˆè”ç¨‹èˆªç­å®šä¹‰ä¸ºï¼Œå‰åæ®µè¡”æ¥å¹¶ä¸”èˆªç­å·ç›¸åŒçš„å¤šä¸ªèˆªç­ï¼‰ æœºç»„è°ƒæ•´ï¼ˆä¸€ï¼‰ å¤‡ä»½æœºç»„åœ¨èˆªç­è®¡åˆ’å‡ºç°æœºç»„å®åŠ›ç¼ºå£æ—¶ï¼Œå¯ä»¥åœ¨èˆªç­çš„å‡ºå‘åœ°å¯»æ‰¾ç©ºé—²æœºç»„ï¼Œå®‰æ’å…¶æ‰§è¡Œè¯¥èˆªç­ã€‚ï¼ˆäºŒï¼‰ è°ƒæ¢æœºç»„å°†å¤šä¸ªæœºç»„çš„èˆªç­è®¡åˆ’è¿›è¡Œè°ƒæ¢ã€‚ï¼ˆä¸‰ï¼‰ æœºç»„æ‘†æ¸¡å½“é‡åˆ°æœºç»„è®¡åˆ’ä¸è¡”æ¥ï¼ˆæœºç»„çš„ä¸Šä¸ªèˆªç­çš„ç›®çš„åœ°ä¸ä¸‹ä¸ªèˆªç­çš„å‡ºå‘åœ°ä¸ä¸€è‡´ï¼‰æ—¶ï¼Œå¯ä»¥é€šè¿‡æ‘†æ¸¡çš„æ–¹å¼ï¼Œé‡‡ç”¨é£æœºæˆ–æ˜¯å…¶ä»–äº¤é€šå·¥å…·åˆ°è¾¾ä¸‹ä¸ªèˆªç­çš„å‡ºå‘åœ°ã€‚ ç›®æ ‡ï¼š å°†èˆªç­è¿è¡Œæƒ…å†µå—åˆ°çš„å½±å“é™åˆ°æœ€ä½ä»è€Œä½¿å¾—èˆªç­ä¸æœºç»„è®¡åˆ’å¾—åˆ°å¿«é€Ÿæ¢å¤ã€å‡å°‘èˆªç­å»¶è¯¯ã€æé«˜èˆªç­æ­£å¸¸ç‡ï¼Œä½¿æ—…å®¢æœ‰æ›´å¥½çš„å‡ºè¡Œä½“éªŒï¼Œå¹¶æå‡å…¬å¸çš„è¿è¡Œæ•ˆç‡ä¸ç»æµæ•ˆç›Šã€‚ èˆªå…¬å…¬å¸ï¼š æŸå¤±æœ€å° æ¸¸å®¢: èˆªç­å»¶æ—¶çŸ­]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux]]></title>
    <url>%2F2019%2F11%2F27%2Flinux%2F</url>
    <content type="text"><![CDATA[linuxå†…æ ¸ï¼Œlinuxå‘è¡Œç‰ˆï¼ˆå¸¦æ¡Œé¢ç¯å¢ƒï¼‰ï¼ŒæœåŠ¡å™¨çš„è®¿é—®æ–¹å¼ï¼ˆä¸‰ç§ï¼‰ï¼Œlinuxæ“ä½œç³»ç»Ÿçš„ç›¸å…³ä½¿ç”¨ï¼Œé€šè¿‡å‘½ä»¤è¡Œå’Œé”®ç›˜è¾“å…¥æå®šï¼ˆç”¨æˆ·æƒé™ï¼Œç”¨æˆ·åˆ†ç»„ï¼Œç”¨æˆ·ä¹‹é—´çš„å…³ç³»ï¼Œç”¨æˆ·æ“ä½œï¼›æ–‡ä»¶ç»“æ„ï¼Œæ–‡ä»¶ä½¿ç”¨ï¼Œæ–‡ä»¶æƒé™ï¼Œæ–‡ä»¶ç¼–è¾‘ï¼Œæ–‡ä»¶å‹ç¼©å’Œè§£å‹ï¼Œè¿™ç³»åˆ—æ“ä½œç±»æ¯”æ“ä½œç³»ç»Ÿï¼Œåªæ˜¯linuxç³»ç»Ÿé‡Œé¢ï¼Œéƒ½æ˜¯å‘½ä»¤è¡Œå®Œæˆï¼Œä¸æ˜¯å¯è§†åŒ–ç•Œé¢ç½¢äº†ï¼›å¸®åŠ©ï¼Œç»ˆæ­¢æ“ä½œï¼Œrootï¼Œsudo,è¶…çº§ç®¡ç†å‘˜ï¼Œç®¡ç†å‘˜ç»„ï¼Œæ™®é€šç”¨æˆ·ï¼‰windowsæ“ä½œç³»ç»Ÿå¯ä»¥å¹²çš„äº‹æƒ…ï¼Œåœ¨linuxæœåŠ¡å™¨é‡Œé¢ï¼Œéƒ½å¯ä»¥å¹²ï¼Œé€šè¿‡å‘½ä»¤è¡Œé…ç½®ï¼Œå®‰è£…ï¼Œå®Œæˆï¼ LinuxLinux çš„ç§‘æ™® Linux æ˜¯ä¸€å¥—å…è´¹ä½¿ç”¨å’Œè‡ªç”±ä¼ æ’­çš„ç±» Unix æ“ä½œç³»ç»Ÿ ï¼Œæ”¯æŒå¤šç”¨æˆ·ï¼Œå¤šä»»åŠ¡ï¼Œæ”¯æŒå¤šçº¿ç¨‹å’Œå¯¹CPUçš„æ“ä½œç³»ç»Ÿã€‚ï¼Œå°±åƒä½ å¤šå°‘å·²ç»äº†è§£çš„ Windowsï¼ˆxpï¼Œ7ï¼Œ8ï¼‰å’Œ Mac OS ã€‚ æˆ–è®¸ä½ ä¹‹å‰ä¸çŸ¥é“ Linux ï¼Œè¦çŸ¥é“ï¼Œä½ ä¹‹å‰åœ¨ Windows ä½¿ç”¨ç™¾åº¦ã€è°·æ­Œï¼Œä¸Šæ·˜å®ï¼ŒèŠ QQ æ—¶ï¼Œæ”¯æ’‘è¿™äº›è½¯ä»¶å’ŒæœåŠ¡çš„ï¼Œæ˜¯åå°æˆåƒä¸Šä¸‡çš„ Linux æœåŠ¡å™¨ä¸»æœºï¼Œå®ƒä»¬æ—¶æ—¶åˆ»åˆ»éƒ½åœ¨å¿™ç¢Œåœ°è¿›è¡Œç€æ•°æ®å¤„ç†å’Œè¿ç®—ï¼Œå¯ä»¥è¯´ä¸–ç•Œä¸Šå¤§éƒ¨åˆ†è½¯ä»¶å’ŒæœåŠ¡éƒ½æ˜¯è¿è¡Œåœ¨ Linux ä¹‹ä¸Šçš„ã€‚ æ˜ç¡®ç›®çš„ï¼šä½ æ˜¯è¦ç”¨ Linux æ¥å¹²ä»€ä¹ˆï¼Œæ­å»ºæœåŠ¡å™¨ã€åšç¨‹åºå¼€å‘ã€æ—¥å¸¸åŠå…¬ï¼Œè¿˜æ˜¯å¨±ä¹æ¸¸æˆï¼› å…¼å…·å›¾å½¢ç•Œé¢æ“ä½œï¼ˆéœ€è¦ä½¿ç”¨å¸¦æœ‰æ¡Œé¢ç¯å¢ƒçš„å‘è¡Œç‰ˆï¼‰å’Œå®Œå…¨çš„å‘½ä»¤è¡Œæ“ä½œï¼Œå¯ä»¥åªç”¨é”®ç›˜å®Œæˆä¸€åˆ‡æ“ä½œï¼Œæ–°æ‰‹å…¥é—¨è¾ƒå›°éš¾ï¼Œéœ€è¦ä¸€äº›å­¦ä¹ å’ŒæŒ‡å¯¼ï¼ˆè¿™æ­£æ˜¯æˆ‘ä»¬è¦åšçš„äº‹æƒ…ï¼‰ï¼Œä¸€æ—¦ç†Ÿç»ƒä¹‹åæ•ˆç‡æé«˜ã€‚ ä¸€èˆ¬å‘½ä»¤è¡Œæ“ä½œï¼Œé€šè¿‡é”®ç›˜å®Œæˆ å› ä¸ºlinuxçš„å“²å­¦å°±æ˜¯ï¼šæ²¡æœ‰ç»“æœå°±æ˜¯æœ€å¥½çš„ç»“æœ å¦‚æœåªæ˜¯æ‰§è¡Œï¼Œæ‰§è¡Œå¤±è´¥ä¼šå‘Šè¯‰ä½ å“ªé‡Œé”™äº†ï¼Œå¦‚æœæ‰§è¡ŒæˆåŠŸé‚£ä¹ˆä¼šæ²¡æœ‰è¾“å‡ºï¼Œå› ä¸ºlinuxçš„å“²å­¦å°±æ˜¯ï¼šæ²¡æœ‰ç»“æœå°±æ˜¯æœ€å¥½çš„ç»“æœ Linuxçš„å‘è¡Œç‰ˆLinuxå‘è¡Œç‰ˆ = linuxå†…æ ¸+åº”ç”¨è½¯ä»¶çš„æ‰“åŒ… çŸ¥åçš„å‘è¡Œç‰ˆï¼š ubuntuï¼Œredhat,centos Linuxç³»ç»Ÿ ç”¨æˆ·ç™»å½•ç³»ç»Ÿ ï¼ˆ1ï¼‰å‘½ä»¤è¡Œ ï¼ˆ2ï¼‰sshç™»å½• SSH ä¸º Secure Shell çš„ç¼©å†™ ï¼Œç”¨äºè¿œç¨‹ç™»é™†çš„åè®® è¿œç¨‹è¿æ¥å·¥å…·å®¢æˆ·ç«¯ï¼šxshell, putty, (3) å›¾å½¢ç•Œé¢ç™»å½• æ–‡ä»¶ç›®å½•ä»¥åŠæƒé™ Linux ä¸­åˆ›å»ºã€åˆ é™¤ç”¨æˆ·ï¼ŒåŠç”¨æˆ·ç»„ç­‰æ“ä½œã€‚ Linux ä¸­çš„æ–‡ä»¶æƒé™è®¾ç½®ã€‚ 1.2 å®éªŒçŸ¥è¯†ç‚¹ Linux ç”¨æˆ·ç®¡ç† Linux æƒé™ç®¡ç† ç”¨æˆ·ç®¡ç† é€šè¿‡ç¬¬ä¸€èŠ‚è¯¾ç¨‹çš„å­¦ä¹ ï¼Œä½ åº”è¯¥å·²ç»çŸ¥é“ï¼ŒLinux æ˜¯ä¸€ä¸ªå¯ä»¥å®ç°å¤šç”¨æˆ·ç™»å½•çš„æ“ä½œç³»ç»Ÿï¼Œæ¯”å¦‚â€œæé›·â€å’Œâ€œéŸ©æ¢…æ¢…â€éƒ½å¯ä»¥åŒæ—¶ç™»å½•åŒä¸€å°ä¸»æœºï¼Œä»–ä»¬å…±äº«ä¸€äº›ä¸»æœºçš„èµ„æºï¼Œä½†ä»–ä»¬ä¹Ÿåˆ†åˆ«æœ‰è‡ªå·±çš„ç”¨æˆ·ç©ºé—´ï¼Œç”¨äºå­˜æ”¾å„è‡ªçš„æ–‡ä»¶ã€‚ä½†å®é™…ä¸Šä»–ä»¬çš„æ–‡ä»¶éƒ½æ˜¯æ”¾åœ¨åŒä¸€ä¸ªç‰©ç†ç£ç›˜ä¸Šçš„ç”šè‡³åŒä¸€ä¸ªé€»è¾‘åˆ†åŒºæˆ–è€…ç›®å½•é‡Œï¼Œä½†æ˜¯ç”±äº Linux çš„ ç”¨æˆ·ç®¡ç†å’Œ æƒé™æœºåˆ¶ï¼Œä¸åŒç”¨æˆ·ä¸å¯ä»¥è½»æ˜“åœ°æŸ¥çœ‹ã€ä¿®æ”¹å½¼æ­¤çš„æ–‡ä»¶ã€‚ åœ¨ Linux ç³»ç»Ÿé‡Œï¼Œ root è´¦æˆ·æ‹¥æœ‰æ•´ä¸ªç³»ç»Ÿè‡³é«˜æ— ä¸Šçš„æƒåˆ©ï¼Œæ¯”å¦‚ æ–°å»º/æ·»åŠ  ç”¨æˆ·ã€‚ sudo adduser lilei åˆ›å»ºç”¨æˆ·ï¼ˆsudo ç»„ï¼‰ æˆ‘ä»¬ä¸€èˆ¬ç™»å½•ç³»ç»Ÿæ—¶éƒ½æ˜¯ä»¥æ™®é€šè´¦æˆ·çš„èº«ä»½ç™»å½•çš„ï¼Œè¦åˆ›å»ºç”¨æˆ·éœ€è¦ root æƒé™ï¼Œè¿™é‡Œå°±è¦ç”¨åˆ° sudo è¿™ä¸ªå‘½ä»¤äº†ã€‚ä¸è¿‡ä½¿ç”¨è¿™ä¸ªå‘½ä»¤æœ‰ä¸¤ä¸ªå¤§å‰æï¼Œä¸€æ˜¯ä½ è¦çŸ¥é“å½“å‰ç™»å½•ç”¨æˆ·çš„å¯†ç ï¼ŒäºŒæ˜¯å½“å‰ç”¨æˆ·å¿…é¡»åœ¨ sudo ç”¨æˆ·ç»„ã€‚ sudoå‘½ä»¤ï¼šè·å¾—rootæƒé™ ç”¨æˆ·ç»„ æŸ¥çœ‹ï¼š åœ¨ Linux é‡Œé¢æ¯ä¸ªç”¨æˆ·éƒ½æœ‰ä¸€ä¸ªå½’å±ï¼ˆç”¨æˆ·ç»„ï¼‰ï¼Œç”¨æˆ·ç»„ç®€å•åœ°ç†è§£å°±æ˜¯ä¸€ç»„ç”¨æˆ·çš„é›†åˆï¼Œå®ƒä»¬å…±äº«ä¸€äº›èµ„æºå’Œæƒé™ï¼ŒåŒæ—¶æ‹¥æœ‰ç§æœ‰èµ„æº ã€‚ groups shiyanlou åŠ å…¥sudoç”¨æˆ·ç»„ su ï¼šåˆ‡æ¢ç”¨æˆ·userï¼Œéœ€è¦è¾“å…¥ç›®æ ‡ç”¨æˆ·å’Œå¯†ç  sudo usermod -G sudo lilei æ–‡ä»¶æ‰€ä»¥è€… su -l lilei su chown ä¿®æ”¹æƒé™ sudo å¯ä»¥ä»¥ç‰¹æƒçº§åˆ«è¿è¡Œ cmd å‘½ä»¤ï¼Œéœ€è¦å½“å‰ç”¨æˆ·å±äº sudo ç»„ï¼Œä¸”éœ€è¦è¾“å…¥å½“å‰ç”¨æˆ·çš„å¯†ç ã€‚ æ–‡æ¡£ç¼–è¾‘ vimç¼–è¾‘å™¨ i esc :wq linuxæ–‡ä»¶ç³»ç»Ÿä¸ç£ç›˜ç®¡ç† $ tree / pwd cd ..: ä¸Šä¸€çº§ç›®å½• ../ /:æ ¹ç›®å½•ï¼šç»å¯¹è·¯å¾„ cd /home/shiyanlou touch test mkdir mydir cpï¼ˆcopyï¼‰å‘½ä»¤å¤åˆ¶ä¸€ä¸ªæ–‡ä»¶åˆ°æŒ‡å®šç›®å½• è¦æˆåŠŸå¤åˆ¶ç›®å½•éœ€è¦åŠ ä¸Š -r æˆ–è€… -R å‚æ•°ï¼Œè¡¨ç¤ºé€’å½’å¤åˆ¶ cd /home/shiyanlou mkdir familyâ€‹ cp -r father family rm test è·Ÿå¤åˆ¶ç›®å½•ä¸€æ ·ï¼Œè¦åˆ é™¤ä¸€ä¸ªç›®å½•ï¼Œä¹Ÿéœ€è¦åŠ ä¸Š `-r` æˆ– `-R` å‚æ•° mv æºç›®å½•æ–‡ä»¶ ç›®çš„ç›®å½• ï¼Œå¯ä»¥ç”¨æ¥é‡å‘½åæ–‡ä»¶ $ cd /home/shiyanlou/ ä½¿ç”¨é€šé…ç¬¦æ‰¹é‡åˆ›å»º 5 ä¸ªæ–‡ä»¶: $ touch file{1..5}.txt æ‰¹é‡å°†è¿™ 5 ä¸ªåç¼€ä¸º .txt çš„æ–‡æœ¬æ–‡ä»¶é‡å‘½åä¸ºä»¥ .c ä¸ºåç¼€çš„æ–‡ä»¶: $ rename â€˜s/.txt/.c/â€˜ *.txt æ‰¹é‡å°†è¿™ 5 ä¸ªæ–‡ä»¶ï¼Œæ–‡ä»¶åå’Œåç¼€æ”¹ä¸ºå¤§å†™: $ rename â€˜y/a-z/A-Z/â€˜ *.c æ–‡ä»¶æ‰“åŒ…å’Œè§£å‹ç¼© zipï¼š æ‰“åŒ… ï¼šzip something.zip something ï¼ˆç›®å½•è¯·åŠ  -r å‚æ•°ï¼‰ è§£åŒ…ï¼šunzip something.zip æŒ‡å®šè·¯å¾„ï¼š-d å‚æ•° tarï¼š æ‰“åŒ…ï¼štar -cf something.tar something è§£åŒ…ï¼štar -xf something.tar æŒ‡å®šè·¯å¾„ï¼š-C å‚æ•°ã€ tar -cf shiyanlou.tar /home/shiyanlou/Desktop -c è¡¨ç¤ºåˆ›å»ºä¸€ä¸ª tar åŒ…æ–‡ä»¶ï¼Œ-f ç”¨äºæŒ‡å®šåˆ›å»ºçš„æ–‡ä»¶åï¼Œæ³¨æ„æ–‡ä»¶åå¿…é¡»ç´§è·Ÿåœ¨ -f å‚æ•°ä¹‹å tar -xf shiyanlou.tar -C tardir è§£åŒ…ä¸€ä¸ªæ–‡ä»¶ï¼ˆ-x å‚æ•°ï¼‰åˆ°æŒ‡å®šè·¯å¾„çš„å·²å­˜åœ¨ç›®å½•ï¼ˆ-C å‚æ•°ï¼‰ tar -xzf shiyanlou.tar.gz | å‹ç¼©æ–‡ä»¶æ ¼å¼ | å‚æ•° || â€”â€”â€”â€”â€”â€” | â€”â€” || *.tar.gz | -z || *.tar.xz | -J || *tar.bz2 | -j | linuxå®‰è£…è½¯ä»¶ è¾“å…¥ï¼Œè¾“å‡º è¾“å…¥ï¼šè¾“å…¥å½“ç„¶å°±æ˜¯æ‰“å¼€ç»ˆç«¯ï¼Œç„¶åæŒ‰é”®ç›˜è¾“å…¥ï¼Œç„¶åæŒ‰å›è½¦ï¼Œè¾“å…¥æ ¼å¼ä¸€èˆ¬å°±æ˜¯è¿™ç±»çš„ è¾“å‡ºï¼š è¾“å‡ºä¼šè¿”å›ä½ æƒ³è¦çš„ç»“æœï¼Œæ¯”å¦‚ä½ è¦çœ‹ä»€ä¹ˆæ–‡ä»¶ï¼Œå°±ä¼šè¿”å›æ–‡ä»¶çš„å†…å®¹ã€‚ å¦‚æœåªæ˜¯æ‰§è¡Œï¼Œæ‰§è¡Œå¤±è´¥ä¼šå‘Šè¯‰ä½ å“ªé‡Œé”™äº†ï¼Œå¦‚æœæ‰§è¡ŒæˆåŠŸé‚£ä¹ˆä¼šæ²¡æœ‰è¾“å‡ºï¼Œå› ä¸ºlinuxçš„å“²å­¦å°±æ˜¯ï¼šæ²¡æœ‰ç»“æœå°±æ˜¯æœ€å¥½çš„ç»“æœ Tab: å‘½ä»¤è¡¥å…¨ Ctrl+C:å¼ºåˆ¶ç»ˆæ­¢ å­¦ä¼šä½¿ç”¨é€šé…ç¬¦ï¼šé€šé…ç¬¦ï¼š*,? å­¦ä¼šåœ¨å‘½ä»¤è¡Œä¸­è·å–å¸®åŠ©ï¼šmanå‘½ä»¤è°ƒç”¨æ‰‹å†Œé¡µï¼Œ åŒºæ®µ è¯´æ˜ 1 ä¸€èˆ¬å‘½ä»¤ 2 ç³»ç»Ÿè°ƒç”¨ 3 åº“å‡½æ•°ï¼Œæ¶µç›–äº†Cæ ‡å‡†å‡½æ•°åº“ 4 ç‰¹æ®Šæ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯/devä¸­çš„è®¾å¤‡ï¼‰å’Œé©±åŠ¨ç¨‹åº 5 æ–‡ä»¶æ ¼å¼å’Œçº¦å®š 6 æ¸¸æˆå’Œå±ä¿ 7 æ‚é¡¹ 8 ç³»ç»Ÿç®¡ç†å‘½ä»¤å’Œå®ˆæŠ¤è¿›ç¨‹ 1man 1 ls 1ls --help]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ¸…æ™°æœ‰æ•ˆçš„æ•°æ®åˆ†ææ€è·¯]]></title>
    <url>%2F2019%2F11%2F26%2F%E6%B8%85%E6%99%B0%E6%9C%89%E6%95%88%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[å¦‚ä½•åšæ•°æ®åˆ†ææ±‡æŠ¥1. æè¿°æ•°æ®çš„è¡¨å¾æè¿°æ€§ç»Ÿè®¡ï¼š å¹³å‡æ•° ä¸­ä½æ•° ä¼—æ•° å‡ ä½•å¹³å‡æ•° è°ƒå’Œå¹³å‡æ•° å¹³å‡å€¼ ä¸­é—´ä½ç½®çš„æ•° å‡ºç°æ¬¡æ•°æœ€å¤š æ–¹å·® æ ‡å‡†å·® åˆ†å¸ƒ å¾—åˆ°ç¬¬ä¸€ä»½æ•°æ®ç»“è®º 2. å¯»æ‰¾å˜åŒ–ï¼Œæ·±å…¥è§‚å¯Ÿå‘ç”Ÿå˜åŒ–çš„æŒ‡æ ‡ä¸€èˆ¬å°±æ˜¯æŒ‡æ ‡å…³è”çš„ä¸šåŠ¡ç¯å¢ƒå‘ç”Ÿäº†æŸç§å˜åŒ–ã€‚é€šè¿‡è§‚å¯Ÿå˜åŒ–é‡ï¼Œå¯»æ‰¾å¯èƒ½çš„ä¸šåŠ¡é—®é¢˜ç‚¹ã€‚ åŒæ¯” å¯¹æ¯”åŒæœŸçš„å˜åŒ– å¦‚ï¼šä¸Šå‘¨äº”å’Œå»å¹´è¿‡å¹´ ç¯æ¯” å¯¹æ¯”è¿ç»­å‘¨æœŸ å¦‚ï¼šä»Šå¤©å’Œæ˜¨å¤©ï¼›æœ¬æœˆå’Œä¸Šæœˆï¼› å¢é•¿ç‡ è¯„ä¼°ç´¯è®¡å‹æŒ‡æ ‡çš„æœ‰åŠ›å·¥å…· å¦‚ï¼šæ”¶å…¥ æ—¶é—´ä¸Šçš„å¯¹æ¯”ï¼Œä¹Ÿç§°ä¸ºçºµæ¯” ï¼šç¯æ¯”ï¼ŒåŒæ¯” åŒçº§å•ä½ä¹‹é—´çš„æ¯”è¾ƒï¼Œç®€ç§°æ¨ªæ¯” ï¼š ä¸åŒçœä»½ä¹‹é—´çš„åˆ†æ å¾—åˆ°ç¬¬äºŒä»½æ•°æ®ç»“è®ºï¼Œå¯ä»¥åˆ†æåˆ°é—®é¢˜æ‰€åœ¨ã€‚ 3.å…¨é¢è¯„ä¼°ï¼Œå¤šç»´åˆ†æå¤šç»´åˆ†æï¼š ç»´åº¦æ˜¯æè¿°æŒ‡æ ‡ ä¸åŒè§’åº¦ï¼Œé€šè¿‡å¤šç»´åˆ†æï¼Œæ¥å¯»æ±‚æŒ‡æ ‡çš„å˜åŒ–çš„å¯ä»¥çš„åŸå› ã€‚ å¹¿ä¹‰çš„å¤šç»´åˆ†æï¼Œä¸ä»…ä»…åŒ…æ‹¬ä»æŒ‡æ ‡çš„ä¸åŒç»´åº¦è¿›è¡Œåˆ†æï¼Œä¹ŸåŒ…å«æ‹†åˆ†ä¸ºå¤šä¸ªå­æŒ‡æ ‡è¿›è¡Œåˆ†æã€‚ æŒ‡æ ‡ä½“ç³»+ç»´åº¦ä½“ç³» åŸºç¡€/é€šç”¨ å¹´é¾„ã€æ€§åˆ«ã€å­¦å†ã€åœ°åŸŸã€æ‰‹æœºå‹å·ã€æ“ä½œç³»ç»Ÿ äº§å“ äº§å“ç±»å‹ã€å½’å±ä¸šåŠ¡ è¿è¥ å½’å±æ¸ é“ã€æŠ•æ”¾å‘¨æœŸã€æ´»åŠ¨ç±»å‹ è¥é”€ å¸‚åœºæ¨å¹¿ã€è¥é”€æ–¹å¼ã€è¥é”€ç›®çš„ å¦‚ç²½å­çš„ç»´åº¦ äº§å“ç»´åº¦ è‚‰ç²½ï¼Œå¤§æ£æ£•ï¼Œç³–æ€» æ¸ é“ç»´åº¦ çº¿ä¸Šï¼šè‡ªæœ‰APP,ç”µå•†æ¸ é“ï¼Œåˆä½œæ¸ é“ï¼›çº¿ä¸‹ï¼šåˆä½œé—¨åº—ï¼Œå¤§å±å¹¿å‘Š æ—¶é—´ç»´åº¦ æŠ•æ”¾å‘¨æœŸï¼›æŠ•æ”¾æ—¶æ®µ åœ°åŸŸç»´åº¦ ç›´è¾–å¸‚ï¼›çœä¼šï¼›äºŒä¸‰çº¿åŸå¸‚ å¹´é¾„ç»´åº¦ å¹´é¾„æ®µ çº¿ä¸Šå…¥å£ splash,banner,å¼¹çª—ï¼Œè§’æ ‡ è¾“å…¥ï¼šç¬¬ä¸‰ä»½ç»“è®ºï¼›å•æŒ‡æ ‡åˆ†æï¼šå¾—åˆ°åˆ†æåˆ°ä¸Šå‡ï¼Œä¸‹é™çš„åŸå› ã€‚ 4. å¤šæŒ‡æ ‡äº¤å‰åˆ†æç»´åº¦åå·®ï¼š å¤§æ•°æ®æ¶‰åŠçš„ç»´åº¦å¾ˆå¤šå•ä¸€ç»´åº¦åˆ†æä¼šå‡ºç°åå·®ï¼Œå¤šä¸ªç»´åº¦ç»„åˆèµ·æ¥çš„æ—¶å€™å¯èƒ½å¾—åˆ°ç›¸åçš„ç»“è®ºã€‚ å¹¸å­˜è€…åå·®ï¼šæ ·æœ¬çš„ä¸¢å¤±é—®é¢˜ ç¬¬å››ä»½åˆ†æç»“è®ºï¼šåˆ†æå¾—åˆ°å‡ºç°çš„é—®é¢˜ï¼Ÿ 5. é‡åŒ–è¯„ä¼°ï¼Œå¯»æ‰¾å½’å› ç›¸å…³æ€§åˆ†æï¼š åœ¨ä¸šåŠ¡ä¸­ï¼Œé€šè¿‡æ˜¯ä¸ºäº†é‡åŒ–è¯„ä¼°å„ç§å› ç´ å¯¹äºæ ¸å¿ƒæŒ‡æ ‡çš„å½±å“ç¨‹åº¦ï¼Œå¯»æ‰¾å¯¹ä¸šåŠ¡å½±å“çš„åŸå› ã€‚ ç›¸å…³æ€§åˆ†æï¼š å•å› ç´ ç›¸å…³æ€§åˆ†æ å¤šå› ç´ çš„ç›¸å…³æ€§åˆ†æ ç¬¬äº”ä»½åˆ†æç»“è®ºï¼š æ‰¾åˆ°äº†æ ¸å¿ƒå½±å“å› ç´ äº† 6. å›åˆ°æœªæ¥ã€è¶‹åŠ¿é¢„æµ‹è¶‹åŠ¿é¢„æµ‹ï¼š é¢„æµ‹åˆ†ææ˜¯ä¸€ç§ç»Ÿè®¡æˆ–æ•°æ®æŒ–æ˜è§£å†³æ–¹æ¡ˆ æ—¶é—´åºåˆ—é¢„æµ‹ï¼šä¸€èˆ¬æ—¶é—´åºåˆ—é¢„æµ‹ï¼›å­£èŠ‚æ€§æ—¶é—´åºåˆ—é¢„æµ‹ï¼›å¤åˆæ—¶é—´åºåˆ—é¢„æµ‹ æ•°å­¦å±‚é¢æ˜¯ä¸¥è°¨çš„ ç”¨ä¸€äº›æ•°æ®é¢„æµ‹æ–¹æ³•å’Œç®—æ³•ï¼šæŒ‡æ•°å¹³æ»‘æ¨¡å‹ ä¸šåŠ¡å±‚é¢æ˜¯æ˜“å˜çš„ å®é™…ä¸šåŠ¡ç¯å¢ƒä¸­ï¼Œå½±å“æœªæ¥å‘å±•çš„è¿˜ä¼šæœ‰è¡Œä¸šç¯å¢ƒçš„çªå˜ï¼Œèµ„æºçš„çªå˜ï¼Œäº§å“å®¢ç¾¤çš„çªå˜ç­‰ï¼Œäººä¸ºçš„å¹²æ‰°è¾ƒå¤§ã€‚ä¸šåŠ¡å±‚é¢çš„è¶‹åŠ¿é¢„æµ‹æ˜¯ä¸ç¨³å®šçš„ï¼Œä¸”æ˜“å˜çš„ å¾—åˆ°ç¬¬äº”ä»½ç»“è®ºï¼šæœªæ¥æ•ˆæœ 7. åˆ†æçš„å®ç›¸ï¼Œè½åœ°ä¸šåŠ¡åˆ†æçš„ç»“è®ºå’Œæ•°æ®é€»è¾‘ä¸ä¸šåŠ¡æ–¹â€”-ç¡®è®¤ï¼Œæ•°æ®åˆ†æä¸€å®šè¦é—­ç¯ï¼Œå³ä»ä¸šåŠ¡ä¸­æ¥ï¼Œåˆ°ä¸šåŠ¡ä¸­å»ã€‚ æŒ‡æ ‡å’Œç»´çš„æ¦‚å¿µ æŒ‡æ ‡ â€‹ æŒ‡æ ‡:è¡¡é‡äº‹ç‰©å‘å±•ç¨‹åº¦çš„å•ä½å’Œæ–¹æ³•ï¼Œä¹Ÿå«åº¦é‡ã€‚å¦‚ï¼šäººå£æ•°ï¼ŒGDP, æ”¶å…¥ï¼Œç”¨æˆ·æ•°ï¼Œåˆ©æ¶¦åˆ©ï¼Œç•™å­˜ç‡ï¼Œè¦†ç›–ç‡ç­‰ã€‚ â€‹ æŒ‡æ ‡åˆ†ä¸ºï¼šç»å¯¹æ•°æŒ‡æ ‡å’Œç›¸å¯¹æ•°æŒ‡æ ‡ã€‚ç»å¯¹æŒ‡æ ‡ï¼šåæ˜ äº†è§„æ¨¡å¤§å°ï¼›ç›¸å¯¹æŒ‡æ ‡ï¼šåæ˜ äº†è´¨é‡å¥½åçš„æŒ‡æ ‡ã€‚ ç»´åº¦ äº‹ç‰©æˆ–è€…ç°è±¡çš„æŸç§ç‰¹å¾ï¼Œå¦‚æ€§åˆ«ï¼Œåœ°åŒºï¼Œæ—¶é—´ã€‚ â€‹ åˆ†ä¸ºå®šé‡ç»´åº¦å’Œå®šæ€§ç»´åº¦ã€‚å®šæ€§ï¼šå­—ç¬¦å‹æ•°æ®ï¼›å®šé‡ï¼šæ•°å€¼å‹ã€‚ åªæœ‰é€šè¿‡äº‹ç‰©å‘å±•çš„æ•°é‡ã€è´¨é‡ä¸¤å¤§æ–¹é¢ï¼Œä»æ¨ªæ¯”ã€çºµæ¯”è§’åº¦è¿›è¡Œå…¨æ–¹ä½çš„æ¯”è¾ƒï¼Œæˆ‘ä»¬æ‰èƒ½å¤Ÿå…¨é¢çš„äº†è§£äº‹ç‰©å‘å±•çš„å¥½å é€šä¿—ä¸¾ä¸ªä¾‹å­ï¼š2019å¹´å„ä¸ªçœçº§çš„ç»æµå‘å±•çŠ¶å†µï¼šGDPæ€»é‡ï¼šæŒ‡æ ‡ï¼›çœä»½ï¼ŒäºŒä¸‰çº¿åŸå¸‚ï¼šç»´åº¦ï¼› â€‹ æ€»ç»“ï¼š æ•°æ®åˆ†æçš„å…¸å‹è¿‡ç¨‹ï¼›æŒ‡æ ‡æ‹†åˆ†ï¼Œç»´åº¦å¯¹æ¯”ï¼› äº§å“ï¼ˆProductï¼‰ï¼Œæ˜¯ç”¨æ¥æ»¡è¶³äººä»¬éœ€æ±‚å’Œæ¬²æœ›çš„ç‰©ä½“æˆ–æ— å½¢çš„è½½ä½“ã€‚äº§å“çš„å®ä½“ç§°ä¸ºä¸€èˆ¬äº§å“ã€‚äº§å“åŒ…å«äº†äº§å“çš„æ ¸å¿ƒåˆ©ç›Šï¼ˆå‘æ¶ˆè´¹è€…æä¾›çš„åŸºæœ¬æ•ˆç”¨å’Œåˆ©ç›Šï¼‰ 1. è½¯ä»¶ï¼Œé€šè®¯ï¼Œæ‰‹æœºï¼Œç§‘æŠ€äº§å“ å¸‚åœºæ˜¯æŒ‡ä¸€ç§è´§ç‰©æˆ–åŠ³åŠ¡çš„æ½œåœ¨è´­ä¹°è€…çš„é›†åˆéœ€æ±‚ã€‚ åœ¨å¸‚åœºè¥é”€ç»„åˆä¸­ï¼Œ 4P åˆ†åˆ«æ˜¯äº§å“( product) ã€ä»·æ ¼( price) ã€åœ°ç‚¹( place) ã€ä¿ƒé”€( promotion) è¥é”€æ˜¯åˆ›é€ ã€æ²Ÿé€šä¸ä¼ é€ä»·å€¼ç»™é¡¾å®¢ï¼ŒåŠç»è¥é¡¾å®¢å…³ç³»ä»¥ä¾¿è®©ç»„ç»‡ä¸å…¶åˆ©ç›Šå…³ç³»äººï¼ˆstakeholderï¼‰å—ç›Šçš„ä¸€ç§ç»„ç»‡åŠŸèƒ½ä¸ç¨‹åºã€‚ é€šä¿—åœ°è®²ï¼Œå°±æ˜¯é€šè¿‡å®£ä¼ ã€æ¨å¹¿ï¼Œè¿›è€Œä¿ƒè¿›äº§å“æˆ–æœåŠ¡çš„é”€å”®ã€‚ äº’è”ç½‘äº§å“å…¬å¸ä¸‰ä¸ªä¸šåŠ¡éƒ¨åˆ†ï¼šäº§å“ï¼ŒæŠ€æœ¯ï¼Œè¿è¥ äº§å“ï¼šæŠŠä¸œè¥¿æƒ³å‡ºæ¥ æŠ€æœ¯ï¼šæŠŠä¸œè¥¿åšå‡ºæ¥ è¿è¥ï¼šæŠŠä¸œè¥¿ç”¨èµ·æ¥ ä»å­—é¢ä¸Šçœ‹ï¼Œè¿ï¼Œæ˜¯è®©äº§å“ç»´æŒè¿è½¬ï¼›è¥ï¼Œæ˜¯è®©äº§å“è¿è½¬å¾—æ›´å¥½ï¼Œå°±æ˜¯è¦å¯¹ç”¨æˆ·ç¾¤ä½“è¿›è¡Œæœ‰ç›®çš„åœ°ç»„ç»‡å’Œç®¡ç†ï¼Œå¢åŠ ç”¨æˆ·æ•°é‡ã€ç”¨æˆ·ç²˜æ€§ã€ç”¨æˆ·è´¡çŒ®å’Œç”¨æˆ·å¿ è¯šåº¦ï¼Œè¿™ä¹Ÿå°±æ¶‰åŠåˆ°è¿è¥å·¥ä½œçš„ä¸‰ä¸ªé‡è¦æ–¹é¢ï¼šæ‹‰æ–°ã€ç•™å­˜ã€ä¿ƒæ´»ã€‚ ç†è§£é—®é¢˜â€”&gt; è®¾è®¡è§£å†³æ–¹æ¡ˆâ€”&gt; è¿­ä»£æ–¹æ¡ˆï¼Œç›´åˆ°é—®é¢˜è§£å†³ æ•°æ®åˆ†æå¸ˆçš„æŠ€èƒ½ä¹‹è·¯ week 01: Excelå­¦ä¹ æŒæ¡ week 02: æ•°æ®å¯è§†åŒ– week 03ï¼š åˆ†ææ€ç»´çš„è®­ç»ƒ week 04: æ•°æ®åº“å­¦ä¹  week 05: ç»Ÿè®¡çŸ¥è¯†å­¦ä¹  week 06: ä¸šåŠ¡å­¦ä¹ ï¼ˆç”¨æˆ·è¡Œä¸ºï¼Œäº§å“ï¼Œè¿è¥ï¼‰ week 07ï¼š Python/Rå­¦ä¹  æ•°æ®åˆ†æåº”æœ‰çš„é€»è¾‘æ€ç»´åŠåˆ†ææ–¹æ³•æå‡ºé—®é¢˜âŸåˆ†æé—®é¢˜âŸæå‡ºå‡è®¾âŸéªŒè¯å‡è®¾âŸè¾“å‡ºç»“è®º 01 ç›®æ ‡æ€ç»´ åœ¨é™ˆè¿°é—®é¢˜æ—¶æ‰€ä½¿ç”¨çš„KWICæ–¹æ³•ï¼Œå…¶å®ä¹Ÿæ˜¯é€»è¾‘è¦ç´ çš„å»¶ä¼¸ï¼š 1ï¼‰Kï¼ˆKEYï¼‰ï¼šæ ¸å¿ƒè§‚ç‚¹ 2ï¼‰Wï¼ˆWidenï¼‰ï¼šæ‰©å±•æ ¸å¿ƒè§‚ç‚¹åŒ…å«çš„å†…å®¹ 3ï¼‰Iï¼ˆIllustrateï¼‰ï¼šä¸¾ä¾‹è¯´æ˜ä½è¯è§‚ç‚¹ 4ï¼‰Cï¼ˆConcludeï¼‰ï¼šæ€»ç»“ 02 ç»“æ„åŒ–æ€ç»´ç»“æ„åŒ–æ€ç»´èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬å°†æ— åºã€æ•£ä¹±çš„ä¿¡æ¯è¿›è¡Œèšç„¦ã€å½’çº³ã€åˆ†ç±»ã€‚ 03 æ¨ç†æ€ç»´ç¡®è®¤è®ºç‚¹ï¼Œç»“æ„åŒ–è®ºæ®ï¼Œä¸‹ä¸€æ­¥æ˜¯è®ºè¯ã€‚åœ¨è®ºè¯ä¸­è¿ç”¨æ¨ç†æ€ç»´èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬è¿…é€Ÿæ‰¾åˆ°é—®é¢˜çš„å¼‚åŒç‚¹ï¼Œä»è€Œå‘ç°å®ƒä»¬çš„è§„å¾‹ã€‚ å½’çº³æ³•ï¼ŒæŒ‡ä»ç‰¹æ®Šï¼ˆéƒ¨åˆ†æ ·æœ¬ï¼‰åˆ°ä¸€èˆ¬ï¼ˆå…¨é‡æ ·æœ¬ï¼‰çš„è¿‡ç¨‹ï¼Œé€šä¿—çš„è¯´æ˜¯ä»ä¸ªåˆ«çš„ç»éªŒå½’çº³å‡ºæ™®éè§„å¾‹çš„æ–¹æ³•ã€‚ è¿™å®è´¨ä¸Šæ˜¯ä»¥åæ¦‚å…¨çš„æ–¹æ³•ï¼Œä¸€æ—¦æœ‰ä¸€ä¸ªç”¨æˆ·ä¸æ»¡è¶³è¿™ä¸ªå‰æï¼Œè¿™ä¸ªç»“è®ºå°±æ— æ³•æˆç«‹ã€‚ åœ¨è¾“å‡ºç»“è®ºä¹‹å‰éœ€è¦åˆ¤æ–­æ ·æœ¬æ˜¯å¦è¶³å¤Ÿæœ‰ä»£è¡¨æ€§ï¼Œåˆ¤æ–­æ˜¯å¿…ç„¶äº‹ä»¶è¿˜æ˜¯éšæœºäº‹ä»¶ã€‚ 3-2ã€æ¼”ç»æ³• æ¼”ç»æ³•åˆ™ä¸å½’çº³æ³•ç›¸å,æ˜¯ä»æ—¢æœ‰ç»è¯å®çš„æ™®éæ€§ç»“è®ºï¼Œæ¨å¯¼å‡ºä¸ªåˆ«æ€§ç»“è®ºçš„ä¸€ç§æ–¹æ³•ï¼Œå¸¸è§çš„è¡¨ç°å½¢å¼æ˜¯é€»è¾‘ä¸‰æ®µè®ºã€‚ é€»è¾‘ä¸‰æ®µè®ºçš„æ ¼å¼ä¸ºï¼šå¤§å‰æã€å°å‰æã€ç»“è®ºã€‚ 3-3ã€å› æœå…³ç³»åˆ†ææ³• æšä¸¾å®Œæ¯•åï¼Œè¾©è¯æ—¶æé—®3ä¸ªé—®é¢˜ï¼š 1ï¼‰åŸå› æ˜¯å¦çœŸå®ï¼Ÿ 2ï¼‰ç»“æœæ˜¯å¦çœŸå® 3ï¼‰è¿™ä¸ªåŸå› ä¸€å®šä¼šå¼•èµ·è¿™ä¸ªç»“æœå—ï¼Ÿæ˜¯å¦æœ‰å…¶ä»–çš„åŸå› ï¼Ÿ æ•°æ®åˆ†æçš„æ–¹æ³•01 æ•°æ®åˆ†æå‰çš„å‡†å¤‡1-1ã€åˆ†æ¸…æ¥šç›®æ ‡å’ŒæŒ‡æ ‡ æ•°æ®åˆ†æï¼Œèƒ½å¸®åŠ©æˆ‘ä»¬äº†è§£ä¸šåŠ¡è¿è¡ŒçŠ¶å†µï¼Œå¹¶ä»ä¸­å‘ç°é—®é¢˜ã€ä¼˜åŒ–é—®é¢˜ã€‚å…¶æ¬¡ï¼Œè¿˜èƒ½å¤Ÿå¸®åŠ©æ´å¯Ÿä¸‹ä¸€ä¸ªå¢é•¿ç‚¹ã€‚ æ•°æ®åˆ†æçš„æ„ä¹‰ï¼Œå¾€å¾€åœ¨æ•°æ®äº§ç”Ÿä¹‹å‰ã€‚æˆ‘ä»¬åº”å›´ç»•äº§å“ç›®æ ‡ï¼Œè¿›è¡Œäº§å“è®¾è®¡ä»¥åŠè¿è¥ç­–åˆ’ã€‚ ç›®æ ‡æ˜¯ç»“æœï¼Œè€ŒæŒ‡æ ‡æ˜¯å¯¹ç»“æœåˆ†æ‹†çš„å…·ä½“è¦æ±‚ï¼Œæ˜¯å¯¹ç›®æ ‡çš„è¡¡é‡ã€‚ å‡è®¾æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æå‡å¹´åº¦æˆäº¤é‡‘é¢ï¼Œé‚£è¡¡é‡è¿™ä¸ªç›®æ ‡çš„æ–¹æ³•æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ æ ¹æ®è¡¡é‡çš„æ–¹æ³•æˆ‘ä»¬æ‰èƒ½å®šå‘çš„è®¾ç½®è°ƒæ•´äº§å“è®¾è®¡åŠè¿è¥ç­–ç•¥ã€‚å¦‚æœç¼ºå°‘å¯è¡¡é‡ç›®æ ‡çš„å•ä½å’Œæ–¹æ³•ï¼Œç›®æ ‡ä¼šéš¾ä»¥è¾¾æˆã€‚ è€Œå›´ç»•ç›®æ ‡è®¾ç½®æ•°æ®çš„é‡‡é›†æ–¹æ¡ˆï¼Œå¯ä»¥å¤§å¤§èŠ‚çœæ•°æ®è¿‡æ»¤å’Œæ¸…æ´—çš„æ—¶é—´ã€‚ ç”šè‡³äºåœ¨æ˜ç¡®æŒ‡æ ‡åå†æœ€å¼€å§‹å°±è®¾ç½®å¥½åˆ†ææ¨¡å‹ï¼Œé€šè¿‡ç›‘æµ‹æ¨¡å‹ä¸­çš„æ•°æ®æƒ…å†µæ›´åŠæ—¶çš„å‘ç°é—®é¢˜ï¼Œåšå‡ºæ›´é«˜è´¨ã€é«˜æ•ˆçš„å†³ç­–ã€‚ 1-2ã€è¾¨åˆ«æŒ‡æ ‡çš„ç›®çš„ ç»“æœæŒ‡æ ‡ç”¨äºè¡¡é‡ç›®æ ‡ï¼Œè¿‡ç¨‹æŒ‡æ ‡ç”¨äºä½“ç°å¦‚ä½•å®Œæˆã€‚è§‚å¯ŸæŒ‡æ ‡åˆ™æŒ‡çš„å—å½±å“æŒ‡æ ‡ï¼Œå…¶æ˜¯å¦ä¼šå—åˆ°è‡ªå˜é‡ï¼ˆç»“æœæŒ‡æ ‡ï¼‰çš„å½±å“ï¼Œå¯¼è‡´ä¸Šå‡æˆ–ä¸‹é™ã€‚ åœ¨ä¸Šå›¾ä¸­ï¼ŒåŸºäºæˆäº¤è®¢å•æ•°ï¼Œè®¾ç½®è¿‡ç¨‹æŒ‡æ ‡ä¸ºè®¢å•å¹³å‡é‡‘é¢åŠå•†å“åˆ†å¸ƒèƒ½å¸®åŠ©æˆ‘ä»¬äº†è§£å®Œæˆçš„æ–¹å¼ã€‚ 1-3ã€ç¡®è®¤åˆ†æç±»å‹ åœ¨å®Œæˆç›®æ ‡å’ŒæŒ‡æ ‡åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯åº”ç”¨ç»“æ„åŒ–æ€ç»´è¿›è¡Œæ‹†è§£å’Œå»¶ä¼¸ã€‚ æ‹†è§£å‡ºçš„æŒ‡æ ‡ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿæ ¹æ®ç›®çš„æˆ‘ä»¬æ‰èƒ½æœ‰å€¾å‘æ€§çš„åˆ†æã€‚ 1ï¼‰æè¿°æ€§åˆ†æ è¡¨ç°å½¢å¼ï¼šæ•°æ®æŠ¥è¡¨ æ•°æ®æŠ¥è¡¨èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬æè¿°äº‹ä»¶å‘å±•çš„æƒ…å†µï¼Œä½†å¾ˆéš¾è§£é‡ŠæŸç§ç»“æœå‘ç”Ÿçš„åŸå› å’Œæœªæ¥å¯èƒ½çš„è¶‹åŠ¿ã€‚ å®ƒæ›´åå‘ç»“æœæ€§çš„æè¿°ï¼Œæ­¤å‰çš„ç»“æœå¯¹æ­¤åæ˜¯ä¸å…·å¤‡å¤ªå¤šå‚è€ƒæ„ä¹‰çš„ã€‚ 2ï¼‰æµ‹æ€§åˆ†æ è¡¨ç°å½¢å¼ï¼šç”¨æˆ·ç›¸ä¼¼åº¦åŠç‰©å“ç›¸ä¼¼åº¦è®¡ç®—ã€ç”¨æˆ·è´­ä¹°é¥±å’Œåº¦ã€ç”¨æˆ·æˆäº¤å½±å“å› å­ é¢„æµ‹æ€§åˆ†æå¯ä»¥ç†è§£ä¸ºå¯¹ç»“æœå’Œå˜é‡çš„å…³ç³»è¿›è¡Œé¢„æµ‹çš„è¿‡ç¨‹ï¼ŒåŒ…å«ç›¸ä¼¼åº¦ã€ç›¸å…³æ€§åˆ†æã€å›å½’åˆ†æç­‰ã€‚ ç›¸ä¼¼åº¦å¤šç”¨äºæ¨èç®—æ³•ï¼Œé€šè¿‡è®¡ç®—ç”¨æˆ·çš„ç›¸ä¼¼åº¦å’Œå•†å“ç›¸ä¼¼åº¦ä»è€Œæ¨èç»™ç”¨æˆ·ã€‚è€Œç›¸å…³åˆ†æç”¨äºé¢„æµ‹å˜é‡çš„å…³è”æ€§ï¼Œå¦‚ç”¨æˆ·çš„æˆäº¤ä¼šå—ä»€ä¹ˆå› ç´ å½±å“ã€‚ 3ï¼‰å®è¯æ€§åˆ†æåŠè§„èŒƒæ€§åˆ†æ è¡¨ç°å½¢å¼ï¼šA/Bå®éªŒ å®è¯æ€§åˆ†æï¼ŒæŒ‡æ˜¯ä»€ä¹ˆï¼Œåå‘äºå®¢è§‚ï¼›è§„èŒƒæ€§åˆ†ææŒ‡åº”å½“åšä»€ä¹ˆï¼Œåå‘äºä¸»è§‚ã€‚ åœ¨å®é™…ä½¿ç”¨è¿‡ç¨‹ï¼Œä¸Šè¿°çš„4ç§åˆ†æç±»å‹å¸¸å¸¸ä¼šè¢«æ··åˆä½¿ç”¨ï¼Œæ··åˆä½¿ç”¨æ—¶åº”æ˜ç¡®ä¸åŒç±»å‹æˆ‘ä»¬åº”é‡‡å–çš„åˆ†æç»´åº¦ã€‚ æ•°æ®åˆ†ææ˜¯æœ‰é¡ºæ‰¿å…³ç³»çš„ï¼Œå…ˆé‡‡é›†äº‹å®ï¼Œå†æ ¹æ®äº‹å®æˆ–è€…é¢„æµ‹ï¼Œæå‡ºæˆ‘ä»¬çš„å‡è®¾ã€‚é€æ­¥ç°åº¦åœ°éªŒè¯å‡è®¾ï¼Œæœ€ç»ˆæ‰è¾“å‡ºæˆ‘ä»¬çš„ç»“è®ºã€‚ ä¸èƒ½å°†ä¸»è§‚çŒœæµ‹å¼ºåŠ äºäº‹å®ä¹‹ä¸Šï¼Œå·²ç»å‘ç”Ÿçš„ç»“æœå¹¶ä¸ä¸€å®šæ˜¯æœªæ¥çš„ç»“æœ 02 æ•°æ®åˆ†æå¦‚ä½•å¸¦æ¥é•¿æœŸä»·å€¼ ä¸ºäº†ä½¿æœ‰ç”¨åŠŸæ›´å¤šï¼Œä¸‹æ–‡å°†ä»ç”¨æˆ·å’Œæ”¶ç›Š2ä¸ªç»´åº¦åˆ†äº«æ•°æ®å¦‚ä½•ä¸ºæˆ‘ä»¬æ²‰æ·€é•¿æœŸä»·å€¼ã€‚ 2-1ã€äº†è§£æˆ‘ä»¬çš„ç”¨æˆ· 1ï¼‰åŸºç¡€ä¿¡æ¯ åŸºç¡€ä¿¡æ¯ï¼ŒæŒ‡ç”¨æˆ·æœ¬èº«çš„å±æ€§ã€‚ èº«ä»½ç‰¹å¾ï¼Œå¯ä»¥ä»è‡ªç„¶å±æ€§ã€ç¤¾ä¼šå±æ€§å‘ä¸‹ç»†åˆ†ï¼ŒåŒ…å«ç”¨æˆ·çš„æ€§åˆ«ã€å¹´é¾„ã€èŒä¸šã€æ•™è‚²ç­‰ã€‚ æ¸ é“å±æ€§ï¼ŒæŒ‡ç”¨æˆ·çš„æ³¨å†Œæ—¶é—´ã€æ³¨å†Œå¹³å°ã€æ³¨å†Œæ¥æºç­‰ã€‚ 2ï¼‰å†³ç­–ç±»å‹ å†³ç­–ç±»å‹ï¼Œä¸»è¦åˆ†ä¸ºå†³ç­–å‘¨æœŸã€å“ç±»åå¥½ã€ä¿ƒé”€åå¥½ã€å¯¹è±¡åå¥½ï¼Œè¿™æ˜¯ç”¨æˆ·åˆ†æä¸­å¸¸å¸¸è¢«å¿½ç•¥çš„ä¸€æ–¹é¢ã€‚ å†³ç­–å‘¨æœŸä¸­çš„é¦–æ¬¡è®¿é—®ï¼ŒæŒ‡çš„é¦–æ¬¡è§¦åŠè¯¥å•†å“çš„æ—¶é—´ã€‚ç»“åˆæ¬¡æ•°ã€æ—¶é•¿ä»¥åŠæˆäº¤æ—¶é—´ï¼Œä»è€Œäº†è§£ç”¨æˆ·çš„å†³ç­–å‘¨æœŸã€‚ å“ç±»åå¥½ï¼Œç»“åˆå“ç‰Œå’Œå†å²æˆäº¤å•æ•°ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬è·æ‚‰å“ç‰Œã€ä»·æ ¼ç»¼åˆå¯¹ç”¨æˆ·çš„å½±å“ã€‚ è€Œæˆäº¤å“ç±»ã€å•†å“ã€å•æ•°åˆ™æ˜¯å¸®åŠ©æˆ‘ä»¬ç†è§£å…¶å“ç±»è´­ä¹°æ·±åº¦åŠè·¯å¾„ï¼Œç”¨äºè¿›è¡Œå…³è”æ¨èå’Œè¯„åˆ¤ç”¨æˆ·çš„ä»·å€¼ã€‚ ä¿ƒé”€åå¥½ï¼Œç»“åˆå“ç±»å’ŒæŠ˜æ‰£é‡‘é¢äº†è§£ç”¨æˆ·çš„æ•æ„Ÿåº¦ï¼Œèƒ½æ›´å¥½çš„æé«˜å…¶è½¬åŒ–ç‡ã€‚å¯¹è±¡åå¥½ï¼ŒåŒæ ·æ˜¯äº†è§£è´­ä¹°æ·±åº¦åŠè·¯å¾„ï¼Œä¸è¿‡ç»´åº¦ä¸åŒã€‚ åœ¨ç”¨æˆ·å±‚é¢çš„åˆ†æï¼Œæ­¤å‰æ¥è§¦çš„ä¸€äº›æœ‹å‹éƒ½éå¸¸çƒ­è¡·äºä½¿ç”¨RFMæ¨¡å‹ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ä¹Ÿåº”â€œå› åœ°åˆ¶å®œâ€ã€‚ 3ï¼‰è´­ä¹°è·¯å¾„ å“ç±»æ·±åº¦ã€å¯¹è±¡æ·±åº¦æ˜¯å½±å“å†³ç­–ç±»å‹çš„å› å­ï¼Œå½“å®ƒä»¬åœ¨è´­ä¹°è·¯å¾„æ—¶åˆ™èšç„¦äºæ¬¡åºã€‚ æ ¹æ®æ¬¡åºï¼Œåˆ¶å®šè¿è¥çš„å‘åŠ›ç‚¹ï¼Œå†éµå¾ªç”¨æˆ·çš„è´­ä¹°è·¯å¾„åˆ¶å®šè½¬åŒ–è·¯å¾„ã€‚ åœ¨ç”¨æˆ·åˆ†å¸ƒç›¸å¯¹ç¨³å®šçš„å‰æä¸‹ï¼Œåº”é¡ºä»ç”¨æˆ·çš„è´­ä¹°è§„å¾‹è€Œéå€¾åŠ›äºå¦ä¸€æ¡ä¸»çº¿ã€‚ ä¸€ä¸“å¤šå¼ºçš„å‰ææ˜¯ä¸“ï¼Œåªæœ‰èšç„¦ä¼˜åŠ¿å“ç±»æˆ–ä¸»é¢˜å»ºç«‹äº†ä¼˜åŠ¿ï¼Œæ‰èƒ½ä¸ºå…¶ä»–çš„æ–¹å‘ä¾›åº”ç‚®å¼¹ã€‚ 4ï¼‰å¢é•¿è§‚å¯Ÿ å‰é¢è§£å†³çš„é—®é¢˜æ˜¯ï¼šä»–æ˜¯è°ï¼Œä¹°ä»€ä¹ˆä»¥åŠæ€ä¹ˆä¹°ã€‚æœ€åä¸€ç‚¹ï¼Œåˆ™æ˜¯å¢é•¿è§‚å¯Ÿã€‚ è´­ä¹°è·¯å¾„èšç„¦äºæ¬¡åºï¼Œå¢é•¿è§‚å¯Ÿèšç„¦äºæ·±åº¦ã€‚è´­ä¹°çš„æ¬¡åºæ˜¯è¿è¥çš„ä¸»çº¿ï¼Œè´­ä¹°çš„æ·±åº¦ç”¨äºç²¾ç»†åŒ–è¿è¥ã€‚ äº†è§£ç”¨æˆ·åœ¨å“ç±»å’Œå¯¹è±¡çš„è´­ä¹°æ·±åº¦ï¼Œå†è¾…ä»¥ARPUä¸LTVçš„æ¯”å¯¹ï¼Œä»ç”¨æˆ·çš„å‰©ä½™æ½œåŠ›å¯»æ‰¾å¹³å°å¢é•¿ç‚¹çš„æ–¹å¼ã€‚ 2-2ã€å»ºç«‹ä½ çš„ç”¨æˆ·æ¨¡å‹ å½“æ—¶æˆ‘æŠŠå¹³å°ç”¨æˆ·çš„åœ°åŸŸå¹´é¾„ã€æ€§åˆ«ç­‰åˆ†å¸ƒä»‹ç»äº†ä¸€ç•ªã€‚ç´§æ¥ç€ä»–æé—®ï¼šâ€œæ ¹æ®è¿™æ ·çš„ç”»åƒä½ èƒ½å¤Ÿåšä»€ä¹ˆå‘¢ï¼Ÿâ€ åŸºäºå¯¹ç”¨æˆ·çš„è®¤è¯†å»ºç«‹æ¨¡å‹ï¼Œä»¥ä¸Šä¸€å°èŠ‚çš„å†³ç­–æ¨¡å‹ä¸ºä¾‹ã€‚ å°†å†³ç­–ç±»å‹ã€å“ç±»åå¥½ã€å¯¹è±¡åå¥½ã€ä¿ƒé”€åå¥½4ä¸ªå› å­çš„å…³è”ï¼Œå¹¶è¾…ä»¥ç”¨æˆ·çš„åŸºç¡€ä¿¡æ¯è¿›è¡Œç»„åˆã€‚ å¦‚ï¼šâ€œç²¾æ‰“ç»†ç®—ã€ä¸“æ³¨å¤§ç‰Œã€ç–¼çˆ±å­©å­çš„æ¯äº²â€ã€‚ è¿™æ ·ä¸€æ¥å†°å†·çš„æ•°æ®ä¹Ÿè¢«èµ‹äºˆäº†æƒ…æ„ŸåŒ–çš„è¡¨è¾¾ï¼Œæ— è®ºæ˜¯äº§å“è®¾è®¡ã€äº¤äº’è®¾è®¡ã€äº§å“è¿è¥éƒ½ä¼šå˜å¾—å®¹æ˜“çš„å¤šã€‚ å»ºç«‹èµ·ç”¨æˆ·æ¨¡å‹ï¼Œæ‰èƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œæƒ…æ„ŸåŒ–è®¾è®¡ã€ç²¾ç»†åŒ–è¿è¥ã€‚ https://mp.weixin.qq.com/s/eWYiHNJ57aXtqygitnwVqw æ•°æ®åˆ†æçš„æµç¨‹]]></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>æ•°æ®åˆ†æ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apriori]]></title>
    <url>%2F2019%2F11%2F25%2FApriori%2F</url>
    <content type="text"><![CDATA[Apriori ç®—æ³•æ˜¯ä¸€ç§æŒ–æ˜å…³è”è§„åˆ™çš„é¢‘ç¹é¡¹é›†çš„ç®—æ³•ã€‚ å¼•è¨€å¯¹äºç‰¹å¾æ„æˆçš„é›†åˆ$A$, å¦‚æœåˆ—å‡ºéç©ºé›†åˆæœ‰$a^{|A|}-1$ç§ï¼Œå¤ªææ€–äº†ã€‚ Apriorç®—æ³•ï¼šæ ¸å¿ƒæƒ³æ³•æ˜¯ L_1æ˜¯é¢‘ç¹çš„ï¼Œåˆ™å…¶å­é›†ä¹Ÿæ˜¯é¢‘ç¹çš„ã€‚ L_1æ˜¯éé¢‘ç¹çš„ï¼Œåˆ™å…¶è¶…é›†æ˜¯éé¢‘ç¹çš„ è¿™æ ·çš„åŒ–ï¼Œå°±å¤§å¤§å‡å°äº†æœç´¢ç©ºé—´äº†ã€‚ Apriorç®—æ³•çš„è¿‡ç¨‹ï¼š $C_i$ï¼šè¡¨ç¤ºæ•°æ®é›†ç”Ÿæˆå€™é€‰é¡¹é›† $L_i$:è¡¨ç¤ºç”Ÿæˆçš„é¢‘ç¹é¡¹é›† $C_{k-1}$äº§ç”Ÿ$L_k$ æ”¯æŒåº¦ support(\{A,B\}) = num\{AUB\}/W = P(A \ bing \ B)W:æ€»çš„è®°å½•ï¼Œ ç½®ä¿¡åº¦ Confidence(A->B) = support(\{A,B\})/support(B) = P(B/A)æ³¨æ„ï¼šsupport(B)å’ŒConfidence(A-&gt;B)çš„å½±å“ï¼Œ åºåˆ—æ¨¡å‹è€ƒè™‘æ—¶é—´ï¼Œå¦‚å‘¨ä¸€ä¹°ä¸€å †å¯¹è±¡ï¼Œå‘¨äºŒä¹°ä¸€å †ä¸œè¥¿ t= {t_1,t_2,..,t_n}\\ s = {s_1,s_2,..,s_n}&lt;{s1},{s_2}&gt;æ˜¯æ­£ç¡®çš„ &lt;{s1,s2}}&gt;æ˜¯é”™è¯¯çš„è¡¨è¾¾]]></content>
      <categories>
        <category>æ•°æ®æŒ–æ˜</category>
      </categories>
      <tags>
        <tag>å…³è”è§„åˆ™</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç®€å•çš„æ•°æ®æ¢ç´¢]]></title>
    <url>%2F2019%2F11%2F20%2F%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[ç®€å•çš„æ¢ç´¢æ•°æ®çš„æ–¹æ³•æ€»ç»“ä¸€äº›ç®€å•çš„æ•°æ®åˆ†ææ–¹æ³•ï¼Œä»¥åŠå¸¸ç”¨çš„python åº“ Pandasé‡Œé¢ç›¸åº”çš„å‡½æ•°ã€‚ ç»Ÿè®¡æ±‡æ€»å•ä¸ªç‰¹å¾1decrible() # ç»™å‡ºæ ·æœ¬çš„åŸºæœ¬ç»Ÿè®¡é‡ é¢‘ç‡ ä¼—æ•° ç™¾åˆ†ä½æ•° ä½ç½®åº¦é‡ å‡å€¼å’Œæ–¹å·® æ•£å¸ƒåº¦é‡ï¼š æå·®å’Œæ–¹å·®]]></content>
      <categories>
        <category>æ•°æ®æŒ–æ˜</category>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>æ•°æ®æ¢ç´¢</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F11%2F15%2Ftest%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[è‹±è¯­Daily]]></title>
    <url>%2F2019%2F08%2F25%2F%E8%8B%B1%E8%AF%ADDaily%2F</url>
    <content type="text"><![CDATA[20200905ä¸Šæ˜ŸæœŸæˆ‘å»çœ‹æˆã€‚æˆ‘çš„åº§ä½å¾ˆå¥½ï¼Œæˆå¾ˆæœ‰æ„æ€ï¼Œä½†æˆ‘å´æ— æ³•æ¬£èµã€‚ä¸€é’å¹´ç”·å­ä¸ä¸€é’å¹´å¥³å­ååœ¨æˆ‘çš„èº«åï¼Œå¤§å£°åœ°è¯´ç€è¯ã€‚æˆ‘éå¸¸ç”Ÿæ°”ï¼Œå› ä¸ºæˆ‘å¬ä¸è§æ¼”å‘˜åœ¨è¯´ä»€ä¹ˆã€‚æˆ‘å›è¿‡å¤´å»æ€’è§†ç€é‚£ä¸€ç”·ä¸€å¥³ï¼Œä»–ä»¬å´æ¯«ä¸ç†ä¼šã€‚æœ€åï¼Œæˆ‘å¿ä¸ä½äº†ï¼Œåˆä¸€æ¬¡å›è¿‡å¤´å»ï¼Œç”Ÿæ°”åœ°è¯´ï¼šâ€æˆ‘ä¸€ä¸ªå­—ä¹Ÿå¬ä¸è§äº†ï¼â€ â€œä¸å…³ä½ çš„äº‹ï¼Œâ€é‚£ç”·çš„æ¯«ä¸å®¢æ°”åœ°è¯´ï¼Œâ€è¿™æ˜¯ç§äººé—´çš„è°ˆè¯ï¼â€]]></content>
      <categories>
        <category>è‹±è¯­</category>
      </categories>
      <tags>
        <tag>æ–°æ¦‚å¿µ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Basics]]></title>
    <url>%2F2019%2F05%2F28%2FPython-basic%2F</url>
    <content type="text"><![CDATA[é‡æ–°å­¦ä¹ å¼€å§‹å¾ˆä¹±çš„å­¦ä¹ Pythonï¼Œç°åœ¨æƒ³ç³»ç»Ÿå­¦ä¹ åŸºç¡€ï¼ŒçœŸæ­£äº†è§£pythonic,]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å­¦ä¹ ã®å†ç¨‹]]></title>
    <url>%2F2019%2F05%2F22%2FPandas%20%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Pandas åšæ•°æ®åˆ†æhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv æˆ‘è¦å¤§å±å¹•ï¼Œæ–‡æ¡£+ç¼–ç¨‹ï¼ä¸€è¾¹çœ‹ï¼Œä¸€è¾¹å†™ï¼Œä¸ç„¶ï¼Œä¸ç†Ÿæ‚‰çš„ï¼ Step 1: è¯»å–æ–‡ä»¶ csv/txt names: columnsï¼Œå½“namesæ²¡è¢«èµ‹å€¼æ—¶ï¼Œheaderä¼šå˜æˆ0ï¼Œå³é€‰å–æ•°æ®æ–‡ä»¶çš„ç¬¬ä¸€è¡Œä½œä¸ºåˆ—åã€‚å½“ names è¢«èµ‹å€¼ï¼Œheader æ²¡è¢«èµ‹å€¼æ—¶ï¼Œé‚£ä¹ˆheaderä¼šå˜æˆNoneã€‚å¦‚æœéƒ½èµ‹å€¼ï¼Œå°±ä¼šå®ç°ä¸¤ä¸ªå‚æ•°çš„ç»„åˆåŠŸèƒ½ã€‚header = 0:æ˜¯ç¬¬ä¸€è¡Œæ˜¯åå­— sep=â€˜\tâ€™ header=None:æŒ‡å®šåˆ—åï¼Œæ•°æ®å¼€å§‹è¡Œæ•°ã€‚é»˜è®¤0è¡Œ;None = æ— æ ‡é¢˜ index_col :Noneï¼› æŒ‡å®šåˆ—ä½œä¸ºè¡Œç´¢å¼• æ•°å€¼ã€‚ Falseè¡¨ç¤ºæ— ç´¢å¼• usecols ; å¦‚æœåˆ—æœ‰å¾ˆå¤šï¼Œè€Œæˆ‘ä»¬ä¸æƒ³è¦å…¨éƒ¨çš„åˆ—ã€è€Œæ˜¯åªè¦æŒ‡å®šçš„åˆ—å°±å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‚æ•°ã€‚ prefix .prefix å‚æ•°ï¼Œå½“å¯¼å…¥çš„æ•°æ®æ²¡æœ‰ header æ—¶ï¼Œè®¾ç½®æ­¤å‚æ•°ä¼šè‡ªåŠ¨åŠ ä¸€ä¸ªå‰ç¼€ã€‚ https://www.jianshu.com/p/42f1d2909bb6 Step 2: ç¼ºçœå€¼å¤„ç†1. dropDataFrame.drop(*self*, *labels=None*, *axis=0*, index=None**, columns=None, level=None, inplace=False, errors=â€™raiseâ€™)** Parameters labels single label or list-like Index or column labels to drop. axis {0 or â€˜indexâ€™, 1 or â€˜columnsâ€™}, default 0 Whether to drop labels from the index (0 or â€˜indexâ€™) or columns (1 or â€˜columnsâ€™). index single label or list-like Alternative to specifying axis (labels, axis=0 is equivalent to index=labels).New in version 0.21.0. columns single label or list-like Alternative to specifying axis (labels, axis=1 is equivalent to columns=labels).New in version 0.21.0. level int or level name, optional For MultiIndex, level from which the labels will be removed. inplace bool, default False If True, do operation inplace and return None. errors{â€˜ignoreâ€™, â€˜raiseâ€™}, default â€˜raiseâ€™ If â€˜ignoreâ€™, suppress error and only existing labels are dropped. 2. dropnaDataFrame.dropna(*self*, *axis=0*, *how=â€™anyâ€™*, thresh=None**, *subset=None*, *inplace=False*)**4 3. isna()DataFrame.isna(*self*) å¡«å…… 4. fillna()DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs) å¡«å……ç©ºå€¼ï¼Œvalueså¯ä»¥æ˜¯å­—å…¸ values = {â€˜Aâ€™: 0, â€˜Bâ€™: 1, â€˜Câ€™: 2, â€˜Dâ€™: 3} dropä½¿ç”¨ dropnaåˆ é™¤ç¼ºçœå€¼ df = df.drop(some labels) df = df.drop(df[].index) â€‹ axis: 0(index) â€‹ how: any all â€‹ subset: label â€‹ inplace : bool dropåˆ é™¤ drop(labels(index, column labels), axis=0(è¡Œ), level=None, inplace=False, errors=â€™raiseâ€™) â€‹ axis: label â€‹ index, columns fillna å¡«å…… â€‹ fillna(value, method, limit) Step 3: é€‰å–å­—æ®µ åˆ— df[labels] è¡Œ df.loc[index_label,] df.iloc[æ•´æ•°å€¼,] åˆ—[â€œâ€] ä¹Ÿå¯ä»¥ä¼ å…¥æ¡ä»¶è¯­å¥ æè¿°æ€§ç»Ÿè®¡å‡½æ•°sum().mean().count()â€‹ axis:1;æŒ‰åˆ—æ±‚å’Œï¼Œæ°´å¹³çº¿ ã€‚å¾€å³çœ‹ï¼›æ‰€æœ‰åˆ—è®¡ç®— â€‹ axis:0; æŒ‰è¡Œæ±‚å’Œ, å‚ç›´çº¿ï¼›æŠŠå­—æ®µçš„æ‰€æœ‰çš„æ‰€æœ‰è¡Œå’Œã€‚å¾€ä¸‹æŒ‰ ï¼›æ‰€æœ‰è¡Œè®¡ç®— .describle() .transpose()åŠŸèƒ½æ€§å‡½æ•°groupby[].å¤šä¸ªDataFameå½’å¹¶â€‹ ### pd.merge(left, right, how=â€™inneräº¤é›†/Outerå¹¶é›†ï¼ˆå­˜åœ¨ä¸é‡åˆçš„keyæ˜¯â€™, on=â€™keyâ€™å¯ä»¥æ˜¯ä¸€ä¸ªåˆ—è¡¨[]) .apply()æ–¹æ³• ä¼ å…¥å‡½æ•°åï¼šç„¶åæ¯ä¸€ä¸ªå…ƒç´ éƒ½èƒŒè®¡ç®—â€‹ lambda x : x*x æ’åº .sort_values()æ•´ä¸ªè¡¨æ ¼éƒ½è¿™ä¹ˆæ’åˆ— DataFrame.sort_values(by=[lables],axis=[0,1], ascending:, kind:æ’åºç®—æ³•ï¼Œ) æ—¥æœŸç±»å‹: æ—¥æœŸç­‰æ•°å€¼å¤„ç†stråˆ—è½¬æ¢æˆæ—¥æœŸç±»å‹ pd.to_datetimeæ³¨æ„éæ—¥æœŸç±»å‹çš„ç‰¹æ®Šå¤„ç† 12345678df[&apos;æ—¥æœŸæ—¶é—´&apos;] = pd.to_datetime(df[&apos;æ—¥æœŸæ—¶é—´&apos;],format=&apos;%Y/%m/%d %H:%M:%S&apos;) #è·å– æ—¥æœŸæ•°æ® çš„å¹´ã€æœˆã€æ—¥ã€æ—¶ã€åˆ†df[&apos;å¹´&apos;] = df[&apos;æ—¥æœŸæ—¶é—´&apos;].dt.yeardf[&apos;æœˆ&apos;] = df[&apos;æ—¥æœŸæ—¶é—´&apos;].dt.monthdf[&apos;æ—¥&apos;] = df[&apos;æ—¥æœŸæ—¶é—´&apos;].dt.daydf[&apos;æ—¶&apos;] = df[&apos;æ—¥æœŸæ—¶é—´&apos;].dt.hourdf[&apos;åˆ†&apos;] = df[&apos;æ—¥æœŸæ—¶é—´&apos;].dt.minute æŒ‡å®šç±»å‹â€‹ method1 df1[â€˜year_monthâ€™] = df1[â€˜dateâ€™].apply(lambda x : x.strftime(â€˜%Y-%mâ€™)) â€‹ method2 df1[â€˜periodâ€™] = df1[â€˜dateâ€™].dt.to_period(â€˜Mâ€™) å‚æ•° M è¡¨ç¤ºæœˆä»½ï¼ŒQ è¡¨ç¤ºå­£åº¦ï¼ŒA è¡¨ç¤ºå¹´åº¦ï¼ŒD è¡¨ç¤ºæŒ‰å¤© strp/ftimeå­—ç¬¦ä¸²å’Œæ—¥æœŸçš„è½¬æ¢ strftime: time-&gt;str strptime: str-&gt;time datetime.timedeltaè¡¨ç¤ºæ—¶é—´é—´éš”ï¼Œä¸¤ä¸ªæ—¶é—´ç‚¹ä¹‹é—´çš„é•¿åº¦ï¼Œä¸»è¦ç”¨äºæ—¶é—´è®¡ç®—,å¦‚æ—¶é—´åºåˆ—é¢„æµ‹çš„æ—¶å€™ï¼Œéœ€è¦å¤–æ¨ï¼Œå¯èƒ½æ¶‰åŠåˆ°æ—¶é—´çš„è®¡ç®—1timedelta(weeks=0, days=0, hours=0, minutes=0, seconds=0, milliseconds=0, microseconds=0, ) #ä¾æ¬¡ä¸º "å‘¨" "å¤©", "æ—¶","åˆ†","ç§’","æ¯«ç§’","å¾®ç§’" datetimeæ¨¡å— ç±»å‹ è¯´æ˜ date ä»¥å…¬å†å½¢å¼å­˜å‚¨æ—¥å†æ—¥æœŸï¼ˆå¹´ã€æœˆã€æ—¥ï¼‰ time å°†æ—¶é—´å­˜å‚¨ä¸ºæ—¶ã€åˆ†ã€ç§’ã€æ¯«ç§’ datetime å­˜å‚¨æ—¥æœŸå’Œæ—¶é—´ 1ï¼‰pythonæ ‡å‡†åº“å‡½æ•° æ—¥æœŸè½¬æ¢æˆå­—ç¬¦ä¸²ï¼šåˆ©ç”¨str æˆ–strftime å­—ç¬¦ä¸²è½¬æ¢æˆæ—¥æœŸï¼šdatetime.strptime 12345678910stamp = datetime(2017,6,27)str(stamp) '2017-06-27 00:00:00'stamp.strftime('%y-%m-%d')#%Yæ˜¯4ä½å¹´ï¼Œ%yæ˜¯2ä½å¹´ '17-06-27'#å¯¹å¤šä¸ªæ—¶é—´è¿›è¡Œè§£ææˆå­—ç¬¦ä¸²date = ['2017-6-26','2017-6-27']datetime2 = [datetime.strptime(x,'%Y-%m-%d') for x in date]datetime2[datetime.datetime(2017, 6, 26, 0, 0), datetime.datetime(2017, 6, 27, 0, 0)] 3ï¼‰pandaså¤„ç†æˆç»„æ—¥æœŸ pandasé€šå¸¸ç”¨äºå¤„ç†æˆç»„æ—¥æœŸï¼Œä¸ç®¡è¿™äº›æ—¥æœŸæ˜¯DataFrameçš„è½´ç´¢å¼•è¿˜æ˜¯åˆ—ï¼Œto_datetimeæ–¹æ³•å¯ä»¥è§£æå¤šç§ä¸åŒçš„æ—¥æœŸè¡¨ç¤ºå½¢å¼ã€‚ datetime æ ¼å¼å®šä¹‰ ä»£ç  è¯´æ˜ %Y 4ä½æ•°çš„å¹´ %y 2ä½æ•°çš„å¹´ %m 2ä½æ•°çš„æœˆ[01,12] %d 2ä½æ•°çš„æ—¥[01ï¼Œ31] %H æ—¶ï¼ˆ24å°æ—¶åˆ¶ï¼‰[00,23] %l æ—¶ï¼ˆ12å°æ—¶åˆ¶ï¼‰[01,12] %M 2ä½æ•°çš„åˆ†[00,59] %S ç§’[00,61]æœ‰é—°ç§’çš„å­˜åœ¨ %w ç”¨æ•´æ•°è¡¨ç¤ºçš„æ˜ŸæœŸå‡ [0ï¼ˆæ˜ŸæœŸå¤©ï¼‰ï¼Œ6] %F %Y-%m-%dç®€å†™å½¢å¼ä¾‹å¦‚ï¼Œ2017-06-27 %D %m/%d/%yç®€å†™å½¢å¼ å­—ç¬¦ä¸²è½¬æ¢æˆdatetimeæ ¼å¼: strptimedatetime.strptime(str, â€˜%Y/%m/%dâ€™).date() datetimeå˜å›stringæ ¼å¼: strftime1234567df = pd.DataFrame(&#123;&quot;y&quot;: [1, 2, 3]&#125;,... index=pd.to_datetime([&quot;2000-03-31 00:00:00&quot;,... &quot;2000-05-31 00:00:00&quot;,... &quot;2000-08-31 00:00:00&quot;]))&gt;&gt;&gt; df.index.to_period(&quot;M&quot;)PeriodIndex([&apos;2000-03&apos;, &apos;2000-05&apos;, &apos;2000-08&apos;], dtype=&apos;period[M]&apos;, freq=&apos;M&apos;) 1â€”pd.Period()å‚æ•°ï¼šä¸€ä¸ªæ—¶é—´æˆ³ç”Ÿæˆå™¨ Step 4: æ•°æ®é€æè¡¨ pivot_table.pivot_table æ•°æ®é€æè¡¨ åˆ†ç±»æ±‡æ€»çš„ç»Ÿè®¡æ•°æ®â€‹ (data,values= column to aggregate optional, index = grouper, columns=grouper, aggfunc:np.sum ) â€‹ table = pd.pivot_table(df, values=[â€˜Dâ€™, â€˜Eâ€™], index=[â€˜Aâ€™, â€˜Câ€™], aggfunc={â€˜Dâ€™: np.mean, â€˜Eâ€™: np.mean}) .groupby() ç”±äºé€šè¿‡groupby()å‡½æ•°åˆ†ç»„å¾—åˆ°çš„æ˜¯ä¸€ä¸ªDataFrameGroupByå¯¹è±¡ï¼Œè€Œé€šè¿‡å¯¹è¿™ä¸ªå¯¹è±¡è°ƒç”¨get_group()ï¼Œè¿”å›çš„åˆ™æ˜¯ä¸€ä¸ªÂ·DataFrameÂ·å¯¹è±¡ï¼Œæ‰€ä»¥å¯ä»¥å°†DataFrameGroupByå¯¹è±¡ç†è§£ä¸ºæ˜¯å¤šä¸ªDataFrameç»„æˆçš„ã€‚ 12grouped = df.groupby('Gender')grouped_muti = df.groupby(['Gender', 'Age']) 123456789print(grouped.get_group('Female'))print(grouped_muti.get_group(('Female', 17))) Name Gender Age Score2 Cidy Female 18 934 Ellen Female 17 967 Hebe Female 22 98 Name Gender Age Score4 Ellen Female 17 96 123456789101112131415print(grouped.count())print(grouped.max()[['Age', 'Score']])print(grouped.mean()[['Age', 'Score']]) Name Age ScoreGender Female 3 3 3Male 5 5 5 Age ScoreGender Female 22 98Male 21 100 Age ScoreGender Female 19.0 95.666667Male 19.6 89.000000 å¦‚æœå…¶ä¸­çš„å‡½æ•°æ— æ³•æ»¡è¶³ä½ çš„éœ€æ±‚ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä½¿ç”¨èšåˆå‡½æ•°aggregateï¼Œä¼ é€’numpyæˆ–è€…è‡ªå®šä¹‰çš„å‡½æ•°ï¼Œå‰ææ˜¯è¿”å›ä¸€ä¸ªèšåˆå€¼ 12345678910def getSum(data): total = 0 for d in data: total+=d return totalprint(grouped.aggregate(np.median))print(grouped.aggregate(&#123;'Age':np.median, 'Score':np.sum&#125;))print(grouped.aggregate(&#123;'Age':getSum&#125;)) è¿­ä»£ 1234567891011121314151617grouped = df.groupby('A')for name, group in grouped: print(name) print(group) bar A B C D1 bar one 0.254161 1.5117633 bar three 0.215897 -0.9905825 bar two -0.077118 1.211526foo A B C D0 foo one -0.575247 1.3460612 foo two -1.143704 1.6270814 foo two 1.193555 -0.4416526 foo one -0.408530 0.2685207 foo three -0.862495 0.024580 å¯è§†åŒ– å¯¹ç»„å†…çš„æ•°æ®ç»˜åˆ¶æ¦‚ç‡å¯†åº¦åˆ†å¸ƒï¼š 12grouped['Age'].plot(kind='kde', legend=True)plt.show() è®¡ç®—ä¸åŒç»„çš„æŸä¸€åˆ—çš„å€¼ 12data.groupby('race')['age'].mean()è¦æ±‚è¢«ä¸åŒç§æ—å†…è¢«å‡»æ¯™äººå‘˜å¹´é¾„çš„å‡å€¼: å¯¹ä¸åŒå–å€¼çš„è®¡æ•°: .value_counts() 12data.groupby('race')['signs_of_mental_illness'].value_counts()æ±‚ä¸åŒç§æ—å†…, æ˜¯å¦æœ‰ç²¾ç¥å¼‚å¸¸è¿¹è±¡çš„åˆ†åˆ«æœ‰å¤šå°‘äºº 12data.groupby('race')['signs_of_mental_illness'].value_counts().unstack()ç»„å†…æ“ä½œçš„ç»“æœä¸æ˜¯å•ä¸ªå€¼, æ˜¯ä¸€ä¸ªåºåˆ—, æˆ‘ä»¬å¯ä»¥ç”¨.unstack()å°†å®ƒå±•å¼€ï¼Œå¾—åˆ°DateFrame 1data.groupby('race')['flee'].value_counts().unstack().plot(kind='bar', figsize=(20, 4)) è¿™é‡Œæœ‰ä¸€ä¸ªä¹‹å‰ä»‹ç»çš„.unstackæ“ä½œ, è¿™ä¼šè®©ä½ å¾—åˆ°ä¸€ä¸ªDateFrame, ç„¶åè°ƒç”¨æ¡å½¢å›¾, pandaså°±ä¼šéå†æ¯ä¸€ä¸ªç»„(unstackåä¸ºæ¯ä¸€è¡Œ), ç„¶åä½œå„ç»„çš„æ¡å½¢å›¾ æŒ‰ä¸åŒé€ƒé€¸ç±»å‹åˆ†ç»„, ç»„å†…çš„å¹´é¾„åˆ†å¸ƒæ˜¯å¦‚ä½•çš„?1data.groupby('flee')['age'].plot(kind='kde', legend=True, figsize=(20, 5)) è¿™é‡Œdata.groupby(&#39;flee&#39;)[&#39;age&#39;]æ˜¯ä¸€ä¸ªSeriesGroupbyå¯¹è±¡, é¡¾åæ€ä¹‰, å°±æ˜¯æ¯ä¸€ä¸ªç»„éƒ½æœ‰ä¸€ä¸ªSeries. å› ä¸ºåˆ’åˆ†äº†ä¸åŒé€ƒé€¸ç±»å‹çš„ç»„, æ¯ä¸€ç»„åŒ…å«äº†ç»„å†…çš„å¹´é¾„æ•°æ®, æ‰€ä»¥ç›´æ¥plotç›¸å½“äºéå†äº†æ¯ä¸€ä¸ªé€ƒé€¸ç±»å‹, ç„¶ååˆ†åˆ«ç”»åˆ†å¸ƒå›¾. Step 5: å†™å…¥è¡¨æ ¼to_csvï¼ˆpath_or_bufï¼Œsepï¼Œheader: bool or list of str : defaultï¼štrueï¼Œ index: bool, default trueï¼‰ å­—ç¬¦ä¸²å¤„ç†å¤šä¸ªå­—ç¬¦ä¸²åˆ†å‰²Pythonä¸­çš„spiltæ–¹æ³•åªèƒ½é€šè¿‡æŒ‡å®šçš„æŸä¸ªå­—ç¬¦åˆ†å‰²å­—ç¬¦ä¸²ï¼Œå¦‚æœéœ€è¦æŒ‡å®šå¤šä¸ªå­—ç¬¦ï¼Œéœ€è¦ç”¨åˆ°reæ¨¡å—é‡Œçš„splitæ–¹æ³•ã€‚ 1234567&gt;&gt;&gt; import re&gt;&gt;&gt; a = &quot;Hello world!How are you?My friend.Tom&quot;&gt;&gt;&gt; re.split(&quot; |!|\?|\.&quot;, a)[&apos;Hello&apos;, &apos;world&apos;, &apos;How&apos;, &apos;are&apos;, &apos;you&apos;, &apos;My&apos;, &apos;friend&apos;, &apos;Tom&apos;] å»æ‰å¤šä½™ç©ºæ ¼ filter aStr_splited = aStr.split(â€˜ â€˜) print(filter(lambda x : x, aStr_splited)) list(filter(None,s.split(â€˜,â€™))) åˆ—è¡¨ [x for x in s.split(â€˜,â€™) if x] æ­£åˆ™è¡¨è¾¾å¼https://docs.python.org/zh-cn/3/library/re.html æ­£åˆ™è¡¨è¾¾å¼ï¼šä¸€ç§ç‰¹æ®Šçš„å­—ç¬¦ä¸²ï¼Œç”¨äºæŸ¥æ‰¾æŸç§å½¢å¼çš„å­—ç¬¦ä¸²ï¼Œæ»¡è¶³æŸç§æ¡ä»¶çš„æ ¼å¼ã€‚ ç”¨äºæŸ¥æ‰¾ï¼ŒåŒ¹é… reæ¨¡å— re. pattern â€‹ [a-z] [abc] â€‹ ab 1\d åŒ¹é…ä»»ä½•åè¿›åˆ¶æ•°å­—ï¼›è¿™ç­‰ä»·äºç±» [0-9]ã€‚ 1\D åŒ¹é…ä»»ä½•éæ•°å­—å­—ç¬¦ï¼›è¿™ç­‰ä»·äºç±» [^0-9]ã€‚ 1\s åŒ¹é…ä»»ä½•ç©ºç™½å­—ç¬¦ï¼›è¿™ç­‰ä»·äºç±» [ \t\n\r\f\v]ã€‚ 1\S åŒ¹é…ä»»ä½•éç©ºç™½å­—ç¬¦ï¼›è¿™ç›¸å½“äºç±» [^ \t\n\r\f\v]ã€‚ 1\w åŒ¹é…ä»»ä½•å­—æ¯ä¸æ•°å­—å­—ç¬¦ï¼›è¿™ç›¸å½“äºç±» [a-zA-Z0-9_]ã€‚ 1\W åŒ¹é…ä»»ä½•éå­—æ¯ä¸æ•°å­—å­—ç¬¦ï¼›è¿™ç›¸å½“äºç±» [^a-zA-Z0-9_]ã€‚ ca*t å°†åŒ¹é… &#39;ct&#39; (0ä¸ª &#39;a&#39; å­—ç¬¦)ï¼Œ&#39;cat&#39; (1ä¸ª &#39;a&#39; )ï¼Œ &#39;caaat&#39; (3ä¸ª &#39;a&#39; å­—ç¬¦) å¦ä¸€ä¸ªé‡å¤çš„å…ƒå­—ç¬¦æ˜¯ +ï¼Œå®ƒåŒ¹é…ä¸€æ¬¡æˆ–å¤šæ¬¡ã€‚ è¦ç‰¹åˆ«æ³¨æ„ * å’Œ + ä¹‹é—´çš„åŒºåˆ«ï¼›* åŒ¹é… é›¶æ¬¡ æˆ–æ›´å¤šæ¬¡ï¼Œå› æ­¤é‡å¤çš„ä»»ä½•ä¸œè¥¿éƒ½å¯èƒ½æ ¹æœ¬ä¸å­˜åœ¨ï¼Œè€Œ + è‡³å°‘éœ€è¦ ä¸€æ¬¡ã€‚ ä½¿ç”¨ç±»ä¼¼çš„ä¾‹å­ï¼Œca+t å°†åŒ¹é… &#39;cat&#39; (1 ä¸ª &#39;a&#39;)ï¼Œ&#39;caaat&#39; (3 ä¸ª &#39;a&#39;)ï¼Œä½†ä¸ä¼šåŒ¹é… &#39;ct&#39;ã€‚ æœ€å¤æ‚çš„é‡å¤é™å®šç¬¦æ˜¯ {m,n}ï¼Œå…¶ä¸­ m å’Œ n æ˜¯åè¿›åˆ¶æ•´æ•°ã€‚ è¿™ä¸ªé™å®šç¬¦æ„å‘³ç€å¿…é¡»è‡³å°‘é‡å¤ m æ¬¡ï¼Œæœ€å¤šé‡å¤ n æ¬¡ã€‚ ä¾‹å¦‚ï¼Œa/{1,3}b å°†åŒ¹é… &#39;a/b&#39; ï¼Œ&#39;a//b&#39; å’Œ &#39;a///b&#39; ã€‚ å®ƒä¸åŒ¹é…æ²¡æœ‰æ–œçº¿çš„ &#39;ab&#39;ï¼Œæˆ–è€…æœ‰å››ä¸ªçš„ &#39;a////b&#39;ã€‚ ^è¡¨ç¤ºè¡Œçš„å¼€å¤´ï¼Œ^\dè¡¨ç¤ºå¿…é¡»ä»¥æ•°å­—å¼€å¤´ã€‚ `è¡¨ç¤ºè¡Œçš„ç»“æŸï¼Œ`\dè¡¨ç¤ºå¿…é¡»ä»¥æ•°å­—ç»“æŸã€‚ æ–¹æ³• / å±æ€§ ç›®çš„ match() ç¡®å®šæ­£åˆ™æ˜¯å¦ä»å­—ç¬¦ä¸²çš„å¼€å¤´åŒ¹é…ã€‚ search() æ‰«æå­—ç¬¦ä¸²ï¼ŒæŸ¥æ‰¾æ­¤æ­£åˆ™åŒ¹é…çš„ä»»ä½•ä½ç½®ã€‚ findall() æ‰¾åˆ°æ­£åˆ™åŒ¹é…çš„æ‰€æœ‰å­å­—ç¬¦ä¸²ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºåˆ—è¡¨è¿”å›ã€‚ finditer() æ‰¾åˆ°æ­£åˆ™åŒ¹é…çš„æ‰€æœ‰å­å­—ç¬¦ä¸²ï¼Œå¹¶å°†å®ƒä»¬è¿”å›ä¸ºä¸€ä¸ª iteratorã€‚ åŒ¹é…å¯¹è±¡è¿”å›å€¼çš„å‡½æ•° æ–¹æ³• / å±æ€§ ç›®çš„ 1group() è¿”å›æ­£åˆ™åŒ¹é…çš„å­—ç¬¦ä¸² 1start() è¿”å›åŒ¹é…çš„å¼€å§‹ä½ç½® 1end() è¿”å›åŒ¹é…çš„ç»“æŸä½ç½® 1span() è¿”å›åŒ…å«åŒ¹é… (start, end) ä½ç½®çš„å…ƒç»„ 123456&gt;&gt;&gt; m.group()&apos;tempo&apos;&gt;&gt;&gt; m.start(), m.end()(0, 5)&gt;&gt;&gt; m.span()(0, 5) re.``search(pattern, string, flags=0)Â¶ æ‰«ææ•´ä¸ª å­—ç¬¦ä¸² æ‰¾åˆ°åŒ¹é…æ ·å¼çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼Œå¹¶è¿”å›ä¸€ä¸ªç›¸åº”çš„ åŒ¹é…å¯¹è±¡ã€‚å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°±è¿”å›ä¸€ä¸ª None ï¼› æ³¨æ„è¿™å’Œæ‰¾åˆ°ä¸€ä¸ªé›¶é•¿åº¦åŒ¹é…æ˜¯ä¸åŒçš„ã€‚ re.``match(pattern, string, flags=0) å¦‚æœ string å¼€å§‹çš„0æˆ–è€…å¤šä¸ªå­—ç¬¦åŒ¹é…åˆ°äº†æ­£åˆ™è¡¨è¾¾å¼æ ·å¼ï¼Œå°±è¿”å›ä¸€ä¸ªç›¸åº”çš„ åŒ¹é…å¯¹è±¡ ã€‚ å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°±è¿”å› None ï¼›æ³¨æ„å®ƒè·Ÿé›¶é•¿åº¦åŒ¹é…æ˜¯ä¸åŒçš„ã€‚ Matplotlibimport matplotlib.pyplot as plt plt.figure() ç”»å¸ƒ plt.subplot() åˆ’åˆ†å­å›¾åŸºæœ¬å±æ€§æ ‡é¢˜ market linstyle plt.text() è®¾ç½®å›¾å†…æ–‡æœ¬ è½´æ ‡ç­¾ plt.xlabel() è®¾ç½®åæ ‡è½´æ ‡ç­¾ plt.ylabel() èŒƒå›´ plt.xlim() è®¾ç½®åæ ‡å–å€¼èŒƒå›´ å…ƒç»„ plt.ylim() plt.imshow() plt.axis(â€œoffâ€) è®¾ç½®è®°å·åˆ»åº¦ åˆ»åº¦æ ‡ç­¾plt.xticksï¼ˆ[-np.piï¼Œ-np.pi / 2,0ï¼Œnp.pi / 2ï¼Œnp.pi]ï¼‰ plt.yticksï¼ˆ[ - 1ï¼Œ0ï¼Œ+1]ï¼‰ plt.xticks(new_ticks)plt.yticks([-2, -1.8, -1, 1.22, 3], [râ€™$really\ bad$â€™, râ€™$bad$â€™, râ€™$normal\ \alpha$â€™, râ€™$good$â€™, râ€™$really\ good$â€™]) è®¾ç½®è®°å·æ ‡ç­¾plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [râ€™$-\pi$â€™, râ€™$-\pi/2$â€™, râ€™$0$â€™, râ€™$+\pi/2$â€™, râ€™$+\pi$â€™]) plt.yticks([-1, 0, +1], [râ€™$-1$â€™, râ€™$0$â€™, râ€™$+1$â€™]) è®¾ç½®åæ ‡plt.plot([],[],) linestyle marker marketsize https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html linestyle or ls {â€˜-â€˜, â€˜â€”â€˜, â€˜-.â€™, â€˜:â€™, â€˜â€™, (offset, on-off-seq), â€¦} linewidth or lw float marker marker style markeredgecolor or mec color markeredgewidth or mew float markerfacecolor or mfc color markerfacecoloralt or mfcalt color markersize or ms float plt.axis([2011,2014,0.04,0.18]) plt.xticks(np.arange(2011,2015,1)) plt.yticks(np.arange(0.04,0.20,0.02)) plt.ylabel(â€œRMSEâ€) plt.xlabel(â€œ(a) LSTMâ€) plt.grid(Trueï¼‰ plt.figure(2) #plt.subplot(222) pandas1df.plot(subplots=True, figsize=(6, 6)); plt.legend(loc=&apos;best&apos;) data : DataFrame x : label or position, default None y : label or position, default None Allows plotting of one column versus another kind : str â€˜lineâ€™ : line plot (default) â€˜barâ€™ : vertical bar plot â€˜barhâ€™ : horizontal bar plot â€˜histâ€™ : histogram â€˜boxâ€™ : boxplot â€˜kdeâ€™ : Kernel Density Estimation plot â€˜densityâ€™ : same as â€˜kdeâ€™ â€˜areaâ€™ : area plot â€˜pieâ€™ : pie plot â€˜scatterâ€™ : scatter plot â€˜hexbinâ€™ : hexbin plot ax : matplotlib axes object, default None æ—¶é—´åºåˆ—123456789101112131415161718192021222324252627import datetimeimport matplotlib.pyplot as pltimport matplotlib.dates as mdatesimport numpy as npfig, ax = plt.subplots()months = mdates.MonthLocator()dateFmt = mdates.DateFormatter("%m/%d/%y")ax.xaxis.set_major_formatter(dateFmt)ax.xaxis.set_minor_locator(months)ax.tick_params(axis="both", direction="out", labelsize=10)date1 = datetime.date(2005, 8, 8)date2 = datetime.date(2015, 6, 6)delta = datetime.timedelta(days=5)dates = mdates.drange(date1, date2, delta)y = np.random.normal(100, 15, len(dates))ax.plot_date(dates, y, "#FF8800", alpha=0.7)fig.autofmt_xdate()plt.show() plot()12345678910111213141516171819202122232425262728293031323334DataFrame.plot(self, *args, **kwargs)kindstrThe kind of plot to produce:â€˜lineâ€™ : line plot (default)â€˜barâ€™ : vertical bar plotâ€˜barhâ€™ : horizontal bar plotâ€˜histâ€™ : histogramâ€˜boxâ€™ : boxplotâ€˜kdeâ€™ : Kernel Density Estimation plotâ€˜densityâ€™ : same as â€˜kdeâ€™â€˜areaâ€™ : area plotâ€˜pieâ€™ : pie plotâ€˜scatterâ€™ : scatter plotâ€˜hexbinâ€™ : hexbin plot.figsizea tuple (width, height) in inchesx :labely:labelxlim:xticks:titlepandas.DataFrame.plot.barpandas.DataFrame.plot.barhpandas.DataFrame.plot.boxpandas.DataFrame.plot.densitypandas.DataFrame.plot.hexbinpandas.DataFrame.plot.histpandas.DataFrame.plot.kdepandas.DataFrame.plot.linepandas.DataFrame.plot.piepandas.DataFrame.plot.scatterpandas.DataFrame.boxplotpandas.DataFrame.hist https://blog.csdn.net/fengbingchun/article/details/81035861?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase https://www.cnblogs.com/Summer-skr--blog/p/11705925.html æ—¶é—´åºåˆ—ç»˜å›¾åæ ‡è½´xtickè®¾ç½®æ–¹æ³•plt.xticks(statiem,[datetime.strftime(x,â€™%Y-%mâ€™) for x in statiem]) æ³¨æ„äº‹é¡¹list() dict()çš„æ‹·è´1ã€b = a: èµ‹å€¼å¼•ç”¨ï¼Œa å’Œ b éƒ½æŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡ã€‚ 2ã€b = a.copy(): æµ…æ‹·è´, a å’Œ b æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å¯¹è±¡ï¼Œä½†ä»–ä»¬çš„å­å¯¹è±¡è¿˜æ˜¯æŒ‡å‘ç»Ÿä¸€å¯¹è±¡ï¼ˆæ˜¯å¼•ç”¨ï¼‰ã€‚ b = copy.deepcopy(a): æ·±åº¦æ‹·è´, a å’Œ b å®Œå…¨æ‹·è´äº†çˆ¶å¯¹è±¡åŠå…¶å­å¯¹è±¡ï¼Œä¸¤è€…æ˜¯å®Œå…¨ç‹¬ç«‹çš„ã€‚ Linuxnohuplinuxåå°æ‰§è¡Œå‘½ä»¤ï¼š&amp;å’Œnohup ç”¨é€”ï¼šä¸æŒ‚æ–­åœ°è¿è¡Œå‘½ä»¤ã€‚ è¯­æ³•ï¼šnohup Command [ Arg â€¦ ] [ &amp; ] ä¾‹å­ï¼š nohup sh example.sh &amp; nohup å‘½ä»¤å¯ä»¥ä½¿å‘½ä»¤æ°¸ä¹…çš„æ‰§è¡Œä¸‹å»ï¼Œå’Œç»ˆç«¯æ²¡æœ‰å…³ç³»ï¼Œé€€å‡ºç»ˆç«¯ä¹Ÿä¸ä¼šå½±å“ç¨‹åºçš„è¿è¡Œï¼›&amp; æ˜¯åå°è¿è¡Œçš„æ„æ€ï¼Œä½†å½“ç”¨æˆ·é€€å‡ºçš„æ—¶å€™ï¼Œå‘½ä»¤è‡ªåŠ¨ä¹Ÿè·Ÿç€é€€å‡ºã€‚é‚£ä¹ˆï¼ŒæŠŠä¸¤ä¸ªç»“åˆèµ·æ¥nohup å‘½ä»¤ &amp;è¿™æ ·å°±èƒ½ä½¿å‘½ä»¤æ°¸ä¹…çš„åœ¨åå°æ‰§è¡Œ nohup å‘½ä»¤ &gt; output.log 2&gt;&amp;1 &amp;è®©å‘½ä»¤åœ¨åå°æ‰§è¡Œã€‚ å…¶ä¸­ 0ã€1ã€2åˆ†åˆ«ä»£è¡¨å¦‚ä¸‹å«ä¹‰ï¼š0 â€“ stdin (standard input)1 â€“ stdout (standard output)2 â€“ stderr (standard error) nohup+æœ€åé¢çš„&amp;æ˜¯è®©å‘½ä»¤åœ¨åå°æ‰§è¡Œ &gt;output.log æ˜¯å°†ä¿¡æ¯è¾“å‡ºåˆ°output.logæ—¥å¿—ä¸­ 2&gt;&amp;1æ˜¯å°†æ ‡å‡†é”™è¯¯ä¿¡æ¯è½¬å˜æˆæ ‡å‡†è¾“å‡ºï¼Œè¿™æ ·å°±å¯ä»¥å°†é”™è¯¯ä¿¡æ¯è¾“å‡ºåˆ°output.log æ—¥å¿—é‡Œé¢æ¥ã€‚ &amp; åå°æ‰§è¡Œ> è¾“å‡ºåˆ°ä¸è¿‡è”åˆä½¿ç”¨ä¹Ÿæœ‰å…¶ä»–æ„æ€ï¼Œæ¯”å¦‚nohupè¾“å‡ºé‡å®šå‘ä¸Šçš„åº”ç”¨ä¾‹å­ï¼šnohup abc.sh &gt; nohup.log 2&gt;&amp;1 &amp;å…¶ä¸­2&gt;&amp;1 æŒ‡å°†STDERRé‡å®šå‘åˆ°å‰é¢æ ‡å‡†è¾“å‡ºå®šå‘åˆ°çš„åŒåæ–‡ä»¶ä¸­ï¼Œå³&amp;1å°±æ˜¯nohup.log ps -ef|grep pythonpså‘½ä»¤å°†æŸä¸ªè¿›ç¨‹æ˜¾ç¤ºå‡ºæ¥ grepå‘½ä»¤æ˜¯æŸ¥æ‰¾ ä¸­é—´çš„|æ˜¯ç®¡é“å‘½ä»¤ æ˜¯æŒ‡pså‘½ä»¤ä¸grepåŒæ—¶æ‰§è¡Œ PSæ˜¯LINUXä¸‹æœ€å¸¸ç”¨çš„ä¹Ÿæ˜¯éå¸¸å¼ºå¤§çš„è¿›ç¨‹æŸ¥çœ‹å‘½ä»¤ grepå‘½ä»¤ æ˜¯æŸ¥æ‰¾ï¼Œ æ˜¯ä¸€ç§å¼ºå¤§çš„æ–‡æœ¬æœç´¢å·¥å…·ï¼Œå®ƒèƒ½ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ æœç´¢æ–‡æœ¬ï¼Œå¹¶æŠŠåŒ¹ é…çš„è¡Œæ‰“å°å‡ºæ¥ã€‚ grepå…¨ç§°æ˜¯Global Regular Expression Printï¼Œè¡¨ç¤ºå…¨å±€æ­£åˆ™è¡¨è¾¾å¼ç‰ˆæœ¬ï¼Œå®ƒçš„ä½¿ç”¨æƒé™æ˜¯æ‰€æœ‰ç”¨æˆ·ã€‚ ä»¥ä¸‹è¿™æ¡å‘½ä»¤æ˜¯æ£€æŸ¥ java è¿›ç¨‹æ˜¯å¦å­˜åœ¨ï¼šps -ef |grep java å­—æ®µå«ä¹‰å¦‚ä¸‹ï¼šUID PID PPID C STIME TTY TIME CMD zzw 14124 13991 0 00:38 pts/0 00:00:00 grep â€”color=auto dae UID ï¼šç¨‹åºè¢«è¯¥ UID æ‰€æ‹¥æœ‰ PID ï¼šå°±æ˜¯è¿™ä¸ªç¨‹åºçš„ ID PPID ï¼šåˆ™æ˜¯å…¶ä¸Šçº§çˆ¶ç¨‹åºçš„ID C ï¼šCPUä½¿ç”¨çš„èµ„æºç™¾åˆ†æ¯” STIME ï¼šç³»ç»Ÿå¯åŠ¨æ—¶é—´ TTY ï¼šç™»å…¥è€…çš„ç»ˆç«¯æœºä½ç½® TIME ï¼šä½¿ç”¨æ‰çš„CPUæ—¶é—´ã€‚ CMD ï¼šæ‰€ä¸‹è¾¾çš„æ˜¯ä»€ä¹ˆæŒ‡ä»¤]]></content>
      <categories>
        <category>æ•°æ®åˆ†æ</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Networks]]></title>
    <url>%2F2019%2F05%2F12%2FDeel%20Learning%20ai_Convolutional%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[C4 : Convolutional Neural Networks(å·ç§¯ç¥ç»ç½‘ç»œ)W1 :Convolutional Neural Networks(å·ç§¯ç¥ç»ç½‘ç»œ)L1: Computer Vision Image classification Object detection Neural Style Transfer Problem : input big ç¥ç»ç½‘ç»œç»“æ„å¤æ‚ï¼Œæ•°æ®é‡ç›¸å¯¹è¾ƒå°‘ï¼Œå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆï¼› æ‰€éœ€å†…å­˜å’Œè®¡ç®—é‡å·¨å¤§ã€‚ L2: Edge detection exampleæˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡ï¼Œç¥ç»ç½‘ç»œç”±æµ…å±‚åˆ°æ·±å±‚ï¼Œåˆ†åˆ«å¯ä»¥æ£€æµ‹å‡ºå›¾ç‰‡çš„è¾¹ç¼˜ç‰¹å¾ã€å±€éƒ¨ç‰¹å¾ï¼ˆä¾‹å¦‚çœ¼ç›ã€é¼»å­ç­‰ï¼‰ï¼Œåˆ°æœ€åé¢çš„ä¸€å±‚å°±å¯ä»¥æ ¹æ®å‰é¢æ£€æµ‹çš„ç‰¹å¾æ¥è¯†åˆ«æ•´ä½“é¢éƒ¨è½®å»“ã€‚è¿™äº›å·¥ä½œéƒ½æ˜¯ä¾æ‰˜å·ç§¯ç¥ç»ç½‘ç»œæ¥å®ç°çš„ã€‚ å·ç§¯è¿ç®—ï¼ˆConvolutional Operationï¼‰æ˜¯å·ç§¯ç¥ç»ç½‘ç»œæœ€åŸºæœ¬çš„ç»„æˆéƒ¨åˆ†ã€‚æˆ‘ä»¬ä»¥è¾¹ç¼˜æ£€æµ‹ä¸ºä¾‹ï¼Œæ¥è§£é‡Šå·ç§¯æ˜¯æ€æ ·è¿ç®—çš„ã€‚ å¸¸è§çš„è¾¹ç¼˜æ£€æµ‹ å‚ç›´è¾¹ç¼˜ï¼ˆVertical Edges) å’Œ æ°´å¹³è¾¹ç¼˜ï¼ˆhorizontal Edges) è¿™å¼ å›¾çš„æ æ†å°±å¯¹åº”å‚ç›´çº¿ï¼Œæ æ†çš„æ°´å¹³çº¿æ˜¯æ°´å¹³è¾¹ç¼˜ã€‚ é‚£ä¹ˆå›¾ç‰‡æ˜¯æ€ä¹ˆæ£€æµ‹è¾¹ç¼˜çš„å‘¢ï¼Ÿ è¿‡æ»¤å™¨ï¼šfilter åœ¨æ•°å­¦ä¸­â€œâ€å°±æ˜¯å·ç§¯çš„æ ‡å‡†æ ‡å¿—ï¼Œä½†æ˜¯åœ¨Pythonä¸­ï¼Œè¿™ä¸ªæ ‡è¯†å¸¸å¸¸è¢«ç”¨æ¥è¡¨ç¤ºä¹˜æ³•æˆ–è€…å…ƒç´ ä¹˜æ³•ã€‚ Output; 4 by 4 å…·ä½“è¿ç®—ï¼š 1ï¼‰ ä¸ºäº†è®¡ç®—ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œåœ¨4Ã—4å·¦ä¸Šè§’çš„é‚£ä¸ªå…ƒç´ ï¼Œä½¿ç”¨3Ã—3çš„è¿‡æ»¤å™¨ï¼Œå°†å…¶è¦†ç›–åœ¨è¾“å…¥å›¾åƒï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ç„¶åè¿›è¡Œå…ƒç´ ä¹˜æ³•ï¼ˆelement-wise productsï¼‰è¿ç®— 2ï¼‰ä¸ºäº†å¼„æ˜ç™½ç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä»€ä¹ˆï¼Œä½ è¦æŠŠè“è‰²çš„æ–¹å—ï¼Œå‘å³ç§»åŠ¨ä¸€æ­¥ï¼Œåƒè¿™æ ·ï¼ŒæŠŠè¿™äº›ç»¿è‰²çš„æ ‡è®°å»æ‰ï¼š 6Ã—6çŸ©é˜µå’Œ3Ã—3çŸ©é˜µè¿›è¡Œå·ç§¯è¿ç®—å¾—åˆ°4Ã—4çŸ©é˜µã€‚è¿™äº›å›¾ç‰‡å’Œè¿‡æ»¤å™¨æ˜¯ä¸åŒç»´åº¦çš„çŸ©é˜µï¼Œä½†å·¦è¾¹çŸ©é˜µå®¹æ˜“è¢«ç†è§£ä¸ºä¸€å¼ å›¾ç‰‡ï¼Œä¸­é—´çš„è¿™ä¸ªè¢«ç†è§£ä¸ºè¿‡æ»¤å™¨ï¼Œå³è¾¹çš„å›¾ç‰‡æˆ‘ä»¬å¯ä»¥ç†è§£ä¸ºå¦ä¸€å¼ å›¾ç‰‡ã€‚è¿™ä¸ªå°±æ˜¯å‚ç›´è¾¹ç¼˜æ£€æµ‹å™¨ã€‚ ä¸¾ä¾‹è¯´æ˜ï¼š Vertical edge detection è¿™é‡Œåœ¨ç»“æœå¯èƒ½æœ‰ç‚¹ä¸å¯¹å¤´ï¼Œæ£€æµ‹åˆ°çš„è¾¹ç¼˜å¤ªç²—äº†ï¼Œä¸»è¦æ˜¯å›¾ç‰‡å¤ªå°äº†ï¼Œ å·ç§¯æ“ä½œAPI åœ¨ Python ä¸­ï¼Œå·ç§¯ç”¨conv_forward()è¡¨ç¤ºï¼› åœ¨ Tensorflow ä¸­ï¼Œå·ç§¯ç”¨tf.nn.conv2d()è¡¨ç¤ºï¼› åœ¨ keras ä¸­ï¼Œå·ç§¯ç”¨Conv2D()è¡¨ç¤ºã€‚ L3: Edge Detection Example é¢œè‰²ç”±æš—åˆ°äº®ï¼Œè¿˜æ˜¯äº®åˆ°æš— è¿™ç§æ»¤æ³¢å™¨å¯ä»¥åŒºåˆ†æ˜æš—å˜åŒ–ï¼Œå–ç»å¯¹å€¼æ²¡æœ‰åŒºåˆ«äº† æ°´å¹³è¾¹ç¼˜ ä¸Šè¾¹ç›¸å¯¹è¾ƒäº®ï¼Œè€Œä¸‹æ–¹ç›¸å¯¹è¾ƒæš— å¤æ‚æ —å­ è¿™å—åŒºåŸŸå·¦è¾¹ä¸¤åˆ—æ˜¯æ­£è¾¹ï¼Œå³è¾¹ä¸€åˆ—æ˜¯è´Ÿè¾¹ï¼Œæ­£è¾¹å’Œè´Ÿè¾¹çš„å€¼åŠ åœ¨ä¸€èµ·å¾—åˆ°äº†ä¸€ä¸ªä¸­é—´å€¼ã€‚ä½†å‡å¦‚è¿™ä¸ªä¸€ä¸ªéå¸¸å¤§çš„1000Ã—1000çš„ç±»ä¼¼è¿™æ ·æ£‹ç›˜é£æ ¼çš„å¤§å›¾ï¼Œå°±ä¸ä¼šå‡ºç°è¿™äº›äº®åº¦ä¸º10çš„è¿‡æ¸¡å¸¦äº†ï¼Œå› ä¸ºå›¾ç‰‡å°ºå¯¸å¾ˆå¤§ï¼Œè¿™äº›ä¸­é—´å€¼å°±ä¼šå˜å¾—éå¸¸å°ã€‚ filter sobelè¿‡æ»¤å™¨ï¼Œä¼˜ç‚¹åœ¨äºå¢åŠ äº†ä¸­é—´ä¸€è¡Œå…ƒç´ çš„æƒé‡ï¼Œè¿™ä½¿å¾—ç»“æœçš„é²æ£’æ€§ä¼šæ›´é«˜ä¸€äº›ã€‚ charrè¿‡æ»¤å™¨ï¼Œå®ƒæœ‰ç€å’Œä¹‹å‰å®Œå…¨ä¸åŒçš„ç‰¹æ€§ï¼Œå®é™…ä¸Šä¹Ÿæ˜¯ä¸€ç§å‚ç›´è¾¹ç¼˜æ£€æµ‹ï¼Œå¦‚æœä½ å°†å…¶ç¿»è½¬90åº¦ï¼Œä½ å°±èƒ½å¾—åˆ°å¯¹åº”æ°´å¹³è¾¹ç¼˜æ£€æµ‹ã€‚ å­¦ä¹ çš„å…¶ä¸­ä¸€ä»¶äº‹å°±æ˜¯å½“ä½ çœŸæ­£æƒ³å»æ£€æµ‹å‡ºå¤æ‚å›¾åƒçš„è¾¹ç¼˜ï¼Œä½ ä¸ä¸€å®šè¦å»ä½¿ç”¨é‚£äº›ç ”ç©¶è€…ä»¬æ‰€é€‰æ‹©çš„è¿™ä¹ä¸ªæ•°å­—ï¼Œä½†ä½ å¯ä»¥ä»ä¸­è·ç›ŠåŒªæµ…ã€‚æŠŠè¿™çŸ©é˜µä¸­çš„9ä¸ªæ•°å­—å½“æˆ9ä¸ªå‚æ•°ï¼Œå¹¶ä¸”åœ¨ä¹‹åä½ å¯ä»¥å­¦ä¹ ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•ï¼Œå…¶ç›®æ ‡å°±æ˜¯å»ç†è§£è¿™9ä¸ªå‚æ•°ã€‚ è¿™æ ·å¯èƒ½å¾—åˆ°ä¸€ä¸ªå‡ºè‰²çš„è¾¹ç¼˜æ£€æµ‹ ç›¸æ¯”è¿™ç§å•çº¯çš„å‚ç›´è¾¹ç¼˜å’Œæ°´å¹³è¾¹ç¼˜ï¼Œå®ƒå¯ä»¥æ£€æµ‹å‡º45Â°æˆ–70Â°æˆ–73Â°ï¼Œç”šè‡³æ˜¯ä»»ä½•è§’åº¦çš„è¾¹ç¼˜ã€‚æ‰€ä»¥å°†çŸ©é˜µçš„æ‰€æœ‰æ•°å­—éƒ½è®¾ç½®ä¸ºå‚æ•°ï¼Œé€šè¿‡æ•°æ®åé¦ˆï¼Œè®©ç¥ç»ç½‘ç»œè‡ªåŠ¨å»å­¦ä¹ å®ƒä»¬ï¼Œæˆ‘ä»¬ä¼šå‘ç°ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ ä¸€äº›ä½çº§çš„ç‰¹å¾ï¼Œä¾‹å¦‚è¿™äº›è¾¹ç¼˜çš„ç‰¹å¾ã€‚ ä¸ç®¡æ˜¯å‚ç›´çš„è¾¹ç¼˜ï¼Œæ°´å¹³çš„è¾¹ç¼˜ï¼Œè¿˜æœ‰å…¶ä»–å¥‡æ€ªè§’åº¦çš„è¾¹ç¼˜ï¼Œç”šè‡³æ˜¯å…¶å®ƒçš„è¿åå­—éƒ½æ²¡æœ‰çš„è¿‡æ»¤å™¨ã€‚ PaddingæŒ‰ç…§æˆ‘ä»¬ä¸Šé¢è®²çš„å›¾ç‰‡å·ç§¯ï¼Œå¦‚æœåŸå§‹å›¾ç‰‡å°ºå¯¸ä¸º$n x n$ï¼Œfilterå°ºå¯¸ä¸º$f x f$ï¼Œåˆ™å·ç§¯åçš„å›¾ç‰‡å°ºå¯¸ä¸º$(n-f+1) x (n-f+1)$ï¼Œæ³¨æ„fä¸€èˆ¬ä¸ºå¥‡æ•°ã€‚è¿™æ ·ä¼šå¸¦æ¥ä¸¤ä¸ªé—®é¢˜ï¼š å·ç§¯è¿ç®—åï¼Œè¾“å‡ºå›¾ç‰‡å°ºå¯¸ç¼©å° åŸå§‹å›¾ç‰‡è¾¹ç¼˜ä¿¡æ¯å¯¹è¾“å‡ºè´¡çŒ®å¾—å°‘ï¼Œè¾“å‡ºå›¾ç‰‡ä¸¢å¤±è¾¹ç¼˜ä¿¡æ¯ è¾¹ç¼˜åƒç´ ç‚¹åªè¢«ä¸€ä¸ªè¾“å‡ºæ‰€è§¦ç¢°æˆ–è€…ä½¿ç”¨ï¼Œ ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œå¯ä»¥åœ¨è¿›è¡Œå·ç§¯æ“ä½œå‰ï¼Œå¯¹åŸå§‹å›¾ç‰‡åœ¨è¾¹ç•Œä¸Šè¿›è¡Œå¡«å……ï¼ˆPaddingï¼‰ï¼Œä»¥å¢åŠ çŸ©é˜µçš„å¤§å°ã€‚é€šå¸¸å°† 0 ä½œä¸ºå¡«å……å€¼ã€‚ ç»è¿‡paddingä¹‹åï¼Œå¡«å……p,åŸå§‹å›¾ç‰‡å°ºå¯¸ä¸º$(n+2p) x (n+2p)$ï¼Œfilterå°ºå¯¸ä¸º$f x f$ï¼Œåˆ™å·ç§¯åçš„å›¾ç‰‡å°ºå¯¸ä¸º$(n+2p-f+1) x (n+2p-f+1)$ã€‚è‹¥è¦ä¿è¯å·ç§¯å‰åå›¾ç‰‡å°ºå¯¸ä¸å˜ï¼Œåˆ™påº”æ»¡è¶³ï¼š$ p=(f-1)/2$,fé€šå¸¸æ˜¯å¥‡æ•°ï¼Œå¦‚æœæ˜¯å¶æ•°ï¼Œé€ æˆä¸å¯¹ç§°å¡«å……ï¼Œç¬¬äºŒä¸ªåŸå› æ˜¯å½“ä½ æœ‰ä¸€ä¸ªå¥‡æ•°ç»´è¿‡æ»¤å™¨ï¼Œæ¯”å¦‚3Ã—3æˆ–è€…5Ã—5çš„ï¼Œå®ƒå°±æœ‰ä¸€ä¸ªä¸­å¿ƒç‚¹ã€‚æœ‰æ—¶åœ¨è®¡ç®—æœºè§†è§‰é‡Œï¼Œå¦‚æœæœ‰ä¸€ä¸ªä¸­å¿ƒåƒç´ ç‚¹ä¼šæ›´æ–¹ä¾¿ï¼Œä¾¿äºæŒ‡å‡ºè¿‡æ»¤å™¨çš„ä½ç½® p=0,Valid convolution p=((f-1))/2,Same convolution L05: Strided convolutionï¼ˆå·ç§¯æ­¥é•¿ï¼‰Strideè¡¨ç¤ºfilteråœ¨åŸå›¾ç‰‡ä¸­æ°´å¹³æ–¹å‘å’Œå‚ç›´æ–¹å‘æ¯æ¬¡çš„æ­¥è¿›é•¿åº¦ã€‚ä¹‹å‰æˆ‘ä»¬é»˜è®¤stride=1ã€‚è‹¥stride=2ï¼Œåˆ™è¡¨ç¤ºfilteræ¯æ¬¡æ­¥è¿›é•¿åº¦ä¸º2ï¼Œå³éš”ä¸€ç‚¹ç§»åŠ¨ä¸€æ¬¡ã€‚ æˆ‘ä»¬ç”¨sè¡¨ç¤ºstrideé•¿åº¦ï¼Œpè¡¨ç¤ºpaddingé•¿åº¦ï¼Œå¦‚æœåŸå§‹å›¾ç‰‡å°ºå¯¸ä¸ºn x nï¼Œfilterå°ºå¯¸ä¸ºf x fï¼Œåˆ™å·ç§¯åçš„å›¾ç‰‡å°ºå¯¸ä¸ºï¼š \left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloorå‘ä¸‹å–æ•´ ç›®å‰ä¸ºæ­¢æˆ‘ä»¬å­¦ä¹ çš„â€œå·ç§¯â€å®é™…ä¸Šè¢«ç§°ä¸ºäº’ç›¸å…³ï¼ˆcross-correlationï¼‰ï¼Œè€Œéæ•°å­¦æ„ä¹‰ä¸Šçš„å·ç§¯ã€‚çœŸæ­£çš„å·ç§¯æ“ä½œåœ¨åšå…ƒç´ ä¹˜ç§¯æ±‚å’Œä¹‹å‰ï¼Œè¦å°†æ»¤æ³¢å™¨æ²¿æ°´å¹³å’Œå‚ç›´è½´ç¿»è½¬ï¼ˆç›¸å½“äºæ—‹è½¬ 180 åº¦ï¼‰ã€‚å› ä¸ºè¿™ç§ç¿»è½¬å¯¹ä¸€èˆ¬ä¸ºæ°´å¹³æˆ–å‚ç›´å¯¹ç§°çš„æ»¤æ³¢å™¨å½±å“ä¸å¤§ï¼ŒæŒ‰ç…§æœºå™¨å­¦ä¹ çš„æƒ¯ä¾‹ï¼Œæˆ‘ä»¬é€šå¸¸ä¸è¿›è¡Œç¿»è½¬æ“ä½œï¼Œåœ¨ç®€åŒ–ä»£ç çš„åŒæ—¶ä½¿ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚ äº’ç›¸å…³ï¼šè¿‡æ»¤å™¨æ²¿æ°´å¹³å’Œå‚ç›´è½´ç¿»è½¬ï¼Œå…ƒç´ ç›¸ä¹˜æ¥è®¡ç®—ï¼Œè¿™äº›è§†é¢‘ä¸­å®šä¹‰å·ç§¯è¿ç®—æ—¶ï¼Œæˆ‘ä»¬è·³è¿‡äº†è¿™ä¸ªé•œåƒæ“ä½œã€‚ï¼ˆä¸è¿›è¡Œç¿»è½¬æ“ä½œï¼‰å«åšå·ç§¯æ“ä½œ L06: Convolution over volumes(ä¸‰ç»´å·ç§¯) å·ç§¯è¿ç®— è¿‡ç¨‹æ˜¯å°†æ¯ä¸ªå•é€šé“ï¼ˆRï¼ŒGï¼ŒBï¼‰ä¸å¯¹åº”çš„filterè¿›è¡Œå·ç§¯è¿ç®—æ±‚å’Œï¼Œç„¶åå†å°†3é€šé“çš„å’Œç›¸åŠ ï¼Œå¾—åˆ°è¾“å‡ºå›¾ç‰‡çš„ä¸€ä¸ªåƒç´ å€¼ã€‚ ä¸åŒé€šé“çš„æ»¤æ³¢ç®—å­å¯ä»¥ä¸ç›¸åŒã€‚ä¾‹å¦‚Ré€šé“filterå®ç°å‚ç›´è¾¹ç¼˜æ£€æµ‹ï¼ŒGå’ŒBé€šé“ä¸è¿›è¡Œè¾¹ç¼˜æ£€æµ‹ï¼Œå…¨éƒ¨ç½®é›¶ï¼Œæˆ–è€…å°†Rï¼ŒGï¼ŒBä¸‰é€šé“filterå…¨éƒ¨è®¾ç½®ä¸ºæ°´å¹³è¾¹ç¼˜æ£€æµ‹ã€‚ ä¸ºäº†è¿›è¡Œå¤šä¸ªå·ç§¯è¿ç®—ï¼Œå®ç°æ›´å¤šè¾¹ç¼˜æ£€æµ‹ï¼Œå¯ä»¥å¢åŠ æ›´å¤šçš„æ»¤æ³¢å™¨ç»„ã€‚ä¾‹å¦‚è®¾ç½®ç¬¬ä¸€ä¸ªæ»¤æ³¢å™¨ç»„å®ç°å‚ç›´è¾¹ç¼˜æ£€æµ‹ï¼Œç¬¬äºŒä¸ªæ»¤æ³¢å™¨ç»„å®ç°æ°´å¹³è¾¹ç¼˜æ£€æµ‹ã€‚è¿™æ ·ï¼Œä¸åŒæ»¤æ³¢å™¨ç»„å·ç§¯å¾—åˆ°ä¸åŒçš„è¾“å‡ºï¼Œä¸ªæ•°ç”±æ»¤æ³¢å™¨ç»„å†³å®šã€‚ ä¸ºäº†è¿›è¡Œå¤šä¸ªå·ç§¯è¿ç®—ï¼Œå®ç°æ›´å¤šè¾¹ç¼˜æ£€æµ‹ï¼Œå¯ä»¥å¢åŠ æ›´å¤šçš„æ»¤æ³¢å™¨ç»„ã€‚ä¾‹å¦‚è®¾ç½®ç¬¬ä¸€ä¸ªæ»¤æ³¢å™¨ç»„å®ç°å‚ç›´è¾¹ç¼˜æ£€æµ‹ï¼Œç¬¬äºŒä¸ªæ»¤æ³¢å™¨ç»„å®ç°æ°´å¹³è¾¹ç¼˜æ£€æµ‹ã€‚è¿™æ ·ï¼Œä¸åŒæ»¤æ³¢å™¨ç»„å·ç§¯å¾—åˆ°ä¸åŒçš„è¾“å‡ºï¼Œä¸ªæ•°ç”±æ»¤æ³¢å™¨ç»„å†³å®šã€‚ è‹¥è¾“å…¥å›¾ç‰‡çš„å°ºå¯¸ä¸ºn x n x ncï¼Œnc: é€šé“æ•°ç›®ï¼Œfilterå°ºå¯¸ä¸ºf x f x ncï¼Œåˆ™å·ç§¯åçš„å›¾ç‰‡å°ºå¯¸ä¸º(n-f+1) x (n-f+1) x ncâ€²ã€‚å…¶ä¸­ï¼Œncä¸ºå›¾ç‰‡é€šé“æ•°ç›®ï¼Œncâ€²ä¸ºæ»¤æ³¢å™¨ç»„ä¸ªæ•°ã€‚ L7 : One layer of a convolution network (å•å±‚ç¥ç»ç½‘ç»œ) CNNå•å±‚çš„æ‰€ä»¥æ ‡è®°ç¬¦å·ï¼Œè®¾å±‚æ•°$l$, \begin{array}{l}{f^{[l]}=\text { filter size }} \\ {p^{[l]}=\text { padding }} \\ {g^{[l]}=\text { stride }} \\ {n_{c}^{[l]}=\text { number of filters }}\end{array} \begin{array}{c}{n_{H}^{[l]}=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor} \\ { n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor}\end{array}å¦‚æœ$m$ä¸ªæ ·æœ¬ï¼Œè¿›è¡Œå‘é‡åŒ–è¿ç®—ï¼Œç›¸åº”çš„è¾“å‡ºç»´åº¦ï¼Œä¸º \mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}L8 : A simple convolution network exampleï¼ˆç®€å•å·ç§¯ç½‘ç»œç¤ºä¾‹ï¼‰ ä¸€èˆ¬è€Œè¨€ï¼Œå›¾ç‰‡çš„height $n^{[l]}_{H}$å’Œwidth $n^{[l]}_W$éšç€å±‚æ•°çš„å¢åŠ é€æ¸é™ä½ï¼Œä½†channel $n^{[l]}_C$é€æ¸å¢åŠ ã€‚ CNNæœ‰ä¸‰ç§ç±»å‹çš„layerï¼š Convolutionå±‚ï¼ˆCONVï¼‰ Poolingå±‚ï¼ˆPOOLï¼‰ Fully connectedå±‚ï¼ˆFCï¼‰ L9: Pooling layers(æ± åŒ–å±‚)å·ç§¯ç¥ç»ç½‘ç»œé™¤äº†å·ç§¯å±‚ï¼Œè¿˜æœ‰æ± åŒ–å±‚æ¥ç¼©å‡æ¨¡å‹çš„å¤§å°ï¼Œæé«˜è¿ç®—é€Ÿåº¦å’Œé²æ£’æ€§ æ± çš„ç±»å‹æœ‰max pooling(æœ€å¤§æ± åŒ–) è¿™é‡Œæ­¥å¹…æ˜¯s=2ï¼Œfilter = 2*2æ˜¯æœ€å¤§æ± åŒ–çš„è¶…å‚æ•°,å¦‚æœæ˜¯ä¸‰ç»´ï¼Œåˆ™å•ç‹¬åœ¨æ¯ä¸ªé€šé“æ‰§è¡Œæœ€å¤§æ± åŒ–æ“ä½œ å…³äºmax poolingçš„ç›´è§‰è§£é‡Šï¼š å…ƒç´ è¾ƒå¤§çš„å€¼ï¼Œå¯èƒ½æ˜¯å·ç§¯è¿‡ç¨‹ä¸­æå–åˆ°çš„æŸäº›ç‰¹å¾ï¼ˆæ¯”å¦‚è¾¹ç•Œï¼‰ï¼Œè€Œmax poolingåˆ™åœ¨å‹ç¼©äº†çŸ©é˜µå¤§å°çš„æƒ…å†µä¸‹ï¼Œä¿ç•™æ¯ä¸ªåˆ†åŒºå†…æœ€å¤§çš„è¾“å‡ºï¼Œå³ä¿ç•™äº†æå–çš„ç‰¹å¾ã€‚ä½†ç†è®ºä¸Šè¿˜æ²¡æœ‰è¯æ˜max poolingçš„åŸç†ï¼Œmax poolingåº”ç”¨çš„åŸå› æ˜¯åœ¨å®è·µä¸­æ•ˆæœå¾ˆå¥½ã€‚ Pooling layer: Average pooling ä½†æ˜¯æœ€å¤§æ± åŒ–æ›´å¥½ç”¨ summary : è¾“å…¥$n_Hn_Wn_C$,å¦‚æœæ²¡æœ‰padding,è¾“å‡º$(n_h-f)/s+1(n_w-f)/s+1n_c$ L10: Convolutional neural network example (å·ç§¯ç¥ç»ç½‘ç»œå®ä¾‹)åšä¸€ä¸ªè¯†åˆ«æ•°å­—çš„CNNç½‘ç»œ LeNet-5æ¶æ„å¦‚ä¸‹ï¼š é€šå¸¸Conv Layerå’ŒPooling Layeråˆåœ¨ä¸€èµ·ç®—ä¸€ä¸ªlayerï¼Œå› ä¸ºpooling layerå¹¶æ²¡æœ‰å‚æ•°è®­ç»ƒ å¸¸è§çš„ç»“æ„ï¼šConv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax æœ€ç»ˆè¿˜ä¼šç”¨FCå±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰ï¼Œä¸ä¸€èˆ¬NNçš„å¤„ç†ä¸€æ ·ï¼›å¹¶åœ¨è¾“å‡ºå±‚ï¼Œåº”ç”¨softmaxå¾—åˆ°10ä¸ªæ•°å­—çš„æ¦‚ç‡ã€‚ åœ¨æ•´ä¸ªç½‘ç»œä¸­ï¼ŒHeightå’ŒWidthæ˜¯é€æ¸é€’å‡çš„ï¼Œä½†channelå’Œfilteræ˜¯é€’å¢çš„ã€‚ å…³äºCNNå¦‚ä½•é€‰æ‹©è¶…å‚ï¼šå¯ä»¥å‚è€ƒè®ºæ–‡çš„ç»éªŒã€‚ Activation shape Activation Size #parameters Input: (32, 32, 3) 3072 0 CONV1(f=5, s=1) (28, 28, 6) 4704 156 (=556+6) POOL1 (14, 14, 6) 1176 0 CONV2(f=5, s=1) (10, 10, 16) 1600 416 (=5516+16) POOL2 (5, 5, 16) 400 0 FC3 (120, 1) 120 48120 (=120*400+120) FC4 (84, 1) 84 10164 (=84*120+84) Softmax (10, 1) 10 850 (=10*84+10) L11 Why convolution å‚æ•°å…±äº«ï¼ˆparameter sharing) å¦‚æœç”¨FCçš„è¯ï¼Œå‚æ•°çˆ†ç‚¸å•Šï¼å¦‚æœconv layer å°±éœ€è¦filteræ£€æµ‹å™¨ï¼Œè¿™ä¸ªå‚æ•°å°±å°‘äº†ï¼Œè¿˜å‚æ•°å…±äº« ç¨€ç–è¿æ¥(sparsity of connection) è¾“å‡ºä¸­çš„æ¯ä¸ªå•å…ƒä»…å’Œè¾“å…¥çš„ä¸€ä¸ªå°åˆ†åŒºç›¸å…³ï¼Œæ¯”å¦‚è¾“å‡ºçš„å·¦ä¸Šè§’çš„åƒç´ ä»…ä»…ç”±è¾“å…¥å·¦ä¸Šè§’çš„9ä¸ªåƒç´ å†³å®šï¼ˆå‡è®¾filterå¤§å°æ˜¯3*3ï¼‰ï¼Œè€Œå…¶ä»–è¾“å…¥éƒ½ä¸ä¼šå½±å“ã€‚ summary1. å·ç§¯ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ„é€ å’Œè®¡ç®—è¿‡ç¨‹ 2. å¦‚ä½•æ•´åˆè¿™äº›æ¨¡å‹ 3. å“ªäº›è¶…å‚æ•° 4. ä¸ºä»€ä¹ˆä½¿ç”¨å·ç§¯ W2 : Deep convolutional models: case studies(æ·±åº¦å·ç§¯ç½‘ç»œï¼šå®ä¾‹æ¢ç©¶)L1 : Why look at case studies?(ä¸ºä»€ä¹ˆè¦è¿›è¡Œå®ä¾‹æ¢ç©¶ï¼Ÿ)æœ¬æ–‡å°†ä¸»è¦ä»‹ç»å‡ ä¸ªå…¸å‹çš„CNNæ¡ˆä¾‹ã€‚é€šè¿‡å¯¹å…·ä½“CNNæ¨¡å‹åŠæ¡ˆä¾‹çš„ç ”ç©¶ï¼Œæ¥å¸®åŠ©æˆ‘ä»¬ç†è§£çŸ¥è¯†å¹¶è®­ç»ƒå®é™…çš„æ¨¡å‹ã€‚ å…¸å‹çš„CNNæ¨¡å‹åŒ…æ‹¬ï¼š LeNet-5 AlexNet VGG è¿˜ä¼šä»‹ç»Residual Networkï¼ˆResNetï¼‰ã€‚å…¶ç‰¹ç‚¹æ˜¯å¯ä»¥æ„å»ºå¾ˆæ·±å¾ˆæ·±çš„ç¥ç»ç½‘ç»œï¼ˆç›®å‰æœ€æ·±çš„å¥½åƒæœ‰152å±‚ï¼‰ã€‚è¿˜ä¼šä»‹ç»Inception Neural Network L2 : Classic networks(ç»å…¸ç½‘ç»œ)1. LeNet-5LeNet-5æ˜¯é’ˆå¯¹ç°åº¦å›¾ç‰‡è®­ç»ƒçš„ï¼Œä½¿ç”¨6ä¸ª5Ã—5çš„è¿‡æ»¤å™¨ï¼Œæ­¥å¹…ä¸º1ã€‚ç”±äºä½¿ç”¨äº†6ä¸ªè¿‡æ»¤å™¨ï¼Œæ­¥å¹…ä¸º1ï¼Œpaddingä¸º0ï¼Œè¾“å‡ºç»“æœä¸º28Ã—28Ã—6ï¼Œå›¾åƒå°ºå¯¸ä»32Ã—32ç¼©å°åˆ°28Ã—28ã€‚ç„¶åè¿›è¡Œæ± åŒ–æ“ä½œï¼Œåœ¨è¿™ç¯‡è®ºæ–‡å†™æˆçš„é‚£ä¸ªå¹´ä»£ï¼Œäººä»¬æ›´å–œæ¬¢ä½¿ç”¨å¹³å‡æ± åŒ–ï¼Œè€Œç°åœ¨æˆ‘ä»¬å¯èƒ½ç”¨æœ€å¤§æ± åŒ–æ›´å¤šä¸€äº›ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œå¹³å‡æ± åŒ–ï¼Œè¿‡æ»¤å™¨çš„å®½åº¦ä¸º2ï¼Œæ­¥å¹…ä¸º2ï¼Œå›¾åƒçš„å°ºå¯¸ï¼Œé«˜åº¦å’Œå®½åº¦éƒ½ç¼©å°äº†2å€ï¼Œè¾“å‡ºç»“æœæ˜¯ä¸€ä¸ª14Ã—14Ã—6çš„å›¾åƒã€‚æˆ‘è§‰å¾—è¿™å¼ å›¾ç‰‡åº”è¯¥ä¸æ˜¯å®Œå…¨æŒ‰ç…§æ¯”ä¾‹ç»˜åˆ¶çš„ï¼Œå¦‚æœä¸¥æ ¼æŒ‰ç…§æ¯”ä¾‹ç»˜åˆ¶ï¼Œæ–°å›¾åƒçš„å°ºå¯¸åº”è¯¥åˆšå¥½æ˜¯åŸå›¾åƒçš„ä¸€åŠã€‚ è¯¥LeNetæ¨¡å‹æ€»å…±åŒ…å«äº†å¤§çº¦6ä¸‡ä¸ªå‚æ•°ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå½“æ—¶Yann LeCunæå‡ºçš„LeNet-5æ¨¡å‹æ± åŒ–å±‚ä½¿ç”¨çš„æ˜¯average poolï¼Œè€Œä¸”å„å±‚æ¿€æ´»å‡½æ•°ä¸€èˆ¬æ˜¯Sigmoidå’Œtanhã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®éœ€è¦ï¼Œåšå‡ºæ”¹è¿›ï¼Œä½¿ç”¨max poolå’Œæ¿€æ´»å‡½æ•°ReLUã€‚ 1. AlexNetAlexNetæ¨¡å‹æ˜¯ç”±Alex Krizhevskyã€Ilya Sutskeverå’ŒGeoffrey Hintonå…±åŒæå‡ºçš„ï¼Œå…¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š AlexNeté¦–å…ˆç”¨ä¸€å¼ 227Ã—227Ã—3çš„å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œå®é™…ä¸ŠåŸæ–‡ä¸­ä½¿ç”¨çš„å›¾åƒæ˜¯224Ã—224Ã—3ï¼Œä½†æ˜¯å¦‚æœä½ å°è¯•å»æ¨å¯¼ä¸€ä¸‹ï¼Œä½ ä¼šå‘ç°227Ã—227è¿™ä¸ªå°ºå¯¸æ›´å¥½ä¸€äº›ã€‚ç¬¬ä¸€å±‚æˆ‘ä»¬ä½¿ç”¨96ä¸ª11Ã—11çš„è¿‡æ»¤å™¨ï¼Œæ­¥å¹…ä¸º4ï¼Œç”±äºæ­¥å¹…æ˜¯4ï¼Œå› æ­¤å°ºå¯¸ç¼©å°åˆ°55Ã—55ï¼Œç¼©å°äº†4å€å·¦å³ã€‚ç„¶åç”¨ä¸€ä¸ª3Ã—3çš„è¿‡æ»¤å™¨æ„å»ºæœ€å¤§æ± åŒ–å±‚,f=3ï¼Œæ­¥å¹…ä¸º2ï¼Œå·ç§¯å±‚å°ºå¯¸ç¼©å°ä¸º27Ã—27Ã—96ã€‚æ¥ç€å†æ‰§è¡Œä¸€ä¸ª5Ã—5çš„å·ç§¯ï¼Œpaddingä¹‹åï¼Œè¾“å‡ºæ˜¯27Ã—27Ã—276ã€‚ç„¶åå†æ¬¡è¿›è¡Œæœ€å¤§æ± åŒ–ï¼Œå°ºå¯¸ç¼©å°åˆ°13Ã—13ã€‚å†æ‰§è¡Œä¸€æ¬¡sameå·ç§¯ï¼Œç›¸åŒçš„paddingï¼Œå¾—åˆ°çš„ç»“æœæ˜¯13Ã—13Ã—384ï¼Œ384ä¸ªè¿‡æ»¤å™¨ã€‚å†åšä¸€æ¬¡sameå·ç§¯ï¼Œå°±åƒè¿™æ ·ã€‚å†åšä¸€æ¬¡åŒæ ·çš„æ“ä½œï¼Œæœ€åå†è¿›è¡Œä¸€æ¬¡æœ€å¤§æ± åŒ–ï¼Œå°ºå¯¸ç¼©å°åˆ°6Ã—6Ã—256ã€‚6Ã—6Ã—256ç­‰äº9216ï¼Œå°†å…¶å±•å¼€ä¸º9216ä¸ªå•å…ƒï¼Œç„¶åæ˜¯ä¸€äº›å…¨è¿æ¥å±‚ã€‚æœ€åä½¿ç”¨softmaxå‡½æ•°è¾“å‡ºè¯†åˆ«çš„ç»“æœï¼Œçœ‹å®ƒç©¶ç«Ÿæ˜¯1000ä¸ªå¯èƒ½çš„å¯¹è±¡ä¸­çš„å“ªä¸€ä¸ªã€‚ å®é™…ä¸Šï¼Œè¿™ç§ç¥ç»ç½‘ç»œä¸LeNetæœ‰å¾ˆå¤šç›¸ä¼¼ä¹‹å¤„ï¼Œä¸è¿‡AlexNetè¦å¤§å¾—å¤šã€‚æ­£å¦‚å‰é¢è®²åˆ°çš„LeNetæˆ–LeNet-5å¤§çº¦æœ‰6ä¸‡ä¸ªå‚æ•°ï¼Œè€ŒAlexNetåŒ…å«çº¦6000ä¸‡ä¸ªå‚æ•°ã€‚å½“ç”¨äºè®­ç»ƒå›¾åƒå’Œæ•°æ®é›†æ—¶ï¼ŒAlexNetèƒ½å¤Ÿå¤„ç†éå¸¸ç›¸ä¼¼çš„åŸºæœ¬æ„é€ æ¨¡å—ï¼Œè¿™äº›æ¨¡å—å¾€å¾€åŒ…å«ç€å¤§é‡çš„éšè—å•å…ƒæˆ–æ•°æ®ï¼Œè¿™ä¸€ç‚¹AlexNetè¡¨ç°å‡ºè‰²ã€‚AlexNetæ¯”LeNetè¡¨ç°æ›´ä¸ºå‡ºè‰²çš„å¦ä¸€ä¸ªåŸå› æ˜¯å®ƒä½¿ç”¨äº†ReLuæ¿€æ´»å‡½æ•°ã€‚åŸä½œè€…è¿˜æåˆ°äº†ä¸€ç§ä¼˜åŒ–æŠ€å·§ï¼Œå«åšLocal Response Normalization(LRN)ã€‚ è€Œåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒLRNçš„æ•ˆæœå¹¶ä¸çªå‡ºã€‚ 3. VGG-16 é¦–å…ˆç”¨3Ã—3ï¼Œæ­¥å¹…ä¸º1çš„è¿‡æ»¤å™¨æ„å»ºå·ç§¯å±‚ï¼Œpaddingå‚æ•°ä¸ºsameå·ç§¯ä¸­çš„å‚æ•°ã€‚ç„¶åç”¨ä¸€ä¸ª2Ã—2ï¼Œæ­¥å¹…ä¸º2çš„è¿‡æ»¤å™¨æ„å»ºæœ€å¤§æ± åŒ–å±‚ã€‚å› æ­¤VGGç½‘ç»œçš„ä¸€å¤§ä¼˜ç‚¹æ˜¯å®ƒç¡®å®ç®€åŒ–äº†ç¥ç»ç½‘ç»œç»“æ„ï¼Œä¸‹é¢æˆ‘ä»¬å…·ä½“è®²è®²è¿™ç§ç½‘ç»œç»“æ„ã€‚ æ•°å­—16ï¼Œå°±æ˜¯æŒ‡åœ¨è¿™ä¸ªç½‘ç»œä¸­åŒ…å«16ä¸ªå·ç§¯å±‚å’Œå…¨è¿æ¥å±‚ã€‚æ€»å…±åŒ…å«çº¦1.38äº¿ä¸ªå‚æ•° L3 : Residual Networks (ResNets)(æ®‹å·®ç½‘ç»œ(ResNets))æˆ‘ä»¬çŸ¥é“ï¼Œå¦‚æœç¥ç»ç½‘ç»œå±‚æ•°è¶Šå¤šï¼Œç½‘ç»œè¶Šæ·±ï¼Œæºäºæ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„å½±å“ï¼Œæ•´ä¸ªæ¨¡å‹éš¾ä»¥è®­ç»ƒæˆåŠŸã€‚è§£å†³çš„æ–¹æ³•ä¹‹ä¸€æ˜¯äººä¸ºåœ°è®©ç¥ç»ç½‘ç»œæŸäº›å±‚è·³è¿‡ä¸‹ä¸€å±‚ç¥ç»å…ƒçš„è¿æ¥ï¼Œéš”å±‚ç›¸è¿ï¼Œå¼±åŒ–æ¯å±‚ä¹‹é—´çš„å¼ºè”ç³»ã€‚è¿™ç§ç¥ç»ç½‘ç»œè¢«ç§°ä¸ºResidual Networks(ResNets)ã€‚ L4: Why ResNets work?(æ®‹å·®ç½‘ç»œä¸ºä»€ä¹ˆæœ‰ç”¨ï¼Ÿ) å› æ­¤ï¼Œè¿™ä¸¤å±‚é¢å¤–çš„æ®‹å·®å—ä¸ä¼šé™ä½ç½‘ç»œæ€§èƒ½ã€‚è€Œå¦‚æœæ²¡æœ‰å‘ç”Ÿæ¢¯åº¦æ¶ˆå¤±æ—¶ï¼Œè®­ç»ƒå¾—åˆ°çš„éçº¿æ€§å…³ç³»ä¼šä½¿å¾—è¡¨ç°æ•ˆæœè¿›ä¸€æ­¥æé«˜ã€‚ æ³¨æ„ï¼Œå¦‚æœ$ a[l]$ä¸ $a[l+2]$çš„ç»´åº¦ä¸åŒï¼Œéœ€è¦å¼•å…¥çŸ©é˜µ $W_s$ä¸ $a_{[l]}$ç›¸ä¹˜ï¼Œä½¿å¾—äºŒè€…çš„ç»´åº¦ç›¸åŒ¹é…ã€‚å‚æ•°çŸ©é˜µ $W_s$æ—¢å¯ä»¥é€šè¿‡æ¨¡å‹è®­ç»ƒå¾—åˆ°ï¼Œä¹Ÿå¯ä»¥ä½œä¸ºå›ºå®šå€¼ï¼Œä»…ä½¿ $a[l]$æˆªæ–­æˆ–è€…è¡¥é›¶ã€‚ L5 : Network in Network and 1Ã—1 convolutions(ç½‘ç»œä¸­çš„ç½‘ç»œä»¥åŠ 1Ã—1 å·ç§¯) ä½œç”¨ å‡è®¾è¿™æ˜¯ä¸€ä¸ª28Ã—28Ã—192çš„è¾“å…¥å±‚ï¼Œä½ å¯ä»¥ä½¿ç”¨æ± åŒ–å±‚å‹ç¼©å®ƒçš„é«˜åº¦å’Œå®½åº¦ï¼Œè¿™ä¸ªè¿‡ç¨‹æˆ‘ä»¬å¾ˆæ¸…æ¥šã€‚ä½†å¦‚æœé€šé“æ•°é‡å¾ˆå¤§ï¼Œè¯¥å¦‚ä½•æŠŠå®ƒå‹ç¼©ä¸º28Ã—28Ã—32ç»´åº¦çš„å±‚å‘¢ï¼Ÿä½ å¯ä»¥ç”¨32ä¸ªå¤§å°ä¸º1Ã—1çš„è¿‡æ»¤å™¨ï¼Œä¸¥æ ¼æ¥è®²æ¯ä¸ªè¿‡æ»¤å™¨å¤§å°éƒ½æ˜¯1Ã—1Ã—192ç»´ï¼Œå› ä¸ºè¿‡æ»¤å™¨ä¸­é€šé“æ•°é‡å¿…é¡»ä¸è¾“å…¥å±‚ä¸­é€šé“çš„æ•°é‡ä¿æŒä¸€è‡´ã€‚ä½†æ˜¯ä½ ä½¿ç”¨äº†32ä¸ªè¿‡æ»¤å™¨ï¼Œè¾“å‡ºå±‚ä¸º28Ã—28Ã—32ï¼Œè¿™å°±æ˜¯å‹ç¼©é€šé“æ•°ï¼ˆ$n_c$ï¼‰çš„æ–¹æ³•ï¼Œå¯¹äºæ± åŒ–å±‚æˆ‘åªæ˜¯å‹ç¼©äº†è¿™äº›å±‚çš„é«˜åº¦å’Œå®½åº¦ doing something pretty non-trivial å®ƒç»™ç¥ç»ç½‘ç»œæ·»åŠ äº†ä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼Œä»è€Œå‡å°‘æˆ–ä¿æŒè¾“å…¥å±‚ä¸­çš„é€šé“æ•°é‡ä¸å˜ï¼Œå½“ç„¶å¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥å¢åŠ é€šé“æ•°é‡ã€‚ L6 : Inception network motivation(è°·æ­Œ Inception ç½‘ç»œç®€ä»‹) æœ‰äº†è¿™æ ·çš„Inceptionæ¨¡å—ï¼Œä½ å°±å¯ä»¥è¾“å…¥æŸä¸ªé‡ï¼Œå› ä¸ºå®ƒç´¯åŠ äº†æ‰€æœ‰æ•°å­—ï¼Œè¿™é‡Œçš„æœ€ç»ˆè¾“å‡ºä¸º32+32+128+64=256ã€‚æœ‰äº†è¿™æ ·çš„Inceptionæ¨¡å—ï¼Œä½ å°±å¯ä»¥è¾“å…¥æŸä¸ªé‡ï¼Œå› ä¸ºå®ƒç´¯åŠ äº†æ‰€æœ‰æ•°å­—ï¼Œè¿™é‡Œçš„æœ€ç»ˆè¾“å‡ºä¸º32+32+128+64=256ã€‚Inception ç½‘ç»œé€‰ç”¨ä¸åŒå°ºå¯¸çš„æ»¤æ³¢å™¨è¿›è¡Œ Same å·ç§¯ï¼Œå¹¶å°†å·ç§¯å’Œæ± åŒ–å¾—åˆ°çš„è¾“å‡ºç»„åˆæ‹¼æ¥èµ·æ¥ï¼Œæœ€ç»ˆè®©ç½‘ç»œè‡ªå·±å»å­¦ä¹ éœ€è¦çš„å‚æ•°å’Œé‡‡ç”¨çš„æ»¤æ³¢å™¨ç»„åˆã€‚ 1x1 çš„å·ç§¯å±‚é€šå¸¸è¢«ç§°ä½œç“¶é¢ˆå±‚ï¼ˆBottleneck layerï¼‰ è®¡ç®—é‡ä¸º 28x28x32x5x5x192 = 1.2äº¿ 28x28x192x16 + 28x28x32x5x5x15 = 1.24 åƒä¸‡ï¼Œå‡å°‘äº†çº¦ 90%ã€‚ L7 : Inception network(Inception ç½‘ç»œ) L8 : Using open-source implementations( ä½¿ç”¨å¼€æºçš„å®ç°æ–¹æ¡ˆ)å¼€æºé¡¹ç›® L9 ï¼š Transfer Learningï¼ˆè¿ç§»å­¦ä¹ ï¼‰å¦‚æœä½ ä¸‹è½½åˆ«äººå·²ç»è®­ç»ƒå¥½ç½‘ç»œç»“æ„çš„æƒé‡ï¼Œä½ é€šå¸¸èƒ½å¤Ÿè¿›å±•çš„ç›¸å½“å¿«ï¼Œç”¨è¿™ä¸ªä½œä¸ºé¢„è®­ç»ƒï¼Œç„¶åè½¬æ¢åˆ°ä½ æ„Ÿå…´è¶£çš„ä»»åŠ¡ä¸Šã€‚ åªæœ‰å¾ˆå°æ•°æ®é›†ï¼š å¯ä»¥ä½ åªéœ€è¦è®­ç»ƒsoftmaxå±‚çš„æƒé‡ï¼ŒæŠŠå‰é¢è¿™äº›å±‚çš„æƒé‡éƒ½å†»ç»“ã€‚ ç¨å¾®æ›´å¤§çš„æ•°æ®é›†ï¼š ä½ åº”è¯¥å†»ç»“æ›´å°‘çš„å±‚ï¼Œæ¯”å¦‚åªæŠŠè¿™äº›å±‚å†»ç»“ï¼Œç„¶åè®­ç»ƒåé¢çš„å±‚ã€‚å¦‚æœä½ çš„è¾“å‡ºå±‚çš„ç±»åˆ«ä¸åŒï¼Œé‚£ä¹ˆä½ éœ€è¦æ„å»ºè‡ªå·±çš„è¾“å‡ºå•å…ƒï¼›æˆ–è€…ä½ å¯ä»¥ç›´æ¥å»æ‰è¿™å‡ å±‚ï¼Œæ¢æˆä½ è‡ªå·±çš„éšè—å•å…ƒå’Œä½ è‡ªå·±çš„softmaxè¾“å‡ºå±‚ï¼Œè¿™äº›æ–¹æ³•å€¼å¾—ä¸€è¯•ã€‚ å¤§é‡æ•°æ®ï¼š ä½ å¯ä»¥ç”¨ä¸‹è½½çš„æƒé‡åªä½œä¸ºåˆå§‹åŒ–ï¼Œç”¨å®ƒä»¬æ¥ä»£æ›¿éšæœºåˆå§‹åŒ–ï¼Œæ¥ç€ä½ å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™è®­ç»ƒï¼Œæ›´æ–°ç½‘ç»œæ‰€æœ‰å±‚çš„æ‰€æœ‰æƒé‡ã€‚ L10 ï¼š Data augmentationï¼ˆæ•°æ®å¢å¼ºï¼‰æ•°æ®é‡è¿œè¿œä¸å¤Ÿ Mirroring Random Cropping å½©è‰²è½¬æ¢color shifting r,g,bæ•°æ®æ”¹å˜ é™¤äº†éšæ„æ”¹å˜RGBé€šé“æ•°å€¼å¤–ï¼Œè¿˜å¯ä»¥æ›´æœ‰é’ˆå¯¹æ€§åœ°å¯¹å›¾ç‰‡çš„RGBé€šé“è¿›è¡ŒPCA color augmentationï¼Œä¹Ÿå°±æ˜¯å¯¹å›¾ç‰‡é¢œè‰²è¿›è¡Œä¸»æˆåˆ†åˆ†æï¼Œå¯¹ä¸»è¦çš„é€šé“é¢œè‰²è¿›è¡Œå¢åŠ æˆ–å‡å°‘ï¼Œå¯ä»¥é‡‡ç”¨é«˜æ–¯æ‰°åŠ¨åšæ³•ã€‚è¿™æ ·ä¹Ÿèƒ½å¢åŠ æœ‰æ•ˆçš„æ ·æœ¬æ•°é‡ã€‚å…·ä½“çš„PCA color augmentationåšæ³•å¯ä»¥æŸ¥é˜…AlexNetçš„ç›¸å…³è®ºæ–‡ã€‚ å¸¸ç”¨çš„å®ç°æ•°æ®æ‰©å……çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ä¸ªçº¿ç¨‹æˆ–è€…æ˜¯å¤šçº¿ç¨‹ï¼Œè¿™äº›å¯ä»¥ç”¨æ¥åŠ è½½æ•°æ®ï¼Œå®ç°å˜å½¢å¤±çœŸï¼Œç„¶åä¼ ç»™å…¶ä»–çš„çº¿ç¨‹æˆ–è€…å…¶ä»–è¿›ç¨‹ï¼Œæ¥è®­ç»ƒè¿™ä¸ªï¼ˆç¼–å·2ï¼‰å’Œè¿™ä¸ªï¼ˆç¼–å·1ï¼‰ï¼Œå¯ä»¥å¹¶è¡Œå®ç°ã€‚ L11ï¼šThe state of computer vision(è®¡ç®—æœºè§†è§‰ç°çŠ¶) ç¥ç»ç½‘ç»œéœ€è¦æ•°æ®ï¼Œä¸åŒçš„ç½‘ç»œæ¨¡å‹æ‰€éœ€çš„æ•°æ®é‡æ˜¯ä¸åŒçš„ã€‚Object dectionï¼ŒImage recognitionï¼ŒSpeech recognitionæ‰€éœ€çš„æ•°æ®é‡ä¾æ¬¡å¢åŠ ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœdataè¾ƒå°‘ï¼Œé‚£ä¹ˆå°±éœ€è¦æ›´å¤šçš„hand-engineeringï¼Œå¯¹å·²æœ‰dataè¿›è¡Œå¤„ç†ã€‚ hand-engineeringæ˜¯ä¸€é¡¹éå¸¸é‡è¦ä¹Ÿæ¯”è¾ƒå›°éš¾çš„å·¥ä½œã€‚å¾ˆå¤šæ—¶å€™ï¼Œhand-engineeringå¯¹æ¨¡å‹è®­ç»ƒæ•ˆæœå½±å“å¾ˆå¤§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®é‡ä¸å¤šçš„æƒ…å†µä¸‹ã€‚ å½“ä½ æœ‰å°‘é‡çš„æ•°æ®æ—¶ï¼Œæœ‰ä¸€ä»¶äº‹å¯¹ä½ å¾ˆæœ‰å¸®åŠ©ï¼Œé‚£å°±æ˜¯è¿ç§»å­¦ä¹ ã€‚åœ¨åˆ«äººåšå¥½çš„åŸºç¡€ä¸Šç ”ç©¶ æå‡æ€§èƒ½ * ç”±äºè®¡ç®—æœºè§†è§‰é—®é¢˜å»ºç«‹åœ¨å°æ•°æ®é›†ä¹‹ä¸Šï¼Œå…¶ä»–äººå·²ç»å®Œæˆäº†å¤§é‡çš„ç½‘ç»œæ¶æ„çš„æ‰‹å·¥å·¥ç¨‹ã€‚ä¸€ä¸ªç¥ç»ç½‘ç»œåœ¨æŸä¸ªè®¡ç®—æœºè§†è§‰é—®é¢˜ä¸Šå¾ˆæœ‰æ•ˆï¼Œä½†ä»¤äººæƒŠè®¶çš„æ˜¯å®ƒé€šå¸¸ä¹Ÿä¼šè§£å†³å…¶ä»–è®¡ç®—æœºè§†è§‰é—®é¢˜ã€‚ æ‰€ä»¥ï¼Œè¦æƒ³å»ºç«‹ä¸€ä¸ªå®ç”¨çš„ç³»ç»Ÿï¼Œä½ æœ€å¥½å…ˆä»å…¶ä»–äººçš„ç¥ç»ç½‘ç»œæ¶æ„å…¥æ‰‹ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œä½ å¯ä»¥ä½¿ç”¨å¼€æºçš„ä¸€äº›åº”ç”¨ï¼Œå› ä¸ºå¼€æ”¾çš„æºç å®ç°å¯èƒ½å·²ç»æ‰¾åˆ°äº†æ‰€æœ‰ç¹ççš„ç»†èŠ‚ï¼Œæ¯”å¦‚å­¦ä¹ ç‡è¡°å‡æ–¹å¼æˆ–è€…è¶…å‚æ•°ã€‚ summary1. CNNçš„å¸¸è§ç½‘ç»œç»“æ„ é‡ç‚¹è¯´äº†ä¸€äº›æ®‹å·®ç½‘ç»œ 2.æ•°æ®å¢åŠ çš„æ–¹æ³• 3. å¤šç”¨å¼€æºæ¡†æ¶ï¼Œä¸ç”¨ä»å¤´å¼€å§‹è®­ç»ƒ W3 Object detection(ç›®æ ‡æ£€æµ‹)L1 :Object localization(ç›®æ ‡å®šä½)ç›®æ ‡å®šä½å’Œç›®æ ‡æ£€æµ‹ æ¨¡å‹ è¾“å…¥è¿˜åŒ…æ‹¬ä½ç½®ä¿¡æ¯ æŸå¤±å‡½æ•° æƒ…å†µä¸€ï¼šæ£€æµ‹åˆ°äº† æƒ…å†µäºŒï¼š L2: Landmark detection(ç‰¹å¾ç‚¹æ£€æµ‹) è¯¥ç½‘ç»œæ¨¡å‹å…±æ£€æµ‹äººè„¸ä¸Š64å¤„ç‰¹å¾ç‚¹ï¼ŒåŠ ä¸Šæ˜¯å¦ä¸ºfaceçš„æ ‡å¿—ä½ï¼Œè¾“å‡ºlabelå…±æœ‰64x2+1=129ä¸ªå€¼ã€‚é€šè¿‡æ£€æµ‹äººè„¸ç‰¹å¾ç‚¹å¯ä»¥è¿›è¡Œæƒ…ç»ªåˆ†ç±»ä¸åˆ¤æ–­ï¼Œæˆ–è€…åº”ç”¨äºARé¢†åŸŸç­‰ç­‰ã€‚ é™¤äº†äººè„¸ç‰¹å¾ç‚¹æ£€æµ‹ä¹‹å¤–ï¼Œè¿˜å¯ä»¥æ£€æµ‹äººä½“å§¿åŠ¿åŠ¨ä½œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š L3 :Object detection(ç›®æ ‡æ£€æµ‹)å­¦è¿‡äº†å¯¹è±¡å®šä½å’Œç‰¹å¾ç‚¹æ£€æµ‹ï¼Œä»Šå¤©æˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ªå¯¹è±¡æ£€æµ‹ç®—æ³•ã€‚è¿™èŠ‚è¯¾ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•é€šè¿‡å·ç§¯ç½‘ç»œè¿›è¡Œå¯¹è±¡æ£€æµ‹ï¼Œé‡‡ç”¨çš„æ˜¯åŸºäºæ»‘åŠ¨çª—å£çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ã€‚ è®­ç»ƒå®Œè¿™ä¸ªå·ç§¯ç½‘ç»œï¼Œå°±å¯ä»¥ç”¨å®ƒæ¥å®ç°æ»‘åŠ¨çª—å£ç›®æ ‡æ£€æµ‹ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ã€‚ é€‰å®šç‰¹å®šå¤§å°çš„çª—å£ï¼Œçª—å£åœˆå®šè¾“å…¥å·ç§¯ç¥ç»ç½‘ç»œï¼Œå·ç§¯ç¥ç»ç½‘ç»œå¼€å§‹é¢„æµ‹ã€‚ é‡å¤ä¸Šè¿°æ“ä½œï¼Œä¸è¿‡è¿™æ¬¡æˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªæ›´å¤§çš„çª—å£ï¼Œæˆªå–æ›´å¤§çš„åŒºåŸŸï¼Œå¹¶è¾“å…¥ç»™å·ç§¯ç¥ç»ç½‘ç»œå¤„ç†ï¼Œä½ å¯ä»¥æ ¹æ®å·ç§¯ç½‘ç»œå¯¹è¾“å…¥å¤§å°è°ƒæ•´è¿™ä¸ªåŒºåŸŸï¼Œç„¶åè¾“å…¥ç»™å·ç§¯ç½‘ç»œï¼Œè¾“å‡º0æˆ– å¦‚æœä½ è¿™æ ·åšï¼Œä¸è®ºæ±½è½¦åœ¨å›¾ç‰‡çš„ä»€ä¹ˆä½ç½®ï¼Œæ€»æœ‰ä¸€ä¸ªçª—å£å¯ä»¥æ£€æµ‹åˆ°å®ƒã€‚ è¿™ç§ç®—æ³•å«ä½œæ»‘åŠ¨çª—å£ç›®æ ‡æ£€æµ‹ï¼Œå› ä¸ºæˆ‘ä»¬ä»¥æŸä¸ªæ­¥å¹…æ»‘åŠ¨è¿™äº›æ–¹æ¡†çª—å£éå†æ•´å¼ å›¾ç‰‡ï¼Œå¯¹è¿™äº›æ–¹å½¢åŒºåŸŸè¿›è¡Œåˆ†ç±»ï¼Œåˆ¤æ–­é‡Œé¢æœ‰æ²¡æœ‰æ±½è½¦ã€‚ æ»‘åŠ¨çª—ç®—æ³•çš„ä¼˜ç‚¹æ˜¯åŸç†ç®€å•ï¼Œä¸”ä¸éœ€è¦äººä¸ºé€‰å®šç›®æ ‡åŒºåŸŸï¼ˆæ£€æµ‹å‡ºç›®æ ‡çš„æ»‘åŠ¨çª—å³ä¸ºç›®æ ‡åŒºåŸŸï¼‰ã€‚ä½†æ˜¯å…¶ç¼ºç‚¹ä¹Ÿå¾ˆæ˜æ˜¾ï¼Œé¦–å…ˆæ»‘åŠ¨çª—çš„å¤§å°å’Œæ­¥è¿›é•¿åº¦éƒ½éœ€è¦äººä¸ºç›´è§‚è®¾å®šã€‚æ»‘åŠ¨çª—è¿‡å°æˆ–è¿‡å¤§ï¼Œæ­¥è¿›é•¿åº¦è¿‡å¤§å‡ä¼šé™ä½ç›®æ ‡æ£€æµ‹æ­£ç¡®ç‡ã€‚è€Œä¸”ï¼Œæ¯æ¬¡æ»‘åŠ¨çª—åŒºåŸŸéƒ½è¦è¿›è¡Œä¸€æ¬¡CNNç½‘ç»œè®¡ç®—ï¼Œå¦‚æœæ»‘åŠ¨çª—å’Œæ­¥è¿›é•¿åº¦è¾ƒå°ï¼Œæ•´ä¸ªç›®æ ‡æ£€æµ‹çš„ç®—æ³•è¿è¡Œæ—¶é—´ä¼šå¾ˆé•¿ã€‚æ‰€ä»¥ï¼Œæ»‘åŠ¨çª—ç®—æ³•è™½ç„¶ç®€å•ï¼Œä½†æ˜¯æ€§èƒ½ä¸ä½³ï¼Œä¸å¤Ÿå¿«ï¼Œä¸å¤Ÿçµæ´»ã€‚ L 4 : Convolutional implementation of sliding windows(æ»‘åŠ¨çª—å£çš„å·ç§¯å®ç°) å…¨è¿æ¥å±‚è½¬åŒ–ä¸ºå·ç§¯å±‚ å•ä¸ªçª—å£åŒºåŸŸå·ç§¯ç½‘ç»œç»“æ„å»ºç«‹å®Œæ¯•ä¹‹åï¼Œå¯¹äºå¾…æ£€æµ‹å›¾ç‰‡ï¼Œå³å¯ä½¿ç”¨è¯¥ç½‘ç»œå‚æ•°å’Œç»“æ„è¿›è¡Œè¿ç®—ã€‚ä¾‹å¦‚16 x 16 x 3çš„å›¾ç‰‡ï¼Œæ­¥è¿›é•¿åº¦ä¸º2ï¼ŒCNNç½‘ç»œå¾—åˆ°çš„è¾“å‡ºå±‚ä¸º2 x 2 x 4ã€‚å…¶ä¸­ï¼Œ2 x 2è¡¨ç¤ºå…±æœ‰4ä¸ªçª—å£ç»“æœã€‚å¯¹äºæ›´å¤æ‚çš„28 x 28 x3çš„å›¾ç‰‡ï¼ŒCNNç½‘ç»œå¾—åˆ°çš„è¾“å‡ºå±‚ä¸º8 x 8 x 4ï¼Œå…±64ä¸ªçª—å£ç»“æœã€‚ ä¹‹å‰çš„æ»‘åŠ¨çª—ç®—æ³•éœ€è¦åå¤è¿›è¡ŒCNNæ­£å‘è®¡ç®—ï¼Œä¾‹å¦‚16 x 16 x 3çš„å›¾ç‰‡éœ€è¿›è¡Œ4æ¬¡ï¼Œ28 x 28 x3çš„å›¾ç‰‡éœ€è¿›è¡Œ64æ¬¡ã€‚è€Œåˆ©ç”¨å·ç§¯æ“ä½œä»£æ›¿æ»‘åŠ¨çª—ç®—æ³•ï¼Œåˆ™ä¸ç®¡åŸå§‹å›¾ç‰‡æœ‰å¤šå¤§ï¼Œåªéœ€è¦è¿›è¡Œä¸€æ¬¡CNNæ­£å‘è®¡ç®—ï¼Œå› ä¸ºå…¶ä¸­å…±äº«äº†å¾ˆå¤šé‡å¤è®¡ç®—éƒ¨åˆ†ï¼Œè¿™å¤§å¤§èŠ‚çº¦äº†è¿ç®—æˆæœ¬ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œçª—å£æ­¥è¿›é•¿åº¦ä¸é€‰æ‹©çš„MAX POOLå¤§å°æœ‰å…³ã€‚å¦‚æœéœ€è¦æ­¥è¿›é•¿åº¦ä¸º4ï¼Œåªéœ€è®¾ç½®MAX POOLä¸º4 x 4å³å¯ã€‚ L5 ï¼š Bounding box predictionsï¼ˆBounding Boxé¢„æµ‹ï¼‰ YOLOï¼ˆYou Only Look Onceï¼‰ç®—æ³•å¯ä»¥è§£å†³è¿™ç±»é—®é¢˜ï¼Œç”Ÿæˆæ›´åŠ å‡†ç¡®çš„ç›®æ ‡åŒºåŸŸï¼ˆå¦‚ä¸Šå›¾çº¢è‰²çª—å£ï¼‰ã€‚ å¦‚æœç›®æ ‡ä¸­å¿ƒåæ ‡(bx,by)ä¸åœ¨å½“å‰ç½‘æ ¼å†…ï¼Œåˆ™å½“å‰ç½‘æ ¼Pc=0ï¼›ç›¸åï¼Œåˆ™å½“å‰ç½‘æ ¼Pc=1ï¼ˆå³åªçœ‹ä¸­å¿ƒåæ ‡æ˜¯å¦åœ¨å½“å‰ç½‘æ ¼å†…ï¼‰ã€‚åˆ¤æ–­æœ‰ç›®æ ‡çš„ç½‘æ ¼ä¸­ï¼Œbx,by,bh,bwé™å®šäº†ç›®æ ‡åŒºåŸŸã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå½“å‰ç½‘æ ¼å·¦ä¸Šè§’åæ ‡è®¾å®šä¸º(0, 0)ï¼Œå³ä¸‹è§’åæ ‡è®¾å®šä¸º(1, 1)ï¼Œ(bx,by)èŒƒå›´é™å®šåœ¨[0,1]ä¹‹é—´ï¼Œä½†æ˜¯bh,bwå¯ä»¥å¤§äº1ã€‚å› ä¸ºç›®æ ‡å¯èƒ½è¶…å‡ºè¯¥ç½‘æ ¼ï¼Œæ¨ªè·¨å¤šä¸ªåŒºåŸŸï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚ç›®æ ‡å å‡ ä¸ªç½‘æ ¼æ²¡æœ‰å…³ç³»ï¼Œç›®æ ‡ä¸­å¿ƒåæ ‡å¿…ç„¶åœ¨ä¸€ä¸ªç½‘æ ¼ä¹‹å†…ã€‚ L6 ï¼šIntersection over unionï¼ˆäº¤å¹¶æ¯”) ä¸€èˆ¬çº¦å®šï¼Œåœ¨è®¡ç®—æœºæ£€æµ‹ä»»åŠ¡ä¸­ï¼Œå¦‚æœlou&gt;=0.5ï¼Œå°±è¯´æ£€æµ‹æ­£ç¡®ï¼Œå¦‚æœé¢„æµ‹å™¨å’Œå®é™…è¾¹ç•Œæ¡†å®Œç¾é‡å ï¼ŒloUå°±æ˜¯1ï¼Œå› ä¸ºäº¤é›†å°±ç­‰äºå¹¶é›†ã€‚ä½†ä¸€èˆ¬æ¥è¯´åªè¦lou&gt;=0.5ï¼Œé‚£ä¹ˆç»“æœæ˜¯å¯ä»¥æ¥å—çš„ï¼Œçœ‹èµ·æ¥è¿˜å¯ä»¥ã€‚ä¸€èˆ¬çº¦å®šï¼Œ0.5æ˜¯é˜ˆå€¼ï¼Œç”¨æ¥åˆ¤æ–­é¢„æµ‹çš„è¾¹ç•Œæ¡†æ˜¯å¦æ­£ç¡®ã€‚ä¸€èˆ¬æ˜¯è¿™ä¹ˆçº¦å®šï¼Œä½†å¦‚æœä½ å¸Œæœ›æ›´ä¸¥æ ¼ä¸€ç‚¹ï¼Œä½ å¯ä»¥å°†loUå®šå¾—æ›´é«˜ï¼Œæ¯”å¦‚è¯´å¤§äº0.6æˆ–è€…æ›´å¤§çš„æ•°å­—ï¼Œä½†loUè¶Šé«˜ï¼Œè¾¹ç•Œæ¡†è¶Šç²¾ç¡®ã€‚ L7: Non-max suppression(éæå¤§å€¼æŠ‘åˆ¶)åˆ°ç›®å‰ä¸ºæ­¢ä½ ä»¬å­¦åˆ°çš„å¯¹è±¡æ£€æµ‹ä¸­çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä½ çš„ç®—æ³•å¯èƒ½å¯¹åŒä¸€ä¸ªå¯¹è±¡åšå‡ºå¤šæ¬¡æ£€æµ‹ï¼Œæ‰€ä»¥ç®—æ³•ä¸æ˜¯å¯¹æŸä¸ªå¯¹è±¡æ£€æµ‹å‡ºä¸€æ¬¡ï¼Œè€Œæ˜¯æ£€æµ‹å‡ºå¤šæ¬¡ã€‚éæå¤§å€¼æŠ‘åˆ¶è¿™ä¸ªæ–¹æ³•å¯ä»¥ç¡®ä¿ä½ çš„ç®—æ³•å¯¹æ¯ä¸ªå¯¹è±¡åªæ£€æµ‹ä¸€æ¬¡ï¼Œæˆ‘ä»¬è®²ä¸€ä¸ªä¾‹å­ã€‚ å‡è®¾ä½ éœ€è¦åœ¨è¿™å¼ å›¾ç‰‡é‡Œæ£€æµ‹è¡Œäººå’Œæ±½è½¦ï¼Œä½ å¯èƒ½ä¼šåœ¨ä¸Šé¢æ”¾ä¸ª19Ã—19ç½‘æ ¼ï¼Œç†è®ºä¸Šè¿™è¾†è½¦åªæœ‰ä¸€ä¸ªä¸­ç‚¹ï¼Œæ‰€ä»¥å®ƒåº”è¯¥åªè¢«åˆ†é…åˆ°ä¸€ä¸ªæ ¼å­é‡Œï¼Œå·¦è¾¹çš„è½¦å­ä¹Ÿåªæœ‰ä¸€ä¸ªä¸­ç‚¹ï¼Œæ‰€ä»¥ç†è®ºä¸Šåº”è¯¥åªæœ‰ä¸€ä¸ªæ ¼å­åšå‡ºæœ‰è½¦çš„é¢„æµ‹ã€‚ å®é™…æƒ…å†µæ˜¯æ ¼å­1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6éƒ½è®¤ä¸ºé‡Œé¢æœ‰è½¦ã€‚å› ä¸ºä½ è¦åœ¨361ä¸ªæ ¼å­ä¸Šéƒ½è¿è¡Œä¸€æ¬¡å›¾åƒæ£€æµ‹å’Œå®šä½ç®—æ³•ï¼Œé‚£ä¹ˆå¯èƒ½å¾ˆå¤šæ ¼å­éƒ½ä¼šä¸¾æ‰‹è¯´æˆ‘çš„pc,æˆ‘è¿™ä¸ªæ ¼å­é‡Œæœ‰è½¦çš„æ¦‚ç‡å¾ˆé«˜ï¼Œè€Œä¸æ˜¯361ä¸ªæ ¼å­ä¸­ä»…æœ‰ä¸¤ä¸ªæ ¼å­ä¼šæŠ¥å‘Šå®ƒä»¬æ£€æµ‹å‡ºä¸€ä¸ªå¯¹è±¡ã€‚ éæœ€å¤§å€¼æŠ‘åˆ¶ï¼ˆNon-max Suppressionï¼‰åšæ³•å¾ˆç®€å•ï¼Œå›¾ç¤ºæ¯ä¸ªç½‘æ ¼çš„Pcå€¼å¯ä»¥æ±‚å‡ºï¼ŒPcå€¼åæ˜ äº†è¯¥ç½‘æ ¼åŒ…å«ç›®æ ‡ä¸­å¿ƒåæ ‡çš„å¯ä¿¡åº¦ã€‚é¦–å…ˆé€‰å–Pcæœ€å¤§å€¼å¯¹åº”çš„ç½‘æ ¼å’ŒåŒºåŸŸï¼Œç„¶åè®¡ç®—è¯¥åŒºåŸŸä¸æ‰€æœ‰å…¶å®ƒåŒºåŸŸçš„IoUï¼Œå‰”é™¤æ‰IoUå¤§äºé˜ˆå€¼ï¼ˆä¾‹å¦‚0.5ï¼‰çš„æ‰€æœ‰ç½‘æ ¼åŠåŒºåŸŸã€‚è¿™æ ·å°±èƒ½ä¿è¯åŒä¸€ç›®æ ‡åªæœ‰ä¸€ä¸ªç½‘æ ¼ä¸ä¹‹å¯¹åº”ï¼Œä¸”è¯¥ç½‘æ ¼Pcæœ€å¤§ï¼Œæœ€å¯ä¿¡ã€‚æ¥ç€ï¼Œå†ä»å‰©ä¸‹çš„ç½‘æ ¼ä¸­é€‰å–Pcæœ€å¤§çš„ç½‘æ ¼ï¼Œé‡å¤ä¸Šä¸€æ­¥çš„æ“ä½œã€‚æœ€åï¼Œå°±èƒ½ä½¿å¾—æ¯ä¸ªç›®æ ‡éƒ½ä»…ç”±ä¸€ä¸ªç½‘æ ¼å’ŒåŒºåŸŸå¯¹åº”ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š æ€»ç»“ä¸€ä¸‹éæœ€å¤§å€¼æŠ‘åˆ¶ç®—æ³•çš„æµç¨‹ï¼š å‰”é™¤Pcå€¼å°äºæŸé˜ˆå€¼ï¼ˆä¾‹å¦‚0.6ï¼‰çš„æ‰€æœ‰ç½‘æ ¼ï¼› é€‰å–Pcå€¼æœ€å¤§çš„ç½‘æ ¼ï¼Œåˆ©ç”¨IoUï¼Œæ‘’å¼ƒä¸è¯¥ç½‘æ ¼äº¤å è¾ƒå¤§çš„ç½‘æ ¼ï¼› å¯¹å‰©ä¸‹çš„ç½‘æ ¼ï¼Œé‡å¤æ­¥éª¤2ã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¯¹è±¡æ£€æµ‹ä¸­å­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜æ˜¯æ¯ä¸ªæ ¼å­åªèƒ½æ£€æµ‹å‡ºä¸€ä¸ªå¯¹è±¡ï¼Œå¦‚æœä½ æƒ³è®©ä¸€ä¸ªæ ¼å­æ£€æµ‹å‡ºå¤šä¸ªå¯¹è±¡ï¼Œä½ å¯ä»¥è¿™ä¹ˆåšï¼Œå°±æ˜¯ä½¿ç”¨anchor boxè¿™ä¸ªæ¦‚å¿µï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªä¾‹å­å¼€å§‹è®²å§ã€‚æ–¹æ³•æ˜¯ä½¿ç”¨ä¸åŒå½¢çŠ¶çš„Anchor Boxesã€‚ è¿™å°±æ˜¯anchor boxçš„æ¦‚å¿µï¼Œæˆ‘ä»¬å»ºç«‹anchor boxè¿™ä¸ªæ¦‚å¿µï¼Œæ˜¯ä¸ºäº†å¤„ç†ä¸¤ä¸ªå¯¹è±¡å‡ºç°åœ¨åŒä¸€ä¸ªæ ¼å­çš„æƒ…å†µï¼Œå®è·µä¸­è¿™ç§æƒ…å†µå¾ˆå°‘å‘ç”Ÿ L9 : YOLO ç®—æ³•ï¼ˆPutting it together: YOLO algorithmï¼‰ è¿™å°±æ˜¯YOLOå¯¹è±¡æ£€æµ‹ç®—æ³•ï¼Œè¿™å®é™…ä¸Šæ˜¯æœ€æœ‰æ•ˆçš„å¯¹è±¡æ£€æµ‹ç®—æ³•ä¹‹ä¸€ï¼ŒåŒ…å«äº†æ•´ä¸ªè®¡ç®—æœºè§†è§‰å¯¹è±¡æ£€æµ‹é¢†åŸŸæ–‡çŒ®ä¸­å¾ˆå¤šæœ€ç²¾å¦™çš„æ€è·¯ Region proposals (Optional)ï¼ˆå€™é€‰åŒºåŸŸï¼ˆé€‰ä¿®ï¼‰ï¼‰ä¹‹å‰ä»‹ç»çš„æ»‘åŠ¨çª—ç®—æ³•ä¼šå¯¹åŸå§‹å›¾ç‰‡çš„æ¯ä¸ªåŒºåŸŸéƒ½è¿›è¡Œæ‰«æï¼Œå³ä½¿æ˜¯ä¸€äº›ç©ºç™½çš„æˆ–æ˜æ˜¾æ²¡æœ‰ç›®æ ‡çš„åŒºåŸŸï¼Œä¾‹å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚è¿™æ ·ä¼šé™ä½ç®—æ³•è¿è¡Œæ•ˆç‡ï¼Œè€—è´¹æ—¶é—´ã€‚ ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå°½é‡é¿å…å¯¹æ— ç”¨åŒºåŸŸçš„æ‰«æï¼Œå¯ä»¥ä½¿ç”¨Region Proposalsçš„æ–¹æ³•ã€‚å…·ä½“åšæ³•æ˜¯å…ˆå¯¹åŸå§‹å›¾ç‰‡è¿›è¡Œåˆ†å‰²ç®—æ³•å¤„ç†ï¼Œç„¶åæ”¯é˜Ÿåˆ†å‰²åçš„å›¾ç‰‡ä¸­çš„å—è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚ Region Proposalså…±æœ‰ä¸‰ç§æ–¹æ³•ï¼š R-CNN: æ»‘åŠ¨çª—çš„å½¢å¼ï¼Œä¸€æ¬¡åªå¯¹å•ä¸ªåŒºåŸŸå—è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè¿ç®—é€Ÿåº¦æ…¢ã€‚ Fast R-CNN: åˆ©ç”¨å·ç§¯å®ç°æ»‘åŠ¨çª—ç®—æ³•ï¼Œç±»ä¼¼ç¬¬4èŠ‚åšæ³•ã€‚ Faster R-CNN: åˆ©ç”¨å·ç§¯å¯¹å›¾ç‰‡è¿›è¡Œåˆ†å‰²ï¼Œè¿›ä¸€æ­¥æé«˜è¿è¡Œé€Ÿåº¦ã€‚ W4ï¼šSpecial applications: Face recognition &amp;Neural style transfer( ç‰¹æ®Šåº”ç”¨ï¼šäººè„¸è¯†åˆ«å’Œç¥ç»é£æ ¼è½¬æ¢)C1 ï¼š What is face recognition?é¦–å…ˆç®€å•ä»‹ç»ä¸€ä¸‹äººè„¸éªŒè¯ï¼ˆface verificationï¼‰å’Œäººè„¸è¯†åˆ«ï¼ˆface recognitionï¼‰çš„åŒºåˆ«ã€‚ äººè„¸éªŒè¯ï¼šè¾“å…¥ä¸€å¼ äººè„¸å›¾ç‰‡ï¼ŒéªŒè¯è¾“å‡ºä¸æ¨¡æ¿æ˜¯å¦ä¸ºåŒä¸€äººï¼Œå³ä¸€å¯¹ä¸€é—®é¢˜ã€‚ äººè„¸è¯†åˆ«ï¼šè¾“å…¥ä¸€å¼ äººè„¸å›¾ç‰‡ï¼ŒéªŒè¯è¾“å‡ºæ˜¯å¦ä¸ºKä¸ªæ¨¡æ¿ä¸­çš„æŸä¸€ä¸ªï¼Œå³ä¸€å¯¹å¤šé—®é¢˜ã€‚ L2 ï¼š One-shot learningOne-shot learningå°±æ˜¯è¯´æ•°æ®åº“ä¸­æ¯ä¸ªäººçš„è®­ç»ƒæ ·æœ¬åªåŒ…å«ä¸€å¼ ç…§ç‰‡ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªCNNæ¨¡å‹æ¥è¿›è¡Œäººè„¸è¯†åˆ«ã€‚è‹¥æ•°æ®åº“æœ‰Kä¸ªäººï¼Œåˆ™CNNæ¨¡å‹è¾“å‡ºsoftmaxå±‚å°±æ˜¯Kç»´çš„ã€‚ ä½†æ˜¯One-shot learningçš„æ€§èƒ½å¹¶ä¸å¥½ï¼Œå…¶åŒ…å«äº†ä¸¤ä¸ªç¼ºç‚¹ï¼š æ¯ä¸ªäººåªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œè®­ç»ƒæ ·æœ¬å°‘ï¼Œæ„å»ºçš„CNNç½‘ç»œä¸å¤Ÿå¥å£®ã€‚ è‹¥æ•°æ®åº“å¢åŠ å¦ä¸€ä¸ªäººï¼Œè¾“å‡ºå±‚softmaxçš„ç»´åº¦å°±è¦å‘ç”Ÿå˜åŒ–ï¼Œç›¸å½“äºè¦é‡æ–°æ„å»ºCNNç½‘ç»œï¼Œä½¿æ¨¡å‹è®¡ç®—é‡å¤§å¤§å¢åŠ ï¼Œä¸å¤Ÿçµæ´»ã€‚ ä¸ºäº†è§£å†³One-shot learningçš„é—®é¢˜ï¼Œæˆ‘ä»¬å…ˆæ¥ä»‹ç»ç›¸ä¼¼å‡½æ•°ï¼ˆsimilarity functionï¼‰ã€‚ç›¸ä¼¼å‡½æ•°è¡¨ç¤ºä¸¤å¼ å›¾ç‰‡çš„ç›¸ä¼¼ç¨‹åº¦ï¼Œç”¨d(img1,img2)æ¥è¡¨ç¤ºã€‚è‹¥d(img1,img2)è¾ƒå°ï¼Œåˆ™è¡¨ç¤ºä¸¤å¼ å›¾ç‰‡ç›¸ä¼¼ï¼›è‹¥d(img1,img2)è¾ƒå¤§ï¼Œåˆ™è¡¨ç¤ºä¸¤å¼ å›¾ç‰‡ä¸æ˜¯åŒä¸€ä¸ªäººã€‚ç›¸ä¼¼å‡½æ•°å¯ä»¥åœ¨äººè„¸éªŒè¯ä¸­ä½¿ç”¨ï¼š d(img1,img2)â‰¤Ï„ : ä¸€æ · d(img1,img2)&gt;Ï„ : ä¸ä¸€æ · ç°åœ¨ä½ å·²ç»çŸ¥é“å‡½æ•°dæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œé€šè¿‡è¾“å…¥ä¸¤å¼ ç…§ç‰‡ï¼Œå®ƒå°†è®©ä½ èƒ½å¤Ÿè§£å†³ä¸€æ¬¡å­¦ä¹ é—®é¢˜ã€‚é‚£ä¹ˆï¼Œä¸‹èŠ‚è§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†ä¼šå­¦ä¹ å¦‚ä½•è®­ç»ƒä½ çš„ç¥ç»ç½‘ç»œå­¦ä¼šè¿™ä¸ªå‡½æ•°ã€‚ L3: Siamese networkæœ€åä¸€å±‚å»æ‰softmaxå•å…ƒåšåˆ†ç±» å¦‚æœä½ è¦æ¯”è¾ƒä¸¤ä¸ªå›¾ç‰‡çš„è¯ï¼Œä¾‹å¦‚è¿™é‡Œçš„ç¬¬ä¸€å¼ ï¼ˆç¼–å·1ï¼‰å’Œç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆç¼–å·2ï¼‰ï¼Œä½ è¦åšçš„å°±æ˜¯æŠŠç¬¬äºŒå¼ å›¾ç‰‡å–‚ç»™æœ‰åŒæ ·å‚æ•°çš„åŒæ ·çš„ç¥ç»ç½‘ç»œï¼Œç„¶åå¾—åˆ°ä¸€ä¸ªä¸åŒçš„128ç»´çš„å‘é‡ï¼ˆç¼–å·3ï¼‰ï¼Œè¿™ä¸ªå‘é‡ä»£è¡¨æˆ–è€…ç¼–ç ç¬¬äºŒä¸ªå›¾ç‰‡ï¼Œæˆ‘è¦æŠŠç¬¬äºŒå¼ å›¾ç‰‡çš„ç¼–ç å«åš$f(x^{(2)})$ã€‚è¿™é‡Œæˆ‘ç”¨$x^{(1)}$å’Œ$x^{(2)}$ä»…ä»…ä»£è¡¨ä¸¤ä¸ªè¾“å…¥å›¾ç‰‡, d(x^{(1)},x^{(2)})=||f(x^{(1)}-f(x^{(2)}||^2ä¸åŒçš„å›¾ç‰‡çš„CNNç½‘ç»œç»“æ„å’Œå‚æ•°éƒ½æ˜¯ä¸€æ ·çš„ï¼Œç›®æ ‡å°±æ˜¯åˆ©ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œè°ƒæ•´ç½‘ç»œå‚æ•°]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Deep Learning Specialization]]></title>
    <url>%2F2019%2F05%2F05%2FDeep%20Learning%20ai_Deep%20Learning%20Specialization%2F</url>
    <content type="text"><![CDATA[C3 Improving Model PerformanceW1 ML Strategy(1)L01 Improving Model Performanceéœ€è¦æé«˜è®­ç»ƒç»“æœçš„è¡¨ç°ï¼Œè¡¨ç°å¾—æ›´å¥½çš„æªæ–½ Machine Learning Strategy L2 : Orthogonalization(æ­£äº¤åŒ–)æ‰€è°“æ­£äº¤ï¼Œå°±æ˜¯ä½ çš„æ“æ§æ•ˆæœå°½é‡åªå½±å“ä¸€ä¸ªæ–¹é¢ã€‚æ¯”å¦‚ä»¥è€å¼ç”µè§†æœºä¸ºä¾‹ï¼Œè°ƒèŠ‚å›¾åƒçš„å¤§å°ã€å·¦å³åç§»ã€ä¸Šä¸‹åç§»ã€‚è€Œä¸æ˜¯ä¸€ä¸ªæŒ‰é’®å¯ä»¥åŒæ—¶è°ƒèŠ‚å›¾åƒå¤§å°å’Œå·¦å³åç§»ï¼Œé‚£æ ·ä¼šå¾ˆéš¾æ“ä½œã€‚ å…·ä½“åˆ°supervised learningï¼Œæœ‰ä»¥ä¸‹4ä¸ªå‡è®¾æ˜¯æ­£äº¤çš„ï¼Ÿ Fit training set well in cost function If it doesnâ€™t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help. Fit development set well on cost function If it doesnâ€™t fit well, regularization or using bigger training set might help. Fit test set well on cost function If it doesnâ€™t fit well, the use of a bigger development set might help Performs well in real world If it doesnâ€™t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing. åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°æ¬ ä½³ï¼Œéœ€è¦åˆ‡æ¢åˆ°å¥½çš„ä¼˜åŒ–ç®—æ³• åœ¨éªŒè¯é›†ä¸Šè¡¨ç°ä¸å¥½ï¼Œä¸€ç»„æ­£åˆ™åŒ–æŒ‰é’® åœ¨æµ‹è¯•é›†è¡¨ç°ä¸å¥½ï¼Œéœ€è¦æ›´å¥½çš„éªŒè¯é›† åœ¨ç”¨æˆ·ä½“éªŒä¸å¥½ï¼Œéœ€è¦æ”¹å˜æµ‹è¯•é›†å¤§å°æˆ–è€…æˆæœ¬å‡½æ•° L3 Single number evaluation metric(å•ä¸€æ•°å­—è¯„ä¼°æŒ‡æ ‡)classification Precesion ï¼ˆæŸ¥å‡†ç‡ï¼‰ recallï¼ˆæŸ¥å…¨ç‡ï¼‰ F 1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2 P R}{P+R}L4 Satisficing and optimizing metrics(æ»¡è¶³å’Œä¼˜åŒ–æŒ‡æ ‡)å¦‚æœæˆ‘ä»¬è¿˜æƒ³è¦å°†åˆ†ç±»å™¨çš„è¿è¡Œæ—¶é—´ä¹Ÿçº³å…¥è€ƒè™‘èŒƒå›´ï¼Œå°†å…¶å’Œç²¾ç¡®ç‡ã€å¬å›ç‡ç»„åˆæˆä¸€ä¸ªå•å€¼è¯„ä»·æŒ‡æ ‡æ˜¾ç„¶ä¸é‚£ä¹ˆåˆé€‚ã€‚è¿™æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†æŸäº›æŒ‡æ ‡ä½œä¸ºä¼˜åŒ–æŒ‡æ ‡ï¼ˆOptimizing Matricï¼‰ï¼Œå¯»æ±‚å®ƒä»¬çš„æœ€ä¼˜å€¼ï¼›è€Œå°†æŸäº›æŒ‡æ ‡ä½œä¸ºæ»¡è¶³æŒ‡æ ‡ï¼ˆSatisficing Matricï¼‰ï¼Œåªè¦åœ¨ä¸€å®šé˜ˆå€¼ä»¥å†…å³å¯ã€‚ åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå‡†ç¡®ç‡å°±æ˜¯ä¸€ä¸ªä¼˜åŒ–æŒ‡æ ‡ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è¦åˆ†ç±»å™¨å°½å¯èƒ½åšåˆ°æ­£ç¡®åˆ†ç±»ï¼›è€Œè¿è¡Œæ—¶é—´å°±æ˜¯ä¸€ä¸ªæ»¡è¶³æŒ‡æ ‡ï¼Œå¦‚æœä½ æƒ³è¦åˆ†ç±»å™¨çš„è¿è¡Œæ—¶é—´ä¸å¤šäºæŸä¸ªé˜ˆå€¼ï¼Œé‚£æœ€ç»ˆé€‰æ‹©çš„åˆ†ç±»å™¨å°±åº”è¯¥æ˜¯ä»¥è¿™ä¸ªé˜ˆå€¼ä¸ºç•Œé‡Œé¢å‡†ç¡®ç‡æœ€é«˜çš„é‚£ä¸ªã€‚ å¦‚æ­¤ï¼Œaccuracyå°±å˜æˆäº†optimizing metricï¼Œè€Œrunning timeåˆ™æ˜¯satisfying metricï¼Œstatisfying metricåªè¦è¾¾åˆ°æ ‡å‡†å³å¯ï¼Œè€Œoptimizing metricåˆ™è¿½æ±‚æ›´å¥½ã€‚ä¸€èˆ¬çš„ï¼Œé€‰æ‹©ä¸€é¡¹metricä½œä¸ºoptimizing metricï¼Œå…¶ä»–çš„åˆ™è®¾ç½®ä¸ºsatisfying metricï¼š L 5: Train/dev/test distributions(è®­ç»ƒ/å¼€å‘/æµ‹è¯•é›†åˆ’åˆ†)å¼€å‘ï¼ˆdevï¼‰é›†ä¹Ÿå«åšå¼€å‘é›†ï¼ˆdevelopment setï¼‰ï¼Œæœ‰æ—¶ç§°ä¸ºä¿ç•™äº¤å‰éªŒè¯é›†ï¼ˆhold out cross validation setï¼‰ã€‚ å¦‚ä½•è®¾ç½®Train/dev/testé›†ï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šå½±å“äº†æœºå™¨å­¦ä¹ çš„é€Ÿåº¦ã€‚ Train/dev/testçš„åŒºåˆ« Workflow in machine learning is that you try a lot of ideas, train up different models on the training set, and then use the dev set to evaluate the different ideas and pick one. And, keep innovating to improve dev set performance until, finally, you have one class that youâ€™re happy with that you then evaluate on your test set. å¼€å‘é›†åˆå’Œå¼€å‘é›†åˆæ¥è‡ªåŒä¸€åˆ†å¸ƒï¼Œå¦‚æœæ˜¯ä¸åŒåˆ†å¸ƒï¼Œç›¸å½“äºé¶å¿ƒç§»åŠ¨äº† L 6: Size of dev and test sets(å¼€å‘é›†å’Œæµ‹è¯•é›†çš„å¤§å°) L7 : When to change dev/test sets and metrics(ä»€ä¹ˆæ—¶å€™è¯¥æ”¹å˜å¼€å‘/æµ‹è¯•é›†å’ŒæŒ‡æ ‡)å¦‚æœå‘ç°è®¾å®šç›®æ ‡å’Œå®é™…æœŸæœ›ä¸ç¬¦ï¼Œé‚£å°±è°ƒæ•´ç›®æ ‡ã€‚ ä¸¾ä¸ªä¾‹å­ Aå¯èƒ½æŠŠä¸€äº›è‰²æƒ…ç…§ç‰‡ä¹Ÿåˆ†ç±»æˆçŒ«äº†ï¼Œå› æ­¤æ”¹å˜ä¼˜åŒ–æŒ‡æ ‡ æˆ‘æƒ³ä½ å¤„ç†æœºå™¨å­¦ä¹ é—®é¢˜æ—¶ï¼Œåº”è¯¥æŠŠå®ƒåˆ‡åˆ†æˆç‹¬ç«‹çš„æ­¥éª¤ã€‚ä¸€æ­¥æ˜¯å¼„æ¸…æ¥šå¦‚ä½•å®šä¹‰ä¸€ä¸ªæŒ‡æ ‡æ¥è¡¡é‡ä½ æƒ³åšçš„äº‹æƒ…çš„è¡¨ç°ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥åˆ†å¼€è€ƒè™‘å¦‚ä½•æ”¹å–„ç³»ç»Ÿåœ¨è¿™ä¸ªæŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚ä½ ä»¬è¦æŠŠæœºå™¨å­¦ä¹ ä»»åŠ¡çœ‹æˆä¸¤ä¸ªç‹¬ç«‹çš„æ­¥éª¤ï¼Œç”¨ç›®æ ‡è¿™ä¸ªæ¯”å–»ï¼Œç¬¬ä¸€æ­¥å°±æ˜¯è®¾å®šç›®æ ‡ã€‚æ‰€ä»¥è¦å®šä¹‰ä½ è¦ç„å‡†çš„ç›®æ ‡ï¼Œè¿™æ˜¯å®Œå…¨ç‹¬ç«‹çš„ä¸€æ­¥ï¼Œè¿™æ˜¯ä½ å¯ä»¥è°ƒèŠ‚çš„ä¸€ä¸ªæ—‹é’®ã€‚å¦‚ä½•è®¾ç«‹ç›®æ ‡æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„é—®é¢˜ï¼ŒæŠŠå®ƒçœ‹æˆæ˜¯ä¸€ä¸ªå•ç‹¬çš„æ—‹é’®ï¼Œå¯ä»¥è°ƒè¯•ç®—æ³•è¡¨ç°çš„æ—‹é’®ï¼Œå¦‚ä½•ç²¾ç¡®ç„å‡†ï¼Œå¦‚ä½•å‘½ä¸­ç›®æ ‡ï¼Œå®šä¹‰æŒ‡æ ‡æ˜¯ç¬¬ä¸€æ­¥ã€‚ åç¬¬äºŒæ­¥è¦åšåˆ«çš„äº‹æƒ…ï¼Œåœ¨é€¼è¿‘ç›®æ ‡çš„æ—¶å€™ï¼Œä¹Ÿè®¸ä½ çš„å­¦ä¹ ç®—æ³•é’ˆå¯¹æŸä¸ªé•¿è¿™æ ·çš„æˆæœ¬å‡½æ•°ä¼˜åŒ–ï¼Œ$J=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)$ä½ è¦æœ€å°åŒ–è®­ç»ƒé›†ä¸Šçš„æŸå¤±ã€‚ä½ å¯ä»¥åšçš„å…¶ä¸­ä¸€ä»¶äº‹æ˜¯ï¼Œä¿®æ”¹è¿™ä¸ªï¼Œä¸ºäº†å¼•å…¥è¿™äº›æƒé‡ï¼Œä¹Ÿè®¸æœ€åéœ€è¦ä¿®æ”¹è¿™ä¸ªå½’ä¸€åŒ–å¸¸æ•°ï¼Œ$J=\frac{1}{\sum w^{(i)}} \sum_{i=1}^{m} w^{(i)} L\left(\hat{y}^{(i)}, y^{(i)}\right)$ å†æ¬¡ï¼Œå¦‚ä½•å®šä¹‰Jå¹¶ä¸é‡è¦ï¼Œå…³é”®åœ¨äºæ­£äº¤åŒ–çš„æ€è·¯ï¼ŒæŠŠè®¾ç«‹ç›®æ ‡å®šä¸ºç¬¬ä¸€æ­¥ï¼Œç„¶åç„å‡†å’Œå°„å‡»ç›®æ ‡æ˜¯ç‹¬ç«‹çš„ç¬¬äºŒæ­¥ã€‚æ¢ç§è¯´æ³•ï¼Œæˆ‘é¼“åŠ±ä½ ä»¬å°†å®šä¹‰æŒ‡æ ‡çœ‹æˆä¸€æ­¥ï¼Œç„¶ååœ¨å®šä¹‰äº†æŒ‡æ ‡ä¹‹åï¼Œä½ æ‰èƒ½æƒ³å¦‚ä½•ä¼˜åŒ–ç³»ç»Ÿæ¥æé«˜è¿™ä¸ªæŒ‡æ ‡è¯„åˆ†ã€‚æ¯”å¦‚æ”¹å˜ä½ ç¥ç»ç½‘ç»œè¦ä¼˜åŒ–çš„æˆæœ¬å‡½æ•°Jã€‚ L8 : Why human-level performance?(ä¸ºä»€ä¹ˆæ˜¯äººçš„è¡¨ç°ï¼Ÿ) ä¸Šå›¾å±•ç¤ºäº†éšç€æ—¶é—´çš„æ¨è¿›ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿå’Œäººçš„è¡¨ç°æ°´å¹³çš„å˜åŒ–ã€‚ä¸€èˆ¬çš„ï¼Œå½“æœºå™¨å­¦ä¹ è¶…è¿‡äººçš„è¡¨ç°æ°´å¹³åï¼Œå®ƒçš„è¿›æ­¥é€Ÿåº¦é€æ¸å˜å¾—ç¼“æ…¢ï¼Œæœ€ç»ˆæ€§èƒ½æ— æ³•è¶…è¿‡æŸä¸ªç†è®ºä¸Šé™ï¼Œè¿™ä¸ªä¸Šé™è¢«ç§°ä¸ºè´å¶æ–¯æœ€ä¼˜è¯¯å·®ï¼ˆBayes Optimal Errorï¼‰ã€‚ ä¹Ÿå› æ­¤ï¼Œåªè¦å»ºç«‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¡¨ç°è¿˜æ²¡è¾¾åˆ°äººç±»çš„è¡¨ç°æ°´å¹³æ—¶ï¼Œå°±å¯ä»¥é€šè¿‡å„ç§æ‰‹æ®µæ¥æå‡å®ƒã€‚ä¾‹å¦‚é‡‡ç”¨äººå·¥æ ‡è®°è¿‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡äººå·¥è¯¯å·®åˆ†æäº†è§£ä¸ºä»€ä¹ˆäººèƒ½å¤Ÿæ­£ç¡®è¯†åˆ«ï¼Œæˆ–è€…æ˜¯è¿›è¡Œåå·®ã€æ–¹å·®åˆ†æã€‚ å½“æ¨¡å‹çš„è¡¨ç°è¶…è¿‡äººç±»åï¼Œè¿™äº›æ‰‹æ®µèµ·çš„ä½œç”¨å°±å¾®ä¹å…¶å¾®äº†ã€‚ L9 : Avoidable bias(å¯é¿å…åå·®) training error æˆ‘ä»¬ç»å¸¸ä½¿ç”¨çŒ«åˆ†ç±»å™¨æ¥åšä¾‹å­ï¼Œæ¯”å¦‚äººç±»å…·æœ‰è¿‘ä¹å®Œç¾çš„å‡†ç¡®åº¦ï¼Œæ‰€ä»¥äººç±»æ°´å¹³çš„é”™è¯¯æ˜¯1%ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæ‚¨çš„å­¦ä¹ ç®—æ³•è¾¾åˆ°8%çš„è®­ç»ƒé”™è¯¯ç‡å’Œ10%çš„å¼€å‘é”™è¯¯ç‡ï¼Œé‚£ä¹ˆä½ ä¹Ÿè®¸æƒ³åœ¨è®­ç»ƒé›†ä¸Šå¾—åˆ°æ›´å¥½çš„ç»“æœã€‚æ‰€ä»¥äº‹å®ä¸Šï¼Œä½ çš„ç®—æ³•åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°å’Œäººç±»æ°´å¹³çš„è¡¨ç°æœ‰å¾ˆå¤§å·®è·çš„è¯ï¼Œè¯´æ˜ä½ çš„ç®—æ³•å¯¹è®­ç»ƒé›†çš„æ‹Ÿåˆå¹¶ä¸å¥½ã€‚æ‰€ä»¥ä»å‡å°‘åå·®å’Œæ–¹å·®çš„å·¥å…·è¿™ä¸ªè§’åº¦çœ‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä¼šæŠŠé‡ç‚¹æ”¾åœ¨å‡å°‘åå·®ä¸Šã€‚ä½ éœ€è¦åšçš„æ˜¯ï¼Œæ¯”å¦‚è¯´è®­ç»ƒæ›´å¤§çš„ç¥ç»ç½‘ç»œï¼Œæˆ–è€…è·‘ä¹…ä¸€ç‚¹æ¢¯åº¦ä¸‹é™ï¼Œå°±è¯•è¯•èƒ½ä¸èƒ½åœ¨è®­ç»ƒé›†ä¸Šåšå¾—æ›´å¥½ã€‚ dev error è´å¶æ–¯é”™è¯¯ç‡æˆ–è€…å¯¹è´å¶æ–¯é”™è¯¯ç‡çš„ä¼°è®¡å’Œè®­ç»ƒé”™è¯¯ç‡ä¹‹é—´çš„å·®å€¼ç§°ä¸ºå¯é¿å…åå·® L 10: Understanding human-level performance(ç†è§£äººçš„è¡¨ç°)è¿˜è®°å¾—ä¸Šä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬ç”¨è¿‡è¿™ä¸ªè¯â€œäººç±»æ°´å¹³é”™è¯¯ç‡â€ç”¨æ¥ä¼°è®¡è´å¶æ–¯è¯¯å·®ï¼Œé‚£å°±æ˜¯ç†è®ºæœ€ä½çš„é”™è¯¯ç‡ï¼Œä»»ä½•å‡½æ•°ä¸ç®¡æ˜¯ç°åœ¨è¿˜æ˜¯å°†æ¥ï¼Œèƒ½å¤Ÿåˆ°è¾¾çš„æœ€ä½å€¼ L11 : Surpassing human- level performance(è¶…è¿‡äººçš„è¡¨ç°)ç°åœ¨ï¼Œæœºå™¨å­¦ä¹ æœ‰å¾ˆå¤šé—®é¢˜å·²ç»å¯ä»¥å¤§å¤§è¶…è¶Šäººç±»æ°´å¹³äº†ã€‚ L12 : Improving your model performance(æ”¹å–„ä½ çš„æ¨¡å‹çš„è¡¨ç°)ä½ ä»¬å­¦è¿‡æ­£äº¤åŒ–ï¼Œå¦‚ä½•è®¾ç«‹å¼€å‘é›†å’Œæµ‹è¯•é›†ï¼Œç”¨äººç±»æ°´å¹³é”™è¯¯ç‡æ¥ä¼°è®¡è´å¶æ–¯é”™è¯¯ç‡ä»¥åŠå¦‚ä½•ä¼°è®¡å¯é¿å…åå·®å’Œæ–¹å·®ã€‚æˆ‘ä»¬ç°åœ¨æŠŠå®ƒä»¬å…¨éƒ¨ç»„åˆèµ·æ¥å†™æˆä¸€å¥—æŒ‡å¯¼æ–¹é’ˆï¼Œå¦‚ä½•æé«˜å­¦ä¹ ç®—æ³•æ€§èƒ½çš„æŒ‡å¯¼æ–¹é’ˆã€‚ method summaryè¿™ä¸€å‘¨çš„å†…å®¹ä¸»è¦æ˜¯æ”¹å–„æ¨¡å‹çš„è¡¨ç°ï¼Œä¸»è¦æ˜¯æŒ‰ç…§æ­£äº¤åŒ–ï¼Œä½¿å¾—æ›´å¥½çš„æ»¡è¶³ 1. è¯„ä»·æŒ‡æ ‡ 2. æ•°æ®é›†çš„åˆ’åˆ† 3. äººçš„è¡¨ç°çš„é‡è¦æ€§ 4. å½“å‡ºç°è¡¨ç°ä¸å¥½çš„æ—¶å€™ï¼Œå¦‚ä½•æ”¹å–„å‘¢ï¼Œæœ‰å“ªäº›æ–¹æ³•å‘¢ï¼Ÿ W2 ML Strategy(2)C 1: Carrying out error analysis(è¿›è¡Œè¯¯å·®åˆ†æ)1. simple analysis é€šè¿‡è§‚å¯Ÿå‘ç°ç®—æ³•åˆ†ç±»å‡ºé”™çš„ä¾‹å­ï¼Œæ˜¯æŠŠç‹—åˆ†æˆçŒ«ï¼Œæé«˜å‡†ç¡®ç‡çš„æ–¹æ³•å°±æ˜¯å¦‚ä½•é’ˆå¯¹ç‹—çš„å›¾ç‰‡ä¼˜åŒ–ç®—æ³•ã€‚ä½ å¯ä»¥é’ˆå¯¹ç‹—ï¼Œæ”¶é›†æ›´å¤šçš„ç‹—å›¾ï¼Œæˆ–è€…è®¾è®¡ä¸€äº›åªå¤„ç†ç‹—çš„ç®—æ³•åŠŸèƒ½ä¹‹ç±»çš„ï¼Œä¸ºäº†è®©ä½ çš„çŒ«åˆ†ç±»å™¨åœ¨ç‹—å›¾ä¸Šåšçš„æ›´å¥½ï¼Œè®©ç®—æ³•ä¸å†å°†ç‹—åˆ†ç±»æˆçŒ«ã€‚ç°åœ¨è€ƒè™‘çš„æ˜¯åº”è¯¥ä¸åº”è¯¥è¿™ä¹ˆå»åšå‘¢ï¼Ÿç»Ÿè®¡ä¸€ä¸‹dev seté‡Œé¢å¤šå°‘æ˜¯é”™è¯¯æ ‡è®°æ˜¯ç‹—çš„ä¸ªæ•°ï¼Œåˆ†æå‡ºå¯ä»¥æ”¹å–„çš„ç®—æ³•çš„ä¸Šé™ã€‚ mutiply analysis C2 : Cleaning up Incorrectly labeled data(æ¸…é™¤æ ‡æ³¨é”™è¯¯çš„æ•°æ®)incorrct labeltraning setDL algorithms are quite robust to random errors in the traning set so long as your errors or your labeled example to once those errors are not too far from random . distributioné¦–å…ˆï¼Œæˆ‘é¼“åŠ±ä½ ä¸ç®¡ç”¨ä»€ä¹ˆä¿®æ­£æ‰‹æ®µï¼Œéƒ½è¦åŒæ—¶ä½œç”¨åˆ°å¼€å‘é›†å’Œæµ‹è¯•é›†ä¸Šï¼Œæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡ä¸ºä»€ä¹ˆï¼Œå¼€å‘å’Œæµ‹è¯•é›†å¿…é¡»æ¥è‡ªç›¸åŒçš„åˆ†å¸ƒã€‚å¼€å‘é›†ç¡®å®šäº†ä½ çš„ç›®æ ‡ï¼Œå½“ä½ å‡»ä¸­ç›®æ ‡åï¼Œä½ å¸Œæœ›ç®—æ³•èƒ½å¤Ÿæ¨å¹¿åˆ°æµ‹è¯•é›†ä¸Šï¼Œè¿™æ ·ä½ çš„å›¢é˜Ÿèƒ½å¤Ÿæ›´é«˜æ•ˆçš„åœ¨æ¥è‡ªåŒä¸€åˆ†å¸ƒçš„å¼€å‘é›†å’Œæµ‹è¯•é›†ä¸Šè¿­ä»£ã€‚å¦‚æœä½ æ‰“ç®—ä¿®æ­£å¼€å‘é›†ä¸Šçš„éƒ¨åˆ†æ•°æ®ï¼Œé‚£ä¹ˆæœ€å¥½ä¹Ÿå¯¹æµ‹è¯•é›†åšåŒæ ·çš„ä¿®æ­£ä»¥ç¡®ä¿å®ƒä»¬ç»§ç»­æ¥è‡ªç›¸åŒçš„åˆ†å¸ƒã€‚æ‰€ä»¥æˆ‘ä»¬é›‡ä½£äº†ä¸€ä¸ªäººæ¥ä»”ç»†æ£€æŸ¥è¿™äº›æ ‡ç­¾ï¼Œä½†å¿…é¡»åŒæ—¶æ£€æŸ¥å¼€å‘é›†å’Œæµ‹è¯•é›†ã€‚ suggestionæœ€åæˆ‘è®²å‡ ä¸ªå»ºè®®ï¼š é¦–å…ˆï¼Œæ·±åº¦å­¦ä¹ ç ”ç©¶äººå‘˜æœ‰æ—¶ä¼šå–œæ¬¢è¿™æ ·è¯´ï¼šâ€œæˆ‘åªæ˜¯æŠŠæ•°æ®æä¾›ç»™ç®—æ³•ï¼Œæˆ‘è®­ç»ƒè¿‡äº†ï¼Œæ•ˆæœæ‹”ç¾¤â€ã€‚è¿™è¯è¯´å‡ºäº†å¾ˆå¤šæ·±åº¦å­¦ä¹ é”™è¯¯çš„çœŸç›¸ï¼Œæ›´å¤šæ—¶å€™ï¼Œæˆ‘ä»¬æŠŠæ•°æ®å–‚ç»™ç®—æ³•ï¼Œç„¶åè®­ç»ƒå®ƒï¼Œå¹¶å‡å°‘äººå·¥å¹²é¢„ï¼Œå‡å°‘ä½¿ç”¨äººç±»çš„è§è§£ã€‚ä½†æˆ‘è®¤ä¸ºï¼Œåœ¨æ„é€ å®é™…ç³»ç»Ÿæ—¶ï¼Œé€šå¸¸éœ€è¦æ›´å¤šçš„äººå·¥é”™è¯¯åˆ†æï¼Œæ›´å¤šçš„äººç±»è§è§£æ¥æ¶æ„è¿™äº›ç³»ç»Ÿï¼Œå°½ç®¡æ·±åº¦å­¦ä¹ çš„ç ”ç©¶äººå‘˜ä¸æ„¿æ„æ‰¿è®¤è¿™ç‚¹ã€‚ å…¶æ¬¡ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæˆ‘çœ‹ä¸€äº›å·¥ç¨‹å¸ˆå’Œç ”ç©¶äººå‘˜ä¸æ„¿æ„äº²è‡ªå»çœ‹è¿™äº›æ ·æœ¬ï¼Œä¹Ÿè®¸åšè¿™äº›äº‹æƒ…å¾ˆæ— èŠï¼Œåä¸‹æ¥çœ‹100æˆ–å‡ ç™¾ä¸ªæ ·æœ¬æ¥ç»Ÿè®¡é”™è¯¯æ•°é‡ï¼Œä½†æˆ‘ç»å¸¸äº²è‡ªè¿™ä¹ˆåšã€‚å½“æˆ‘å¸¦é¢†ä¸€ä¸ªæœºå™¨å­¦ä¹ å›¢é˜Ÿæ—¶ï¼Œæˆ‘æƒ³çŸ¥é“å®ƒæ‰€çŠ¯çš„é”™è¯¯ï¼Œæˆ‘ä¼šäº²è‡ªå»çœ‹çœ‹è¿™äº›æ•°æ®ï¼Œå°è¯•å’Œä¸€éƒ¨åˆ†é”™è¯¯ä½œæ–—äº‰ã€‚æˆ‘æƒ³å°±å› ä¸ºèŠ±äº†è¿™å‡ åˆ†é’Ÿï¼Œæˆ–è€…å‡ ä¸ªå°æ—¶å»äº²è‡ªç»Ÿè®¡æ•°æ®ï¼ŒçœŸçš„å¯ä»¥å¸®ä½ æ‰¾åˆ°éœ€è¦ä¼˜å…ˆå¤„ç†çš„ä»»åŠ¡ï¼Œæˆ‘å‘ç°èŠ±æ—¶é—´äº²è‡ªæ£€æŸ¥æ•°æ®éå¸¸å€¼å¾—ï¼Œæ‰€ä»¥æˆ‘å¼ºçƒˆå»ºè®®ä½ ä»¬è¿™æ ·åšï¼Œå¦‚æœä½ åœ¨æ­å»ºä½ çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„è¯ï¼Œç„¶åä½ æƒ³ç¡®å®šåº”è¯¥ä¼˜å…ˆå°è¯•å“ªäº›æƒ³æ³•ï¼Œæˆ–è€…å“ªäº›æ–¹å‘ã€‚ è¿™å°±æ˜¯é”™è¯¯åˆ†æè¿‡ç¨‹ï¼Œåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ä¸‹é”™è¯¯åˆ†ææ˜¯å¦‚ä½•åœ¨å¯åŠ¨æ–°çš„æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­å‘æŒ¥ä½œç”¨çš„ã€‚ C3: Build your first system quickly, then iterate(å¿«é€Ÿæ­å»ºä½ çš„ç¬¬ä¸€ä¸ªç³»ç»Ÿï¼Œå¹¶è¿›è¡Œè¿­ä»£)1. iterationI recommend that you first quickly set up a definition and metrics so this is really you know deciding where to place your target and you get it wrong you can always move it later we just set up a target somewhere and then I recommend you build an inital machine learning system quickly find the traning set train it and see start to see and understand how well your are doing against your Devon chess setting evaluation metric when you build your initial system you then be able to use bias variance analysis we should talk about earlier as well as error analysis whick we talked about just in last several videos to prioritize the next step in particular if error analysis causes you to realize that a lot of the errors are from the spearker being very far from the mirophone which causes special challenges speech recognitin then that would give you a good reason to focus on techniques to address this it called fast used speech recognition which basically means handling when the speaker is very far from microphone along the value of building this inital system it can be a quick and diry implementation you know do not overthink it but all the value of the inital system is having some learning system having some tranin system allows you lok at bias and variance to do error analysis look at some mistakes to figure out all the different directins you could go in. æˆ‘é¼“åŠ±ä½ ä»¬æ­å»ºå¿«é€Ÿè€Œç²—ç³™çš„å®ç°ï¼Œç„¶åç”¨å®ƒåšåå·®/æ–¹å·®åˆ†æï¼Œç”¨å®ƒåšé”™è¯¯åˆ†æï¼Œç„¶åç”¨åˆ†æç»“æœç¡®å®šä¸‹ä¸€æ­¥ä¼˜å…ˆè¦åšçš„æ–¹å‘ã€‚ C4 : Training and testing on different distributions(ä½¿ç”¨æ¥è‡ªä¸åŒåˆ†å¸ƒçš„æ•°æ®ï¼Œè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•)this is resulted in many teams sometimes taking one of the days you can find and just shoving it into the training set . Cat app example å‡è®¾ä½ åœ¨å¼€å‘ä¸€ä¸ªæ‰‹æœºåº”ç”¨ï¼Œç”¨æˆ·ä¼šä¸Šä¼ ä»–ä»¬ç”¨æ‰‹æœºæ‹æ‘„çš„ç…§ç‰‡ï¼Œä½ æƒ³è¯†åˆ«ç”¨æˆ·ä»åº”ç”¨ä¸­ä¸Šä¼ çš„å›¾ç‰‡æ˜¯ä¸æ˜¯çŒ«ã€‚ç°åœ¨ä½ æœ‰ä¸¤ä¸ªæ•°æ®æ¥æºï¼Œä¸€ä¸ªæ˜¯ä½ çœŸæ­£å…³å¿ƒçš„æ•°æ®åˆ†å¸ƒï¼Œæ¥è‡ªåº”ç”¨ä¸Šä¼ çš„æ•°æ®ï¼Œæ¯”å¦‚å³è¾¹çš„åº”ç”¨ï¼Œè¿™äº›ç…§ç‰‡ä¸€èˆ¬æ›´ä¸šä½™ï¼Œå–æ™¯ä¸å¤ªå¥½ï¼Œæœ‰äº›ç”šè‡³å¾ˆæ¨¡ç³Šï¼Œå› ä¸ºå®ƒä»¬éƒ½æ˜¯ä¸šä½™ç”¨æˆ·æ‹çš„ã€‚å¦ä¸€ä¸ªæ•°æ®æ¥æºå°±æ˜¯ä½ å¯ä»¥ç”¨çˆ¬è™«ç¨‹åºæŒ–æ˜ç½‘é¡µç›´æ¥ä¸‹è½½ï¼Œå°±è¿™ä¸ªæ ·æœ¬è€Œè¨€ï¼Œå¯ä»¥ä¸‹è½½å¾ˆå¤šå–æ™¯ä¸“ä¸šã€é«˜åˆ†è¾¨ç‡ã€æ‹æ‘„ä¸“ä¸šçš„çŒ«å›¾ç‰‡ã€‚å¦‚æœä½ çš„åº”ç”¨ç”¨æˆ·æ•°è¿˜ä¸å¤šï¼Œä¹Ÿè®¸ä½ åªæ”¶é›†åˆ°10,000å¼ ç”¨æˆ·ä¸Šä¼ çš„ç…§ç‰‡ï¼Œä½†é€šè¿‡çˆ¬è™«æŒ–æ˜ç½‘é¡µï¼Œä½ å¯ä»¥ä¸‹è½½åˆ°æµ·é‡çŒ«å›¾ï¼Œä¹Ÿè®¸ä½ ä»äº’è”ç½‘ä¸Šä¸‹è½½äº†è¶…è¿‡20ä¸‡å¼ çŒ«å›¾ã€‚è€Œä½ çœŸæ­£å…³å¿ƒçš„ç®—æ³•è¡¨ç°æ˜¯ä½ çš„æœ€ç»ˆç³»ç»Ÿå¤„ç†æ¥è‡ªåº”ç”¨ç¨‹åºçš„è¿™ä¸ªå›¾ç‰‡åˆ†å¸ƒæ—¶æ•ˆæœå¥½ä¸å¥½ï¼Œå› ä¸ºæœ€åä½ çš„ç”¨æˆ·ä¼šä¸Šä¼ ç±»ä¼¼å³è¾¹è¿™äº›å›¾ç‰‡ï¼Œä½ çš„åˆ†ç±»å™¨å¿…é¡»åœ¨è¿™ä¸ªä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚ç°åœ¨ä½ å°±é™·å…¥å›°å¢ƒäº†ï¼Œå› ä¸ºä½ æœ‰ä¸€ä¸ªç›¸å¯¹å°çš„æ•°æ®é›†ï¼Œåªæœ‰10,000ä¸ªæ ·æœ¬æ¥è‡ªé‚£ä¸ªåˆ†å¸ƒï¼Œè€Œä½ è¿˜æœ‰ä¸€ä¸ªå¤§å¾—å¤šçš„æ•°æ®é›†æ¥è‡ªå¦ä¸€ä¸ªåˆ†å¸ƒï¼Œå›¾ç‰‡çš„å¤–è§‚å’Œä½ çœŸæ­£æƒ³è¦å¤„ç†çš„å¹¶ä¸ä¸€æ ·ã€‚ä½†ä½ åˆä¸æƒ³ç›´æ¥ç”¨è¿™10,000å¼ å›¾ç‰‡ï¼Œå› ä¸ºè¿™æ ·ä½ çš„è®­ç»ƒé›†å°±å¤ªå°äº†ï¼Œä½¿ç”¨è¿™20ä¸‡å¼ å›¾ç‰‡ä¼¼ä¹æœ‰å¸®åŠ©ã€‚ä½†æ˜¯ï¼Œå›°å¢ƒåœ¨äºï¼Œè¿™20ä¸‡å¼ å›¾ç‰‡å¹¶ä¸å®Œå…¨æ¥è‡ªä½ æƒ³è¦çš„åˆ†å¸ƒï¼Œé‚£ä¹ˆä½ å¯ä»¥æ€ä¹ˆåšå‘¢ï¼Ÿ æˆ‘ä»¬çœŸæ­£å…³å¿ƒçš„æ˜¯æ¥è‡ªæ‰‹æœºæ‰‹æœºæ”¶é›†çš„æ•°æ®ï¼Œè€Œä¸æ˜¯æ¥è‡ªç½‘é¡µã€‚æ–¹æ³•ä¸€ï¼Œéšæœºåˆ†é…è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ï¼Œè¿™æ ·çš„åæœå°±æ˜¯èŠ±äº†å¤§é‡æ—¶é—´åœ¨å®é™…ä¸å…³å¿ƒçš„æ•°æ®åˆ†å¸ƒå»ä¼˜åŒ–ã€‚ è®­ç»ƒé›†20ä¸‡å¼ ç½‘ç»œï¼Œ5000æ‰‹æœºï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†å„2500ï¼Œè¿™æ ·å¯ä»¥ä¿è¯éªŒè¯é›†å’Œæµ‹è¯•é›†æ›´æ¥è¿‘å®é™…åº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬è¯•è¯•æ­å»ºä¸€ä¸ªå­¦ä¹ ç³»ç»Ÿï¼Œè®©ç³»ç»Ÿåœ¨å¤„ç†æ‰‹æœºä¸Šä¼ å›¾ç‰‡åˆ†å¸ƒæ—¶æ•ˆæœè‰¯å¥½ã€‚ç¼ºç‚¹åœ¨äºï¼Œå½“ç„¶äº†ï¼Œç°åœ¨ä½ çš„è®­ç»ƒé›†åˆ†å¸ƒå’Œä½ çš„å¼€å‘é›†ã€æµ‹è¯•é›†åˆ†å¸ƒå¹¶ä¸ä¸€æ ·ã€‚ä½†äº‹å®è¯æ˜ï¼Œè¿™æ ·æŠŠæ•°æ®åˆ†æˆè®­ç»ƒã€å¼€å‘å’Œæµ‹è¯•é›†ï¼Œåœ¨é•¿æœŸèƒ½ç»™ä½ å¸¦æ¥æ›´å¥½çš„ç³»ç»Ÿæ€§èƒ½ã€‚æˆ‘ä»¬ä»¥åä¼šè®¨è®ºä¸€äº›ç‰¹æ®Šçš„æŠ€å·§ï¼Œå¯ä»¥å¤„ç† è®­ç»ƒé›†çš„åˆ†å¸ƒå’Œå¼€å‘é›†å’Œæµ‹è¯•é›†åˆ†å¸ƒä¸ä¸€æ ·çš„æƒ…å†µã€‚ C5: Bias and Variance with mismatched data distributionsï¼ˆæ•°æ®åˆ†å¸ƒä¸åŒ¹é…æ—¶ï¼Œåå·®ä¸æ–¹å·®çš„åˆ†æï¼‰é¦–å…ˆç®—æ³•åªçœ‹è¿‡è®­ç»ƒé›†æ•°æ®ï¼Œæ²¡çœ‹è¿‡å¼€å‘é›†æ•°æ®ã€‚ç¬¬äºŒï¼Œå¼€å‘é›†æ•°æ®æ¥è‡ªä¸åŒçš„åˆ†å¸ƒã€‚å¾ˆéš¾ç¡®è®¤è¿™å¢åŠ çš„9%è¯¯å·®ç‡æœ‰å¤šå°‘æ˜¯å› ä¸ºç®—æ³•æ²¡çœ‹åˆ°å¼€å‘é›†ä¸­çš„æ•°æ®å¯¼è‡´çš„ï¼Œè¿™ä¹ˆè¯„ä¼°å‘¢ï¼Ÿåˆ°åº•å“ªä¸ªå½±å“å…ƒç´ æ›´å¤§ï¼Œ è¯„ä¼°æ–¹æ³•ï¼Œè®­ç»ƒé›†çš„åˆ†å¸ƒæŒ–å‡ºï¼Œtraning-dev set : Same distributation as traning set ,but not used for training. ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†è®­ç»ƒé›†é”™è¯¯ç‡ã€è®­ç»ƒ-éªŒè¯é›†é”™è¯¯ç‡ï¼Œä»¥åŠéªŒè¯é›†é”™è¯¯ç‡ã€‚å…¶ä¸­ï¼Œè®­ç»ƒé›†é”™è¯¯ç‡å’Œè®­ç»ƒ-éªŒè¯é›†é”™è¯¯ç‡çš„å·®å€¼åæ˜ äº†æ–¹å·®ï¼›è€Œè®­ç»ƒ-éªŒè¯é›†é”™è¯¯ç‡å’ŒéªŒè¯é›†é”™è¯¯ç‡çš„å·®å€¼åæ˜ äº†æ ·æœ¬åˆ†å¸ƒä¸ä¸€è‡´çš„é—®é¢˜ï¼Œä»è€Œè¯´æ˜æ¨¡å‹æ“…é•¿å¤„ç†çš„æ•°æ®å’Œæˆ‘ä»¬å…³å¿ƒçš„æ•°æ®æ¥è‡ªä¸åŒçš„åˆ†å¸ƒï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºæ•°æ®ä¸åŒ¹é…ï¼ˆData Mismatchï¼‰é—®é¢˜ã€‚ C6: Addressing data mismatchï¼ˆå¤„ç†æ•°æ®ä¸åŒ¹é…é—®é¢˜ï¼‰I Data: Artifical data synthesis æ‰€ä»¥ï¼Œæ€»è€Œè¨€ä¹‹ï¼Œå¦‚æœä½ è®¤ä¸ºå­˜åœ¨æ•°æ®ä¸åŒ¹é…é—®é¢˜ï¼Œæˆ‘å»ºè®®ä½ åšé”™è¯¯åˆ†æï¼Œæˆ–è€…çœ‹çœ‹è®­ç»ƒé›†ï¼Œæˆ–è€…çœ‹çœ‹å¼€å‘é›†ï¼Œè¯•å›¾æ‰¾å‡ºï¼Œè¯•å›¾äº†è§£è¿™ä¸¤ä¸ªæ•°æ®åˆ†å¸ƒåˆ°åº•æœ‰ä»€ä¹ˆä¸åŒï¼Œç„¶åçœ‹çœ‹æ˜¯å¦æœ‰åŠæ³•æ”¶é›†æ›´å¤šçœ‹èµ·æ¥åƒå¼€å‘é›†çš„æ•°æ®ä½œè®­ç»ƒã€‚ C7: Transfer learningï¼ˆè¿ç§»å­¦ä¹ ï¼‰è¿ç§»å­¦ä¹ ï¼ˆTranfer Learningï¼‰æ˜¯é€šè¿‡å°†å·²è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ¨¡å‹çš„ä¸€éƒ¨åˆ†ç½‘ç»œç»“æ„åº”ç”¨åˆ°å¦ä¸€æ¨¡å‹ï¼Œå°†ä¸€ä¸ªç¥ç»ç½‘ç»œä»æŸä¸ªä»»åŠ¡ä¸­å­¦åˆ°çš„çŸ¥è¯†å’Œç»éªŒè¿ç”¨åˆ°å¦ä¸€ä¸ªä»»åŠ¡ä¸­ï¼Œä»¥æ˜¾è‘—æé«˜å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä¸ºçŒ«è¯†åˆ«å™¨æ„å»ºçš„ç¥ç»ç½‘ç»œè¿ç§»åº”ç”¨åˆ°æ”¾å°„ç§‘è¯Šæ–­ä¸­ã€‚å› ä¸ºçŒ«è¯†åˆ«å™¨çš„ç¥ç»ç½‘ç»œå·²ç»å­¦ä¹ åˆ°äº†æœ‰å…³å›¾åƒçš„ç»“æ„å’Œæ€§è´¨ç­‰æ–¹é¢çš„çŸ¥è¯†ï¼Œæ‰€ä»¥åªè¦å…ˆåˆ é™¤ç¥ç»ç½‘ç»œä¸­åŸæœ‰çš„è¾“å‡ºå±‚ï¼ŒåŠ å…¥æ–°çš„è¾“å‡ºå±‚å¹¶éšæœºåˆå§‹åŒ–æƒé‡ç³»æ•°ï¼ˆ$W[L]$ã€$b[L]$ï¼‰ï¼Œéšåç”¨æ–°çš„è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒï¼Œå°±å®Œæˆäº†ä»¥ä¸Šçš„è¿ç§»å­¦ä¹ ã€‚ å¦‚æœæ–°çš„æ•°æ®é›†å¾ˆå°ï¼Œå¯èƒ½åªéœ€è¦é‡æ–°è®­ç»ƒè¾“å‡ºå±‚å‰çš„æœ€åä¸€å±‚çš„æƒé‡ï¼Œå³$W[L]$$ã€b[L]$ï¼Œå¹¶ä¿æŒå…¶ä»–å‚æ•°ä¸å˜ï¼›è€Œå¦‚æœæœ‰è¶³å¤Ÿå¤šçš„æ•°æ®ï¼Œå¯ä»¥åªä¿ç•™ç½‘ç»œç»“æ„ï¼Œé‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œä¸­æ‰€æœ‰å±‚çš„ç³»æ•°ã€‚è¿™æ—¶åˆå§‹æƒé‡ç”±ä¹‹å‰çš„æ¨¡å‹è®­ç»ƒå¾—åˆ°ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºé¢„è®­ç»ƒï¼ˆPre-Trainingï¼‰ï¼Œä¹‹åçš„æƒé‡æ›´æ–°è¿‡ç¨‹ç§°ä¸ºå¾®è°ƒï¼ˆFine-Tuningï¼‰ã€‚ åœ¨ä¸‹è¿°åœºåˆè¿›è¡Œè¿ç§»å­¦ä¹ æ˜¯æœ‰æ„ä¹‰çš„ï¼š ä¸¤ä¸ªä»»åŠ¡æœ‰åŒæ ·çš„è¾“å…¥ï¼ˆæ¯”å¦‚éƒ½æ˜¯å›¾åƒæˆ–è€…éƒ½æ˜¯éŸ³é¢‘ï¼‰ï¼›æ‹¥æœ‰æ›´å¤šæ•°æ®çš„ä»»åŠ¡è¿ç§»åˆ°æ•°æ®è¾ƒå°‘çš„ä»»åŠ¡ï¼›æŸä¸€ä»»åŠ¡çš„ä½å±‚æ¬¡ç‰¹å¾ï¼ˆåº•å±‚ç¥ç»ç½‘ç»œçš„æŸäº›åŠŸèƒ½ï¼‰å¯¹å¦ä¸€ä¸ªä»»åŠ¡çš„å­¦ä¹ æœ‰å¸®åŠ©ã€‚ C8; Multi-task learning ï¼ˆå¤šä»»åŠ¡å­¦ä¹ ï¼‰For example, autonomous driving example,check cars,stop signs,trfffic lights ,è¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªå‘é‡ï¼Œ C9 : What is end-to-end deep learning?(ä»€ä¹ˆæ˜¯ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ )åœ¨ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ åˆ†å—æ¨¡å‹ä¸­ï¼Œæ¯ä¸€ä¸ªæ¨¡å—å¤„ç†ä¸€ç§è¾“å…¥ï¼Œç„¶åå…¶è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ¨¡å—çš„è¾“å…¥ï¼Œæ„æˆä¸€æ¡æµæ°´çº¿ã€‚è€Œç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ ï¼ˆEnd-to-end Deep Learningï¼‰åªç”¨ä¸€ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ¥å®ç°æ‰€æœ‰çš„åŠŸèƒ½ã€‚å®ƒå°†æ‰€æœ‰æ¨¡å—æ··åˆåœ¨ä¸€èµ·ï¼Œåªå…³å¿ƒè¾“å…¥å’Œè¾“å‡ºã€‚ ä¼˜ç‚¹ä¸ç¼ºç‚¹åº”ç”¨ç«¯åˆ°ç«¯å­¦ä¹ çš„ä¼˜ç‚¹ï¼š åªè¦æœ‰è¶³å¤Ÿå¤šçš„æ•°æ®ï¼Œå‰©ä¸‹çš„å…¨éƒ¨äº¤ç»™ä¸€ä¸ªè¶³å¤Ÿå¤§çš„ç¥ç»ç½‘ç»œã€‚æ¯”èµ·ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ åˆ†å—æ¨¡å‹ï¼Œå¯èƒ½æ›´èƒ½æ•è·æ•°æ®ä¸­çš„ä»»ä½•ç»Ÿè®¡ä¿¡æ¯ï¼Œè€Œä¸éœ€è¦ç”¨äººç±»å›ºæœ‰çš„è®¤çŸ¥ï¼ˆæˆ–è€…è¯´ï¼Œæˆè§ï¼‰æ¥è¿›è¡Œåˆ†æï¼› æ‰€éœ€æ‰‹å·¥è®¾è®¡çš„ç»„ä»¶æ›´å°‘ï¼Œç®€åŒ–è®¾è®¡å·¥ä½œæµç¨‹ï¼› ç¼ºç‚¹ï¼š éœ€è¦å¤§é‡çš„æ•°æ®ï¼› æ’é™¤äº†å¯èƒ½æœ‰ç”¨çš„äººå·¥è®¾è®¡ç»„ä»¶ï¼› æ ¹æ®ä»¥ä¸Šåˆ†æï¼Œå†³å®šä¸€ä¸ªé—®é¢˜æ˜¯å¦åº”ç”¨ç«¯åˆ°ç«¯å­¦ä¹ çš„å…³é”®ç‚¹æ˜¯ï¼šæ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæ”¯æŒèƒ½å¤Ÿç›´æ¥å­¦ä¹ ä» x æ˜ å°„åˆ° y å¹¶ä¸”è¶³å¤Ÿå¤æ‚çš„å‡½æ•°ï¼Ÿ Whether to use end-to-end learning?(æ˜¯å¦è¦ä½¿ç”¨ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ ?)Pros: â€‹ let the data speak : x-&gt;y â€‹ less hand-designing of components needed Cons: â€‹ May need large amount of data â€‹ excludes potentially useful hand-designed components Key question: Do you hava sufficient data to learn a function of the complexity needed to map x to y? å¦‚æœä½ æƒ³ä½¿ç”¨æœºå™¨å­¦ä¹ æˆ–è€…æ·±åº¦å­¦ä¹ æ¥å­¦ä¹ æŸäº›å•ç‹¬çš„ç»„ä»¶ï¼Œé‚£ä¹ˆå½“ä½ åº”ç”¨ç›‘ç£å­¦ä¹ æ—¶ï¼Œä½ åº”è¯¥ä»”ç»†é€‰æ‹©è¦å­¦ä¹ çš„xåˆ°yæ˜ å°„ç±»å‹ï¼Œè¿™å–å†³äºé‚£äº›ä»»åŠ¡ä½ å¯ä»¥æ”¶é›†æ•°æ®ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè°ˆè®ºçº¯ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ–¹æ³•æ˜¯å¾ˆæ¿€åŠ¨äººå¿ƒçš„ï¼Œä½ è¾“å…¥å›¾åƒï¼Œç›´æ¥å¾—å‡ºæ–¹å‘ç›˜è½¬è§’ï¼Œä½†æ˜¯å°±ç›®å‰èƒ½æ”¶é›†åˆ°çš„æ•°æ®è€Œè¨€ï¼Œè¿˜æœ‰æˆ‘ä»¬ä»Šå¤©èƒ½å¤Ÿç”¨ç¥ç»ç½‘ç»œå­¦ä¹ çš„æ•°æ®ç±»å‹è€Œè¨€ï¼Œè¿™å®é™…ä¸Šä¸æ˜¯æœ€æœ‰å¸Œæœ›çš„æ–¹æ³•ï¼Œæˆ–è€…è¯´è¿™ä¸ªæ–¹æ³•å¹¶ä¸æ˜¯å›¢é˜Ÿæƒ³å‡ºçš„æœ€å¥½ç”¨çš„æ–¹æ³•ã€‚è€Œæˆ‘è®¤ä¸ºè¿™ç§çº¯ç²¹çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå…¶å®å‰æ™¯ä¸å¦‚è¿™æ ·æ›´å¤æ‚çš„å¤šæ­¥æ–¹æ³•ã€‚å› ä¸ºç›®å‰èƒ½æ”¶é›†åˆ°çš„æ•°æ®ï¼Œè¿˜æœ‰æˆ‘ä»¬ç°åœ¨è®­ç»ƒç¥ç»ç½‘ç»œçš„èƒ½åŠ›æ˜¯æœ‰å±€é™çš„ã€‚ Summaryå­¦ä¹ å¦‚ä½•é€šè¿‡ä¸€äº›æ‰‹æ®µæé«˜æ¨¡å‹çš„è¡¨ç°ï¼Œé¦–å…ˆäº†è§£æ¨¡å‹çš„æ€§èƒ½çš„ä½“ç°ï¼Œbiasã€varianceã€è´å¶æ–¯è¯¯å·®ã€‚ä»¥åŠå¦‚ä½•ä¸€æ­¥æ­¥çš„æ”¹å–„æ€§èƒ½ã€‚å…·ä½“è§£å†³äº†å¦‚ä¸‹é—®é¢˜ï¼Œ1. æ•°æ®çš„åˆ’åˆ† 2. äººçš„è¡¨ç°ä¸æœºå™¨æ€§èƒ½çš„å…³ç³»ã€åå·®ã€æ–¹å·® 3. è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„åˆ†å¸ƒé—®é¢˜ï¼Œå½“æ•°æ®æ ·æœ¬å¯¹äºè§£å†³é—®é¢˜ä¸è¶³çš„æ—¶å€™çš„è§£å†³åŠæ³•ï¼Œ4. è¿ç§»å­¦ä¹  5. ç«¯åˆ°ç«¯çš„å­¦ä¹  6. å¤šä»»åŠ¡å­¦ä¹ ã€‚6. åœ¨æ€§èƒ½ä¸å¥½çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨çš„åˆ†æè¯¯å·®ï¼Œå¯¹æµ‹è¯•é›†é”™è¯¯æ ·ä¾‹åšç»Ÿè®¡ç­‰ç­‰ï¼Œ]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aiai_]]></title>
    <url>%2F2019%2F04%2F17%2FImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning%2C%20Regularization%20and%20Optimization%2F</url>
    <content type="text"><![CDATA[C2W1L01 : Train/Dev/Test Sets1. processåº”ç”¨å‹æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªé«˜åº¦è¿­ä»£çš„è¿‡ç¨‹ï¼Œé€šå¸¸åœ¨é¡¹ç›®å¯åŠ¨æ—¶ï¼Œæˆ‘ä»¬ä¼šå…ˆæœ‰ä¸€ä¸ªåˆæ­¥æƒ³æ³•ï¼Œæ¯”å¦‚æ„å»ºä¸€ä¸ªå«æœ‰ç‰¹å®šå±‚æ•°ï¼Œéšè—å•å…ƒæ•°é‡æˆ–æ•°æ®é›†ä¸ªæ•°ç­‰ç­‰çš„ç¥ç»ç½‘ç»œï¼Œç„¶åç¼–ç ï¼Œå¹¶å°è¯•è¿è¡Œè¿™äº›ä»£ç ï¼Œé€šè¿‡è¿è¡Œå’Œæµ‹è¯•å¾—åˆ°è¯¥ç¥ç»ç½‘ç»œæˆ–è¿™äº›é…ç½®ä¿¡æ¯çš„è¿è¡Œç»“æœï¼Œä½ å¯èƒ½ä¼šæ ¹æ®è¾“å‡ºç»“æœé‡æ–°å®Œå–„è‡ªå·±çš„æƒ³æ³•ï¼Œæ”¹å˜ç­–ç•¥ï¼Œæˆ–è€…ä¸ºäº†æ‰¾åˆ°æ›´å¥½çš„ç¥ç»ç½‘ç»œä¸æ–­è¿­ä»£æ›´æ–°è‡ªå·±çš„æ–¹æ¡ˆã€‚ 2. data split è®­ç»ƒé›†ï¼ˆtrain setï¼‰ï¼šç”¨è®­ç»ƒé›†å¯¹ç®—æ³•æˆ–æ¨¡å‹è¿›è¡Œè®­ç»ƒè¿‡ç¨‹ï¼› éªŒè¯é›†ï¼ˆdevelopment setï¼‰ï¼šåˆ©ç”¨éªŒè¯é›†ï¼ˆåˆç§°ä¸ºç®€å•äº¤å‰éªŒè¯é›†ï¼Œhold-out cross validation setï¼‰è¿›è¡Œäº¤å‰éªŒè¯ï¼Œé€‰æ‹©å‡ºæœ€å¥½çš„æ¨¡å‹æˆ–è€…éªŒè¯ä¸åŒç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚ æµ‹è¯•é›†ï¼ˆtest setï¼‰ï¼šæœ€ååˆ©ç”¨æµ‹è¯•é›†å¯¹æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œè·å–æ¨¡å‹è¿è¡Œçš„æ— åä¼°è®¡ï¼ˆå¯¹å­¦ä¹ æ–¹æ³•è¿›è¡Œè¯„ä¼°ï¼‰ã€‚ å‡è®¾è¿™æ˜¯è®­ç»ƒæ•°æ®ï¼Œæˆ‘ç”¨ä¸€ä¸ªé•¿æ–¹å½¢è¡¨ç¤ºï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†è¿™äº›æ•°æ®åˆ’åˆ†æˆå‡ éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ä½œä¸ºè®­ç»ƒé›†ï¼Œä¸€éƒ¨åˆ†ä½œä¸ºç®€å•äº¤å‰éªŒè¯é›†ï¼Œæœ‰æ—¶ä¹Ÿç§°ä¹‹ä¸ºéªŒè¯é›†ï¼Œæ–¹ä¾¿èµ·è§ï¼Œæˆ‘å°±å«å®ƒéªŒè¯é›†ï¼ˆdev setï¼‰ï¼Œå…¶å®éƒ½æ˜¯åŒä¸€ä¸ªæ¦‚å¿µï¼Œæœ€åä¸€éƒ¨åˆ†åˆ™ä½œä¸ºæµ‹è¯•é›†ã€‚ åœ¨æœºå™¨å­¦ä¹ å‘å±•çš„å°æ•°æ®é‡æ—¶ä»£ï¼Œå¦‚ 100ã€1000ã€10000 çš„æ•°æ®é‡å¤§å°ï¼Œå¯ä»¥å°†æ•°æ®é›†æŒ‰ç…§ä»¥ä¸‹æ¯”ä¾‹è¿›è¡Œåˆ’åˆ†ï¼š æ— éªŒè¯é›†çš„æƒ…å†µï¼š70% / 30%ï¼› æœ‰éªŒè¯é›†çš„æƒ…å†µï¼š60% / 20% / 20%ï¼› åœ¨å¦‚ä»Šçš„å¤§æ•°æ®æ—¶ä»£ï¼Œå¯¹äºä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é›†çš„è§„æ¨¡å¯èƒ½æ˜¯ç™¾ä¸‡çº§åˆ«çš„ï¼Œæ‰€ä»¥éªŒè¯é›†å’Œæµ‹è¯•é›†æ‰€å çš„æ¯”é‡ä¼šè¶‹å‘äºå˜å¾—æ›´å°ã€‚ éªŒè¯é›†çš„ç›®çš„æ˜¯ä¸ºäº†éªŒè¯ä¸åŒçš„ç®—æ³•å“ªç§æ›´åŠ æœ‰æ•ˆï¼Œæ‰€ä»¥éªŒè¯é›†åªè¦è¶³å¤Ÿå¤§åˆ°èƒ½å¤ŸéªŒè¯å¤§çº¦ 2-10 ç§ç®—æ³•å“ªç§æ›´å¥½ï¼Œè€Œä¸éœ€è¦ä½¿ç”¨ 20% çš„æ•°æ®ä½œä¸ºéªŒè¯é›†ã€‚å¦‚ç™¾ä¸‡æ•°æ®ä¸­æŠ½å– 1 ä¸‡çš„æ•°æ®ä½œä¸ºéªŒè¯é›†å°±å¯ä»¥äº†ã€‚ æµ‹è¯•é›†çš„ä¸»è¦ç›®çš„æ˜¯è¯„ä¼°æ¨¡å‹çš„æ•ˆæœï¼Œå¦‚åœ¨å•ä¸ªåˆ†ç±»å™¨ä¸­ï¼Œå¾€å¾€åœ¨ç™¾ä¸‡çº§åˆ«çš„æ•°æ®ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©å…¶ä¸­ 1000 æ¡æ•°æ®è¶³ä»¥è¯„ä¼°å•ä¸ªæ¨¡å‹çš„æ•ˆæœã€‚ 100 ä¸‡æ•°æ®é‡ï¼š98% / 1% / 1%ï¼› è¶…ç™¾ä¸‡æ•°æ®é‡ï¼š99.5% / 0.25% / 0.25%ï¼ˆæˆ–è€…99.5% / 0.4% / 0.1%ï¼‰ 3. å»ºè®®éªŒè¯é›†è¦å’Œè®­ç»ƒé›†æ¥è‡ªäºåŒä¸€ä¸ªåˆ†å¸ƒï¼ˆæ•°æ®æ¥æºä¸€è‡´ï¼‰ï¼Œå¯ä»¥ä½¿å¾—æœºå™¨å­¦ä¹ ç®—æ³•å˜å¾—æ›´å¿«å¹¶è·å¾—æ›´å¥½çš„æ•ˆæœã€‚ å¦‚æœä¸éœ€è¦ç”¨æ— åä¼°è®¡æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œåˆ™å¯ä»¥ä¸éœ€è¦æµ‹è¯•é›†ã€‚å¦‚æœåªæœ‰éªŒè¯é›†ï¼Œæ²¡æœ‰æµ‹è¯•é›†ï¼Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒï¼Œå°è¯•ä¸åŒçš„æ¨¡å‹æ¡†æ¶ï¼Œåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°è¿™äº›æ¨¡å‹ï¼Œç„¶åè¿­ä»£å¹¶é€‰å‡ºé€‚ç”¨çš„æ¨¡å‹ã€‚å› ä¸ºéªŒè¯é›†ä¸­å·²ç»æ¶µç›–æµ‹è¯•é›†æ•°æ®ï¼Œå…¶ä¸å†æä¾›æ— åæ€§èƒ½è¯„ä¼°ã€‚å½“ç„¶ï¼Œå¦‚æœä½ ä¸éœ€è¦æ— åä¼°è®¡ï¼Œé‚£å°±å†å¥½ä¸è¿‡äº†ã€‚ L02 : Bias/Varianceâ€œåå·®-æ–¹å·®åˆ†è§£â€ï¼ˆbias-variance decompositionï¼‰æ˜¯è§£é‡Šå­¦ä¹ ç®—æ³•æ³›åŒ–æ€§èƒ½çš„ä¸€ç§é‡è¦å·¥å…·ã€‚ æ³›åŒ–è¯¯å·®å¯åˆ†è§£ä¸ºåå·®ã€æ–¹å·®ä¸å™ªå£°ä¹‹å’Œï¼š åå·®ï¼šåº¦é‡äº†å­¦ä¹ ç®—æ³•çš„æœŸæœ›é¢„æµ‹ä¸çœŸå®ç»“æœçš„åç¦»ç¨‹åº¦ï¼Œå³åˆ»ç”»äº†å­¦ä¹ ç®—æ³•æœ¬èº«çš„æ‹Ÿåˆèƒ½åŠ›ï¼› æ–¹å·®ï¼šåº¦é‡äº†åŒæ ·å¤§å°çš„è®­ç»ƒé›†çš„å˜åŠ¨æ‰€å¯¼è‡´çš„å­¦ä¹ æ€§èƒ½çš„å˜åŒ–ï¼Œå³åˆ»ç”»äº†æ•°æ®æ‰°åŠ¨æ‰€é€ æˆçš„å½±å“ï¼› å™ªå£°ï¼šè¡¨è¾¾äº†åœ¨å½“å‰ä»»åŠ¡ä¸Šä»»ä½•å­¦ä¹ ç®—æ³•æ‰€èƒ½å¤Ÿè¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œå³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ã€‚ high bias ,underfitting high variance, overfitting just right 1. example Your algorithms ever on the training set and dev set you can try to diganose whether has problems high barriers or high variances or both or neither. L03 Basic Recipe for Machine learning1. METHOD Training a bigger network almost never hurts. And the main cost of training a neural network thatâ€™s too big is just computational time, so long as youâ€™re regularizing. ä»Šå¤©æˆ‘ä»¬è®²äº†å¦‚ä½•é€šè¿‡ç»„ç»‡æœºå™¨å­¦ä¹ æ¥è¯Šæ–­åå·®å’Œæ–¹å·®çš„åŸºæœ¬æ–¹æ³•ï¼Œç„¶åé€‰æ‹©è§£å†³é—®é¢˜çš„æ­£ç¡®æ“ä½œï¼Œå¸Œæœ›å¤§å®¶æœ‰æ‰€äº†è§£å’Œè®¤è¯†ã€‚æˆ‘åœ¨è¯¾ä¸Šä¸æ­¢ä¸€æ¬¡æåˆ°äº†æ­£åˆ™åŒ–ï¼Œå®ƒæ˜¯ä¸€ç§éå¸¸å®ç”¨çš„å‡å°‘æ–¹å·®çš„æ–¹æ³•ï¼Œæ­£åˆ™åŒ–æ—¶ä¼šå‡ºç°åå·®æ–¹å·®æƒè¡¡é—®é¢˜ï¼Œåå·®å¯èƒ½ç•¥æœ‰å¢åŠ ï¼Œå¦‚æœç½‘ç»œè¶³å¤Ÿå¤§ï¼Œå¢å¹…é€šå¸¸ä¸ä¼šå¤ªé«˜ï¼Œæˆ‘ä»¬ä¸‹èŠ‚è¯¾å†ç»†è®²ï¼Œä»¥ä¾¿å¤§å®¶æ›´å¥½ç†è§£å¦‚ä½•å®ç°ç¥ç»ç½‘ç»œçš„æ­£åˆ™åŒ–ã€‚ ç¬¬ä¸€ç‚¹ï¼Œé«˜åå·®å’Œé«˜æ–¹å·®æ˜¯ä¸¤ç§ä¸åŒçš„æƒ…å†µï¼Œæˆ‘ä»¬åç»­è¦å°è¯•çš„æ–¹æ³•ä¹Ÿå¯èƒ½å®Œå…¨ä¸åŒ åªè¦æ­£åˆ™é€‚åº¦ï¼Œé€šå¸¸æ„å»ºä¸€ä¸ªæ›´å¤§çš„ç½‘ç»œä¾¿å¯ä»¥ï¼Œåœ¨ä¸å½±å“æ–¹å·®çš„åŒæ—¶å‡å°‘åå·®ï¼Œè€Œé‡‡ç”¨æ›´å¤šæ•°æ®é€šå¸¸å¯ä»¥åœ¨ä¸è¿‡å¤šå½±å“åå·®çš„åŒæ—¶å‡å°‘æ–¹å·®ã€‚è¿™ä¸¤æ­¥å®é™…è¦åšçš„å·¥ä½œæ˜¯ï¼šè®­ç»ƒç½‘ç»œï¼Œé€‰æ‹©ç½‘ç»œæˆ–è€…å‡†å¤‡æ›´å¤šæ•°æ®ï¼Œç°åœ¨æˆ‘ä»¬æœ‰å·¥å…·å¯ä»¥åšåˆ°åœ¨å‡å°‘åå·®æˆ–æ–¹å·®çš„åŒæ—¶ï¼Œä¸å¯¹å¦ä¸€æ–¹äº§ç”Ÿè¿‡å¤šä¸è‰¯å½±å“ã€‚ L041. over fittingregularizationL2 regularization L1 regularizaion: w will be sparse L1 æ­£åˆ™åŒ–æœ€åå¾—åˆ° w å‘é‡ä¸­å°†å­˜åœ¨å¤§é‡çš„ 0 ä¸ºä»€ä¹ˆåªæ­£åˆ™åŒ–å‚æ•°wï¼Ÿä¸ºä»€ä¹ˆä¸å†åŠ ä¸Šå‚æ•°b å‘¢ï¼Ÿä½ å¯ä»¥è¿™ä¹ˆåšï¼Œåªæ˜¯æˆ‘ä¹ æƒ¯çœç•¥ä¸å†™ï¼Œå› ä¸ºé€šå¸¸wæ˜¯ä¸€ä¸ªé«˜ç»´å‚æ•°çŸ¢é‡ï¼Œwå·²ç»å¯ä»¥è¡¨è¾¾é«˜åå·®é—®é¢˜ï¼Œå¯èƒ½wåŒ…å«æœ‰å¾ˆå¤šå‚æ•°ï¼Œæˆ‘ä»¬ä¸å¯èƒ½æ‹Ÿåˆæ‰€æœ‰å‚æ•°ï¼Œè€Œåªæ˜¯bå•ä¸ªæ•°å­—ï¼Œæ‰€ä»¥wå‡ ä¹æ¶µç›–æ‰€æœ‰å‚æ•°ï¼Œè€Œä¸æ˜¯ï¼Œå¦‚æœåŠ äº†å‚æ•°bï¼Œå…¶å®ä¹Ÿæ²¡å¤ªå¤§å½±å“ï¼Œå› ä¸ºbåªæ˜¯ä¼—å¤šå‚æ•°ä¸­çš„ä¸€ä¸ªï¼Œæ‰€ä»¥æˆ‘é€šå¸¸çœç•¥ä¸è®¡ï¼Œå¦‚æœä½ æƒ³åŠ ä¸Šè¿™ä¸ªå‚æ•°ï¼Œå®Œå…¨æ²¡é—®é¢˜ã€‚ 2. çŸ©é˜µèŒƒæ•°è¢«ç§°ä½œâ€œå¼—ç½—è´å°¼ä¹Œæ–¯èŒƒæ•°â€ï¼Œç”¨ä¸‹æ ‡æ ‡æ³¨F åå‘ä¼ æ’­æ—¶ï¼Œå¡«ä¸Šæ­£åˆ™åŒ–çš„ä¸€é¡¹ å› æ­¤L2æ­£åˆ™åŒ–ä¹Ÿè¢«ç§°ä¸ºâ€œæƒé‡è¡°å‡â€ã€‚ to get more training data L05 :Why Regularization Reduces Overfittingæˆ‘ä»¬æ·»åŠ æ­£åˆ™é¡¹ï¼Œå®ƒå¯ä»¥é¿å…æ•°æ®æƒå€¼çŸ©é˜µè¿‡å¤§ï¼Œè¿™å°±æ˜¯å¼—ç½—è´å°¼ä¹Œæ–¯èŒƒæ•°ï¼Œä¸ºä»€ä¹ˆå‹ç¼©èŒƒæ•°ï¼Œæˆ–è€…å¼—ç½—è´å°¼ä¹Œæ–¯èŒƒæ•°æˆ–è€…å‚æ•°å¯ä»¥å‡å°‘è¿‡æ‹Ÿåˆï¼Ÿæˆ‘ä»¬å°è¯•æ¶ˆé™¤æˆ–è‡³å°‘å‡å°‘è®¸å¤šéšè—å•å…ƒçš„å½±å“ï¼Œæœ€ç»ˆè¿™ä¸ªç½‘ç»œä¼šå˜å¾—æ›´ç®€å•.Regularizationå…¶å®æ˜¯è®©å‡½æ•°å˜å¾—ç®€åŒ–ã€‚ ç›´è§‚ä¸Šç†è§£å°±æ˜¯å¦‚æœæ­£åˆ™åŒ–è®¾ç½®å¾—è¶³å¤Ÿå¤§ï¼Œæƒé‡çŸ©é˜µè¢«è®¾ç½®ä¸ºæ¥è¿‘äº0çš„å€¼ï¼Œç›´è§‚ç†è§£å°±æ˜¯æŠŠå¤šéšè—å•å…ƒçš„æƒé‡è®¾ä¸º0ï¼Œäºæ˜¯åŸºæœ¬ä¸Šæ¶ˆé™¤äº†è¿™äº›éšè—å•å…ƒçš„è®¸å¤šå½±å“ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œè¿™ä¸ªè¢«å¤§å¤§ç®€åŒ–äº†çš„ç¥ç»ç½‘ç»œä¼šå˜æˆä¸€ä¸ªå¾ˆå°çš„ç½‘ç»œï¼Œå°åˆ°å¦‚åŒä¸€ä¸ªé€»è¾‘å›å½’å•å…ƒï¼Œå¯æ˜¯æ·±åº¦å´å¾ˆå¤§ï¼Œå®ƒä¼šä½¿è¿™ä¸ªç½‘ç»œä»è¿‡åº¦æ‹Ÿåˆçš„çŠ¶æ€æ›´æ¥è¿‘å·¦å›¾çš„é«˜åå·®çŠ¶æ€ã€‚ æ€»ç»“ä¸€ä¸‹ï¼Œå¦‚æœæ­£åˆ™åŒ–å‚æ•°å˜å¾—å¾ˆå¤§ï¼Œwå‚æ•°å¾ˆå°ï¼Œzä¹Ÿä¼šç›¸å¯¹å˜å°ï¼Œæ­¤æ—¶å¿½ç•¥çš„bå½±å“ï¼Œzä¼šç›¸å¯¹å˜å°ï¼Œå®é™…ä¸Šï¼Œzçš„å–å€¼èŒƒå›´å¾ˆå°ï¼Œè¿™ä¸ªæ¿€æ´»å‡½æ•°tanhï¼Œä¹Ÿå°±æ˜¯æ›²çº¿å‡½æ•°ä¼šç›¸å¯¹å‘ˆçº¿æ€§ï¼Œæ•´ä¸ªç¥ç»ç½‘ç»œä¼šè®¡ç®—ç¦»çº¿æ€§å‡½æ•°è¿‘çš„å€¼ï¼Œè¿™ä¸ªçº¿æ€§å‡½æ•°éå¸¸ç®€å•ï¼Œå¹¶ä¸æ˜¯ä¸€ä¸ªæå¤æ‚çš„é«˜åº¦éçº¿æ€§å‡½æ•°ï¼Œä¸ä¼šå‘ç”Ÿè¿‡æ‹Ÿåˆã€‚ L2 regularizationçš„ä¸è¶³ï¼šè¦é€šè¿‡ä¸æ–­çš„é€‰ç”¨ä¸åŒçš„Î»è¿›è¡Œæµ‹è¯•ï¼Œè®¡ç®—é‡åŠ å¤§äº†ã€‚ L06 : Dropout Regularization1. å·¥ä½œåŸç† å¦‚æœä¸Šé¢è¿™å¹…å›¾å­˜åœ¨over fittingã€‚å¤åˆ¶è¿™ä¸ªç¥ç»ç½‘ç»œï¼Œdropoutä¼šéå†ç½‘ç»œçš„æ¯ä¸€å±‚ã€‚å‡è®¾ç½‘ç»œä¸­çš„æ¯ä¸€å±‚ï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½ä»¥æŠ›ç¡¬å¸çš„æ–¹å¼è®¾ç½®æ¦‚ç‡ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¾—ä»¥ä¿ç•™å’Œæ¶ˆé™¤çš„æ¦‚ç‡éƒ½æ˜¯0.5ï¼Œè®¾ç½®å®ŒèŠ‚ç‚¹æ¦‚ç‡ï¼Œæˆ‘ä»¬ä¼šæ¶ˆé™¤ä¸€äº›èŠ‚ç‚¹ï¼Œç„¶ååˆ é™¤æ‰ä»è¯¥èŠ‚ç‚¹è¿›å‡ºçš„è¿çº¿ï¼Œæœ€åå¾—åˆ°ä¸€ä¸ªèŠ‚ç‚¹æ›´å°‘ï¼Œè§„æ¨¡æ›´å°çš„ç½‘ç»œï¼Œç„¶åç”¨backpropæ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚ æˆ‘ä»¬é’ˆå¯¹æ¯ä¸ªè®­ç»ƒæ ·æœ¬è®­ç»ƒè§„æ¨¡æå°çš„ç½‘ç»œï¼Œæœ€åä½ å¯èƒ½ä¼šè®¤è¯†åˆ°ä¸ºä»€ä¹ˆè¦æ­£åˆ™åŒ–ç½‘ç»œï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è®­ç»ƒæå°çš„ç½‘ç»œã€‚ 2. inverted dropoutï¼ˆåå‘éšæœºå¤±æ´»ï¼‰å¯¹ç¬¬L 1234keep_prob = 0.8 # è®¾ç½®ç¥ç»å…ƒä¿ç•™æ¦‚ç‡dl = np.random.rand(al.shape[0], al.shape[1]) &lt; keep_probal = np.multiply(al, dl)al /= keep_prob æœ€åä¸€æ­¥al /= keep_probæ˜¯å› ä¸º a[l]a[l]ä¸­çš„ä¸€éƒ¨åˆ†å…ƒç´ å¤±æ´»ï¼ˆç›¸å½“äºè¢«å½’é›¶ï¼‰ï¼Œä¸ºäº†åœ¨ä¸‹ä¸€å±‚è®¡ç®—æ—¶ä¸å½±å“ $Z[l+1]=W[l+1]a[l]+b[l+1]$çš„æœŸæœ›å€¼ï¼Œå› æ­¤é™¤ä»¥ä¸€ä¸ªkeep_probã€‚ä¸¾ä¾‹è§£é‡Šæˆ‘ä»¬å‡è®¾ç¬¬ä¸‰éšè—å±‚ä¸Šæœ‰50ä¸ªå•å…ƒæˆ–50ä¸ªç¥ç»å…ƒï¼Œåœ¨ä¸€ç»´ä¸Šæ˜¯50ï¼Œæˆ‘ä»¬é€šè¿‡å› å­åˆ†è§£å°†å®ƒæ‹†åˆ†æˆç»´çš„ï¼Œä¿ç•™å’Œåˆ é™¤å®ƒä»¬çš„æ¦‚ç‡åˆ†åˆ«ä¸º80%å’Œ20%ï¼Œè¿™æ„å‘³ç€æœ€åè¢«åˆ é™¤æˆ–å½’é›¶çš„å•å…ƒå¹³å‡æœ‰10ï¼ˆ50Ã—20%=10ï¼‰ä¸ªï¼Œç°åœ¨æˆ‘ä»¬çœ‹ä¸‹$z^{[4]}$ï¼Œï¼Œæˆ‘ä»¬çš„é¢„æœŸæ˜¯$z^{[4]}=w^{[4]}a^{[3]}$ï¼Œ$a^{[3]}$å‡å°‘20%ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸­æœ‰$a^{[3]}$20%çš„å…ƒç´ è¢«å½’é›¶ï¼Œä¸ºäº†ä¸å½±å“çš„$a^{[4]}$æœŸæœ›å€¼ï¼Œæˆ‘ä»¬éœ€è¦ç”¨$w^{[4]}a^{[3]}/keep_prob$ï¼Œå®ƒå°†ä¼šä¿®æ­£æˆ–å¼¥è¡¥æˆ‘ä»¬æ‰€éœ€çš„é‚£20%ï¼Œ$a^{[3]}$çš„æœŸæœ›å€¼ä¸ä¼šå˜ï¼Œåˆ’çº¿éƒ¨åˆ†å°±æ˜¯æ‰€è°“çš„dropoutæ–¹æ³•ã€‚ L07 : Understanding Dropoutç›´è§‚ä¸Šç†è§£ï¼šä¸è¦ä¾èµ–äºä»»ä½•ä¸€ä¸ªç‰¹å¾ï¼Œå› ä¸ºè¯¥å•å…ƒçš„è¾“å…¥å¯èƒ½éšæ—¶è¢«æ¸…é™¤ï¼Œå› æ­¤è¯¥å•å…ƒé€šè¿‡è¿™ç§æ–¹å¼ä¼ æ’­ä¸‹å»ï¼Œå¹¶ä¸ºå•å…ƒçš„å››ä¸ªè¾“å…¥å¢åŠ ä¸€ç‚¹æƒé‡ï¼Œé€šè¿‡ä¼ æ’­æ‰€æœ‰æƒé‡ï¼Œdropoutå°†äº§ç”Ÿæ”¶ç¼©æƒé‡çš„å¹³æ–¹èŒƒæ•°çš„æ•ˆæœï¼Œå’Œä¹‹å‰è®²çš„L2æ­£åˆ™åŒ–ç±»ä¼¼ï¼›å®æ–½dropoutçš„ç»“æœå®å®ƒä¼šå‹ç¼©æƒé‡ï¼Œå¹¶å®Œæˆä¸€äº›é¢„é˜²è¿‡æ‹Ÿåˆçš„å¤–å±‚æ­£åˆ™åŒ–ï¼›L2å¯¹ä¸åŒæƒé‡çš„è¡°å‡æ˜¯ä¸åŒçš„ï¼Œå®ƒå–å†³äºæ¿€æ´»å‡½æ•°å€å¢çš„å¤§å°ã€‚ è®¡ç®—è§†è§‰ä¸­çš„è¾“å…¥é‡éå¸¸å¤§ï¼Œè¾“å…¥å¤ªå¤šåƒç´ ï¼Œä»¥è‡³äºæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæ‰€ä»¥dropoutåœ¨è®¡ç®—æœºè§†è§‰ä¸­åº”ç”¨å¾—æ¯”è¾ƒé¢‘ç¹ï¼Œæœ‰äº›è®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜éå¸¸å–œæ¬¢ç”¨å®ƒï¼Œå‡ ä¹æˆäº†é»˜è®¤çš„é€‰æ‹©ï¼Œä½†è¦ç‰¢è®°ä¸€ç‚¹ï¼Œdropoutæ˜¯ä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå®ƒæœ‰åŠ©äºé¢„é˜²è¿‡æ‹Ÿåˆï¼Œå› æ­¤é™¤éç®—æ³•è¿‡æ‹Ÿåˆï¼Œä¸ç„¶æˆ‘æ˜¯ä¸ä¼šä½¿ç”¨dropoutçš„ï¼Œæ‰€ä»¥å®ƒåœ¨å…¶å®ƒé¢†åŸŸåº”ç”¨å¾—æ¯”è¾ƒå°‘ï¼Œä¸»è¦å­˜åœ¨äºè®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæ‰€ä»¥ä¸€ç›´å­˜åœ¨è¿‡æ‹Ÿåˆï¼Œè¿™å°±æ˜¯æœ‰äº›è®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜å¦‚æ­¤é’Ÿæƒ…äºdropoutå‡½æ•°çš„åŸå› ã€‚ç›´è§‚ä¸Šæˆ‘è®¤ä¸ºä¸èƒ½æ¦‚æ‹¬å…¶å®ƒå­¦ç§‘ã€‚dropoutå°†äº§ç”Ÿæ”¶ç¼©æƒé‡çš„å¹³æ–¹èŒƒæ•°çš„æ•ˆæœã€‚å½“ç„¶ï¼Œä¸åŒçš„å±‚ï¼Œå€¼å¯ä»¥è®¾ç½®æˆä¸åŒï¼Œå¦‚æœä½ è§‰å¾—æŸä¸€å±‚å®¹æ˜“è¿‡æ‹Ÿåˆï¼ŒæŠŠå€¼è®¾ç½®å°ä¸€ç‚¹ã€‚ dropout çš„ä¸€å¤§ç¼ºç‚¹æ˜¯æˆæœ¬å‡½æ•°æ— æ³•è¢«æ˜ç¡®å®šä¹‰ã€‚å› ä¸ºæ¯æ¬¡è¿­ä»£éƒ½ä¼šéšæœºæ¶ˆé™¤ä¸€äº›ç¥ç»å…ƒç»“ç‚¹çš„å½±å“ï¼Œå› æ­¤æ— æ³•ç¡®ä¿æˆæœ¬å‡½æ•°å•è°ƒé€’å‡ã€‚å› æ­¤ï¼Œä½¿ç”¨ dropout æ—¶ï¼Œå…ˆå°†keep_probå…¨éƒ¨è®¾ç½®ä¸º 1.0 åè¿è¡Œä»£ç ï¼Œç¡®ä¿ $J(w,b)$å‡½æ•°å•è°ƒé€’å‡ï¼Œå†æ‰“å¼€ dropoutã€‚ L08 : Other Regularization Methods æ•°æ®æ‰©å¢ï¼ˆData Augmentationï¼‰ï¼šé€šè¿‡å›¾ç‰‡çš„ä¸€äº›å˜æ¢ï¼ˆç¿»è½¬ï¼Œå±€éƒ¨æ”¾å¤§ååˆ‡å‰²ç­‰ï¼‰ï¼Œå¾—åˆ°æ›´å¤šçš„è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚ æ—©åœæ­¢æ³•ï¼ˆEarly Stoppingï¼‰ï¼šå°†è®­ç»ƒé›†å’ŒéªŒè¯é›†è¿›è¡Œæ¢¯åº¦ä¸‹é™æ—¶çš„æˆæœ¬å˜åŒ–æ›²çº¿ç”»åœ¨åŒä¸€ä¸ªåæ ‡è½´å†…ï¼Œå½“è®­ç»ƒé›†è¯¯å·®é™ä½ä½†éªŒè¯é›†è¯¯å·®å‡é«˜ï¼Œä¸¤è€…å¼€å§‹å‘ç”Ÿè¾ƒå¤§åå·®æ—¶åŠæ—¶åœæ­¢è¿­ä»£ï¼Œå¹¶è¿”å›å…·æœ‰æœ€å°éªŒè¯é›†è¯¯å·®çš„è¿æ¥æƒå’Œé˜ˆå€¼ï¼Œä»¥é¿å…è¿‡æ‹Ÿåˆã€‚è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯æ— æ³•åŒæ—¶è¾¾æˆåå·®å’Œæ–¹å·®çš„æœ€ä¼˜ã€‚ ä½†å¯¹æˆ‘æ¥è¯´early stoppingçš„ä¸»è¦ç¼ºç‚¹å°±æ˜¯ä½ ä¸èƒ½ç‹¬ç«‹åœ°å¤„ç†è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œå› ä¸ºææ—©åœæ­¢æ¢¯åº¦ä¸‹é™ï¼Œä¹Ÿå°±æ˜¯åœæ­¢äº†ä¼˜åŒ–ä»£ä»·å‡½æ•°ï¼Œå› ä¸ºç°åœ¨ä½ ä¸å†å°è¯•é™ä½ä»£ä»·å‡½æ•°ï¼Œæ‰€ä»¥ä»£ä»·å‡½æ•°çš„å€¼å¯èƒ½ä¸å¤Ÿå°ï¼ŒåŒæ—¶ä½ åˆå¸Œæœ›ä¸å‡ºç°è¿‡æ‹Ÿåˆï¼Œä½ æ²¡æœ‰é‡‡å–ä¸åŒçš„æ–¹å¼æ¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œè€Œæ˜¯ç”¨ä¸€ç§æ–¹æ³•åŒæ—¶è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼Œè¿™æ ·åšçš„ç»“æœæ˜¯æˆ‘è¦è€ƒè™‘çš„ä¸œè¥¿å˜å¾—æ›´å¤æ‚ã€‚ Early stoppingçš„ä¼˜ç‚¹æ˜¯ï¼Œåªè¿è¡Œä¸€æ¬¡æ¢¯åº¦ä¸‹é™ï¼Œä½ å¯ä»¥æ‰¾å‡ºçš„wè¾ƒå°å€¼ï¼Œä¸­é—´å€¼å’Œè¾ƒå¤§å€¼ï¼Œè€Œæ— éœ€å°è¯•æ­£åˆ™åŒ–è¶…çº§å‚æ•°çš„å¾ˆå¤šå€¼ã€‚ L09 ï¼š Normalizing inputs é›¶å‡å€¼ $u=\frac{1}{m}\sum x^{(i)}$,$x-u$ å½’ä¸€åŒ–æ–¹å·®ï¼› $\delta^2=\frac{1}{m}(x^{(i)})^2$,æ¯ä¸ªç‰¹å¾çš„æ–¹å·®ï¼Œæ¯ä¸ªç‰¹å¾æ•°æ®é™¤ä»¥å®ƒï¼Œå°±å½’ä¸€åŒ–æ–¹å·®äº† why åœ¨ä¸ä½¿ç”¨æ ‡å‡†åŒ–çš„æˆæœ¬å‡½æ•°ä¸­ï¼Œå¦‚æœè®¾ç½®ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ ç‡ï¼Œå¯èƒ½éœ€è¦å¾ˆå¤šæ¬¡è¿­ä»£æ‰èƒ½åˆ°è¾¾å…¨å±€æœ€ä¼˜è§£ï¼›è€Œå¦‚æœä½¿ç”¨äº†æ ‡å‡†åŒ–ï¼Œé‚£ä¹ˆæ— è®ºä»å“ªä¸ªä½ç½®å¼€å§‹è¿­ä»£ï¼Œéƒ½èƒ½ä»¥ç›¸å¯¹è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚ L10 : Vanishing /Exploding Gradientsè®­ç»ƒç¥ç»ç½‘ç»œï¼Œå°¤å…¶æ˜¯æ·±åº¦ç¥ç»æ‰€é¢ä¸´çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸ï¼Œä¹Ÿå°±æ˜¯ä½ è®­ç»ƒç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œå¯¼æ•°æˆ–å¡åº¦æœ‰æ—¶ä¼šå˜å¾—éå¸¸å¤§ï¼Œæˆ–è€…éå¸¸å°ï¼Œç”šè‡³äºä»¥æŒ‡æ•°æ–¹å¼å˜å°ï¼Œè¿™åŠ å¤§äº†è®­ç»ƒçš„éš¾åº¦ã€‚ åœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œæ¿€æ´»å‡½æ•°å°†ä»¥æŒ‡æ•°çº§é€’å‡ï¼Œè™½ç„¶æˆ‘åªæ˜¯è®¨è®ºäº†æ¿€æ´»å‡½æ•°ä»¥ä¸ç›¸å…³çš„æŒ‡æ•°çº§æ•°å¢é•¿æˆ–ä¸‹é™ï¼Œå®ƒä¹Ÿé€‚ç”¨äºä¸å±‚æ•°ç›¸å…³çš„å¯¼æ•°æˆ–æ¢¯åº¦å‡½æ•°ï¼Œä¹Ÿæ˜¯å‘ˆæŒ‡æ•°çº§å¢é•¿æˆ–å‘ˆæŒ‡æ•°é€’å‡ã€‚ å‡å®š g(z)=z,b[l]=0g(z)=z,b[l]=0ï¼Œå¯¹äºç›®æ ‡è¾“å‡ºæœ‰ï¼š $y^=W[L]W[Lâˆ’1]â€¦W[2]W[1]X$ å¯¹äº$ W[l]$çš„å€¼å¤§äº 1 çš„æƒ…å†µï¼Œæ¿€æ´»å‡½æ•°çš„å€¼å°†ä»¥æŒ‡æ•°çº§é€’å¢ï¼› å¯¹äº $W[l]$çš„å€¼å°äº 1 çš„æƒ…å†µï¼Œæ¿€æ´»å‡½æ•°çš„å€¼å°†ä»¥æŒ‡æ•°çº§é€’å‡ã€‚ å¯¹äºå¯¼æ•°åŒç†ã€‚å› æ­¤ï¼Œåœ¨è®¡ç®—æ¢¯åº¦æ—¶ï¼Œæ ¹æ®ä¸åŒæƒ…å†µæ¢¯åº¦å‡½æ•°ä¼šä»¥æŒ‡æ•°çº§é€’å¢æˆ–é€’å‡ï¼Œå¯¼è‡´è®­ç»ƒå¯¼æ•°éš¾åº¦ä¸Šå‡ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ­¥é•¿ä¼šå˜å¾—éå¸¸å°ï¼Œéœ€è¦è®­ç»ƒçš„æ—¶é—´å°†ä¼šéå¸¸é•¿ã€‚ L11 : Weight initialization in a deep networkä¸ºäº†é¢„é˜²å€¼zè¿‡å¤§æˆ–è¿‡å°ï¼Œä½ å¯ä»¥çœ‹åˆ°nè¶Šå¤§ï¼Œä½ å¸Œæœ›wè¶Šå°ï¼Œå› ä¸ºzæ˜¯wx+bçš„å’Œ,æœ€åˆç†çš„æ–¹æ³•$w_i=1/n$ å› æ­¤ï¼Œå®é™…ä¸Šï¼Œä½ è¦åšçš„å°±æ˜¯è®¾ç½®æŸå±‚æƒé‡çŸ©é˜µ $w^{[l]}=n p . random. randn (shape) * np.sqrt \left(\frac{1}{n^{[l-1]}}\right)$ å½“å¤šä¸ªèŠ‚ç‚¹æ—¶ï¼Œä¹Ÿä¸€æ ·çš„çœ‹ï¼Œä½¿å¾—è¿™ä¸ªèŠ‚ç‚¹$z^{L}$ä¸è¦å¤ªå¤§ï¼Œå•ç‹¬çœ‹æ¯ä¸ªèŠ‚ç‚¹æ—¢å¯ä»¥ relu : var(w(i)) = 2/n or $\frac{2}{n^{[l-1]}*n^{[l]}}$ tanh: var(w(i)) = 1/n é€šè¿‡è®¾ç½®åˆå§‹åŒ–åŒ–æƒé‡çŸ©é˜µï¼Œä½¿å¾—ä¸ä¼šå¢é•¿å¤ªå¿«æˆ–è€…å¤ªæ…¢ L12 ï¼š Numerical Approximations of Gradientså•è¾¹è¯¯å·® $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0} \frac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}$ è¯¯å·®$O(\varepsilon)$ åŒè¾¹è¯¯å·® $f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0}=\frac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2 \varepsilon}$ $O\left(\varepsilon^{2}\right)$ L 13 Gradient Checkingæ¢¯åº¦æ£€éªŒå¸®æˆ‘ä»¬èŠ‚çœäº†å¾ˆå¤šæ—¶é—´ï¼Œä¹Ÿå¤šæ¬¡å¸®æˆ‘å‘ç°backpropå®æ–½è¿‡ç¨‹ä¸­çš„bugï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åˆ©ç”¨å®ƒæ¥è°ƒè¯•æˆ–æ£€éªŒbackpropçš„å®æ–½æ˜¯å¦æ­£ç¡®ã€‚ é¦–å…ˆè¦åšçš„å°±æ˜¯ï¼ŒæŠŠæ‰€æœ‰å‚æ•°è½¬æ¢æˆä¸€ä¸ªå·¨å¤§çš„å‘é‡æ•°æ®ï¼Œä½ è¦åšçš„å°±æ˜¯æŠŠçŸ©é˜µwè½¬æ¢æˆä¸€ä¸ªå‘é‡ï¼ŒæŠŠæ‰€æœ‰çŸ©é˜µwè½¬æ¢æˆå‘é‡ä¹‹åï¼Œåšè¿æ¥è¿ç®—ï¼Œå¾—åˆ°ä¸€ä¸ªå·¨å‹å‘é‡$\theta$ï¼Œè¯¥å‘é‡è¡¨ç¤ºä¸ºå‚æ•°$\theta$ï¼Œä»£ä»·å‡½æ•°Jæ˜¯æ‰€æœ‰Wå’Œbçš„å‡½æ•°ï¼Œç°åœ¨ä½ å¾—åˆ°äº†ä¸€ä¸ªçš„ä»£ä»·å‡½æ•°ï¼ˆå³ï¼‰ã€‚æ¥ç€ï¼Œä½ å¾—åˆ°ä¸å’Œé¡ºåºç›¸åŒçš„æ•°æ®ï¼Œä½ åŒæ ·å¯ä»¥æŠŠ$dW^{[l]}$,å’Œ$db^{[l]}$ è½¬æ¢æˆä¸€ä¸ªæ–°çš„å‘é‡ï¼Œç”¨å®ƒä»¬æ¥åˆå§‹åŒ–å¤§å‘é‡$d\theta$ï¼Œå®ƒä¸$\theta$å…·æœ‰ç›¸åŒç»´åº¦ã€‚ æ¢¯åº¦çš„é€¼è¿‘å€¼ d \theta_{\text { approx }}[i]=\frac{J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}+\varepsilon, \ldots\right)-J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}-\varepsilon, \ldots\right)}{2 \varepsilon} ç°åœ¨ä½ å·²ç»äº†è§£äº†æ¢¯åº¦æ£€éªŒçš„å·¥ä½œåŸç†ï¼Œå®ƒå¸®åŠ©æˆ‘åœ¨ç¥ç»ç½‘ç»œå®æ–½ä¸­å‘ç°äº†å¾ˆå¤šbugï¼Œå¸Œæœ›å®ƒå¯¹ä½ ä¹Ÿæœ‰æ‰€å¸®åŠ©ã€‚ L 14 : Gradient Checking Implementation notes ä¸è¦åœ¨è®­ç»ƒä¸­ä½¿ç”¨æ¢¯åº¦æ£€éªŒï¼Œå®ƒåªç”¨äºè°ƒè¯•ï¼ˆdebugï¼‰ã€‚ä½¿ç”¨å®Œæ¯•å…³é—­æ¢¯åº¦æ£€éªŒçš„åŠŸèƒ½ï¼›å¤ªæ…¢äº† å¦‚æœç®—æ³•çš„æ¢¯åº¦æ£€éªŒå¤±è´¥ï¼Œè¦æ£€æŸ¥æ‰€æœ‰é¡¹ï¼Œå¹¶è¯•ç€æ‰¾å‡º bugï¼Œå³ç¡®å®šå“ªä¸ª dÎ¸approx[i] ä¸ dÎ¸ çš„å€¼ç›¸å·®æ¯”è¾ƒå¤§ï¼› å½“æˆæœ¬å‡½æ•°åŒ…å«æ­£åˆ™é¡¹æ—¶ï¼Œä¹Ÿéœ€è¦å¸¦ä¸Šæ­£åˆ™é¡¹è¿›è¡Œæ£€éªŒï¼› æ¢¯åº¦æ£€éªŒä¸èƒ½ä¸ dropout åŒæ—¶ä½¿ç”¨ã€‚å› ä¸ºæ¯æ¬¡è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œdropout ä¼šéšæœºæ¶ˆé™¤éšè—å±‚å•å…ƒçš„ä¸åŒå­é›†ï¼Œéš¾ä»¥è®¡ç®— dropout åœ¨æ¢¯åº¦ä¸‹é™ä¸Šçš„æˆæœ¬å‡½æ•° Jã€‚å»ºè®®å…³é—­ dropoutï¼Œç”¨æ¢¯åº¦æ£€éªŒè¿›è¡ŒåŒé‡æ£€æŸ¥ï¼Œç¡®å®šåœ¨æ²¡æœ‰ dropout çš„æƒ…å†µä¸‹ç®—æ³•æ­£ç¡®ï¼Œç„¶åæ‰“å¼€ dropoutï¼› Summaryå›é¡¾è¿™ä¸€å‘¨ï¼Œæˆ‘ä»¬è®²äº†å¦‚ä½•é…ç½®è®­ç»ƒé›†ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œå¦‚ä½•åˆ†æåå·®å’Œæ–¹å·®ï¼Œå¦‚ä½•å¤„ç†é«˜åå·®æˆ–é«˜æ–¹å·®ä»¥åŠé«˜åå·®å’Œé«˜æ–¹å·®å¹¶å­˜çš„é—®é¢˜ï¼Œå¦‚ä½•åœ¨ç¥ç»ç½‘ç»œä¸­åº”ç”¨ä¸åŒå½¢å¼çš„æ­£åˆ™åŒ–ï¼Œå¦‚æ­£åˆ™åŒ–å’Œ**dropout**ï¼Œè¿˜æœ‰åŠ å¿«ç¥ç»ç½‘ç»œè®­ç»ƒé€Ÿåº¦çš„æŠ€å·§ï¼Œæœ€åæ˜¯æ¢¯åº¦æ£€éªŒã€‚ C2W2 :Optimization AlgorithmL 01 : Mini Batch Gradient Descent Vectorization Mini batch not entire training set bady training set iï¼Œ$x^{\{i\}}$ mini batch training set mini batch gradient descent L 02 : Understanding Mini-Batch Gradient Decent å·¦å›¾ï¼Œéšç€iterations increased, it should decrease .if it ever goes up on iteration,something is wrong. å³å›¾ : itâ€™s as if on every iteration youâ€™re training on a different training set or really training on a different mini batch. It should trend downwards, but itâ€™s also going to be a little bit noisier.So if you plot J{t}, as youâ€™re training mini batch in descent it may be over multiple epochs,you might expect to see a curve like this. Choosing your mini-batch size 1. ä¼˜ç¼ºç‚¹ é€šè¿‡å‡å°å­¦ä¹ ç‡ï¼Œå™ªå£°ä¼šè¢«æ”¹å–„æˆ–æœ‰æ‰€å‡å°ï¼Œä½†éšæœºæ¢¯åº¦ä¸‹é™æ³•çš„ä¸€å¤§ç¼ºç‚¹æ˜¯ï¼Œä½ ä¼šå¤±å»æ‰€æœ‰å‘é‡åŒ–å¸¦ç»™ä½ çš„åŠ é€Ÿï¼Œå› ä¸ºä¸€æ¬¡æ€§åªå¤„ç†äº†ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œè¿™æ ·æ•ˆç‡è¿‡äºä½ä¸‹ï¼Œæ‰€ä»¥å®è·µä¸­æœ€å¥½é€‰æ‹©ä¸å¤§ä¸å°çš„mini-batchå°ºå¯¸ï¼Œå®é™…ä¸Šå­¦ä¹ ç‡è¾¾åˆ°æœ€å¿«ã€‚ä½ ä¼šå‘ç°ä¸¤ä¸ªå¥½å¤„ï¼Œä¸€æ–¹é¢ï¼Œä½ å¾—åˆ°äº†å¤§é‡å‘é‡åŒ–ï¼Œä¸Šä¸ªè§†é¢‘ä¸­æˆ‘ä»¬ç”¨è¿‡çš„ä¾‹å­ä¸­ï¼Œå¦‚æœmini-batchå¤§å°ä¸º1000ä¸ªæ ·æœ¬ï¼Œä½ å°±å¯ä»¥å¯¹1000ä¸ªæ ·æœ¬å‘é‡åŒ–ï¼Œæ¯”ä½ ä¸€æ¬¡æ€§å¤„ç†å¤šä¸ªæ ·æœ¬å¿«å¾—å¤šã€‚å¦ä¸€æ–¹é¢ï¼Œä½ ä¸éœ€è¦ç­‰å¾…æ•´ä¸ªè®­ç»ƒé›†è¢«å¤„ç†å®Œå°±å¯ä»¥å¼€å§‹è¿›è¡Œåç»­å·¥ä½œï¼Œå†ç”¨ä¸€ä¸‹ä¸Šä¸ªè§†é¢‘çš„æ•°å­—ï¼Œæ¯æ¬¡è®­ç»ƒé›†å…è®¸æˆ‘ä»¬é‡‡å–5000ä¸ªæ¢¯åº¦ä¸‹é™æ­¥éª¤ï¼Œæ‰€ä»¥å®é™…ä¸Šä¸€äº›ä½äºä¸­é—´çš„mini-batchå¤§å°æ•ˆæœæœ€å¥½ã€‚ ä½¿ç”¨batchæ¢¯åº¦ä¸‹é™æ³•æ—¶ï¼Œæ¯æ¬¡è¿­ä»£ä½ éƒ½éœ€è¦å†éæ•´ä¸ªè®­ç»ƒé›†ï¼Œå¯ä»¥é¢„æœŸæ¯æ¬¡è¿­ä»£æˆæœ¬éƒ½ä¼šä¸‹é™ï¼Œæ‰€ä»¥å¦‚æœæˆæœ¬å‡½æ•°æ˜¯è¿­ä»£æ¬¡æ•°çš„ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒåº”è¯¥ä¼šéšç€æ¯æ¬¡è¿­ä»£è€Œå‡å°‘ï¼Œå¦‚æœåœ¨æŸæ¬¡è¿­ä»£ä¸­å¢åŠ äº†ï¼Œé‚£è‚¯å®šå‡ºäº†é—®é¢˜ï¼Œä¹Ÿè®¸ä½ çš„å­¦ä¹ ç‡å¤ªå¤§ã€‚ åœ¨éšæœºæ¢¯åº¦ä¸‹é™æ³•ä¸­ï¼Œä»æŸä¸€ç‚¹å¼€å§‹ï¼Œæˆ‘ä»¬é‡æ–°é€‰å–ä¸€ä¸ªèµ·å§‹ç‚¹ï¼Œæ¯æ¬¡è¿­ä»£ï¼Œä½ åªå¯¹ä¸€ä¸ªæ ·æœ¬è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œå¤§éƒ¨åˆ†æ—¶å€™ä½ å‘ç€å…¨å±€æœ€å°å€¼é è¿‘ï¼Œæœ‰æ—¶å€™ä½ ä¼šè¿œç¦»æœ€å°å€¼ï¼Œå› ä¸ºé‚£ä¸ªæ ·æœ¬æ°å¥½ç»™ä½ æŒ‡çš„æ–¹å‘ä¸å¯¹ï¼Œå› æ­¤éšæœºæ¢¯åº¦ä¸‹é™æ³•æ˜¯æœ‰å¾ˆå¤šå™ªå£°çš„ï¼Œå¹³å‡æ¥çœ‹ï¼Œå®ƒæœ€ç»ˆä¼šé è¿‘æœ€å°å€¼ï¼Œä¸è¿‡æœ‰æ—¶å€™ä¹Ÿä¼šæ–¹å‘é”™è¯¯ï¼Œå› ä¸ºéšæœºæ¢¯åº¦ä¸‹é™æ³•æ°¸è¿œä¸ä¼šæ”¶æ•›ï¼Œè€Œæ˜¯ä¼šä¸€ç›´åœ¨æœ€å°å€¼é™„è¿‘æ³¢åŠ¨ï¼Œä½†å®ƒå¹¶ä¸ä¼šåœ¨è¾¾åˆ°æœ€å°å€¼å¹¶åœç•™åœ¨æ­¤ã€‚ ç”¨mini-batchæ¢¯åº¦ä¸‹é™æ³•ï¼Œæˆ‘ä»¬ä»è¿™é‡Œå¼€å§‹ï¼Œä¸€æ¬¡è¿­ä»£è¿™æ ·åšï¼Œä¸¤æ¬¡ï¼Œä¸‰æ¬¡ï¼Œå››æ¬¡ï¼Œå®ƒä¸ä¼šæ€»æœå‘æœ€å°å€¼é è¿‘ï¼Œä½†å®ƒæ¯”éšæœºæ¢¯åº¦ä¸‹é™è¦æ›´æŒç»­åœ°é è¿‘æœ€å°å€¼çš„æ–¹å‘ï¼Œå®ƒä¹Ÿä¸ä¸€å®šåœ¨å¾ˆå°çš„èŒƒå›´å†…æ”¶æ•›æˆ–è€…æ³¢åŠ¨ï¼Œå¦‚æœå‡ºç°è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥æ…¢æ…¢å‡å°‘å­¦ä¹ ç‡ï¼Œæˆ‘ä»¬åœ¨ä¸‹ä¸ªè§†é¢‘ä¼šè®²åˆ°å­¦ä¹ ç‡è¡°å‡ï¼Œä¹Ÿå°±æ˜¯å¦‚ä½•å‡å°å­¦ä¹ ç‡ã€‚ batch : too long,too time éšæœºï¼š lose speeding ,å™ªå£°å¤§ mini-batchå’Œstochasticéƒ½å­˜åœ¨å™ªå£°é—®é¢˜ï¼Œä¸”åœ¨local optimaé™„è¿‘ä¼šå¾˜å¾Šã€‚ä½†è®¾ç½®åˆé€‚å¤§å°çš„mini-batch sizeï¼Œå™ªå£°å’Œå¾˜å¾Šé—®é¢˜å¯æ¥å—çš„èŒƒå›´å†…ã€‚ size=1,åˆå«éšæœºæ¢¯åº¦ä¸‹é™æ³• stochastic gradient descent howå¦‚ä½•é€‰æ‹©mini-batch sizeï¼ˆè¿™æ˜¯ä¸€ä¸ªhyperparameterï¼‰ï¼š å°æ•°æ®é‡ï¼Œæ¯”å¦‚æ€»çš„æ ·æœ¬åªæœ‰å‡ åƒä¸ªï¼Œå®Œå…¨å¯ä»¥ç›´æ¥ç”¨batch gradient descent å¤§æ•°é‡ï¼Œmini-batch sizeå€¾å‘äºé€‰æ‹©2^nä¸ªï¼Œæ¯”å¦‚64, 128, 256ç­‰ mini-batch ä¸CPU/GPU memoryçš„å†…å­˜å®¹é‡ã€‚ In practice of course the mini batch size is another hyper parameter that you might do a quick search over to try to figure out which one is most sufficient of reducing the cost function j. æŒ‰ç…§ä¸Šé¢çš„æ–¹æ³• L 03: Exponentially Weighted AveragesIn order to understand those algorithms, you need to be able they use something called exponentially weighted averages. Also called exponentially weighted moving averages in statistics. 1. æŒ‡æ•°åŠ æƒå¹³å‡æ•°ï¼ˆExponentially weighted averagesï¼‰ $\theta _i$è¡¨ç¤ºæ¯ä¸€æ—¥çš„æ¸©åº¦å€¼ï¼Œè“è‰²çš„ç‚¹ï¼Œ$v_t$è¡¨ç¤ºåŠ æƒå¹³å‡åçš„,çº¢è‰² æƒå¹³å‡æ–¹æ³•æ˜¯ï¼šæ¯å¤©çš„æ¸©åº¦å€¼åŠ æƒå€¼$vt$è®¾ç½®ä¸ºå‰ä¸€å¤©çš„æ¸©åº¦åŠ æƒå€¼$vtâˆ’1$å’Œå½“å¤©çš„æ¸©åº¦å®é™…å€¼$Î¸t$åšåŠ æƒå¹³å‡ï¼š v_{t}=\beta v_{t-1}+(1-\beta) \theta_{t}ç”±äºä»¥åæˆ‘ä»¬è¦è€ƒè™‘çš„åŸå› ï¼Œåœ¨è®¡ç®—æ—¶å¯è§†$v_T$å¤§æ¦‚æ˜¯$\frac{1}{(1-\beta)}$çš„æ¯æ—¥æ¸©åº¦çš„åŠ æƒå¹³å‡ï¼Œ å¦‚æœæ˜¯$\beta$=0.9ï¼Œè¿™æ˜¯åå¤©çš„å¹³å‡å€¼ï¼Œçº¢è‰² å¦‚æœ$\beta$=0.98,æ˜¯50å¤©çš„ç»“æœï¼Œç»¿è‰² å¦‚æœ$beta$=0.5,æ˜¯2dayçš„ç»“æœï¼Œé»„è‰² ç”±äºä»…å¹³å‡äº†ä¸¤å¤©çš„æ¸©åº¦ï¼Œå¹³å‡çš„æ•°æ®å¤ªå°‘ï¼Œæ‰€ä»¥å¾—åˆ°çš„æ›²çº¿æœ‰æ›´å¤šçš„å™ªå£°ï¼Œæœ‰å¯èƒ½å‡ºç°å¼‚å¸¸å€¼ï¼Œä½†æ˜¯è¿™ä¸ªæ›²çº¿èƒ½å¤Ÿæ›´å¿«é€‚åº”æ¸©åº¦å˜åŒ–ã€‚ å½“ $\beta$è¾ƒå¤§æ—¶ï¼ŒæŒ‡æ•°åŠ æƒå¹³å‡å€¼é€‚åº”åœ°æ›´ç¼“æ…¢ä¸€äº›ã€‚ $ L 04 : Understanding Exponentially Weighted Averageså‡å¦‚Î²=0.9ï¼Œæ¯ä¸ªvçš„è®¡ç®—å¦‚ä¸‹ï¼š \begin{aligned} v_{100} &=0.9 v_{99}+0.1 \theta_{100} \\ v_{99} &=0.9 v_{98}+0.1 \theta_{99} \\ v_{98} &=0.9 v_{97}+0.1 \theta_{98} \end{aligned}é€’æ¨å¯å¾—ï¼š v_{100}=0.1 \theta_{100}+0.1 * 0.9 \theta_{99}+0.1 *(0.9)^{2} \theta_{98}+\ldotsæŒ‡æ•°çš„è¡°å‡è§„å¾‹ ä¸€èˆ¬çš„ v_{t}=\sum_{i=1}^{t}(1-\beta) \beta^{t-i} \theta_{i}æ— ç©·çº§æ•°æ±‚å’Œï¼š \sum_{t=1}^{n}(1-\beta) \beta^{t}=1å› æ­¤å¯ä»¥è¿‘ä¼¼çš„è®¤ä¸ºæ‰€æœ‰é¡¹çš„ç³»æ•°ä¹‹å’Œæ­£å¥½ä¸º100%ã€‚ å³ï¼Œ$vt$æ˜¯å¯¹tæ—¥ä¹‹å‰æ‰€æœ‰çš„å®é™…æ¸©åº¦çš„åŠ æƒå¹³å‡,æƒé‡æ˜¯æŒ‡æ•°é€’å‡çš„ã€‚ åå¤©åï¼Œæ›²çº¿é«˜åº¦ä¸‹é™åˆ°äº†1/3,èµ‹äºˆæƒé‡$\beta^{t-i}$ 0.9^{10}~=0.35~=1/eä¸€èˆ¬è®¤ä¸ºï¼Œ$v_t$è¿‘ä¼¼å‰$\frac{1}{1-\beta}$çš„åŠ æƒå¹³å‡å€¼ L05 : Bias correction in exponentially weighted averagesæŒ‡æ•°åŠ æƒå¹³å‡çš„åå·®ä¿®æ­£ ç”±äºè®¡ç®—$v1$çš„æ—¶å€™ï¼Œå¹¶æ²¡æœ‰å†å²å€¼åšåŠ æƒï¼Œè¿™ä¸ªæ—¶å€™ä»¤å…¶å‰ä¸€ä¸ªåŠ æƒå€¼$v0=0$ï¼Œåˆ™ä¼šå¯¼è‡´$v_1$è¿œå°äº$\theta_1$,ä¾æ¬¡ç±»æ¨ï¼Œåœ¨é è¿‘å‰é¢çš„å€¼ä¼šå‡ºç°æ˜¾è‘—çš„å°äºå®é™…å€¼çš„æƒ…å†µ å› æ­¤åšä¸€ä¸ªä¿®æ­£ v_{t}=\frac{\beta v_{t-1}+(1-\beta) \theta_{t}}{1-\beta^{t}}ä½ ä¼šå‘ç°éšç€$\beta^t$å¢åŠ ï¼Œæ¥è¿‘äº0ï¼Œæ‰€ä»¥å½“tå¾ˆå¤§çš„æ—¶å€™ï¼Œåå·®ä¿®æ­£å‡ ä¹æ²¡æœ‰ä½œç”¨ï¼Œå› æ­¤å½“tè¾ƒå¤§çš„æ—¶å€™ï¼Œç´«çº¿åŸºæœ¬å’Œç»¿çº¿é‡åˆäº†ã€‚ä¸è¿‡åœ¨å¼€å§‹å­¦ä¹ é˜¶æ®µï¼Œä½ æ‰å¼€å§‹é¢„æµ‹çƒ­èº«ç»ƒä¹ ï¼Œåå·®ä¿®æ­£å¯ä»¥å¸®åŠ©ä½ æ›´å¥½é¢„æµ‹æ¸©åº¦ï¼Œåå·®ä¿®æ­£å¯ä»¥å¸®åŠ©ä½ ä½¿ç»“æœä»ç´«çº¿å˜æˆç»¿çº¿ã€‚ å› ä¸ºåœ¨Machine Learningä¸­çœ‹é‡çš„æ˜¯å¾ˆå¤šæ¬¡è¿­ä»£åçš„ç»“æœï¼ŒåˆæœŸçš„åå·®å½±å“å¹¶ä¸å¤§ã€‚ L 06 : Gradient Descent With MomentumåŠ¨é‡æ¢¯åº¦ä¸‹é™æ³•ï¼Œè¿è¡Œé€Ÿåº¦å‡ ä¹æ€»æ˜¯å¿«äºæ ‡å‡†çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œ å½“æ…¢æ…¢ä¸‹é™åˆ°æœ€å°å€¼ï¼Œä¸Šä¸‹æ³¢åŠ¨çš„æ¢¯åº¦ä¸‹é™æ³•çš„é€Ÿåº¦å‡ç¼“ï¼Œæ— æ³•ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ï¼Œ åœ¨çºµè½´ä¸Šï¼Œå¸Œæœ›å­¦æ ¡æ…¢ä¸€ç‚¹ï¼Œä¸éœ€è¦æ‘†åŠ¨ï¼Œæ¨ªç€ä¸Šï¼ŒåŠ å¿«å­¦æ ¡ï¼ŒåŸºäºæ­¤å°±æœ‰äº†Gradient descent with momentumã€‚ \begin{array}{c}{v_{d W} :=\beta v_{d W}+(1-\beta) d W} \\ {v_{d b} :=\beta v_{d b}+(1-\beta) d b} \\ {w=w-\alpha v_{d W}} \\ {b=b-\alpha v_{d b}}\end{array}è¿™æ ·ï¼Œå¯ä»¥è®©gradientæ›´å¹³æ»‘ å¯¹äºä¸Šå›¾å‚ç›´æ–¹å‘ï¼ŒåŸæ¥æ˜¯ä¼šä¸Šä¸‹éœ‡è¡ï¼Œä½†å¼•å…¥äº†exponentially weighted averageï¼Œç›¸å½“äºå¯¹å‰é¢çš„éœ‡è¡è¿›è¡Œäº†å¹³å‡ï¼Œç»“æœå°±æ˜¯ä¸Šä¸‹éœ‡è¡äº’ç›¸æŠµæ¶ˆäº†ã€‚è€Œæ°´å¹³æ–¹å‘éƒ½æ˜¯å‘å³æ²¡æœ‰éœ‡è¡ï¼Œå› æ­¤å¹³å‡åè¿˜æ˜¯å‘å³ã€‚æœ€ç»ˆå¯¼è‡´å‘ˆç°ä¸Šå›¾çº¢è‰²çš„ä¸‹é™è·¯çº¿ã€‚ L 07 : RMSpropRMSprop (Root Mean Square Propagationï¼Œå‡æ–¹æ ¹ä¼ é€’)ï¼Œä¸momentumä¸€æ ·ï¼Œä¹Ÿæ˜¯é™ä½æ¢¯åº¦çš„æŠ–åŠ¨ã€‚è€Œæ˜¯å¹³æŠ‘ä¸åŒå¤§å°æ¢¯åº¦çš„æ›´æ–°é€Ÿç‡ã€‚å®é™…ä¸Š ä½œç”¨åœ¨Î±ä¸Šçš„ å›å¿†ä¸€ä¸‹æˆ‘ä»¬ä¹‹å‰çš„ä¾‹å­ï¼Œå¦‚æœä½ æ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼Œè™½ç„¶æ¨ªè½´æ–¹å‘æ­£åœ¨æ¨è¿›ï¼Œä½†çºµè½´æ–¹å‘ä¼šæœ‰å¤§å¹…åº¦æ‘†åŠ¨ï¼Œä¸ºäº†åˆ†æè¿™ä¸ªä¾‹å­ï¼Œå‡è®¾bçºµè½´ä»£è¡¨å‚æ•°ï¼Œæ¨ªè½´ä»£è¡¨å‚æ•°Wï¼Œå¯èƒ½æœ‰w1ï¼Œæˆ–è€…w2å…¶å®ƒé‡è¦çš„å‚æ•°ï¼Œä¸ºäº†ä¾¿äºç†è§£ï¼Œè¢«ç§°ä¸ºbå’Œwã€‚ æˆ‘ä»¬å¸Œæœ›å­¦ä¹ é€Ÿåº¦å¿«ï¼Œè€Œåœ¨å‚ç›´æ–¹å‘ï¼Œä¹Ÿå°±æ˜¯ä¾‹å­ä¸­çš„æ–¹å‘ï¼Œæˆ‘ä»¬å¸Œæœ›å‡ç¼“çºµè½´ä¸Šçš„æ‘†åŠ¨ï¼Œæ‰€ä»¥æœ‰äº†$S_{d W} $å’Œ$ S_{d b}$ï¼Œæˆ‘ä»¬å¸Œæœ›$S_{d W} $ä¼šç›¸å¯¹è¾ƒå°ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦é™¤ä»¥ä¸€ä¸ªè¾ƒå°çš„æ•°ï¼Œè€Œå¸Œæœ›$ S_{d b}$åˆè¾ƒå¤§ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬è¦é™¤ä»¥è¾ƒå¤§çš„æ•°å­—ï¼Œè¿™æ ·å°±å¯ä»¥å‡ç¼“çºµè½´ä¸Šçš„å˜åŒ–ã€‚ è¿™äº›å¾®åˆ†ï¼Œå‚ç›´æ–¹å‘çš„è¦æ¯”æ°´å¹³æ–¹å‘çš„å¤§å¾—å¤šï¼Œæ‰€ä»¥æ–œç‡åœ¨æ–¹å‘ç‰¹åˆ«å¤§ï¼Œæ‰€ä»¥è¿™äº›å¾®åˆ†ä¸­ï¼Œdbè¾ƒå¤§ï¼Œdwè¾ƒå°ï¼Œå› ä¸ºå‡½æ•°çš„å€¾æ–œç¨‹åº¦ï¼Œåœ¨çºµè½´ä¸Šï¼Œä¹Ÿå°±æ˜¯bæ–¹å‘ä¸Šè¦å¤§äºåœ¨æ¨ªè½´ä¸Šï¼Œä¹Ÿå°±æ˜¯æ–¹å‘ä¸ŠWã€‚dbçš„å¹³æ–¹è¾ƒå¤§ï¼Œæ‰€ä»¥$Sdb$ä¹Ÿä¼šè¾ƒå¤§ï¼Œè€Œç›¸æ¯”ä¹‹ä¸‹ï¼Œdwä¼šå°ä¸€äº›ï¼Œäº¦æˆ–dwå¹³æ–¹ä¼šå°ä¸€äº›ï¼Œå› æ­¤$Sdw$ä¼šå°ä¸€äº›ï¼Œç»“æœå°±æ˜¯çºµè½´ä¸Šçš„æ›´æ–°è¦è¢«ä¸€ä¸ªè¾ƒå¤§çš„æ•°ç›¸é™¤ï¼Œå°±èƒ½æ¶ˆé™¤æ‘†åŠ¨ï¼Œè€Œæ°´å¹³æ–¹å‘çš„æ›´æ–°åˆ™è¢«è¾ƒå°çš„æ•°ç›¸é™¤ã€‚ RMSpropçš„å½±å“å°±æ˜¯ä½ çš„æ›´æ–°æœ€åä¼šå˜æˆè¿™æ ·ï¼ˆç»¿è‰²çº¿ï¼‰ï¼Œçºµè½´æ–¹å‘ä¸Šæ‘†åŠ¨è¾ƒå°ï¼Œè€Œæ¨ªè½´æ–¹å‘ç»§ç»­æ¨è¿›ã€‚è¿˜æœ‰ä¸ªå½±å“å°±æ˜¯ï¼Œä½ å¯ä»¥ç”¨ä¸€ä¸ªæ›´å¤§å­¦ä¹ ç‡ï¼Œç„¶ååŠ å¿«å­¦ä¹ ï¼Œè€Œæ— é¡»åœ¨çºµè½´ä¸Šå‚ç›´æ–¹å‘åç¦»ã€‚ å®é™…ä¸­dwæ˜¯ä¸€ä¸ªé«˜ç»´åº¦çš„å‚æ•°å‘é‡ï¼Œdbä¹Ÿæ˜¯ä¸€ä¸ªé«˜ç»´åº¦å‚æ•°å‘é‡ï¼Œä½†æ˜¯ä½ çš„ç›´è§‰æ˜¯ï¼Œåœ¨ä½ è¦æ¶ˆé™¤æ‘†åŠ¨çš„ç»´åº¦ä¸­ï¼Œæœ€ç»ˆä½ è¦è®¡ç®—ä¸€ä¸ªæ›´å¤§çš„å’Œå€¼ï¼Œè¿™ä¸ªå¹³æ–¹å’Œå¾®åˆ†çš„åŠ æƒå¹³å‡å€¼ï¼Œæ‰€ä»¥ä½ æœ€åå»æ‰äº†é‚£äº›æœ‰æ‘†åŠ¨çš„æ–¹å‘ã€‚æ‰€ä»¥è¿™å°±æ˜¯RMSpropï¼Œå…¨ç§°æ˜¯å‡æ–¹æ ¹ï¼Œå› ä¸ºä½ å°†å¾®åˆ†è¿›è¡Œå¹³æ–¹ï¼Œç„¶åæœ€åä½¿ç”¨å¹³æ–¹æ ¹ã€‚ è§£é‡Šå¹³æ–¹ï¼š å‚ç›´æ–¹å‘ï¼Œæ¯”è¾ƒé™¡ï¼Œæ¢¯åº¦æ¯”è¾ƒå¤§ï¼Œä½†æˆ‘ä»¬åˆå¸Œæœ›å®ƒä¸‹é™çš„æ…¢ã€‚å› æ­¤å¯¹æ¢¯åº¦é™¤ä»¥ä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼Œæ‰€ä»¥ç”¨æ¢¯åº¦çš„å¹³æ–¹çš„å¹³å‡æ¥è¡¨ç¤ºã€‚è®©ä¸åŒçš„å‚æ•°æ‹¥æœ‰ä¸åŒçš„learning rateã€‚ ä»æŸç§è§’åº¦çœ‹ï¼ŒRMSpropä¼šæ ¹æ®å½“å‰çš„æ¢¯åº¦è‡ªåŠ¨è°ƒæ•´å‚æ•°çš„learning rateï¼Œæ¢¯åº¦å¤§é™ä½learning rateï¼Œæ¢¯åº¦å°çš„æ—¶å€™æé«˜learning rateï¼Œä»è€Œä¸€æ–¹é¢é¿å…äº†éœ‡è¡ï¼Œå¦ä¸€æ–¹é¢é¿å…åœ¨å¹³å¦çš„åœ°æ–¹å¾˜å¾Šå¤ªä¹…ã€‚ ä¸ºäº†é¿å…å‡ºç°åˆ†æ¯ä¸º0 \begin{array}{c}{s_{d w}=\beta s_{d w}+(1-\beta)(d w)^{2}} \\ {s_{d b}=\beta s_{d b}+(1-\beta)(d b)^{2}} \\ {w :=w-\alpha \frac{d w}{\sqrt{s_{d w}+\varepsilon}}} \\ {b :=b-\alpha \frac{d b}{\sqrt{s_{d b}+\varepsilon}}}\end{array}$\varepsilon$å–$10^{-8}$ä¸é”™çš„é€‰æ‹©. è¡¥å……ï¼š RMSPropç®—æ³•å¯¹æ¢¯åº¦è®¡ç®—äº†å¾®åˆ†å¹³æ–¹åŠ æƒå¹³å‡æ•°ã€‚è¿™ç§åšæ³•æœ‰åˆ©äºæ¶ˆé™¤äº†æ‘†åŠ¨å¹…åº¦å¤§çš„æ–¹å‘ï¼Œç”¨æ¥ä¿®æ­£æ‘†åŠ¨å¹…åº¦ï¼Œä½¿å¾—å„ä¸ªç»´åº¦çš„æ‘†åŠ¨å¹…åº¦éƒ½è¾ƒå°ã€‚å¦ä¸€æ–¹é¢ä¹Ÿä½¿å¾—ç½‘ç»œå‡½æ•°æ”¶æ•›æ›´å¿« L 08 Adam optimization algorithmAdamï¼ˆAdaptive Moment Estimationï¼Œè‡ªé€‚åº”çŸ©ä¼°è®¡ï¼‰å°±æ˜¯momentumå’ŒRMSpropçš„ç»“åˆã€‚momentumè´Ÿè´£å¹³æ»‘æ¢¯åº¦ï¼Œè€ŒRMSpropè´Ÿè´£è°ƒè§£learning rateã€‚ 1. Adama. å¼•å…¥çš„å˜é‡æœ‰ï¼š $v$ : è®¡ç®—åŒmomentumç®—æ³•ï¼Œå°†æ¢¯åº¦è¿›è¡ŒæŒ‡æ•°åŠ æƒå¹³å‡ $s$: è®¡ç®—åŒRMSpropï¼Œå°†æ¢¯åº¦çš„å¹³æ–¹è¿›è¡ŒæŒ‡æ•°åŠ æƒå¹³å‡ $Î²1$ : è®¡ç®—vvçš„åŠ æƒå‚æ•° $Î²2$ : è®¡ç®—ssçš„åŠ æƒå‚æ•° b. åœ¨è¿­ä»£å‰ï¼Œåˆå§‹åŒ–å‚æ•°vå’Œs v_{d W}=0, s_{d W}=0, v_{d b}=0, s_{d b}=0c. å¯¹ç¬¬tæ¬¡æ¢¯åº¦ä¸‹é™çš„è¿­ä»£ a. é¦–å…ˆè®¡ç®—dwå’Œdbçš„vå’Œs \begin{array}{c}{v_{d W}=\beta_{1} v_{d W}+\left(1-\beta_{1}\right) d W} \\ {s_{d W}=\beta_{2} s_{d W}+\left(1-\beta_{2}\right)(d W)^{2}} \\ {v_{d b}=\beta_{1} v_{d b}+\left(1-\beta_{1}\right) d b} \\ {s_{d b}=\beta_{2} s_{d b}+\left(1-\beta_{2}\right)(d b)^{2}}\end{array}d. ä¿®æ­£ v_{d W}^{\text {corrected}}=\frac{v_{d W}}{1-\left(\beta_{1}\right)^{t}}\\ \begin{aligned} s_{d W}^{\text {corrected}} &=\frac{s_{d W}}{1-\left(\beta_{2}\right)^{t}} \\ v_{d b}^{\text {corrected}} &=\frac{v_{d b}}{1-\left(\beta_{1}\right)^{t}} \\ s_{d b}^{\text {corrected}} &=\frac{s_{d b}}{1-\left(\beta_{2}\right)^{t}} \end{aligned}e. æœ€åæ›´æ–°å‚æ•°Wå’Œb W=W-\alpha \frac{v_{d W}^{\text {corrected}}}{\sqrt{s_{d W}^{\text { corrected }}+\varepsilon}}\\ b=b-\alpha \frac{v_{d b}^{\text {corrected}}}{\sqrt{s_{d b}^{\text { corrected }}+\varepsilon}}è¶…å‚çš„é€‰æ‹©ï¼š Î±ï¼šéœ€è¦è°ƒä¼˜ Î²1: é€šå¸¸é€‰æ‹©ä¸º0.9 Î²2: é€šå¸¸é€‰æ‹©ä¸º0.999 Îµ: ä¸€èˆ¬ä¸éœ€è¦è°ƒä¼˜ï¼Œé€‰æ‹©ä¸€ä¸ªå°æ•°ï¼Œæ¯”å¦‚10âˆ’8 ä½ å¯ä»¥å°è¯•ä¸€ç³»åˆ—å€¼Î±ï¼Œç„¶åçœ‹å“ªä¸ªæœ‰æ•ˆ L09 : Learning Rate Decay why ä¸ºä»€ä¹ˆè¦åšlearning rate decayï¼Ÿ è¾ƒå¤§çš„learning rateè™½ç„¶åœ¨ç®—æ³•å¼€å§‹é˜¶æ®µä¼šåŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œä½†åœ¨æ”¶æ•›æ¥è¿‘åˆ°ä¼˜åŒ–ç‚¹çš„æ—¶å€™ï¼Œç®—æ³•ä¼šåœ¨ä¼˜åŒ–ç‚¹é™„è¿‘éœ‡è¡ï¼Œå¦‚ä¸‹å›¾ï¼š 2.å¦‚ä½•åšlearning rate decayï¼Ÿ æ€è·¯å¾ˆç®€å•ï¼Œå°±æ˜¯å¼•å…¥ä¸€ä¸ªå‡½æ•°ï¼Œè®©Î±éšç€è¿­ä»£ï¼ˆæ¯”å¦‚min-batchçš„epochï¼‰é€’å‡ã€‚ä¸ºæ­¤å¯ä»¥é‡‡ç”¨çš„decayå‡½æ•°æœ‰ï¼š å€’æ•°ï¼š \alpha :=\frac{1}{1+\text { decay rate * epoch num}} \alpha L 10: The Problem of local Optimaäº‹å®ä¸Šï¼Œå¦‚æœä½ è¦åˆ›å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œé€šå¸¸æ¢¯åº¦ä¸ºé›¶çš„ç‚¹å¹¶ä¸æ˜¯è¿™ä¸ªå›¾ä¸­çš„å±€éƒ¨æœ€ä¼˜ç‚¹ï¼Œå®é™…ä¸Šæˆæœ¬å‡½æ•°çš„é›¶æ¢¯åº¦ç‚¹ï¼Œé€šå¸¸æ˜¯éç‚¹ã€‚ ä½†æ˜¯ä¸€ä¸ªå…·æœ‰é«˜ç»´åº¦ç©ºé—´çš„å‡½æ•°ï¼Œå¦‚æœæ¢¯åº¦ä¸º0ï¼Œé‚£ä¹ˆåœ¨æ¯ä¸ªæ–¹å‘ï¼Œå®ƒå¯èƒ½æ˜¯å‡¸å‡½æ•°ï¼Œä¹Ÿå¯èƒ½æ˜¯å‡¹å‡½æ•°ã€‚å¦‚æœä½ åœ¨2ä¸‡ç»´ç©ºé—´ä¸­ï¼Œé‚£ä¹ˆæƒ³è¦å¾—åˆ°å±€éƒ¨æœ€ä¼˜ï¼Œæ‰€æœ‰çš„2ä¸‡ä¸ªæ–¹å‘éƒ½éœ€è¦æ˜¯è¿™æ ·ï¼Œä½†å‘ç”Ÿçš„æœºç‡ä¹Ÿè®¸å¾ˆå°ï¼Œä¹Ÿè®¸æ˜¯$2^{-20000}$ï¼Œå› æ­¤æ›´æœ‰å¯èƒ½é‡åˆ°æœ‰äº›æ–¹å‘çš„æ›²çº¿ä¼šè¿™æ ·å‘ä¸Šå¼¯æ›²ï¼Œå¦ä¸€äº›æ–¹å‘æ›²çº¿å‘ä¸‹å¼¯ï¼Œè€Œä¸æ˜¯æ‰€æœ‰çš„éƒ½å‘ä¸Šå¼¯æ›²ï¼Œå› æ­¤åœ¨é«˜ç»´åº¦ç©ºé—´ï¼Œä½ æ›´å¯èƒ½ç¢°åˆ°éç‚¹ã€‚æ‰€æœ‰ï¼Œæ‹…å¿ƒæ”¶æ•›åˆ°local optimaï¼ŒçœŸæ˜¯äººä»¬æƒ³å¤šäº†ï¼Œå®é™…ä¸Šå¹¶æ²¡æœ‰æƒ³è±¡çš„é‚£ä¹ˆå¤šlocal optimaã€‚åœ¨é«˜ç»´ç©ºé—´ï¼Œå‡ ä¹ä¸å¤ªå¯èƒ½è¢«å›°åœ¨ä¸€ä¸ªlocal optimaï¼Œè¿™æ˜¯ä¸€ä¸ªå¥½æ¶ˆæ¯ã€‚ å› æ­¤ï¼Œåœ¨é«˜ç»´ç©ºé—´é‡åˆ°çš„é—®é¢˜æ˜¯é«˜åŸé—®é¢˜ï¼ˆProblem of plateausï¼‰ Adamç®—æ³•å¯ä»¥åŠ é€Ÿå­¦ä¹  W3 Hyperparameter tuningL01 Tuning process åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ¥è§¦åˆ°çš„hyperparameteræœ‰ï¼š learning rate: Î±Î± momentum å‚æ•°: Î²Î² Adamå‚æ•°: Î²1Î²1å’Œ Î²2Î²2ä»¥åŠÎµÎµ ç¥ç»ç½‘ç»œå±‚æ•°: L ç¥ç»ç½‘ç»œéšè—å±‚neuronæ•°ï¼šn[l]n[l] learning rate decayå‚æ•° min-batch size è¿™äº›hyperparameteré‡è¦æ€§æ’åºï¼š æœ€é‡è¦çš„ï¼š learning rate: Î±Î± æ¯”è¾ƒé‡è¦çš„ï¼š momentum å‚æ•°: Î²Î² ç¥ç»ç½‘ç»œå±‚æ•°: L ç¥ç»ç½‘ç»œéšè—å±‚neuronæ•°ï¼šn[l]n[l] æ¬¡é‡è¦çš„ï¼š ç¥ç»ç½‘ç»œéšè—å±‚neuronæ•° learning rate decayå‚æ•° åŸºæœ¬ä¸éœ€è°ƒæ•´çš„ Î²1Î²1å’Œ Î²2Î²2ä»¥åŠÎµ 1. Try random values : Donâ€™t use a grid why: ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾è¶…å‚æ•°1æ˜¯ï¼ˆå­¦ä¹ é€Ÿç‡ï¼‰ï¼Œå–ä¸€ä¸ªæç«¯çš„ä¾‹å­ï¼Œå‡è®¾è¶…å‚æ•°2æ˜¯Adamç®—æ³•ä¸­ï¼Œåˆ†æ¯ä¸­çš„$\varepsilon$ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œaçš„å–å€¼å¾ˆé‡è¦ï¼Œè€Œ$\varepsilon$å–å€¼åˆ™æ— å…³ç´§è¦ã€‚å¦‚æœä½ åœ¨ç½‘æ ¼ä¸­å–ç‚¹ï¼Œæ¥ç€ï¼Œä½ è¯•éªŒäº†açš„5ä¸ªå–å€¼ï¼Œé‚£ä½ ä¼šå‘ç°ï¼Œæ— è®º$\varepsilon$å–ä½•å€¼ï¼Œç»“æœåŸºæœ¬ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥ï¼Œä½ çŸ¥é“å…±æœ‰25ç§æ¨¡å‹ï¼Œä½†è¿›è¡Œè¯•éªŒçš„å€¼åªæœ‰5ä¸ªï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯å¾ˆé‡è¦çš„ã€‚ å¯¹æ¯”è€Œè¨€ï¼Œå¦‚æœä½ éšæœºå–å€¼ï¼Œä½ ä¼šè¯•éªŒ25ä¸ªç‹¬ç«‹çš„a,$\varepsilon$ï¼Œä¼¼ä¹ä½ æ›´æœ‰å¯èƒ½å‘ç°æ•ˆæœåšå¥½çš„é‚£ä¸ªã€‚ 2. ç”±ç²—ç³™åˆ°ç²¾ç»†çš„ç­–ç•¥ L 02: Using an Appropriate Scale to pick hyperparameters$a$å–å€¼0.0001,1,å¦‚æœä½ ç”»ä¸€æ¡ä»0.0001åˆ°1çš„æ•°è½´ï¼Œæ²¿å…¶éšæœºå‡åŒ€å–å€¼ï¼Œé‚£90%çš„æ•°å€¼å°†ä¼šè½åœ¨0.1åˆ°1ä¹‹é—´ï¼Œç»“æœå°±æ˜¯ï¼Œåœ¨0.1åˆ°1ä¹‹é—´ï¼Œåº”ç”¨äº†90%çš„èµ„æºï¼Œè€Œåœ¨0.0001åˆ°0.1ä¹‹é—´ï¼Œåªæœ‰10%çš„æœç´¢èµ„æºï¼Œè¿™çœ‹ä¸Šå»ä¸å¤ªå¯¹ã€‚ åŒæ—¶åœ¨èŒƒå›´å†…æœç´¢ï¼Œä¹Ÿä¸æ˜¯å‡åŒ€åˆ†å¸ƒï¼ˆuniformly randomï¼‰çš„ï¼Œé€šå¸¸æœ‰è¿™ä¸ªå‚æ•°çš„scaleï¼Œæ¯”å¦‚å¯¹æ•°scaleã€‚ åè€Œï¼Œç”¨å¯¹æ•°æ ‡å°ºæœç´¢è¶…å‚æ•°çš„æ–¹å¼ä¼šæ›´åˆç†ï¼Œå› æ­¤è¿™é‡Œä¸ä½¿ç”¨çº¿æ€§è½´ï¼Œåˆ†åˆ«ä¾æ¬¡å–0.0001ï¼Œ0.001ï¼Œ0.01ï¼Œ0.1ï¼Œ1ï¼Œåœ¨å¯¹æ•°è½´ä¸Šå‡åŒ€éšæœºå–ç‚¹ï¼Œè¿™æ ·ï¼Œåœ¨0.0001åˆ°0.001ä¹‹é—´ï¼Œå°±ä¼šæœ‰æ›´å¤šçš„æœç´¢èµ„æºå¯ç”¨ï¼Œè¿˜æœ‰åœ¨0.001åˆ°0.01ä¹‹é—´ç­‰ç­‰ã€‚ L 03 : Hyperparameter tuning i practice ä¸åŒçš„ç®—æ³•å’Œåœºæ™¯ï¼Œå¯¹è¶…å‚çš„scaleæ•æ„Ÿæ€§å¯èƒ½ä¸ä¸€æ ·. æ ¹æ®è®¡ç®—èµ„æºå’Œæ•°æ®é‡ï¼Œå¯ä»¥é‡‡å–ä¸¤ç§ç­–ç•¥æ¥è°ƒå‚ Pandaï¼ˆç†ŠçŒ«ç­–ç•¥ï¼‰ï¼šå¯¹ä¸€ä¸ªæ¨¡å‹å…ˆåä¿®æ”¹å‚æ•°ï¼ŒæŸ¥çœ‹å…¶è¡¨ç°ï¼Œæœ€ç»ˆé€‰æ‹©æœ€å¥½çš„å‚æ•°ã€‚å°±åƒç†ŠçŒ«ä¸€æ ·ï¼Œä¸€æ¬¡åªæŠšå…»ä¸€ä¸ªåä»£ã€‚ Caviarï¼ˆé±¼å­é…±ç­–ç•¥ï¼‰ï¼šè®¡ç®—èµ„æºè¶³å¤Ÿï¼Œå¯ä»¥åŒæ—¶è¿è¡Œå¾ˆå¤šæ¨¡å‹å®ä¾‹ï¼Œé‡‡ç”¨ä¸åŒçš„å‚æ•°ï¼Œç„¶åæœ€ç»ˆé€‰æ‹©ä¸€ä¸ªå¥½çš„ã€‚ç±»ä¼¼é±¼ç±»ï¼Œä¸€æ¬¡ä¸‹å¾ˆå¤šåµï¼Œè‡ªåŠ¨ç«äº‰æˆæ´»ã€‚ L 04: Normalizing Activations in a Network1. Implementing Batch NormalizingBatchå½’ä¸€åŒ–,Batchå½’ä¸€åŒ–ä¼šä½¿ä½ çš„å‚æ•°æœç´¢é—®é¢˜å˜å¾—å¾ˆå®¹æ˜“ï¼Œä½¿ç¥ç»ç½‘ç»œå¯¹è¶…å‚æ•°çš„é€‰æ‹©æ›´åŠ ç¨³å®šï¼Œè¶…å‚æ•°çš„èŒƒå›´ä¼šæ›´åŠ åºå¤§ï¼Œå·¥ä½œæ•ˆæœä¹Ÿå¾ˆå¥½ï¼Œä¹Ÿä¼šæ˜¯ä½ çš„è®­ç»ƒæ›´åŠ å®¹æ˜“ï¼Œç”šè‡³æ˜¯æ·±å±‚ç½‘ç»œã€‚ å¯ä»¥normalize $a^{[l]},z^{[l]}$,é€‰æ‹©$z^{[L]}$ è®¾ç½® Î³ å’Œ Î² çš„åŸå› æ˜¯ï¼Œå¦‚æœå„éšè—å±‚çš„è¾“å…¥å‡å€¼åœ¨é è¿‘ 0 çš„åŒºåŸŸï¼Œå³å¤„äºæ¿€æ´»å‡½æ•°çš„çº¿æ€§åŒºåŸŸï¼Œä¸åˆ©äºè®­ç»ƒéçº¿æ€§ç¥ç»ç½‘ç»œï¼Œä»è€Œå¾—åˆ°æ•ˆæœè¾ƒå·®çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œéœ€è¦ç”¨ Î³ å’Œ Î² å¯¹æ ‡å‡†åŒ–åçš„ç»“æœåšè¿›ä¸€æ­¥å¤„ç†ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒÎ²å’ŒÎ³ä¸æ˜¯è¶…å‚ï¼Œè€Œæ˜¯æ¢¯åº¦ä¸‹é™éœ€å­¦ä¹ çš„å‚æ•°ã€‚ L 05 : Fitting Batch Norm Into Neural Networks æ³¨æ„ å…ˆå‰æˆ‘è¯´è¿‡æ¯å±‚çš„å‚æ•°æ˜¯$w^{[l]}$å’Œ$b^{[l]}$ï¼Œè¿˜æœ‰$\beta^{[l]}$å’Œ$b^{[l]}$ï¼Œè¯·æ³¨æ„è®¡ç®—çš„æ–¹å¼å¦‚ä¸‹ï¼Œ$z^{[l]}=w^{[l]} a^{[l-1]}+b^{[l]}$ï¼Œä½†Batchå½’ä¸€åŒ–åšçš„æ˜¯ï¼Œå®ƒè¦çœ‹è¿™ä¸ªmini-batchï¼Œå…ˆå°†$z^{[l]}$å½’ä¸€åŒ–ï¼Œç»“æœä¸ºå‡å€¼0å’Œæ ‡å‡†æ–¹å·®ï¼Œå†ç”±$\beta$å’Œbé‡ç¼©æ”¾ï¼Œä½†è¿™æ„å‘³ç€ï¼Œæ— è®º$b^{[l]}$çš„å€¼æ˜¯å¤šå°‘ï¼Œéƒ½æ˜¯è¦è¢«å‡å»çš„ï¼Œå› ä¸ºåœ¨Batchå½’ä¸€åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œä½ è¦è®¡ç®—çš„$z^{[l]}$å‡å€¼ï¼Œå†å‡å»å¹³å‡å€¼ï¼Œåœ¨æ­¤ä¾‹ä¸­çš„mini-batchä¸­å¢åŠ ä»»ä½•å¸¸æ•°ï¼Œæ•°å€¼éƒ½ä¸ä¼šæ”¹å˜ï¼Œå› ä¸ºåŠ ä¸Šçš„ä»»ä½•å¸¸æ•°éƒ½å°†ä¼šè¢«å‡å€¼å‡å»æ‰€æŠµæ¶ˆ. æœ€åï¼Œè¯·è®°ä½çš„ç»´$z^{[l]}$ï¼Œå› ä¸ºåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç»´æ•°ä¼šæ˜¯$\left(n^{[l]}, 1\right)$ï¼Œçš„å°ºå¯¸ä¸ºï¼Œå¦‚æœæ˜¯lå±‚éšè—å•å…ƒçš„æ•°é‡ï¼Œé‚£$ \beta^{[l]}$å’Œ$ \gamma^{[l]}$çš„ç»´åº¦ä¹Ÿæ˜¯$\left(n^{[l]}, 1\right)$ï¼Œå› ä¸ºè¿™æ˜¯ä½ éšè—å±‚çš„æ•°é‡ï¼Œä½ æœ‰éšè—å•å…ƒï¼Œæ‰€ä»¥$\gamma^{[l]}$å’Œ$ \beta^{[l]}$ç”¨æ¥å°†æ¯ä¸ªéšè—å±‚çš„å‡å€¼å’Œæ–¹å·®ç¼©æ”¾ä¸ºç½‘ç»œæƒ³è¦çš„å€¼ã€‚ L 06 Why Doest Batch Norm Work? é¦–å…ˆï¼Œèµ·åˆ°äº†normalizationçš„ä½œç”¨ï¼ŒåŒå¯¹è¾“å…¥æ•°æ®Xçš„normalizationä½œç”¨ç±»ä¼¼ã€‚ è®©æ¯ä¸€å±‚çš„å­¦ä¹ ï¼Œä¸€å®šç¨‹åº¦è§£è€¦äº†å‰å±‚å‚æ•°å’Œåå±‚å‚æ•°ï¼Œè®©å„å±‚æ›´åŠ ç‹¬ç«‹çš„å­¦ä¹ ã€‚æ— è®ºå‰ä¸€å±‚å¦‚ä½•å˜ï¼Œæœ¬å±‚è¾“å…¥çš„æ•°æ®æ€»æ˜¯ä¿æŒç¨³å®šçš„å‡å€¼å’Œæ–¹å·®ã€‚ï¼ˆä¸»è¦åŸå› ï¼‰ æ‰€ä»¥ä½¿ä½ æ•°æ®æ”¹å˜åˆ†å¸ƒçš„è¿™ä¸ªæƒ³æ³•ï¼Œæœ‰ä¸ªæœ‰ç‚¹æ€ªçš„åå­—â€œCovariate shiftâ€ï¼Œæƒ³æ³•æ˜¯è¿™æ ·çš„ï¼Œå¦‚æœä½ å·²ç»å­¦ä¹ äº†åˆ° çš„æ˜ å°„ï¼Œå¦‚æœ çš„åˆ†å¸ƒæ”¹å˜äº†ï¼Œé‚£ä¹ˆä½ å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒä½ çš„å­¦ä¹ ç®—æ³•ã€‚è¿™ç§åšæ³•åŒæ ·é€‚ç”¨äºï¼Œå¦‚æœçœŸå®å‡½æ•°ç”± åˆ° æ˜ å°„ä¿æŒä¸å˜ï¼Œæ­£å¦‚æ­¤ä¾‹ä¸­ï¼Œå› ä¸ºçœŸå®å‡½æ•°æ˜¯æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯ä¸€åªçŒ«ï¼Œè®­ç»ƒä½ çš„å‡½æ•°çš„éœ€è¦å˜å¾—æ›´åŠ è¿«åˆ‡ï¼Œå¦‚æœçœŸå®å‡½æ•°ä¹Ÿæ”¹å˜ï¼Œæƒ…å†µå°±æ›´ç³Ÿäº†ã€‚ å…³äºç¬¬äºŒç‚¹ï¼Œå¦‚æœå®é™…åº”ç”¨æ ·æœ¬å’Œè®­ç»ƒæ ·æœ¬çš„æ•°æ®åˆ†å¸ƒä¸åŒï¼ˆä¾‹å¦‚ï¼Œæ©˜çŒ«å›¾ç‰‡å’Œé»‘çŒ«å›¾ç‰‡ï¼‰ï¼Œæˆ‘ä»¬ç§°å‘ç”Ÿäº†â€œCovariate Shiftâ€ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä¸€èˆ¬è¦å¯¹æ¨¡å‹è¿›è¡Œé‡æ–°è®­ç»ƒã€‚Batch Normalization çš„ä½œç”¨å°±æ˜¯å‡å° Covariate Shift æ‰€å¸¦æ¥çš„å½±å“ï¼Œè®©æ¨¡å‹å˜å¾—æ›´åŠ å¥å£®ï¼Œé²æ£’æ€§ï¼ˆRobustnessï¼‰æ›´å¼ºã€‚ å³ä½¿è¾“å…¥çš„å€¼æ”¹å˜äº†ï¼Œç”±äº Batch Normalization çš„ä½œç”¨ï¼Œä½¿å¾—å‡å€¼å’Œæ–¹å·®ä¿æŒä¸å˜ï¼ˆç”± Î³ å’Œ Î² å†³å®šï¼‰ï¼Œé™åˆ¶äº†åœ¨å‰å±‚çš„å‚æ•°æ›´æ–°å¯¹æ•°å€¼åˆ†å¸ƒçš„å½±å“ç¨‹åº¦ï¼Œå› æ­¤åå±‚çš„å­¦ä¹ å˜å¾—æ›´å®¹æ˜“ä¸€äº›ã€‚Batch Normalization å‡å°‘äº†å„å±‚ W å’Œ b ä¹‹é—´çš„è€¦åˆæ€§ï¼Œè®©å„å±‚æ›´åŠ ç‹¬ç«‹ï¼Œå®ç°è‡ªæˆ‘è®­ç»ƒå­¦ä¹ çš„æ•ˆæœã€‚ å¦å¤–ï¼ŒBatch Normalization ä¹Ÿèµ·åˆ°å¾®å¼±çš„æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰æ•ˆæœã€‚å› ä¸ºåœ¨æ¯ä¸ª mini-batch è€Œéæ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œåªç”±è¿™ä¸€å°éƒ¨åˆ†æ•°æ®ä¼°è®¡å¾—å‡ºçš„å‡å€¼å’Œæ–¹å·®ä¼šæœ‰ä¸€äº›å™ªå£°ï¼Œå› æ­¤æœ€ç»ˆè®¡ç®—å‡ºçš„ z~(i)z~(i)ä¹Ÿæœ‰ä¸€å®šå™ªå£°ã€‚ç±»ä¼¼äº dropoutï¼Œè¿™ç§å™ªå£°ä¼šä½¿å¾—ç¥ç»å…ƒä¸ä¼šå†ç‰¹åˆ«ä¾èµ–äºä»»ä½•ä¸€ä¸ªè¾“å…¥ç‰¹å¾ã€‚ å› ä¸º Batch Normalization åªæœ‰å¾®å¼±çš„æ­£åˆ™åŒ–æ•ˆæœï¼Œå› æ­¤å¯ä»¥å’Œ dropout ä¸€èµ·ä½¿ç”¨ï¼Œä»¥è·å¾—æ›´å¼ºå¤§çš„æ­£åˆ™åŒ–æ•ˆæœã€‚é€šè¿‡åº”ç”¨æ›´å¤§çš„ mini-batch å¤§å°ï¼Œå¯ä»¥å‡å°‘å™ªå£°ï¼Œä»è€Œå‡å°‘è¿™ç§æ­£åˆ™åŒ–æ•ˆæœã€‚ æœ€åï¼Œä¸è¦å°† Batch Normalization ä½œä¸ºæ­£åˆ™åŒ–çš„æ‰‹æ®µï¼Œè€Œæ˜¯å½“ä½œåŠ é€Ÿå­¦ä¹ çš„æ–¹å¼ã€‚æ­£åˆ™åŒ–åªæ˜¯ä¸€ç§éæœŸæœ›çš„å‰¯ä½œç”¨ï¼ŒBatch Normalization è§£å†³çš„è¿˜æ˜¯åå‘ä¼ æ’­è¿‡ç¨‹ä¸­çš„æ¢¯åº¦é—®é¢˜ï¼ˆæ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸ï¼‰ã€‚ L 07 : Batch Norm At Test Timeé—®é¢˜ï¼šBNç®—æ³•åœ¨è®­ç»ƒæ—¶æ˜¯ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®è®­ç»ƒï¼Œèƒ½ç®—å‡ºæ¯ä¸€å±‚Zçš„å‡å€¼å’Œæ–¹å·®ï¼›è€Œåœ¨æµ‹è¯•æ—¶ï¼Œè¾“å…¥çš„åˆ™æ˜¯å•ä¸ªæ•°æ®ï¼Œå•æ¡æ•°æ®æ²¡æ³•åšå‡å€¼å’Œæ–¹å·®çš„è®¡ç®—ï¼Œæ€ä¹ˆåœ¨æµ‹è¯•æœŸè¾“å…¥å‡å€¼å’Œæ–¹å·®å‘¢? å®é™…åº”ç”¨ä¸­ä¸€èˆ¬ä¸ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œè€Œæ˜¯ä½¿ç”¨ä¹‹å‰å­¦ä¹ è¿‡çš„æŒ‡æ•°åŠ æƒå¹³å‡çš„æ–¹æ³•æ¥é¢„æµ‹æµ‹è¯•è¿‡ç¨‹å•ä¸ªæ ·æœ¬çš„ Î¼ å’Œ $Ïƒ^2$ è®¡ç®—$z_{\text { norm }}^{(\hat{2})}$ï¼Œç”¨$\mu$ å’Œ$ \sigma^{2}$çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼Œç”¨ä½ æ‰‹å¤´çš„æœ€æ–°æ•°å€¼æ¥åšè°ƒæ•´ï¼Œç„¶åä½ å¯ä»¥ç”¨å·¦è¾¹æˆ‘ä»¬åˆšç®—å‡ºæ¥çš„å’Œä½ åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­å¾—åˆ°çš„$\beta$å’Œ$\sigma$å‚æ•°æ¥è®¡ç®—ä½ é‚£ä¸ªæµ‹è¯•æ ·æœ¬çš„zå€¼ã€‚ L 08 : Softmax Regression1. [Multi-class classification] æœ€åä¸€å±‚æ˜¯æ¦‚ç‡ï¼Œä¹‹å’Œä¸º1ï¼Œè¦ç”¨åˆ°Softmaxå±‚ï¼ŒSoftmaxæ¿€æ´»å‡½æ•°çš„ç‰¹æ®Šä¹‹å¤„åœ¨äºï¼Œå› ä¸ºéœ€è¦å°†æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºå½’ä¸€åŒ–ï¼Œå°±éœ€è¦è¾“å…¥ä¸€ä¸ªå‘é‡ï¼Œæœ€åè¾“å‡ºä¸€ä¸ªå‘é‡ã€‚ 2. Softmax exampleæ²¡æœ‰éšè—å±‚çš„softmax,ä»£è¡¨ä¸€äº›å†³ç­–è¾¹ç•Œ L 09 Training SoftMax classifier Softmaxè¿™ä¸ªåç§°çš„æ¥æºæ˜¯ä¸æ‰€è°“hardmaxå¯¹æ¯”,Softmaxå›å½’æˆ–Softmaxæ¿€æ´»å‡½æ•°å°†logisticæ¿€æ´»å‡½æ•°æ¨å¹¿åˆ°ç±»ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸¤ç±»ï¼Œç»“æœå°±æ˜¯å¦‚æœC=2ï¼Œé‚£ä¹ˆC=2çš„Softmaxå®é™…ä¸Šå˜å›äº†logisticå›å½’ï¼Œ Loss Function J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right) 3. Gradient descent with softmax æœ€åä¸€å±‚æ±‚å¯¼ï¼Œsoftmaxæ¿€æ´»å‡½æ•° J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)L11 TensorFlow1. åŸºæœ¬æµç¨‹ä½¿ç”¨tensorflowï¼Œåªè¦å‘Šè¯‰tensorflow forward propï¼Œå®ƒè‡ªå·±å°±ä¼šåšbackpropï¼Œå› æ­¤ä¸ç”¨è‡ªå·±å®ç°backprop 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as npimport tensorflow as tf#å¯¼å…¥TensorFlowâ€‹w = tf.Variable(0,dtype = tf.float32)#æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®šä¹‰å‚æ•°wï¼Œåœ¨TensorFlowä¸­ï¼Œä½ è¦ç”¨tf.Variable()æ¥å®šä¹‰å‚æ•°â€‹#ç„¶åæˆ‘ä»¬å®šä¹‰æŸå¤±å‡½æ•°ï¼šâ€‹cost = tf.add(tf.add(w**2,tf.multiply(- 10.,w)),25)#ç„¶åæˆ‘ä»¬å®šä¹‰æŸå¤±å‡½æ•°Jç„¶åæˆ‘ä»¬å†å†™ï¼šâ€‹train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)#(è®©æˆ‘ä»¬ç”¨0.01çš„å­¦ä¹ ç‡ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æŸå¤±)ã€‚â€‹#æœ€åä¸‹é¢çš„å‡ è¡Œæ˜¯æƒ¯ç”¨è¡¨è¾¾å¼:â€‹init = tf.global_variables_initializer()â€‹session = tf.Session()#è¿™æ ·å°±å¼€å¯äº†ä¸€ä¸ªTensorFlow sessionã€‚â€‹session.run(init)#æ¥åˆå§‹åŒ–å…¨å±€å˜é‡ã€‚â€‹#ç„¶åè®©TensorFlowè¯„ä¼°ä¸€ä¸ªå˜é‡ï¼Œæˆ‘ä»¬è¦ç”¨åˆ°:â€‹session.run(w)â€‹#ä¸Šé¢çš„è¿™ä¸€è¡Œå°†wåˆå§‹åŒ–ä¸º0ï¼Œå¹¶å®šä¹‰æŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬å®šä¹‰trainä¸ºå­¦ä¹ ç®—æ³•ï¼Œå®ƒç”¨æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–å™¨ä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–ï¼Œä½†å®é™…ä¸Šæˆ‘ä»¬è¿˜æ²¡æœ‰è¿è¡Œå­¦ä¹ ç®—æ³•ï¼Œæ‰€ä»¥#ä¸Šé¢çš„è¿™ä¸€è¡Œå°†wåˆå§‹åŒ–ä¸º0ï¼Œå¹¶å®šä¹‰æŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬å®šä¹‰trainä¸ºå­¦ä¹ ç®—æ³•ï¼Œå®ƒç”¨æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–å™¨ä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–ï¼Œä½†å®é™…ä¸Šæˆ‘ä»¬è¿˜æ²¡æœ‰è¿è¡Œå­¦ä¹ ç®—æ³•ï¼Œæ‰€ä»¥session.run(w)è¯„ä¼°äº†wï¼Œè®©æˆ‘ï¼šï¼šâ€‹print(session.run(w))â€‹æ‰€ä»¥å¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå®ƒè¯„ä¼°ç­‰äº0ï¼Œå› ä¸ºæˆ‘ä»¬ä»€ä¹ˆéƒ½è¿˜æ²¡è¿è¡Œã€‚#ç°åœ¨è®©æˆ‘ä»¬è¾“å…¥ï¼šâ€‹$session.run(train)ï¼Œå®ƒæ‰€åšçš„å°±æ˜¯è¿è¡Œä¸€æ­¥æ¢¯åº¦ä¸‹é™æ³•ã€‚#æ¥ä¸‹æ¥åœ¨è¿è¡Œäº†ä¸€æ­¥æ¢¯åº¦ä¸‹é™æ³•åï¼Œè®©æˆ‘ä»¬è¯„ä¼°ä¸€ä¸‹wçš„å€¼ï¼Œå†printï¼šâ€‹print(session.run(w))#åœ¨ä¸€æ­¥æ¢¯åº¦ä¸‹é™æ³•ä¹‹åï¼Œwç°åœ¨æ˜¯0.1ã€‚ 2. å¦‚ä½•ç”¨è®­ç»ƒæ•°æ®placeholder åœ¨å®é™…çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¦ç”¨ä¸åŒçš„æ ·æœ¬åå¤æ”¾åˆ°ä¸€ä¸ªå¾…ä¼˜åŒ–å‡½æ•°ä¸­çš„ï¼Œè¿™ä¸ªæ—¶å€™å°±å¯ä»¥ç”¨tensorflowçš„placeholderå®ç°,åœ¨runçš„æ—¶å€™ï¼Œå¯¹åº”ç»™å‡ºfeed_dictï¼Œè¡¨åå ä½ç¬¦xçš„å®é™…å€¼ã€‚ 123456789101112131415161718192021import numpy as npimport tensorflow as tf # å¯¼å…¥Tensorflowcoefficient = np.array([[2.],[-10.],[25.]])w = tf.Variable(0, dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1]) # 3x1å¤§å°çš„placeholdercost = w**x[0][0] - x[1][0]*w + x[2][0] # è¦ä¼˜åŒ–çš„cost functionï¼ˆå³forward propçš„å½¢å¼ï¼‰train = tf.train.GradientDescentOptimizer(0.01).minimize(cost) init = tf.global_variables_initializer()session = tf.Session()session.run(init)print(session.run(w))session.run(train, feed_dict=&#123;x:coefficient&#125;) # xå ä½ç¬¦æ›¿æ¢ä¸ºcoefficientprint(session.run(w))for i in range(1000): session.run(train, feed_dict=&#123;x:coefficient&#125;) # # xå ä½ç¬¦æ›¿æ¢ä¸ºcoefficientprint(session.run(w)) 3. è®¡ç®—æµTensorFlowç¨‹åºçš„æ ¸å¿ƒæ˜¯è®¡ç®—æŸå¤±å‡½æ•°ï¼Œç„¶åTensorFlowè‡ªåŠ¨è®¡ç®—å‡ºå¯¼æ•°ï¼Œä»¥åŠå¦‚ä½•æœ€å°åŒ–æŸå¤±ï¼Œå› æ­¤è¿™ä¸ªç­‰å¼æˆ–è€…è¿™è¡Œä»£ç æ‰€åšçš„å°±æ˜¯è®©TensorFlowå»ºç«‹è®¡ç®—å›¾ï¼Œ with è¯­å¥é€‚ç”¨äºå¯¹èµ„æºè¿›è¡Œè®¿é—®çš„åœºåˆï¼Œç¡®ä¿ä¸ç®¡ä½¿ç”¨è¿‡ç¨‹ä¸­æ˜¯å¦å‘ç”Ÿå¼‚å¸¸éƒ½ä¼šæ‰§è¡Œå¿…è¦çš„â€œæ¸…ç†â€æ“ä½œï¼Œé‡Šæ”¾èµ„æºï¼Œæ¯”å¦‚æ–‡ä»¶ä½¿ç”¨åè‡ªåŠ¨å…³é—­ã€çº¿ç¨‹ä¸­é”çš„è‡ªåŠ¨è·å–å’Œé‡Šæ”¾ç­‰ã€‚å»ºç«‹è®¡ç®—æµçš„è¿‡ç¨‹ï¼Œå‰å‘ä¼ æ’­çš„è¿‡ç¨‹ï¼Œoperation Summaryhow to systematically organize the hyper parameter search process and batch normalization and framework http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Improving_Deep_Neural_Networks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2 http://www.ai-start.com/dl2017/html/lesson2-week1.html#header-n3 http://dl-notes.imshuai.com/#/c2w1?id=_4-heros-of-deep-learning-yoshua-bengio-interview https://www.youtube.com/watch?v=4Ct3Yujl1dk&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=14]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å½©é“…DailyLifeStyle]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%BD%A9%E9%93%85DailyLifeStyle%2F</url>
    <content type="text"><![CDATA[Day one1. å·¥å…·ç®€å•ä»‹ç» å½©é“… æ°´æº¶æ€§ï¼Œæ²¹æ€§ å½©é“…çº¸ é“…ç¬” B 2B&lt;4Bé»‘çš„ç¨‹åº¦ H 4H&lt;8Hè½¯åº¦ æ©¡çš® è½¯æ©¡çš® ç¡¬æ©¡çš® ç”µåŠ¨æ©¡çš®æ“¦ é“…ç¬”åˆ€ å¯è·³æ¡£ç±»å‹ å‹¾çº¿ç¬” é’ˆç®¡ç¬” ï¼ˆæ¨±èŠ±ï¼‰ ç¬”å¥— é«˜å…‰ç¬” å¯ä»¥ç”¨ä¿®æ­£æ¶²æ›¿æ¢ï¼ˆä¸‰æ£±) çº¸æ“¦ç¬” ç›ä¸½ åˆ·å­ ç”»æ¿ é€Ÿå†™æ¿ 2. é¢œè‰²ä¸‰åŸè‰²ï¼š çº¢ é»„ è“ è‰²ç›¸ é¢œè‰² é¥±å’Œåº¦ é²œè‰³ç¨‹åº¦ æ˜åº¦ æ˜æš—ç¨‹åº¦ é‚»è¿‘è‰² å¯¹æ¯”è‰² çº¢-ç»¿ è“-æ©™ ç´«-é»„ æš–è‰²å’Œå†·è‰² 3. æ’çº¿ ä¸€ä¸ªæ–¹å‘ å¾€åŒä¸€ä¸ªæ–¹å‘æ’ï¼Œæ— è¿æ¥ æ¥å› ç›¸è¿æ¥ï¼Œä¸€æ¡çº¿ ä¸åŒæ–¹å‘æ’åˆ— æ³¨æ„ï¼šåŠ›åº¦å’Œé—´è· 4. å¹³æ¶‚åŠ›åº¦ä¸€è‡´ 5. æ¸å˜åŠ›åº¦ä¸ä¸€è‡´]]></content>
      <categories>
        <category>å¨±ä¹ç”Ÿæ´»</category>
      </categories>
      <tags>
        <tag>å½©é“…</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%20test%2F</url>
    <content type="text"><![CDATA[Logistics Regression å¦‚ä½•å‡¸æ˜¾ä½ æ˜¯ä¸€ä¸ªå¯¹é€»è¾‘å›å½’å·²ç»éå¸¸äº†è§£çš„äººå‘¢ã€‚é‚£å°±æ˜¯ç”¨ä¸€å¥è¯æ¦‚æ‹¬å®ƒï¼é€»è¾‘å›å½’å‡è®¾æ•°æ®æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒ,é€šè¿‡æå¤§åŒ–ä¼¼ç„¶å‡½æ•°çš„æ–¹æ³•ï¼Œè¿ç”¨æ¢¯åº¦ä¸‹é™æ¥æ±‚è§£å‚æ•°ï¼Œæ¥è¾¾åˆ°å°†æ•°æ®äºŒåˆ†ç±»çš„ç›®çš„ã€‚ â€‹ è¿™é‡Œé¢å…¶å®åŒ…å«äº†5ä¸ªç‚¹ 1ï¼šé€»è¾‘å›å½’çš„å‡è®¾ï¼Œ2ï¼šé€»è¾‘å›å½’çš„æŸå¤±å‡½æ•°ï¼Œ3ï¼šé€»è¾‘å›å½’çš„æ±‚è§£æ–¹æ³•ï¼Œ4ï¼šé€»è¾‘å›å½’çš„ç›®çš„ï¼Œ5:é€»è¾‘å›å½’å¦‚ä½•åˆ†ç±»ã€‚è¿™äº›é—®é¢˜æ˜¯è€ƒæ ¸ä½ å¯¹é€»è¾‘å›å½’çš„åŸºæœ¬äº†è§£ã€‚ é€»è¾‘å›å½’çš„åŸºæœ¬å‡è®¾ ä»»ä½•çš„æ¨¡å‹éƒ½æ˜¯æœ‰è‡ªå·±çš„å‡è®¾ï¼Œåœ¨è¿™ä¸ªå‡è®¾ä¸‹æ¨¡å‹æ‰æ˜¯é€‚ç”¨çš„ã€‚é€»è¾‘å›å½’çš„ ç¬¬ä¸€ä¸ª åŸºæœ¬å‡è®¾æ˜¯ å‡è®¾æ•°æ®æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚ ä¼¯åŠªåˆ©åˆ†å¸ƒæœ‰ä¸€ä¸ªç®€å•çš„ä¾‹å­æ˜¯æŠ›ç¡¬å¸ï¼ŒæŠ›ä¸­ä¸ºæ­£é¢çš„æ¦‚ç‡æ˜¯p,æŠ›ä¸­ä¸ºè´Ÿé¢çš„æ¦‚ç‡æ˜¯ 1-p,åœ¨é€»è¾‘å›å½’è¿™ä¸ªæ¨¡å‹é‡Œé¢æ˜¯å‡è®¾ $h_Î¸(x)$ä¸ºæ ·æœ¬ä¸ºæ­£çš„æ¦‚ç‡ï¼Œ $1âˆ’h_Î¸(x)$ä¸ºæ ·æœ¬ä¸ºè´Ÿçš„æ¦‚ç‡ã€‚é‚£ä¹ˆæ•´ä¸ªæ¨¡å‹å¯ä»¥æè¿°ä¸º$h_Î¸(x;Î¸)=p$ é€»è¾‘å›å½’çš„ç¬¬äºŒä¸ªå‡è®¾æ˜¯å‡è®¾æ ·æœ¬ä¸ºæ­£çš„æ¦‚ç‡æ˜¯ $p=\frac{1}{1+e^{w^Tx}}$ æ‰€ä»¥é€»è¾‘å›å½’çš„æœ€ç»ˆå½¢å¼ $h_Î¸(x;Î¸)=\frac{1}{1+e^{w^Tx}}$ é€»è¾‘å›å½’çš„æŸå¤±å‡½æ•° é€»è¾‘å›å½’çš„æŸå¤±å‡½æ•°æ˜¯å®ƒçš„æå¤§ä¼¼ç„¶å‡½æ•° $LÎ¸(x)=\pi_{i=1}^{m}h_Î¸(xi;Î¸)^y_iâˆ—(1âˆ’h_Î¸(xi;Î¸))^{1âˆ’y_i}$ é€»è¾‘å›å½’çš„æ±‚è§£æ–¹æ³• ç”±äºè¯¥æå¤§ä¼¼ç„¶å‡½æ•°æ— æ³•ç›´æ¥æ±‚è§£ï¼Œæˆ‘ä»¬ä¸€èˆ¬é€šè¿‡å¯¹è¯¥å‡½æ•°è¿›è¡Œæ¢¯åº¦ä¸‹é™æ¥ä¸æ–­é€¼æ€¥æœ€ä¼˜è§£ã€‚åœ¨è¿™ä¸ªåœ°æ–¹å…¶å®ä¼šæœ‰ä¸ªåŠ åˆ†çš„é¡¹ï¼Œè€ƒå¯Ÿä½ å¯¹å…¶ä»–ä¼˜åŒ–æ–¹æ³•çš„äº†è§£ã€‚å› ä¸ºå°±æ¢¯åº¦ä¸‹é™æœ¬èº«æ¥çœ‹çš„è¯å°±æœ‰éšæœºæ¢¯åº¦ä¸‹é™ï¼Œæ‰¹æ¢¯åº¦ä¸‹é™ï¼Œsmall batch æ¢¯åº¦ä¸‹é™ä¸‰ç§æ–¹å¼ï¼Œé¢è¯•å®˜å¯èƒ½ä¼šé—®è¿™ä¸‰ç§æ–¹å¼çš„ä¼˜åŠ£ä»¥åŠå¦‚ä½•é€‰æ‹©æœ€åˆé€‚çš„æ¢¯åº¦ä¸‹é™æ–¹å¼ã€‚ ç®€å•æ¥è¯´ æ‰¹æ¢¯åº¦ä¸‹é™ä¼šè·å¾—å…¨å±€æœ€ä¼˜è§£ï¼Œç¼ºç‚¹æ˜¯åœ¨æ›´æ–°æ¯ä¸ªå‚æ•°çš„æ—¶å€™éœ€è¦éå†æ‰€æœ‰çš„æ•°æ®ï¼Œè®¡ç®—é‡ä¼šå¾ˆå¤§ï¼Œå¹¶ä¸”ä¼šæœ‰å¾ˆå¤šçš„å†—ä½™è®¡ç®—ï¼Œå¯¼è‡´çš„ç»“æœæ˜¯å½“æ•°æ®é‡å¤§çš„æ—¶å€™ï¼Œæ¯ä¸ªå‚æ•°çš„æ›´æ–°éƒ½ä¼šå¾ˆæ…¢ã€‚ éšæœºæ¢¯åº¦ä¸‹é™æ˜¯ä»¥é«˜æ–¹å·®é¢‘ç¹æ›´æ–°ï¼Œä¼˜ç‚¹æ˜¯ä½¿å¾—sgdä¼šè·³åˆ°æ–°çš„å’Œæ½œåœ¨æ›´å¥½çš„å±€éƒ¨æœ€ä¼˜è§£ï¼Œç¼ºç‚¹æ˜¯ä½¿å¾—æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£çš„è¿‡ç¨‹æ›´åŠ çš„å¤æ‚ã€‚ å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ç»“åˆäº†sgdå’Œbatch gdçš„ä¼˜ç‚¹ï¼Œæ¯æ¬¡æ›´æ–°çš„æ—¶å€™ä½¿ç”¨nä¸ªæ ·æœ¬ã€‚å‡å°‘äº†å‚æ•°æ›´æ–°çš„æ¬¡æ•°ï¼Œå¯ä»¥è¾¾åˆ°æ›´åŠ ç¨³å®šæ”¶æ•›ç»“æœï¼Œä¸€èˆ¬åœ¨æ·±åº¦å­¦ä¹ å½“ä¸­æˆ‘ä»¬é‡‡ç”¨è¿™ç§æ–¹æ³•ã€‚ å…¶å®è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªéšè—çš„æ›´åŠ æ·±çš„åŠ åˆ†é¡¹ï¼Œçœ‹ä½ äº†ä¸äº†è§£è¯¸å¦‚Adamï¼ŒåŠ¨é‡æ³•ç­‰ä¼˜åŒ–æ–¹æ³•ã€‚å› ä¸ºä¸Šè¿°æ–¹æ³•å…¶å®è¿˜æœ‰ä¸¤ä¸ªè‡´å‘½çš„é—®é¢˜ã€‚ ç¬¬ä¸€ä¸ªæ˜¯å¦‚ä½•å¯¹æ¨¡å‹é€‰æ‹©åˆé€‚çš„å­¦ä¹ ç‡ã€‚è‡ªå§‹è‡³ç»ˆä¿æŒåŒæ ·çš„å­¦ä¹ ç‡å…¶å®ä¸å¤ªåˆé€‚ã€‚å› ä¸ºä¸€å¼€å§‹å‚æ•°åˆšåˆšå¼€å§‹å­¦ä¹ çš„æ—¶å€™ï¼Œæ­¤æ—¶çš„å‚æ•°å’Œæœ€ä¼˜è§£éš”çš„æ¯”è¾ƒè¿œï¼Œéœ€è¦ä¿æŒä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ ç‡å°½å¿«é€¼è¿‘æœ€ä¼˜è§£ã€‚ä½†æ˜¯å­¦ä¹ åˆ°åé¢çš„æ—¶å€™ï¼Œå‚æ•°å’Œæœ€ä¼˜è§£å·²ç»éš”çš„æ¯”è¾ƒè¿‘äº†ï¼Œä½ è¿˜ä¿æŒæœ€åˆçš„å­¦ä¹ ç‡ï¼Œå®¹æ˜“è¶Šè¿‡æœ€ä¼˜ç‚¹ï¼Œåœ¨æœ€ä¼˜ç‚¹é™„è¿‘æ¥å›æŒ¯è¡ï¼Œé€šä¿—ä¸€ç‚¹è¯´ï¼Œå°±å¾ˆå®¹æ˜“å­¦è¿‡å¤´äº†ï¼Œè·‘åäº†ã€‚ ç¬¬äºŒä¸ªæ˜¯å¦‚ä½•å¯¹å‚æ•°é€‰æ‹©åˆé€‚çš„å­¦ä¹ ç‡ã€‚åœ¨å®è·µä¸­ï¼Œå¯¹æ¯ä¸ªå‚æ•°éƒ½ä¿æŒçš„åŒæ ·çš„å­¦ä¹ ç‡ä¹Ÿæ˜¯å¾ˆä¸åˆç†çš„ã€‚æœ‰äº›å‚æ•°æ›´æ–°é¢‘ç¹ï¼Œé‚£ä¹ˆå­¦ä¹ ç‡å¯ä»¥é€‚å½“å°ä¸€ç‚¹ã€‚æœ‰äº›å‚æ•°æ›´æ–°ç¼“æ…¢ï¼Œé‚£ä¹ˆå­¦ä¹ ç‡å°±åº”è¯¥å¤§ä¸€ç‚¹ã€‚è¿™é‡Œæˆ‘ä»¬ä¸å±•å¼€ï¼Œæœ‰ç©ºæˆ‘ä¼šä¸“é—¨å‡ºä¸€ä¸ªä¸“é¢˜ä»‹ç»ã€‚ é€»è¾‘å›å½’çš„ç›®çš„ è¯¥å‡½æ•°çš„ç›®çš„ä¾¿æ˜¯å°†æ•°æ®äºŒåˆ†ç±»ï¼Œæé«˜å‡†ç¡®ç‡ã€‚ é€»è¾‘å›å½’å¦‚ä½•åˆ†ç±» é€»è¾‘å›å½’ä½œä¸ºä¸€ä¸ªå›å½’(ä¹Ÿå°±æ˜¯yå€¼æ˜¯è¿ç»­çš„)ï¼Œå¦‚ä½•åº”ç”¨åˆ°åˆ†ç±»ä¸Šå»å‘¢ã€‚yå€¼ç¡®å®æ˜¯ä¸€ä¸ªè¿ç»­çš„å˜é‡ã€‚é€»è¾‘å›å½’çš„åšæ³•æ˜¯åˆ’å®šä¸€ä¸ªé˜ˆå€¼ï¼Œyå€¼å¤§äºè¿™ä¸ªé˜ˆå€¼çš„æ˜¯ä¸€ç±»ï¼Œyå€¼å°äºè¿™ä¸ªé˜ˆå€¼çš„æ˜¯å¦å¤–ä¸€ç±»ã€‚é˜ˆå€¼å…·ä½“å¦‚ä½•è°ƒæ•´æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©ã€‚ä¸€èˆ¬ä¼šé€‰æ‹©0.5åšä¸ºé˜ˆå€¼æ¥åˆ’åˆ†ã€‚ 3.å¯¹é€»è¾‘å›å½’çš„è¿›ä¸€æ­¥æé—®â€‹ é€»è¾‘å›å½’è™½ç„¶ä»å½¢å¼ä¸Šéå¸¸çš„ç®€å•ï¼Œä½†æ˜¯å…¶å†…æ¶µæ˜¯éå¸¸çš„ä¸°å¯Œã€‚æœ‰å¾ˆå¤šé—®é¢˜æ˜¯å¯ä»¥è¿›è¡Œæ€è€ƒçš„ é€»è¾‘å›å½’çš„æŸå¤±å‡½æ•°ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æå¤§ä¼¼ç„¶å‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Ÿ æŸå¤±å‡½æ•°ä¸€èˆ¬æœ‰å››ç§ï¼Œå¹³æ–¹æŸå¤±å‡½æ•°ï¼Œå¯¹æ•°æŸå¤±å‡½æ•°ï¼ŒHingeLoss0-1æŸå¤±å‡½æ•°ï¼Œç»å¯¹å€¼æŸå¤±å‡½æ•°ã€‚å°†æå¤§ä¼¼ç„¶å‡½æ•°å–å¯¹æ•°ä»¥åç­‰åŒäºå¯¹æ•°æŸå¤±å‡½æ•°ã€‚åœ¨é€»è¾‘å›å½’è¿™ä¸ªæ¨¡å‹ä¸‹ï¼Œå¯¹æ•°æŸå¤±å‡½æ•°çš„è®­ç»ƒæ±‚è§£å‚æ•°çš„é€Ÿåº¦æ˜¯æ¯”è¾ƒå¿«çš„ã€‚è‡³äºåŸå› å¤§å®¶å¯ä»¥æ±‚å‡ºè¿™ä¸ªå¼å­çš„æ¢¯åº¦æ›´æ–° $w_j=w_jâˆ’(y^iâˆ’h_w(x^i;w))âˆ—x_j^i\theta$ è¿™ä¸ªå¼å­çš„æ›´æ–°é€Ÿåº¦åªå’Œ$x_j,y_j ç›¸å…³ã€‚å’Œsigmodå‡½æ•°æœ¬èº«çš„æ¢¯åº¦æ˜¯æ— å…³çš„ã€‚è¿™æ ·æ›´æ–°çš„é€Ÿåº¦æ˜¯å¯ä»¥è‡ªå§‹è‡³ç»ˆéƒ½æ¯”è¾ƒçš„ç¨³å®šã€‚ ä¸ºä»€ä¹ˆä¸é€‰å¹³æ–¹æŸå¤±å‡½æ•°çš„å‘¢ï¼Ÿå…¶ä¸€æ˜¯å› ä¸ºå¦‚æœä½ ä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°ï¼Œä½ ä¼šå‘ç°æ¢¯åº¦æ›´æ–°çš„é€Ÿåº¦å’Œsigmodå‡½æ•°æœ¬èº«çš„æ¢¯åº¦æ˜¯å¾ˆç›¸å…³çš„ã€‚sigmodå‡½æ•°åœ¨å®ƒåœ¨å®šä¹‰åŸŸå†…çš„æ¢¯åº¦éƒ½ä¸å¤§äº0.25ã€‚è¿™æ ·è®­ç»ƒä¼šéå¸¸çš„æ…¢ã€‚ é€»è¾‘å›å½’åœ¨è®­ç»ƒçš„è¿‡ç¨‹å½“ä¸­ï¼Œå¦‚æœæœ‰å¾ˆå¤šçš„ç‰¹å¾é«˜åº¦ç›¸å…³æˆ–è€…è¯´æœ‰ä¸€ä¸ªç‰¹å¾é‡å¤äº†100éï¼Œä¼šé€ æˆæ€æ ·çš„å½±å“ï¼Ÿ å…ˆè¯´ç»“è®ºï¼Œå¦‚æœåœ¨æŸå¤±å‡½æ•°æœ€ç»ˆæ”¶æ•›çš„æƒ…å†µä¸‹ï¼Œå…¶å®å°±ç®—æœ‰å¾ˆå¤šç‰¹å¾é«˜åº¦ç›¸å…³ä¹Ÿä¸ä¼šå½±å“åˆ†ç±»å™¨çš„æ•ˆæœã€‚ ä½†æ˜¯å¯¹ç‰¹å¾æœ¬èº«æ¥è¯´çš„è¯ï¼Œå‡è®¾åªæœ‰ä¸€ä¸ªç‰¹å¾ï¼Œåœ¨ä¸è€ƒè™‘é‡‡æ ·çš„æƒ…å†µä¸‹ï¼Œä½ ç°åœ¨å°†å®ƒé‡å¤100éã€‚è®­ç»ƒä»¥åå®Œä»¥åï¼Œæ•°æ®è¿˜æ˜¯è¿™ä¹ˆå¤šï¼Œä½†æ˜¯è¿™ä¸ªç‰¹å¾æœ¬èº«é‡å¤äº†100éï¼Œå®è´¨ä¸Šå°†åŸæ¥çš„ç‰¹å¾åˆ†æˆäº†100ä»½ï¼Œæ¯ä¸€ä¸ªç‰¹å¾éƒ½æ˜¯åŸæ¥ç‰¹å¾æƒé‡å€¼çš„ç™¾åˆ†ä¹‹ä¸€ã€‚ å¦‚æœåœ¨éšæœºé‡‡æ ·çš„æƒ…å†µä¸‹ï¼Œå…¶å®è®­ç»ƒæ”¶æ•›å®Œä»¥åï¼Œè¿˜æ˜¯å¯ä»¥è®¤ä¸ºè¿™100ä¸ªç‰¹å¾å’ŒåŸæ¥é‚£ä¸€ä¸ªç‰¹å¾æ‰®æ¼”çš„æ•ˆæœä¸€æ ·ï¼Œåªæ˜¯å¯èƒ½ä¸­é—´å¾ˆå¤šç‰¹å¾çš„å€¼æ­£è´Ÿç›¸æ¶ˆäº†ã€‚ ä¸ºä»€ä¹ˆæˆ‘ä»¬è¿˜æ˜¯ä¼šåœ¨è®­ç»ƒçš„è¿‡ç¨‹å½“ä¸­å°†é«˜åº¦ç›¸å…³çš„ç‰¹å¾å»æ‰ï¼Ÿ å»æ‰é«˜åº¦ç›¸å…³çš„ç‰¹å¾ä¼šè®©æ¨¡å‹çš„å¯è§£é‡Šæ€§æ›´å¥½ å¯ä»¥å¤§å¤§æé«˜è®­ç»ƒçš„é€Ÿåº¦ã€‚å¦‚æœæ¨¡å‹å½“ä¸­æœ‰å¾ˆå¤šç‰¹å¾é«˜åº¦ç›¸å…³çš„è¯ï¼Œå°±ç®—æŸå¤±å‡½æ•°æœ¬èº«æ”¶æ•›äº†ï¼Œä½†å®é™…ä¸Šå‚æ•°æ˜¯æ²¡æœ‰æ”¶æ•›çš„ï¼Œè¿™æ ·ä¼šæ‹‰ä½è®­ç»ƒçš„é€Ÿåº¦ã€‚å…¶æ¬¡æ˜¯ç‰¹å¾å¤šäº†ï¼Œæœ¬èº«å°±ä¼šå¢å¤§è®­ç»ƒçš„æ—¶é—´ã€‚ 4.é€»è¾‘å›å½’çš„ä¼˜ç¼ºç‚¹æ€»ç»“â€‹ é¢è¯•çš„æ—¶å€™ï¼Œåˆ«äººä¹Ÿç»å¸¸ä¼šé—®åˆ°ï¼Œä½ åœ¨ä½¿ç”¨é€»è¾‘å›å½’çš„æ—¶å€™æœ‰å“ªäº›æ„Ÿå—ã€‚è§‰å¾—å®ƒæœ‰å“ªäº›ä¼˜ç¼ºç‚¹ã€‚ â€‹ åœ¨è¿™é‡Œæˆ‘ä»¬æ€»ç»“äº†é€»è¾‘å›å½’åº”ç”¨åˆ°å·¥ä¸šç•Œå½“ä¸­ä¸€äº›ä¼˜ç‚¹ï¼š å½¢å¼ç®€å•ï¼Œæ¨¡å‹çš„å¯è§£é‡Šæ€§éå¸¸å¥½ã€‚ä»ç‰¹å¾çš„æƒé‡å¯ä»¥çœ‹åˆ°ä¸åŒçš„ç‰¹å¾å¯¹æœ€åç»“æœçš„å½±å“ï¼ŒæŸä¸ªç‰¹å¾çš„æƒé‡å€¼æ¯”è¾ƒé«˜ï¼Œé‚£ä¹ˆè¿™ä¸ªç‰¹å¾æœ€åå¯¹ç»“æœçš„å½±å“ä¼šæ¯”è¾ƒå¤§ã€‚ æ¨¡å‹æ•ˆæœä¸é”™ã€‚åœ¨å·¥ç¨‹ä¸Šæ˜¯å¯ä»¥æ¥å—çš„ï¼ˆä½œä¸ºbaseline)ï¼Œå¦‚æœç‰¹å¾å·¥ç¨‹åšçš„å¥½ï¼Œæ•ˆæœä¸ä¼šå¤ªå·®ï¼Œå¹¶ä¸”ç‰¹å¾å·¥ç¨‹å¯ä»¥å¤§å®¶å¹¶è¡Œå¼€å‘ï¼Œå¤§å¤§åŠ å¿«å¼€å‘çš„é€Ÿåº¦ã€‚ è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ã€‚åˆ†ç±»çš„æ—¶å€™ï¼Œè®¡ç®—é‡ä»…ä»…åªå’Œç‰¹å¾çš„æ•°ç›®ç›¸å…³ã€‚å¹¶ä¸”é€»è¾‘å›å½’çš„åˆ†å¸ƒå¼ä¼˜åŒ–sgdå‘å±•æ¯”è¾ƒæˆç†Ÿï¼Œè®­ç»ƒçš„é€Ÿåº¦å¯ä»¥é€šè¿‡å †æœºå™¨è¿›ä¸€æ­¥æé«˜ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥åœ¨çŸ­æ—¶é—´å†…è¿­ä»£å¥½å‡ ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ã€‚ èµ„æºå ç”¨å°,å°¤å…¶æ˜¯å†…å­˜ã€‚å› ä¸ºåªéœ€è¦å­˜å‚¨å„ä¸ªç»´åº¦çš„ç‰¹å¾å€¼ï¼Œã€‚ æ–¹ä¾¿è¾“å‡ºç»“æœè°ƒæ•´ã€‚é€»è¾‘å›å½’å¯ä»¥å¾ˆæ–¹ä¾¿çš„å¾—åˆ°æœ€åçš„åˆ†ç±»ç»“æœï¼Œå› ä¸ºè¾“å‡ºçš„æ˜¯æ¯ä¸ªæ ·æœ¬çš„æ¦‚ç‡åˆ†æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“çš„å¯¹è¿™äº›æ¦‚ç‡åˆ†æ•°è¿›è¡Œcutoffï¼Œä¹Ÿå°±æ˜¯åˆ’åˆ†é˜ˆå€¼(å¤§äºæŸä¸ªé˜ˆå€¼çš„æ˜¯ä¸€ç±»ï¼Œå°äºæŸä¸ªé˜ˆå€¼çš„æ˜¯ä¸€ç±»)ã€‚ â€‹ ä½†æ˜¯é€»è¾‘å›å½’æœ¬èº«ä¹Ÿæœ‰è®¸å¤šçš„ç¼ºç‚¹: å‡†ç¡®ç‡å¹¶ä¸æ˜¯å¾ˆé«˜ã€‚å› ä¸ºå½¢å¼éå¸¸çš„ç®€å•(éå¸¸ç±»ä¼¼çº¿æ€§æ¨¡å‹)ï¼Œå¾ˆéš¾å»æ‹Ÿåˆæ•°æ®çš„çœŸå®åˆ†å¸ƒã€‚ å¾ˆéš¾å¤„ç†æ•°æ®ä¸å¹³è¡¡çš„é—®é¢˜ã€‚ä¸¾ä¸ªä¾‹å­ï¼šå¦‚æœæˆ‘ä»¬å¯¹äºä¸€ä¸ªæ­£è´Ÿæ ·æœ¬éå¸¸ä¸å¹³è¡¡çš„é—®é¢˜æ¯”å¦‚æ­£è´Ÿæ ·æœ¬æ¯” 10000:1.æˆ‘ä»¬æŠŠæ‰€æœ‰æ ·æœ¬éƒ½é¢„æµ‹ä¸ºæ­£ä¹Ÿèƒ½ä½¿æŸå¤±å‡½æ•°çš„å€¼æ¯”è¾ƒå°ã€‚ä½†æ˜¯ä½œä¸ºä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå®ƒå¯¹æ­£è´Ÿæ ·æœ¬çš„åŒºåˆ†èƒ½åŠ›ä¸ä¼šå¾ˆå¥½ã€‚ å¤„ç†éçº¿æ€§æ•°æ®è¾ƒéº»çƒ¦ã€‚é€»è¾‘å›å½’åœ¨ä¸å¼•å…¥å…¶ä»–æ–¹æ³•çš„æƒ…å†µä¸‹ï¼Œåªèƒ½å¤„ç†çº¿æ€§å¯åˆ†çš„æ•°æ®ï¼Œæˆ–è€…è¿›ä¸€æ­¥è¯´ï¼Œå¤„ç†äºŒåˆ†ç±»çš„é—®é¢˜ ã€‚ é€»è¾‘å›å½’æœ¬èº«æ— æ³•ç­›é€‰ç‰¹å¾ã€‚æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šç”¨gbdtæ¥ç­›é€‰ç‰¹å¾ï¼Œç„¶åå†ä¸Šé€»è¾‘å›å½’ã€‚ æ¨¡å‹ã€ç­–ç•¥ã€ç®—æ³•Codings]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F04%2F13%2Fmachine%20learning%2F</url>
    <content type="text"><![CDATA[è‹±ä¼Ÿè¾¾:èŠ¯ç‰‡ï¼ŒGPU å¼€å‘æ¡†æ¶ï¼štensorflowï¼Œpytorch caffe ç›‘ç£å­¦ä¹ å­¦ä¹ ç›®çš„æ˜¯å­¦ä¹ ä¸€ä¸ªè¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„ï¼Œç§°ä¸ºæ¨¡å‹ã€‚æ¨¡å‹çš„é›†åˆå°±æ˜¯å‡è®¾ç©ºé—´ã€‚ æ¨¡å‹ï¼šæ¦‚ç‡æ¨¡å‹ï¼›éæ¦‚ç‡æ¨¡å‹ï¼› å­¦ä¹ è¿‡ç¨‹ï¼šæœç´¢è¿‡ç¨‹]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow]]></title>
    <url>%2F2019%2F04%2F11%2Ftensorflow%2F</url>
    <content type="text"><![CDATA[official definition What is tensorflowflow of tensors â€œTensorFlow is an open source software library for numerical computation using dataflow graphs. Nodes in the graph represents mathematical operations, while graph edges represent multi-dimensional data arrays (aka tensors) communicated between them. The flexible architecture allows you to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.â€* A major difference between numpy and TensorFlow is that TensorFlow follows a lazy programming paradigm. It first builds a graph of all the operation to be done, and then when a â€œsessionâ€ is called, it â€œrunsâ€ the graph. Itâ€™s built to be scalable, by changing internal data representation to tensors (aka multi-dimensional arrays). Building a computational graph can be considered as the main ingredient of TensorFlow. Itâ€™s easy to classify TensorFlow as a neural network library, but itâ€™s not just that. Yes, it was designed to be a powerful neural network library. But it has the power to do much more than that. You can build other machine learning algorithms on it such as decision trees or k-Nearest Neighbors. You can literally do everything you normally would do in numpy! Itâ€™s aptly called â€œnumpy on steroidsâ€ The advantages of using TensorFlow are: It has an intuitive construct, because as the name suggests it has â€œflow of tensorsâ€. You can easily visualize each and every part of the graph. Easily train on cpu/gpu for distributed computing Platform flexibility. You can run the models wherever you want, whether it is on mobile, server or PC. scikit-learn 123456# define hyperparamters of ML algorithmclf = svm.SVC(gamma=0.001, C=100.)# train clf.fit(X, y)# test clf.predict(X_test) The usual workflow of running a program in TensorFlow is as follows: Build a computational graph, this can be any mathematical operation TensorFlow supports. Initialize variables, to compile the variables defined previously Create session(ä¼šè¯ï¼‰, this is where the magic starts! Run graph in session, the compiled graph is passed to the session, which starts its execution. Close session, shutdown the session. Lets write a small program to add two numbers! 12345678910111213141516171819# import tensorflowimport tensorflow as tf# build computational grapha = tf.placeholder(tf.int16)b = tf.placeholder(tf.int16)addition = tf.add(a, b)# initialize variablesinit = tf.initialize_all_variables()# create session and run the graphwith tf.Session() as sess: sess.run(init) print "Addition: %i" % sess.run(addition, feed_dict=&#123;a: 2, b: 3&#125;)# close sessionsess.close() A typical implementation of Neural Network would be as follows: Define Neural Network architecture to be compiled Transfer data to your model Under the hood, the data is first divided into batches, so that it can be ingested. The batches are first preprocessed, augmented and then fed into Neural Network for training The model then gets trained incrementally Display the accuracy for a specific number of timesteps After training save the model for future use Test the model on a new data and check how it performs ä¸‰ç±»éå¸¸é‡è¦çš„å˜é‡å ä½ç¬¦tensorFlowä¸­æ¥æ”¶å€¼çš„æ–¹å¼ä¸ºå ä½ç¬¦(placeholder)ï¼Œåˆ›å»ºplaceholder 123- # b = tf.placeholder(tf.float32, [None, 1], name='b')ç¬¬äºŒä¸ªå‚æ•°å€¼ä¸º[None, 1]ï¼Œå…¶ä¸­Noneè¡¨ç¤ºä¸ç¡®å®šï¼Œå³ä¸ç¡®å®šç¬¬ä¸€ä¸ªç»´åº¦çš„å¤§å°ï¼Œç¬¬ä¸€ç»´å¯ä»¥æ˜¯ä»»æ„å¤§å°ã€‚ç‰¹åˆ«å¯¹åº”tensoræ•°é‡(æˆ–è€…æ ·æœ¬æ•°é‡)ï¼Œè¾“å…¥çš„tensoræ•°ç›®å¯ä»¥æ˜¯32ã€64â€¦ placeholder: A way to feed data into the graphsfeed_dict: A dictionary to pass numeric values to computational graph å¸¸é‡tf.constant()`å®šä¹‰å¸¸é‡ 1const = tf.constant(2.0, name='const') å˜é‡ â€‹ ä½¿ç”¨tf.Variable()å®šä¹‰å˜é‡ 1c = tf.Variable(1.0, dtype=tf.float32, name='c') TensorFlowä¸­æ‰€æœ‰çš„å˜é‡å¿…é¡»ç»è¿‡åˆå§‹åŒ–æ‰èƒ½ä½¿ç”¨ï¼Œ**åˆå§‹åŒ–æ–¹å¼åˆ†ä¸¤æ­¥ï¼š å®šä¹‰åˆå§‹åŒ–operation 12# 1. å®šä¹‰init operationinit_op = tf.global_variables_initializer() è¿è¡Œåˆå§‹åŒ–operation 12# 2. è¿è¡Œinit operation sess.run(init_op) reference https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/ https://www.toptal.com/machine-learning/tensorflow-machine-learning-tutorial https://github.com/aymericdamien/TensorFlow-Examples video:https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/ course: https://classroom.udacity.com/courses/ud187 tensorflow: GOOGLE å¼€æºã€Deep learning ç»ƒæ•°æˆé‡‘C1 tensorboard ï¼ša tool;visual network;debug alter dir of jupyter é¡ºä¾¿æ”¹äº†ä¸‹æ–°ä¸‹è½½çš„è·¯å¾„ï¼ˆGOODï¼‰ CPU or GPU C2graphs ä»£è¡¨è®¡ç®—ä»»åŠ¡ï¼ŒèŠ‚ç‚¹ï¼ˆop)ï¼Œä¸€ä¸ªopå¯ä»¥è·å¾—oä¸ªæˆ–è€…å¤šä¸ªtensor,è¾“å‡º1ä¸ªæˆ–è€…å¤šä¸ªtensor Session(ä¼šè¯)çš„ä¸Šä¸‹æ–‡ï¼ˆcontext)ä¸­æ‰§è¡Œ tensorè¡¨ç¤ºæ•°æ®,nç»´æ•°ç»„ C3 ç®€å•çš„å›å½’ç¥ç»ç½‘ç»œï¼ˆæ‹ŸåˆäºŒæ¬¡å‡½æ•°ï¼‰ï¼Œè²Œä¼¼å­¦äº†ç†è®ºæ²¡æœ‰å®è·µï¼Œè¿˜çœŸæ˜¯å¿˜å¾—å¿«å•Š æ‰‹å†™ä½“åˆ†ç±»ã€Softmaxå‡½æ•° softmaxå‡½æ•°å¯ä»¥ç»™ä¸åŒçš„å¯¹è±¡åˆ†é…æ¦‚ç‡ï¼Œsoftmax($x_i$)=$\frac{exp(x_i)}{\sum_j{exp(x_j)}}$ å¦‚è¾“å‡º[1,2,5] ,$p1=\frac{exp(1)}{exp(1)+exp(2)+exp(5)}$,$p2=\frac{exp(2)}{exp(1)+exp(2)+exp(5)}$,$p1=\frac{exp(5)}{exp(1)+exp(2)+exp(5)}$ Keras å®‰è£… backend åŸºäºä»€ä¹ˆåšè¿ç®—ï¼ˆtensorflow or theano) import keras æŸ¥çœ‹ åº•å±‚æ­å»º aï¼‰ /.keras/keras.json ç›¸å…³çš„é…ç½®ä¿¡æ¯ b) ç»ˆç«¯æ”¹ï¼Œå•æ¬¡ import os os.environ[â€˜KERAS_BACKENDâ€™]= â€˜tensorflowâ€™ import keras For example model :Sequential layer : Dense activation è®­ç»ƒç®—æ³•ï¼šmodel.compile(å‚æ•°optimizer=â€™æ¢¯åº¦ä¸‹é™æ³•çš„å˜ç§â€™ , loss=â€™rms/â€˜) è®­ç»ƒï¼šmodel. fit (x,y) model.train_on_batch evaluate:model.evaluate prediction: model.predict(x_test, batch_size=128) https://github.com/MorvanZhou/tutorials/blob/master/kerasTUT/5-classifier_example.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 4 - Regressor exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.models import Sequential # æŒ‰é¡ºåºå»ºç«‹from keras.layers import Dense # å…¨è¿æ¥å±‚import matplotlib.pyplot as plt# create some dataX = np.linspace(-1, 1, 200)np.random.shuffle(X) # randomize the dataY = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))# plot dataplt.scatter(X, Y)plt.show()X_train, Y_train = X[:160], Y[:160] # first 160 data pointsX_test, Y_test = X[160:], Y[160:] # last 40 data points# build a neural network from the 1st layer to the last layermodel = Sequential()model.add(Dense(units=1, input_dim=1)) # choose loss function and optimizing methodmodel.compile(loss='mse', optimizer='sgd')# trainingprint('Training -----------')for step in range(301): cost = model.train_on_batch(X_train, Y_train) if step % 100 == 0: print('train cost: ', cost)# testprint('\nTesting ------------')cost = model.evaluate(X_test, Y_test, batch_size=40)print('test cost:', cost)W, b = model.layers[0].get_weights()print('Weights=', W, '\nbiases=', b)# plotting the predictionY_pred = model.predict(X_test)plt.scatter(X_test, Y_test)plt.plot(X_test, Y_pred)plt.show() 51234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: è«çƒ¦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 5 - Classifier exampleimport numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activationfrom keras.optimizers import RMSprop# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# X shape (60,000 28x28), y shape (10,000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(X_train.shape[0], -1) / 255. # normalizeX_test = X_test.reshape(X_test.shape[0], -1) / 255. # normalizey_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your neural netmodel = Sequential([ Dense(32, input_dim=784), Activation('relu'), Dense(10), Activation('softmax'),])# Another way to define your optimizerrmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)# We add metrics to get more results you want to seemodel.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=2, batch_size=32)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('test loss: ', loss)print('test accuracy: ', accuracy) 6 CNNå·ç§¯ç¥ç»ç½‘ç»œä¸æ˜¯å¯¹ https://www.cnblogs.com/skyfsm/p/6790245.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990"""To know more or get code samples, please visit my website:https://morvanzhou.github.io/tutorials/Or search: è«çƒ¦PythonThank you for supporting!"""# please note, all tutorial code are running under python3.5.# If you use the version like python2.7, please modify the code accordingly# 6 - CNN example# to try tensorflow, un-comment following two lines# import os# os.environ['KERAS_BACKEND']='tensorflow'import numpy as npnp.random.seed(1337) # for reproducibilityfrom keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.models import Sequentialfrom keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flattenfrom keras.optimizers import Adam# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )(X_train, y_train), (X_test, y_test) = mnist.load_data()# data pre-processingX_train = X_train.reshape(-1, 1,28, 28)/255.X_test = X_test.reshape(-1, 1,28, 28)/255.y_train = np_utils.to_categorical(y_train, num_classes=10)y_test = np_utils.to_categorical(y_test, num_classes=10)# Another way to build your CNNmodel = Sequential()# Conv layer 1 output shape (32, 28, 28)model.add(Convolution2D( batch_input_shape=(None, 1, 28, 28), filters=32, kernel_size=5, strides=1, padding='same', # Padding method data_format='channels_first',))model.add(Activation('relu'))# Pooling layer 1 (max pooling) output shape (32, 14, 14)model.add(MaxPooling2D( pool_size=2, strides=2, padding='same', # Padding method data_format='channels_first',))# Conv layer 2 output shape (64, 14, 14)model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))model.add(Activation('relu'))# Pooling layer 2 (max pooling) output shape (64, 7, 7)model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)model.add(Flatten())model.add(Dense(1024))model.add(Activation('relu'))# Fully connected layer 2 to shape (10) for 10 classesmodel.add(Dense(10))model.add(Activation('softmax'))# Another way to define your optimizeradam = Adam(lr=1e-4)# We add metrics to get more results you want to seemodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])print('Training ------------')# Another way to train the modelmodel.fit(X_train, y_train, epochs=1, batch_size=64,)print('\nTesting ------------')# Evaluate the model with the metrics we defined earlierloss, accuracy = model.evaluate(X_test, y_test)print('\ntest loss: ', loss)print('\ntest accuracy: ', accuracy)]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>tensorlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep Learning Neural Network and Deep Learning]]></title>
    <url>%2F2019%2F04%2F11%2FDeep%20Learning.ai_Neural%20Networks%20and%20Deep%20Learning%2F</url>
    <content type="text"><![CDATA[Course one : Neural Networks and Deep Learning(Course 1 of the Deep Learning Specialization)C1W1C1W1L01: WelcomeAI is the new Electricity! Course 1: Neural Networks and Deep Learning Course 2: Improving Deep Neural Networks: Hyperparameter tuning,Regularization and Optimization Course 3: Structuring your Machine Learning project Course 4: Convolutional Neural Networks Course 5: Natural Langurge Processing: Building sequence models C1W1L02 : What is Neural NetworkDeep Learning = training (very large) neural network For example of house prize prediction : the simplest neural networkå¦‚æœç°åœ¨æœ‰å…­æ ‹æˆ¿å­çš„ä¿¡æ¯ï¼Œåˆ†åˆ«æ˜¯æˆ¿å­çš„å¤§å°(size of house)å’Œå¯¹åº”çš„ä»·æ ¼(prize),ç»˜åˆ¶å‡ºå¦‚ä¸‹çš„ã€‚è‡ªç„¶çš„æƒ³æ³•ï¼šçº¿æ€§å›å½’ï¼Œå¾—åˆ°æ‹Ÿåˆçš„ç›´çº¿ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ¿ä»·ä¸å¯èƒ½æ˜¯è´Ÿæ•°å§ï¼å› æ­¤ä¸‹å›¾ä¸­è“è‰²çš„çº¿ï¼Œå¤§è‡´å°±æ˜¯æˆ‘ä»¬æ‰€éœ€è¦çš„å‡½æ•°ã€‚è¿™ä¸ªå¯¹åº”ä¸€ä¸ªæœ€ç®€å•ç¥ç»ç½‘ç»œï¼ˆneural networkï¼‰ ä¸Šè¿°æ˜¯ä¸€ä¸ªtiny little neural networkï¼Œæ›´å¤§çš„ï¼Œæ›´å¤æ‚çš„ç¥ç»ç½‘ç»œæ˜¯ æŠŠå¾ˆå¤šæœ€ç®€å•çš„single neuralå †ç§¯(stacking)åˆ°ä¸€èµ·ã€‚ For example of house prize prediction : stacking the neuralä¸Šé¢è¿™ä¸ªä¾‹å­ï¼Œä»…ä»…è€ƒè™‘ç‰¹å¾æ˜¯size,å®é™…æƒ…å†µä¸Šï¼Œä¸æˆ¿å±‹ç›¸å…³çš„ç‰¹å¾è¿˜æœ‰number of bedroomsã€zip codeã€wealth, number of bedrooms and size affect family size. The zip code is a feature that tells you you know walkability. The wealth tells you how good is the school quality hidden layer ç”¨è¾“å…¥å±‚è®¡ç®—å¾—åˆ°ï¼Œå› æ­¤è¯´è¾“å…¥å±‚ä¸ä¸­é—´å±‚ç´§å¯†è¿æ¥èµ·æ¥äº† The actual application of neural networkshidden layer ä¸ä¸Šä¸€å±‚çš„è¿æ¥æƒ…å†µå¹¶ä¸æ˜¯æ‰‹å·¥ç¡®å®šï¼Œæ¯ä¸€å±‚éƒ½æ˜¯ä¸Šä¸€å±‚æ‰€æœ‰çš„è¾“å…¥å‡½æ•°ï¼Œæ‰€ä»¥å»ºç«‹çš„ç¥ç»ç½‘ç»œå¦‚ä¸‹ï¼š The remarkable thing about neural network Given enough data about X&amp;Y (x,y) which good at freaking out functions :map x to y Most powerful in supervised learning C2W1CL03 : Supervised Learning with Neural Networkå¸¸è§çš„ç›‘ç£å­¦ä¹ æˆªæ­¢åˆ°ç›®å‰ï¼ŒNeural Networkçš„æˆåŠŸåº”ç”¨åŸºæœ¬éƒ½åœ¨Supervised Learningã€‚æ¯”å¦‚ï¼šAdï¼ŒImages vision, Audio to Text, Machine translation, Autonomous Driving å¸¸è§çš„ç¥ç»ç½‘ç»œçš„è®¾è®¡ å·ç§¯ç¥ç»ç½‘ç»œï¼šConvolutional Neural Network (CNN) é€šå¸¸æœ‰ç”¨å›¾åƒæ•°æ® é€’å½’ç¥ç»ç½‘ç»œï¼š Recurrent Neural Network (RNN) é€šå¸¸ç”¨äºtime series å¯¹åº”å¤æ‚çš„åº”ç”¨ä¸­ï¼Œå®šåˆ¶ä¸€äº›å¤æ‚çš„æ··åˆçš„ç¥ç»ç½‘ç»œç»“æ„ ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ® å¤„ç†éç»“æ„åŒ–æ•°æ®æ˜¯å¾ˆéš¾çš„ï¼Œä¸ç»“æ„åŒ–æ•°æ®æ¯”è¾ƒï¼Œè®©è®¡ç®—æœºç†è§£éç»“æ„åŒ–æ•°æ®å¾ˆéš¾ C1W1L04: Why is deep learning taking offAnswer: scale If you want to hit this very high level of performance ,firstly, you need to be able train a big enough neural network in order to take advantage of the huge amount of data and second you need to be out here on the x axes you do need a lot of data. If you do not have a lot training data is often up to your skill at hand engineering features that determines the foreman.åœ¨è¿™ä¸ªå°çš„è®­ç»ƒé›†ä¸­ï¼Œå„ç§ç®—æ³•çš„ä¼˜å…ˆçº§äº‹å®ä¸Šå®šä¹‰çš„ä¹Ÿä¸æ˜¯å¾ˆæ˜ç¡®ï¼Œæ‰€ä»¥å¦‚æœä½ æ²¡æœ‰å¤§é‡çš„è®­ç»ƒé›†ï¼Œé‚£æ•ˆæœä¼šå–å†³äºä½ çš„ç‰¹å¾å·¥ç¨‹èƒ½åŠ›ï¼Œé‚£å°†å†³å®šæœ€ç»ˆçš„æ€§èƒ½ã€‚ è¿™ä¸ªå›¾å½¢åŒºåŸŸçš„å·¦è¾¹ï¼Œå„ç§ç®—æ³•ä¹‹é—´çš„ä¼˜å…ˆçº§å¹¶ä¸æ˜¯å®šä¹‰çš„å¾ˆæ˜ç¡®ï¼Œæœ€ç»ˆçš„æ€§èƒ½æ›´å¤šçš„æ˜¯å–å†³äºä½ åœ¨ç”¨å·¥ç¨‹é€‰æ‹©ç‰¹å¾æ–¹é¢çš„èƒ½åŠ›ä»¥åŠç®—æ³•å¤„ç†æ–¹é¢çš„ä¸€äº›ç»†èŠ‚. åªæ˜¯åœ¨æŸäº›å¤§æ•°æ®è§„æ¨¡éå¸¸åºå¤§çš„è®­ç»ƒé›†ï¼Œä¹Ÿå°±æ˜¯åœ¨å³è¾¹è¿™ä¸ªä¼šéå¸¸çš„å¤§æ—¶ï¼Œæˆ‘ä»¬èƒ½æ›´åŠ æŒç»­åœ°çœ‹åˆ°æ›´å¤§çš„ç”±ç¥ç»ç½‘ç»œæ§åˆ¶å…¶å®ƒæ–¹æ³•. The Reason the scale of data the speed of computation such as GPUS innovation of algorithm è®¸å¤šç®—æ³•æ–¹é¢çš„åˆ›æ–°ï¼Œä¸€ç›´æ˜¯åœ¨å°è¯•ç€ä½¿å¾—ç¥ç»ç½‘ç»œè¿è¡Œçš„æ›´å¿« switch sigmoid function to relu function åœ¨è¿™ä¸ªåŒºåŸŸï¼Œä¹Ÿå°±æ˜¯è¿™ä¸ªsigmoidå‡½æ•°çš„æ¢¯åº¦ä¼šæ¥è¿‘é›¶ï¼Œæ‰€ä»¥å­¦ä¹ çš„é€Ÿåº¦ä¼šå˜å¾—éå¸¸ç¼“æ…¢ï¼Œå› ä¸ºå½“ä½ å®ç°æ¢¯åº¦ä¸‹é™ä»¥åŠæ¢¯åº¦æ¥è¿‘é›¶çš„æ—¶å€™ï¼Œå‚æ•°ä¼šæ›´æ–°çš„å¾ˆæ…¢ï¼Œæ‰€ä»¥å­¦ä¹ çš„é€Ÿç‡ä¹Ÿä¼šå˜çš„å¾ˆæ…¢ï¼Œè€Œé€šè¿‡æ”¹å˜è¿™ä¸ªè¢«å«åšæ¿€æ´»å‡½æ•°çš„ä¸œè¥¿ï¼Œç¥ç»ç½‘ç»œæ¢ç”¨è¿™ä¸€ä¸ªå‡½æ•°ï¼Œå«åšReLUçš„å‡½æ•°ï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰ï¼ŒReLUå®ƒçš„æ¢¯åº¦å¯¹äºæ‰€æœ‰è¾“å…¥çš„è´Ÿå€¼éƒ½æ˜¯é›¶ï¼Œå› æ­¤æ¢¯åº¦æ›´åŠ ä¸ä¼šè¶‹å‘é€æ¸å‡å°‘åˆ°é›¶ã€‚ è®­ç»ƒä½ çš„ç¥ç»ç½‘ç»œçš„è¿‡ç¨‹ï¼Œå¾ˆå¤šæ—¶å€™æ˜¯å‡­å€Ÿç›´è§‰çš„ï¼Œå¾€å¾€ä½ å¯¹ç¥ç»ç½‘ç»œæ¶æ„æœ‰äº†ä¸€ä¸ªæƒ³æ³•ï¼Œäºæ˜¯ä½ å°è¯•å†™ä»£ç å®ç°ä½ çš„æƒ³æ³•ï¼Œç„¶åè®©ä½ è¿è¡Œä¸€ä¸ªè¯•éªŒç¯å¢ƒæ¥å‘Šè¯‰ä½ ï¼Œä½ çš„ç¥ç»ç½‘ç»œæ•ˆæœæœ‰å¤šå¥½ï¼Œé€šè¿‡å‚è€ƒè¿™ä¸ªç»“æœå†è¿”å›å»ä¿®æ”¹ä½ çš„ç¥ç»ç½‘ç»œé‡Œé¢çš„ä¸€äº›ç»†èŠ‚ï¼Œç„¶åä½ ä¸æ–­çš„é‡å¤ä¸Šé¢çš„æ“ä½œï¼Œå½“ä½ çš„ç¥ç»ç½‘ç»œéœ€è¦å¾ˆé•¿æ—¶é—´å»è®­ç»ƒï¼Œéœ€è¦å¾ˆé•¿æ—¶é—´é‡å¤è¿™ä¸€å¾ªç¯ï¼Œåœ¨è¿™é‡Œå°±æœ‰å¾ˆå¤§çš„åŒºåˆ«ï¼Œæ ¹æ®ä½ çš„ç”Ÿäº§æ•ˆç‡å»æ„å»ºæ›´é«˜æ•ˆçš„ç¥ç»ç½‘ç»œã€‚å½“ä½ èƒ½å¤Ÿæœ‰ä¸€ä¸ªæƒ³æ³•ï¼Œè¯•ä¸€è¯•ï¼Œçœ‹æ•ˆæœå¦‚ä½•ã€‚åœ¨10åˆ†é’Ÿå†…ï¼Œæˆ–è€…ä¹Ÿè®¸è¦èŠ±ä¸Šä¸€æ•´å¤©ï¼Œå¦‚æœä½ è®­ç»ƒä½ çš„ç¥ç»ç½‘ç»œç”¨äº†ä¸€ä¸ªæœˆçš„æ—¶é—´ï¼Œæœ‰æ—¶å€™å‘ç”Ÿè¿™æ ·çš„äº‹æƒ…ï¼Œä¹Ÿæ˜¯å€¼å¾—çš„ï¼Œå› ä¸ºä½ å¾ˆå¿«å¾—åˆ°äº†ä¸€ä¸ªç»“æœã€‚åœ¨10åˆ†é’Ÿå†…æˆ–è€…ä¸€å¤©å†…ï¼Œä½ åº”è¯¥å°è¯•æ›´å¤šçš„æƒ³æ³•ï¼Œé‚£ææœ‰å¯èƒ½ä½¿å¾—ä½ çš„ç¥ç»ç½‘ç»œåœ¨ä½ çš„åº”ç”¨æ–¹é¢å·¥ä½œçš„æ›´å¥½ã€æ›´å¿«çš„è®¡ç®—ï¼Œåœ¨æé«˜é€Ÿåº¦æ–¹é¢çœŸçš„æœ‰å¸®åŠ©ï¼Œé‚£æ ·ä½ å°±èƒ½æ›´å¿«åœ°å¾—åˆ°ä½ çš„å®éªŒç»“æœã€‚ Summaryæ—©ä¸ŠèŠ±äº†2hå°æ—¶å­¦ä¹ ç¬¬ä¸€å‘¨çš„è§†é¢‘ï¼Œå…ˆçœ‹ä¸€éè§†é¢‘çš„å­—å¹•ï¼Œé€å­—é€å¥çš„ç†è§£ï¼Œè™½ç„¶å¾ˆå¤šæ—¶å€™éƒ½æ˜¯è‡ªå·±ä¹±çŒœçš„ï¼Œå¤§æ¦‚æ¸…æ¥šè®²çš„ä»€ä¹ˆï¼ç„¶åå†çœ‹å¤§ç‰›çš„ç¬”è®°ï¼Œç„¶åå†çœ‹ä¸€ç¯‡ç»“åˆPPTã€‚ä¸‹åˆä¹Ÿçœ‹äº†åŠä¸ªå¤šå°æ—¶ã€‚é—®é¢˜ï¼š1. è‡ªå·±çš„è‹±æ–‡æ°´å¹³ä¸å¤Ÿï¼Œè¿™ä¸ªéœ€è¦å¤§å¤§çš„æé«˜è®·ã€‚2. å…¶å®åªè¦çœ‹åˆ«äººçš„ç¬”è®°å°±å¯ä»¥çŸ¥é“å†…å®¹ï¼Œä½†æ˜¯è¿˜æ˜¯æƒ³å¬andow ngçš„è®²è§£ã€‚3. è§†é¢‘éƒ½æ¯”è¾ƒçŸ­ï¼Œæ¯ä¸ªè§†é¢‘è®¾è®¡çš„çŸ¥è¯†ç‚¹æˆ–è€…å†…å®¹ä¸å¤šï¼Œ1åˆ°3ä¸ªï¼Œåˆ†æˆçŸ¥è¯†ç‚¹åšç¬”è®°è¿˜æ˜¯ä¸é”™çš„ è¿™ä¸€å‘¨çš„å†…å®¹ï¼Œä¹Ÿå°±æ˜¯ä»Šå¤©æˆ‘å­¦ä¹ çš„çŸ¥è¯†ç®€å•å’Œå®¹æ˜“ç†è§£ã€‚å­¦ä¹ äº†ç¥ç»ç½‘ç»œçš„å¤§è‡´ç»“æ„ï¼Œç¥ç»ç½‘ç»œçš„åº”ç”¨é¢†åŸŸï¼Œæ·±åº¦å­¦ä¹ ä¸ºä»€ä¹ˆå–å¾—å¿«é€Ÿçš„å‘å±•çš„ä¸‰ç‚¹åŸå› ï¼Œå°¤å…¶æ˜¯æ•°æ®scaleä¸å…¶ä»–æ–¹æ³•å’Œç¥ç»ç½‘ç»œè§„æ¨¡çš„å¤§è‡´æ€§èƒ½å…³ç³» C1W2C1W2L01: Binary ClassificationIn this week, weâ€™re going to go over the basics of neural network programming. We are going to study handle data without for loop. forward password for propagation backward pass or whatâ€™s called a backward propagation step Why the computations in learning in a neural network can be organized in this board propagation and a separate backward propagation by using logistic regression to convey(ä¼ è¾¾) theses ideas. Binary ClassificationInputï¼› an image . three separate matrices corresponding red green and blue color channels of this image. å¦‚æœä½ çš„å›¾ç‰‡å¤§å°ä¸º64x64åƒç´ ï¼Œé‚£ä¹ˆä½ å°±æœ‰ä¸‰ä¸ªè§„æ¨¡ä¸º64x64çš„çŸ©é˜µï¼Œåˆ†åˆ«å¯¹åº”å›¾ç‰‡ä¸­çº¢ã€ç»¿ã€è“ä¸‰ç§åƒç´ çš„å¼ºåº¦å€¼ unroll all of these pixel intensity values into a feature vector pixel intensity values of this image notation (x,y)ï¼š a pair X comma Y $M_{train}$: M subscript train æ¯æ¡æµ‹è¯•é›†åœ¨çŸ©é˜µä¸­éƒ½æ˜¯ä»¥åˆ—å‘é‡çš„å½¢å¼å­˜åœ¨ Matrix capital Model : hypothesis Function :Logistic RegressionSo given an input X and the parameters W and b, how do we generate the output Y hat? Well, one thing you could try, that doesnâ€™t work, would be to have Y hat be w transpose X plus B, kind of a linear function of the input X. And in fact, this is what you use if you were doing linear regression. But this isnâ€™t a very good algorithm for binary classification because you want Y hat to be the chance that Y is equal to one. So,Y hat should really be between zero and one. This is what the sigmoid function looks like. sigmoid function \sigma(z) = \frac{1}{1+e^{-z}}å› ä¸ºä½ æƒ³è®©$\hat{y}$è¡¨ç¤ºå®é™…å€¼$y$ç­‰äº1çš„æœºç‡çš„è¯ï¼Œ åº”è¯¥åœ¨0åˆ°1ä¹‹é—´ã€‚è¿™æ˜¯ä¸€ä¸ªéœ€è¦è§£å†³çš„é—®é¢˜ï¼Œå› ä¸ºå¯èƒ½æ¯”1è¦å¤§å¾—å¤šï¼Œæˆ–è€…ç”šè‡³ä¸ºä¸€ä¸ªè´Ÿå€¼ã€‚å¯¹äºä½ æƒ³è¦çš„åœ¨0å’Œ1ä¹‹é—´çš„æ¦‚ç‡æ¥è¯´å®ƒæ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œå› æ­¤åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæˆ‘ä»¬çš„è¾“å‡ºåº”è¯¥æ˜¯ç­‰äºç”±ä¸Šé¢å¾—åˆ°çš„çº¿æ€§å‡½æ•°å¼å­ä½œä¸ºè‡ªå˜é‡çš„sigmoidå‡½æ•°ä¸­ï¼Œå…¬å¼å¦‚ä¸Šå›¾æœ€ä¸‹é¢æ‰€ç¤ºï¼Œå°†çº¿æ€§å‡½æ•°è½¬æ¢ä¸ºéçº¿æ€§å‡½æ•°ã€‚ æ³¨æ„ï¼šåŸæ¥$w,b$æ˜¯åˆ†å¼€åœ¨ï¼Œè¿™é‡Œå°±åˆå¹¶ï¼Œå¼•å…¥å˜é‡$x_0=1$,å¯¹åº”åç½®$b$, Strategyï¼šCost functionFirstly : Loss function L(\hat{y},y)=\frac{1}{2}\sum{(y_i-\hat{y_i})^2}è¿™ä¸ªä¼˜åŒ–é—®é¢˜ä¸æ˜¯å‡¸ä¼˜åŒ–é—®é¢˜(non-convex)ï¼Œå› æ­¤ä¸é€‰ç”¨è¿™ä¸ª Secondlyï¼Œ L(y,\hat{y})=-(ylog^{\hat{y}}+(1-y)log^{1-\hat{y}}) Algorithm: Gradient Descent Gradient Descentç®—æ³•æ­¥éª¤ï¼š Initialize $w$, $b$ to zero repeatï¼š $w :=wâˆ’\alpha \frac{âˆ‚J(w,b)}{âˆ‚w}$ $b :=b-\alpha \frac{âˆ‚J(w,b)}{âˆ‚b}$ C1W2L05 &amp; C1W2L06 Derivativesæ±‚å¯¼ï¼Œè¿™ä¸ªæ˜¯å¾®ç§¯åˆ†çš„å†…å®¹ï¼Œä¸ç”¨å†™äº†ï¼ C1W2L07ï¼š Computation GraphC1W2L08 : Derivatives with compution graphsé“¾å¼æ³•åˆ™ \frac{\partial L}{\partial v}=\frac{\partial L}{\partial u}\frac{\partial u}{\partial v}C1W2L09 : Logistic Regression Gradient Descentsingle training exampleYouâ€™ve seen the loss function that measures how well youâ€™re doing on the single training example. Youâ€™ve also seen the cost function that measures how well your parameters w and b are doing on your entire training set. Youâ€™ve heard me say that the computations of a neural network are organized in terms of a forward pass or a forward propagation step, in which we compute the output of the neural network, followed by a backward pass or back propagation step, which we use to compute gradients or compute derivatives. \frac{\partial L}{\partial w}=\frac{\partial L}{\partial \alpha }\frac{\partial \alpha }{\partial z}\frac{\partial z}{\partial w} \\=-(\frac{y}{a}+\frac{1-y}{1-a})a(1-a)x=(a-y)xC1W2L10 Gradient Descent on m example \min L(w,b)=\sum_{i=1}^{m}L(\alpha_i,y_i)/m\\ \frac{\partial L }{\partial w}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial w})/m=(\sum_{i=1}^{m}(a-y_i)x_i)/m\\ \frac{\partial L }{\partial b}=(\sum_{i=1}^{m}\frac{\partial L(a_i,y_i)}{\partial b})/m=(\sum_{i=1}^{m}(a-1)x_i)/m ä¸Šé¢çš„ä¼ªä»£ç å‘Šè¯‰æˆ‘ä»¬ï¼Œéœ€è¦å¤šæ¬¡for loopå®Œæˆä»£ç ï¼Œä½†æ˜¯è¿™ä¼šé€ æˆè¿ç®—é€Ÿåº¦ä¸‹é™ï¼å› ä¸ºæˆ‘ä»¬è¶Šæ¥è¶Šå¤šåœ°è®­ç»ƒéå¸¸å¤§çš„æ•°æ®é›†ï¼Œå› æ­¤ä½ çœŸçš„éœ€è¦ä½ çš„ä»£ç å˜å¾—éå¸¸é«˜æ•ˆã€‚æ‰€ä»¥åœ¨æ¥ä¸‹æ¥çš„å‡ ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬ä¼šè°ˆåˆ°å‘é‡åŒ–ï¼Œä»¥åŠå¦‚ä½•åº”ç”¨å‘é‡åŒ–è€Œè¿ä¸€ä¸ªforå¾ªç¯éƒ½ä¸ä½¿ç”¨ã€‚æ‰€ä»¥å­¦ä¹ äº†è¿™äº›ï¼Œæˆ‘å¸Œæœ›ä½ æœ‰å…³äºå¦‚ä½•åº”ç”¨é€»è¾‘å›å½’ï¼Œæˆ–æ˜¯ç”¨äºé€»è¾‘å›å½’çš„æ¢¯åº¦ä¸‹é™ï¼Œäº‹æƒ…ä¼šå˜å¾—æ›´åŠ æ¸…æ™° summaryä»Šå¤©ä¸»è¦å­¦ä¹ äº†ä»¥logistics regression ä¸ºä¾‹ï¼Œå¦‚ä½•é€šè¿‡é“¾å¼æ±‚å¯¼çš„è¿‡ç¨‹ï¼Œç®€å•çš„ç»ƒä¹ ä¸€ä¸‹ï¼Œä»¥åŠå†æ¬¡äº†è§£ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™æ³•ï¼Œä»¥åŠè®­ç»ƒå­¦ä¹ ç®—æ³•çš„éœ€è¦ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œè®­ç»ƒçš„è¿‡ç¨‹å°±æ˜¯æ±‚æŸå¤±å‡½æ•°æœ€ä¼˜å€¼çš„è¿‡ç¨‹ C1W2L11: Vectorization1. ä»€ä¹ˆæ˜¯Vectorizationï¼šå°† for loop å°½å¯èƒ½è½¬æ¢ä¸ºçŸ©é˜µè¿ç®—é€šè¿‡numpyå†…ç½®å‡½æ•°å’Œé¿å¼€æ˜¾å¼çš„å¾ªç¯(loop)çš„æ–¹å¼è¿›è¡Œå‘é‡åŒ–ï¼Œä»è€Œæœ‰æ•ˆæé«˜ä»£ç é€Ÿåº¦ã€‚ 123np.dot(a,b)å¦‚æœa,bæ˜¯ä¸€ç»´æ•°ç»„ï¼Œåˆ™è®¡ç®—ç‚¹ç§¯å¦‚æœa,bæ˜¯å¤šç»´æ•°æ®ï¼Œåˆ™çŸ©é˜µä¹˜æ³• 2. An example of vectorizationvectorizationçš„å¥½å¤„ï¼šconciser code, but faster execution ä¸€ä¸ªç®€å•çš„å¯¹æ¯”å®éªŒï¼š1,000,000å¤§å°çš„ä¸¤ä¸ªå‘é‡å†…ç§¯è®¡ç®—ï¼Œfor loopè¦æ¯”Vectorizationå¿«300å€ã€‚ åœ¨Deep Learningæ—¶ä»£ï¼Œvectorizationæ˜¯ä¸€é¡¹é‡è¦çš„æŠ€èƒ½ã€‚ 123456789101112131415161718192021import numpy as np #å¯¼å…¥numpyåº“a = np.array([1,2,3,4]) #åˆ›å»ºä¸€ä¸ªæ•°æ®aprint(a)# [1 2 3 4]import time #å¯¼å…¥æ—¶é—´åº“a = np.random.rand(1000000)b = np.random.rand(1000000) #é€šè¿‡roundéšæœºå¾—åˆ°ä¸¤ä¸ªä¸€ç™¾ä¸‡ç»´åº¦çš„æ•°ç»„tic = time.time() #ç°åœ¨æµ‹é‡ä¸€ä¸‹å½“å‰æ—¶é—´#å‘é‡åŒ–çš„ç‰ˆæœ¬c = np.dot(a,b)toc = time.time()print(â€œVectorized version:â€ + str(1000*(toc-tic)) +â€msâ€) #æ‰“å°ä¸€ä¸‹å‘é‡åŒ–çš„ç‰ˆæœ¬çš„æ—¶é—´â€‹#ç»§ç»­å¢åŠ éå‘é‡åŒ–çš„ç‰ˆæœ¬c = 0tic = time.time()for i in range(1000000): c += a[i]*b[i]toc = time.time()print(c)print(â€œFor loop:â€ + str(1000*(toc-tic)) + â€œmsâ€)#æ‰“å°forå¾ªç¯çš„ç‰ˆæœ¬çš„æ—¶é—´ 3. GPU or CPU å¤§è§„æ¨¡çš„æ·±åº¦å­¦ä¹ å†GPUæˆ–è€…å›¾åƒå¤„ç†å•å…ƒè¿è¡Œâ€ï¼ŒCPUå’ŒGPUéƒ½æœ‰å¹¶è¡ŒåŒ–çš„æŒ‡ä»¤ï¼Œä»–ä»¬æœ‰æ—¶å€™ä¼šå«åšSIMDæŒ‡ä»¤ï¼Œè¿™ä¸ªä»£è¡¨äº†ä¸€ä¸ªå•ç‹¬æŒ‡ä»¤å¤šç»´æ•°æ®ï¼Œè¿™ä¸ªçš„åŸºç¡€æ„ä¹‰æ˜¯ï¼Œå¦‚æœä½ ä½¿ç”¨äº†built-inå‡½æ•°,åƒnp.functionæˆ–è€…å¹¶ä¸è¦æ±‚ä½ å®ç°å¾ªç¯çš„å‡½æ•°ï¼Œå®ƒå¯ä»¥è®©pythonçš„å……åˆ†åˆ©ç”¨å¹¶è¡ŒåŒ–è®¡ç®—ã€‚ åªæ˜¯åœ¨GPUå’ŒCPUä¸Šé¢è®¡ç®—ï¼ŒGPUæ›´åŠ æ“…é•¿SIMDè®¡ç®—ï¼Œä½†æ˜¯CPUäº‹å®ä¸Šä¹Ÿä¸æ˜¯å¤ªå·®ï¼Œå¯èƒ½æ²¡æœ‰GPUé‚£ä¹ˆæ“…é•¿å§ã€‚SIMD Both CPU and GPU have parallelization instructions(i.e. SIMD, Signle Instruction Multiple Data) C12L12 ï¼š More Vectorization ExampleçŸ©é˜µå’Œå‘é‡ä¹˜æ³• å‘é‡å‡½æ•° åŸåˆ™ï¼šwhenever possible, avoid explict for-loops ä½¿ç”¨Element wisedçš„çŸ©é˜µè¿ç®—ï¼Œå°†å‡½æ•°ä½œç”¨åœ¨æ¯ä¸ªçŸ©é˜µå…ƒç´ ä¸Šï¼Œæ¯”å¦‚ï¼š np.exp() np.log() np.abs() np.maxium() 1/v v**2 C1W2L13: Vectorizing Logistic Regression1. å‰å‘ä¼ æ’­ \hat{y}=Ïƒ(w^TX+b)=(a(1),a(2),...,a(mâˆ’1),a(m))=\\ (\alpha(z_1),\alpha(z_m),...,\alpha(z_m))=\\ (\alpha(w^Tx_1+b),\alpha(w^Tx_2+b),...,\alpha(w^Tx_m+b))=1234import numpy as npz=np.dot(W^T,X)+b# zè¿™é‡Œå°±æ˜¯python å·§å¦™çš„åœ°æ–¹ï¼Œbæ˜¯å®æ•°ï¼Œä½†æ˜¯å‘é‡åŠ ä¸Šå®æ•°åï¼Œbæ‰©å±•æˆå‘é‡ï¼Œè¢«ç§°ä¸ºå¹¿æ’­ï¼ˆbrosdcastingï¼‰ ä¸ªäººç»éªŒï¼š é¦–å…ˆï¼Œç†Ÿæ‚‰æ¯ä¸ªå˜é‡çš„è®°å·å’Œç»´åº¦ï¼Œå¿…è¦çš„è¯ï¼Œå¯ä»¥ç”»å‡ºæ¥ï¼Œæ›´ç›´è§‚ã€‚ å…ˆä»ä¸€ä¸ªæ ·æœ¬åšå‘é‡åŒ–ï¼Œå†æŠŠmä¸ªæ ·æœ¬çš„æ“ä½œå‘é‡åŒ–ã€‚ for-loopé‡Œé¢æ˜¯å¾ªç¯ä¹˜æ³•ï¼Œåˆ™å‘é‡åŒ–ä¸€å®šæ˜¯ä¸€ä¸ªä¹˜æ³•å½¢å¼ï¼Œè‹¥å¯¹äºä¸ç¡®å®šä¹˜æ³•çš„å·¦å³å…³ç³»ï¼Œæ˜¯å¦éœ€è½¬ç½®ï¼Œå¯ä»¥æ ¹æ®ç›®æ ‡å˜é‡çš„ç»´åº¦æ¨æµ‹ã€‚æˆ–è€…å…ˆä¹˜èµ·æ¥ï¼Œå†æ ¹æ®ç›®æ ‡å˜é‡çœ‹æ˜¯å¦è¦è½¬ç½®ã€‚ C1W2L14 : Vectorzing Logistic Regressionâ€™s Gradient Compution backforwd \frac{âˆ‚J}{âˆ‚w}=\frac{1}{m}X(Aâˆ’Y)T\\ \frac{âˆ‚J}{âˆ‚b}=\frac{1}{m}(a(i)âˆ’y(i)) é‡è¦çš„æ˜¯å¼„æ¸…æ¥šï¼Œé‡Œé¢çš„è¡Œåˆ—å…³ç³»ï¼Œä»£è¡¨çš„æ„æ€ï¼Œè¿ç®—æ—¶å€™ï¼Œå…ˆè‡ªå·±ç†æ¸…æ¥šã€‚è¿˜æœ‰ç‚¹ç§¯ã€ç­‰ç­‰è¿ç®—æ€§è´¨å¯¹åº”çš„æ“ä½œï¼Œæˆ–è€…å¯¹åº”çš„å†…ç½®å‡½æ•° C1W2L15: Broadcasting in PythonOne Example A.sum(axis = 0)ä¸­çš„å‚æ•°axisã€‚axisç”¨æ¥æŒ‡æ˜å°†è¦è¿›è¡Œçš„è¿ç®—æ˜¯æ²¿ç€å“ªä¸ªè½´æ‰§è¡Œï¼Œåœ¨numpyä¸­ï¼Œ0è½´æ˜¯å‚ç›´çš„ï¼Œä¹Ÿå°±æ˜¯åˆ—ï¼Œè€Œ1è½´æ˜¯æ°´å¹³çš„ï¼Œä¹Ÿå°±æ˜¯è¡Œã€‚ ç¬¬äºŒä¸ªA/cal.reshape(1,4)æŒ‡ä»¤åˆ™è°ƒç”¨äº†numpyä¸­çš„å¹¿æ’­æœºåˆ¶ã€‚è¿™é‡Œä½¿ç”¨ 3 by 4çš„çŸ©é˜µé™¤ä»¥1 by 4 çš„çŸ©é˜µã€‚æŠ€æœ¯ä¸Šæ¥è®²ï¼Œå…¶å®å¹¶ä¸éœ€è¦å†å°†çŸ©é˜µ reshape(é‡å¡‘)æˆ ï¼Œå› ä¸ºçŸ©é˜µæœ¬èº«å·²ç»æ˜¯ äº†ã€‚ä½†æ˜¯å½“æˆ‘ä»¬å†™ä»£ç æ—¶ä¸ç¡®å®šçŸ©é˜µç»´åº¦çš„æ—¶å€™ï¼Œé€šå¸¸ä¼šå¯¹çŸ©é˜µè¿›è¡Œé‡å¡‘æ¥ç¡®ä¿å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„åˆ—å‘é‡æˆ–è¡Œå‘é‡ã€‚é‡å¡‘æ“ä½œreshapeæ˜¯ä¸€ä¸ªå¸¸é‡æ—¶é—´çš„æ“ä½œï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯ï¼Œå®ƒçš„è°ƒç”¨ä»£ä»·æä½ã€‚ Secondly Example pythonçš„å¹¿æ’­æœºåˆ¶ä¼šå°†å¸¸æ•°æ‰©å±•æˆ4by 1çš„åˆ—å‘é‡ å…¶å®æ˜¯å°†1by*n çš„çŸ©é˜µå¤åˆ¶æˆä¸ºmbynçš„çŸ©é˜µ å¹¿æ’­æœºåˆ¶çš„ä¸¾ä¾‹ axisè¡¥å……ï¼šnumpyä¸­ï¼Œç±»ä¼¼sumçš„å‡½æ•°ï¼Œç»å¸¸æ¶‰åŠaxiså‚æ•°ï¼Œå¯ä»¥å–å€¼ä¸º0æˆ–1ï¼Œç”šè‡³å…¶ä»–ã€‚ç»å¸¸è®°ä¸ä½ï¼Œè¿™é‡Œæˆ‘æŸ¥äº†äº†ä¸€ä¸‹ï¼Œæ˜¯è¿™æ ·çš„ï¼ˆåŸæ–‡ï¼‰ï¼š axisçš„æ•°å­—ï¼Œå’Œæ•°ç»„çš„shapeå‚æ•°çš„ç´¢å¼•æ˜¯å¯¹åº”çš„ã€‚æ¯”å¦‚ä¸€ä¸ªæ•°ç»„çš„shapeæ˜¯(5,6)ï¼Œåˆ™ä»£è¡¨5ä¸ªrowï¼Œ6ä¸ªcolumnã€‚å³åœ¨shapeä¸­ï¼Œrowå’Œcolumnçš„ä¸ªæ•°çš„ç´¢å¼•æ˜¯0å’Œ1ã€‚ä¹Ÿå°±ç¬¬1ä¸ªåæ ‡ï¼Œåœ¨shapeä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œç´¢å¼•æ˜¯0ï¼Œä»£è¡¨rowçš„æ–¹å‘ï¼›ç¬¬2ä¸ªåæ ‡ï¼Œåœ¨shapeä¸­çš„ç¬¬2ä¸ªå…ƒç´ ï¼Œç´¢å¼•æ˜¯1ï¼Œä»£è¡¨rowçš„æ–¹å‘ã€‚ å¯¹äºsumå‡½æ•°ï¼ŒaxisæŒ‡çš„æ˜¯sumâ€œæ²¿ç€â€çš„æ–¹å‘ï¼Œç»è¿‡è®¡ç®—ï¼Œè¿™ä¸ªæ–¹å‘çš„ç»´åº¦å› ä¸ºæ±‚å’Œåå°±æ¶ˆå¤±äº†ï¼Œæ¯”å¦‚sum(axis=0)ä»£è¡¨æ˜¯æ²¿ç€â€œrowâ€æ–¹å‘è¿›è¡Œæ±‚å’Œï¼Œ å½“ç„¶axiså¯ä»¥æ˜¯ä¸€ä¸ªtupeï¼Œé‚£å°±ç›¸å½“äºæ²¿ç€å¤šä¸ªå¤šä¸ªæ–¹å‘æ±‚å’Œã€‚ sumå¦‚æœä¸ä¼ å…¥axiså‚æ•°ï¼Œé»˜è®¤æ˜¯å¯¹æ‰€æœ‰ç»´åº¦æ±‚å’Œã€‚ broadcasting å½“ä¸¤ä¸ªæ•°ç»„çš„å½¢çŠ¶å¹¶ä¸ç›¸åŒçš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰©å±•æ•°ç»„çš„æ–¹æ³•æ¥å®ç°ç›¸åŠ ã€ç›¸å‡ã€ç›¸ä¹˜ç­‰æ“ä½œï¼Œè¿™ç§æœºåˆ¶å«åšå¹¿æ’­ï¼ˆbroadcastingï¼‰ã€‚ ä¸‰ç§å¹¿æ’­æƒ…å†µ C1W2L16 A Note on Python/numpy vectorsæœ¬èŠ‚ä¸»è¦è®²Pythonä¸­çš„numpyä¸€ç»´æ•°ç»„çš„ç‰¹æ€§ï¼Œä»¥åŠä¸è¡Œå‘é‡æˆ–åˆ—å‘é‡çš„åŒºåˆ« 1. ä¸€ç»´æ•°ç»„çš„ç‰¹æ€§é¦–å…ˆè®¾ç½®a = np.array.random.randn(5)ï¼Œè¿™æ ·ä¼šç”Ÿæˆå­˜å‚¨åœ¨æ•°ç»„aä¸­çš„5ä¸ªé«˜æ–¯éšæœºæ•°å˜é‡ã€‚ä¹‹åè¾“å‡º ï¼Œä»å±å¹•ä¸Šå¯ä»¥å¾—çŸ¥ï¼Œæ­¤æ—¶a çš„shapeï¼ˆå½¢çŠ¶ï¼‰æ˜¯ä¸€ä¸ªçš„ç»“æ„ã€‚è¿™åœ¨Pythonä¸­è¢«ç§°ä½œä¸€ä¸ªä¸€ç»´æ•°ç»„ã€‚å®ƒæ—¢ä¸æ˜¯ä¸€ä¸ªè¡Œå‘é‡ä¹Ÿä¸æ˜¯ä¸€ä¸ªåˆ—å‘é‡ï¼Œè¿™ä¹Ÿå¯¼è‡´å®ƒæœ‰ä¸€äº›ä¸æ˜¯å¾ˆç›´è§‚çš„æ•ˆæœã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘è¾“å‡ºä¸€ä¸ªè½¬ç½®é˜µï¼Œæœ€ç»ˆç»“æœå®ƒä¼šå’Œçœ‹èµ·æ¥ä¸€æ ·ï¼Œæ‰€ä»¥å’Œçš„è½¬ç½®é˜µæœ€ç»ˆç»“æœçœ‹èµ·æ¥ä¸€æ ·ã€‚è€Œå¦‚æœæˆ‘è¾“å‡ºå’Œçš„è½¬ç½®é˜µçš„å†…ç§¯ï¼Œä½ å¯èƒ½ä¼šæƒ³ï¼šä¹˜ä»¥çš„è½¬ç½®è¿”å›ç»™ä½ çš„å¯èƒ½ä¼šæ˜¯ä¸€ä¸ªçŸ©é˜µã€‚ä½†æ˜¯å¦‚æœæˆ‘è¿™æ ·åšï¼Œä½ åªä¼šå¾—åˆ°ä¸€ä¸ªæ•°ã€‚ æ‰€ä»¥æˆ‘å»ºè®®å½“ä½ ç¼–å†™ç¥ç»ç½‘ç»œæ—¶ï¼Œä¸è¦åœ¨ä½¿ç”¨çš„shape(5,1)æ˜¯è¿˜æ˜¯(n,)æˆ–è€…ä¸€ç»´æ•°ç»„ã€‚ç›¸åï¼Œå¦‚æœä½ è®¾ç½®(5,1)ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯5è¡Œ1åˆ—å‘é‡ã€‚åœ¨å…ˆå‰çš„æ“ä½œé‡Œaå’Œaçš„è½¬ç½®çœ‹èµ·æ¥ä¸€æ ·ï¼Œè€Œç°åœ¨è¿™æ ·çš„ aå˜æˆä¸€ä¸ªæ–°çš„a çš„è½¬ç½®ï¼Œå¹¶ä¸”å®ƒæ˜¯ä¸€ä¸ªè¡Œå‘é‡ã€‚è¯·æ³¨æ„ä¸€ä¸ªç»†å¾®çš„å·®åˆ«ï¼Œåœ¨è¿™ç§æ•°æ®ç»“æ„ä¸­ï¼Œå½“æˆ‘ä»¬è¾“å‡ºa çš„è½¬ç½®æ—¶æœ‰ä¸¤å¯¹æ–¹æ‹¬å·ï¼Œè€Œä¹‹å‰åªæœ‰ä¸€å¯¹æ–¹æ‹¬å·ï¼Œæ‰€ä»¥è¿™å°±æ˜¯1è¡Œ5åˆ—çš„çŸ©é˜µå’Œä¸€ç»´æ•°ç»„çš„å·®åˆ«ã€‚ 2. è¡Œå‘é‡å’Œåˆ—å‘é‡rank 1 arrayé—®é¢˜ï¼šshapeæ˜¯(x,)çš„æ•°ç»„ï¼Œæ—¢ä¸æ˜¯è¡Œå‘é‡ï¼Œä¹Ÿä¸æ˜¯åˆ—å‘é‡ï¼Œæ²¡æ³•å‚ä¸æ­£å¸¸çš„çŸ©é˜µè¿ç®—ï¼Œåº”è¯¥æ€»æ˜¯ä½¿ç”¨(x,1)æˆ–(1,x)çš„shapeæ¥è¡¨ç¤ºå‘é‡ã€‚ä½†å¯ä»¥é€šè¿‡reshapeæ–¹æ³•å°†rank 1 arrayè½¬æ¢ä¸ºè¡Œå‘é‡æˆ–åˆ—å‘é‡ã€‚ï¼ˆä»€ä¹ˆæ˜¯rankï¼Œå°±æ˜¯ä¸€ä¸ªæ•°ç»„çš„ç»´åº¦ï¼‰ä¸€ç»´çš„æ•°ç»„æ—¢ä¸æ˜¯è¡Œå‘é‡ä¹Ÿä¸æ˜¯åˆ—å‘é‡ï¼Œè½¬ç½®åï¼Œä¾ç„¶æ˜¯æœ¬èº«ã€‚ 3. è§£å†³æ–¹æ³•12assert(a.shape=ï¼ˆ5ï¼Œ1)ï¼‰# ä¸ºäº†ç¡®ä¿ä½ çš„çŸ©é˜µæˆ–å‘é‡æ‰€éœ€è¦çš„ç»´æ•°æ—¶ï¼Œä¸è¦ç¾äº reshape æ“ä½œ C1W2L18 ï¼šQuick Tour of Jupyter/iPython NotebooksC1W2L18: Explanation of Logistic Regression Cost Functionå¯¹åº”logistic regressionï¼Œè¾“å‡º$\hat{y}=p(y=1|x)$,é‚£ä¹ˆ$p(y=0|x)=1-\hat{y}$ ç»¼åˆä¸Šé¢ p(y|x)= \hat{y}^y*(1-\hat{y})^{1-y}å¯¹äºæ•´ä¸ªè®­ç»ƒé›†ï¼Œ å‡è®¾æ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬æœä»åŒä¸€åˆ†å¸ƒä¸”ç›¸äº’ç‹¬ç«‹ï¼Œä¹Ÿå³ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œæ‰€æœ‰è¿™äº›æ ·æœ¬çš„è”åˆæ¦‚ç‡å°±æ˜¯æ¯ä¸ªæ ·æœ¬æ¦‚ç‡çš„ä¹˜ç§¯: p(labels \ in\ training\ set)=\Pi_{i=1}^mp(y_i|x_i)å¦‚æœåˆ©ç”¨æå¤§ä¼¼ç„¶æ³•åšï¼Œæ‰¾åˆ°ä¸€ç»„å‚æ•°ï¼Œä½¿å¾—æ ·æœ¬è§‚æµ‹å€¼æ¦‚ç‡æœ€å¤§ \max log p(label \ in \ training \ set)=log \Pi_{i=1}^mp(y_i|x_i)=\sum -L(\hat{y^i},y^i) \min cost J(w,b)=\frac{1}{m}L(\hat{y^i},y^i)æ€»ç»“ä¸€ä¸‹ï¼Œä¸ºäº†æœ€å°åŒ–æˆæœ¬å‡½æ•°ï¼Œæˆ‘ä»¬ä»logisticå›å½’æ¨¡å‹çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„è§’åº¦å‡ºå‘ï¼Œå‡è®¾è®­ç»ƒé›†ä¸­çš„æ ·æœ¬éƒ½æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„æ¡ä»¶ä¸‹ Day3 : summaryä¸»è¦å­¦ä¹ äº†pythonç¼–ç¨‹çš„å¦‚ä½•æ‰èƒ½é«˜æ•ˆç‡ï¼Œå†…ç½®å‡½æ•°çš„å…·æœ‰å¹¶è¡Œæ€§ï¼ŒsimdæŒ‡ä»¤ï¼Œä»¥åŠä¸€ç»´æ•°ç»„çš„ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼Œlogistic regressionçš„lost functionçš„åŸç†è¯æ˜ C1W3C1W3L01 : Neural Network Overview è®¸å¤šsigmoidå•å…ƒå †å èµ·æ¥å½¢æˆä¸€ä¸ªç¥ç»ç½‘ç»œã€‚ æ­£å‘ä¼ æ’­ï¼šè¾“å…¥å±‚åˆ°layer one \left.\begin{array}{c}{x} \\ {W^{[1]}} \\ {b^{[1]}}\end{array}\right\} \Longrightarrow z^{[1]}=W^{[1]} x+b^{[1]} \Longrightarrow a^{[1]}=\sigma\left(z^{[1)}\right)layer one åˆ°layer two \left.\begin{array}{r}{a^{(1]}=\sigma\left(z^{[1]}\right)} \\ {W^{[2]}} \\ {b^{[2]}}\end{array}\right\}\begin{array}{l}{\Longrightarrow z^{[2]}=W^{[2]} a^{[1]}+b^{[2]} \Longrightarrow a^{[2]}=\sigma\left(z^{[2]}\right)} \\ {\Longrightarrow L\left(a^{[2]}, y\right)}\end{array}åå‘ä¼ æ’­ \left.\begin{array}{r}{d a^{[1]}=d \sigma\left(z^{[1]}\right)} \\ {d W^{[2]}} \\ {d b^{[2]}}\end{array}\right\}\begin{array}{l}{\Longleftarrow d z^{[2]}=d\left(W^{[2]} \alpha^{[1]}+b^{[2]}\right) \Longleftarrow d a^{[2]}=d \sigma\left(z^{[2]}\right)} \\ {\Longleftarrow d L\left(a^{[2]}, y\right)}\end{array} $W$çš„è¡Œæ•°æ˜¯æœ¬æ¬¡ç»“ç‚¹ä¸ªæ•°ï¼Œåˆ—æ•°æ˜¯ä¸Šå±‚èŠ‚ç‚¹ä¸ªæ•° C1W3L02 : Nerual Network Representationsç¬¦å·è¯´æ˜ C1W3L03ï¼š Computation Neural Network OutputA simple training examples å…¶ä¸­ï¼Œxè¡¨ç¤ºè¾“å…¥ç‰¹å¾ï¼Œaè¡¨ç¤ºæ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼ŒWè¡¨ç¤ºç‰¹å¾çš„æƒé‡ï¼Œä¸Šæ ‡è¡¨ç¤ºç¥ç»ç½‘ç»œçš„å±‚æ•°ï¼ˆéšè—å±‚ä¸º1ï¼‰ï¼Œä¸‹æ ‡è¡¨ç¤ºè¯¥å±‚çš„ç¬¬å‡ ä¸ªç¥ç»å…ƒã€‚è¿™æ˜¯ç¥ç»ç½‘ç»œçš„ç¬¦å·æƒ¯ä¾‹ï¼Œä¸‹åŒã€‚ ç¥ç»ç½‘ç»œçš„è®¡ç®— å…³äºç¥ç»ç½‘ç»œæ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Œä»æˆ‘ä»¬ä¹‹å‰æåŠçš„é€»è¾‘å›å½’å¼€å§‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ç”¨åœ†åœˆè¡¨ç¤ºç¥ç»ç½‘ç»œçš„è®¡ç®—å•å…ƒï¼Œé€»è¾‘å›å½’çš„è®¡ç®—æœ‰ä¸¤ä¸ªæ­¥éª¤ï¼Œé¦–å…ˆä½ æŒ‰æ­¥éª¤è®¡ç®—å‡ºï¼Œç„¶ååœ¨ç¬¬äºŒæ­¥ä¸­ä½ ä»¥sigmoidå‡½æ•°ä¸ºæ¿€æ´»å‡½æ•°è®¡ç®—ï¼ˆå¾—å‡ºï¼‰ï¼Œä¸€ä¸ªç¥ç»ç½‘ç»œåªæ˜¯è¿™æ ·å­åšäº†å¥½å¤šæ¬¡é‡å¤è®¡ç®—ã€‚ è¯´æ˜ï¼š$w_i^{[1]}$å’Œ$W^{[1]}$çš„å…³ç³»ï¼Œä¸€ä¸ªæŒ‰ç…§logistic regression ï¼Œä¸€ä¸ªæ˜¯çŸ©é˜µè¡¨ç¤ºã€‚ å‘é‡åŒ–è®¡ç®— å¦‚æœä½ æ‰§è¡Œç¥ç»ç½‘ç»œçš„ç¨‹åºï¼Œç”¨forå¾ªç¯æ¥åšè¿™äº›çœ‹èµ·æ¥çœŸçš„å¾ˆä½æ•ˆã€‚æ‰€ä»¥æ¥ä¸‹æ¥æˆ‘ä»¬è¦åšçš„å°±æ˜¯æŠŠè¿™å››ä¸ªç­‰å¼å‘é‡åŒ–ã€‚å‘é‡åŒ–çš„è¿‡ç¨‹æ˜¯å°†ç¥ç»ç½‘ç»œä¸­çš„ä¸€å±‚ç¥ç»å…ƒå‚æ•°çºµå‘å †ç§¯èµ·æ¥ï¼Œä¾‹å¦‚éšè—å±‚ä¸­çš„çºµå‘å †ç§¯èµ·æ¥å˜æˆä¸€ä¸ª(4,3)çš„çŸ©é˜µï¼Œç”¨ç¬¦å·$W^{[1]}$è¡¨ç¤ºã€‚å¦ä¸€ä¸ªçœ‹å¾…è¿™ä¸ªçš„æ–¹æ³•æ˜¯æˆ‘ä»¬æœ‰å››ä¸ªé€»è¾‘å›å½’å•å…ƒï¼Œä¸”æ¯ä¸€ä¸ªé€»è¾‘å›å½’å•å…ƒéƒ½æœ‰ç›¸å¯¹åº”çš„å‚æ•°â€”â€”å‘é‡ï¼ŒæŠŠè¿™å››ä¸ªå‘é‡å †ç§¯åœ¨ä¸€èµ·ï¼Œä½ ä¼šå¾—å‡ºè¿™4Ã—3çš„çŸ©é˜µã€‚ z^{[n]}=W^{[n]}X+b^{[n]} a^{[1]}=\left[ \begin{array}{c}{a_{1}^{[1]}} \\ {a_{2}^{[1]}} \\ {a_{3}^{[1]}} \\ {a_{4}^{[1]}}\end{array}\right]=\sigma\left(z^{[1]}\right) Given input Xï¼ˆa single training set) \begin{array}{c}{z^{[1]}=W^{[1]} a^{[0]}+b^{[1]}} \\ {a^{[1]}=\sigma\left(z^{[1]}\right)} \\ {z^{[2]}=W^{[2]} a^{[1]}+b^{[2]}} \\ {a^{[2]}=\sigma\left(z^{[2]}\right)}\end{array}è¯´æ˜ï¼š $W$çš„ç¬¬$i$è¡Œè¡¨ç¤ºï¼Œå½“å‰å±‚åˆ°ä¸Šä¸€å±‚çš„æƒé‡è¡Œå‘é‡ï¼Œå†è®¡ç®—å•ä¸ªçš„æ—¶å€™ï¼Œç”±äºæ˜¯æŒ‰ç…§logristics regressionçš„æ–¹å¼ï¼Œæ‰€ä»¥è®¤ä¸º$w_i$æ˜¯åˆ—å‘é‡ï¼Œæ‰€ä»¥è½¬ç½®æˆè¡Œå‘é‡ã€‚ä¸Šé¢çš„å›¾ä¹Ÿè¯´æ˜äº†ï¼šå¦‚ä½•ä»å•ä¸ªæ“ä½œåˆ°çŸ©é˜µæ“ä½œï¼Œæƒé‡çŸ©é˜µæ˜¯æ€ä¹ˆæ„é€ ï¼Œæ€ä¹ˆè¡¨ç¤ºçš„ã€‚ bæ˜¯åˆ—å‘é‡ã€‚ C1W3L04: Vectorizing Across Mutilple ExampleDifferent training examples in different columns of the matrix for loop vectorizing : stacking training set in columns x=\left[ \begin{array}{cccc}{\vdots} & {\vdots} & {\vdots} & {\vdots} \\ {x^{(1)}} & {x^{(2)}} & {\dots} & {x} \\ {\vdots} & {\vdots} & {\vdots} & {\vdots}\end{array}\right] å°±æœ‰ \left\{\begin{array}{l}{A^{[1]}=\sigma\left(z^{[1]}\right)} \\ {z^{[2]}=W^{[2]} A^{[1]}+b^{[2]}} \\ {A^{[2]}=\sigma\left(z^{[2]}\right)}\end{array}\right. å½“å‚ç›´æ‰«æï¼Œæ˜¯ç´¢å¼•åˆ°éšè—å•ä½çš„æ•°å­—ã€‚å½“æ°´å¹³æ‰«æï¼Œå°†ä»ç¬¬ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹ä¸­ä»ç¬¬ä¸€ä¸ªéšè—çš„å•å…ƒåˆ°ç¬¬äºŒä¸ªè®­ç»ƒæ ·æœ¬ï¼Œç¬¬ä¸‰ä¸ªè®­ç»ƒæ ·æœ¬â€¦â€¦ç›´åˆ°èŠ‚ç‚¹å¯¹åº”äºç¬¬ä¸€ä¸ªéšè—å•å…ƒçš„æ¿€æ´»å€¼ï¼Œä¸”è¿™ä¸ªéšè—å•å…ƒæ˜¯ä½äºè¿™ä¸ªè®­ç»ƒæ ·æœ¬ä¸­çš„æœ€ç»ˆè®­ç»ƒæ ·æœ¬ã€‚ ä»æ°´å¹³ä¸Šçœ‹ï¼ŒçŸ©é˜µä»£è¡¨äº†å„ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ä»ç«–ç›´ä¸Šçœ‹ï¼ŒçŸ©é˜µçš„ä¸åŒçš„ç´¢å¼•å¯¹åº”äºä¸åŒçš„éšè—å•å…ƒã€‚ C1W3L05 : Explanation for vectorized implement C1W3L06 : Activation Functionåœ¨è®¨è®ºä¼˜åŒ–ç®—æ³•æ—¶ï¼Œæœ‰ä¸€ç‚¹è¦è¯´æ˜ï¼šåŸºæœ¬å·²ç»ä¸ç”¨sigmoidæ¿€æ´»å‡½æ•°äº†ï¼Œtanhå‡½æ•°åœ¨æ‰€æœ‰åœºåˆéƒ½ä¼˜äºsigmoidå‡½æ•°ã€‚ sigmoidå‡½æ•°å’Œtanhå‡½æ•°ä¸¤è€…å…±åŒçš„ç¼ºç‚¹æ˜¯ï¼Œåœ¨zç‰¹åˆ«å¤§æˆ–è€…ç‰¹åˆ«å°çš„æƒ…å†µä¸‹ï¼Œå¯¼æ•°çš„æ¢¯åº¦æˆ–è€…å‡½æ•°çš„æ–œç‡ä¼šå˜å¾—ç‰¹åˆ«å°ï¼Œæœ€åå°±ä¼šæ¥è¿‘äº0ï¼Œå¯¼è‡´é™ä½æ¢¯åº¦ä¸‹é™çš„é€Ÿåº¦ã€‚ åœ¨æœºå™¨å­¦ä¹ å¦ä¸€ä¸ªå¾ˆæµè¡Œçš„å‡½æ•°æ˜¯ï¼šä¿®æ­£çº¿æ€§å•å…ƒçš„å‡½æ•°ï¼ˆReLuï¼‰ï¼ŒReLuå‡½æ•°å›¾åƒæ˜¯å¦‚ä¸‹å›¾ã€‚$ a = max(0,z)$ï¼š æ‰€ä»¥ï¼Œåªè¦æ˜¯æ­£å€¼çš„æƒ…å†µä¸‹ï¼Œå¯¼æ•°æ’ç­‰äº1ï¼Œå½“æ˜¯è´Ÿå€¼çš„æ—¶å€™ï¼Œå¯¼æ•°æ’ç­‰äº0ã€‚ä»å®é™…ä¸Šæ¥è¯´ï¼Œå½“ä½¿ç”¨çš„å¯¼æ•°æ—¶ï¼Œ=0çš„å¯¼æ•°æ˜¯æ²¡æœ‰å®šä¹‰çš„ã€‚ä½†æ˜¯å½“ç¼–ç¨‹å®ç°çš„æ—¶å€™ï¼Œçš„å–å€¼åˆšå¥½ç­‰äº0.00000001ï¼Œè¿™ä¸ªå€¼ç›¸å½“å°ï¼Œæ‰€ä»¥ï¼Œåœ¨å®è·µä¸­ï¼Œä¸éœ€è¦æ‹…å¿ƒè¿™ä¸ªå€¼ï¼Œæ˜¯ç­‰äº0çš„æ—¶å€™ï¼Œå‡è®¾ä¸€ä¸ªå¯¼æ•°æ˜¯1æˆ–è€…0æ•ˆæœéƒ½å¯ä»¥ã€‚ å¦‚æœè¾“å‡ºæ˜¯0ã€1å€¼ï¼ˆäºŒåˆ†ç±»é—®é¢˜ï¼‰ï¼Œåˆ™è¾“å‡ºå±‚é€‰æ‹©sigmoidå‡½æ•°ï¼Œç„¶åå…¶å®ƒçš„æ‰€æœ‰å•å…ƒéƒ½é€‰æ‹©Reluå‡½æ•°ã€‚ è¿™æ˜¯å¾ˆå¤šæ¿€æ´»å‡½æ•°çš„é»˜è®¤é€‰æ‹©ï¼Œå¦‚æœåœ¨éšè—å±‚ä¸Šä¸ç¡®å®šä½¿ç”¨å“ªä¸ªæ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆé€šå¸¸ä¼šä½¿ç”¨Reluæ¿€æ´»å‡½æ•°ã€‚æœ‰æ—¶ï¼Œä¹Ÿä¼šä½¿ç”¨tanhæ¿€æ´»å‡½æ•°ï¼Œä½†Reluçš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼šå½“zæ˜¯è´Ÿå€¼çš„æ—¶å€™ï¼Œå¯¼æ•°ç­‰äº0ã€‚ è¿™é‡Œä¹Ÿæœ‰å¦ä¸€ä¸ªç‰ˆæœ¬çš„Reluè¢«ç§°ä¸ºLeaky Reluã€‚ å½“æ˜¯è´Ÿå€¼æ—¶ï¼Œè¿™ä¸ªå‡½æ•°çš„å€¼ä¸æ˜¯ç­‰äº0ï¼Œè€Œæ˜¯è½»å¾®çš„å€¾æ–œã€‚ ä¸¤è€…çš„ä¼˜ç‚¹æ˜¯ï¼š ç¬¬ä¸€ï¼Œåœ¨çš„åŒºé—´å˜åŠ¨å¾ˆå¤§çš„æƒ…å†µä¸‹ï¼Œæ¿€æ´»å‡½æ•°çš„å¯¼æ•°æˆ–è€…æ¿€æ´»å‡½æ•°çš„æ–œç‡éƒ½ä¼šè¿œå¤§äº0ï¼Œåœ¨ç¨‹åºå®ç°å°±æ˜¯ä¸€ä¸ªif-elseè¯­å¥ï¼Œè€Œsigmoidå‡½æ•°éœ€è¦è¿›è¡Œæµ®ç‚¹å››åˆ™è¿ç®—ï¼Œåœ¨å®è·µä¸­ï¼Œä½¿ç”¨ReLuæ¿€æ´»å‡½æ•°ç¥ç»ç½‘ç»œé€šå¸¸ä¼šæ¯”ä½¿ç”¨sigmoidæˆ–è€…tanhæ¿€æ´»å‡½æ•°å­¦ä¹ çš„æ›´å¿«ã€‚ ç¬¬äºŒï¼Œsigmoidå’Œtanhå‡½æ•°çš„å¯¼æ•°åœ¨æ­£è´Ÿé¥±å’ŒåŒºçš„æ¢¯åº¦éƒ½ä¼šæ¥è¿‘äº0ï¼Œè¿™ä¼šé€ æˆæ¢¯åº¦å¼¥æ•£ï¼Œè€ŒReluå’ŒLeaky ReLuå‡½æ•°å¤§äº0éƒ¨åˆ†éƒ½ä¸ºå¸¸æ•°ï¼Œä¸ä¼šäº§ç”Ÿæ¢¯åº¦å¼¥æ•£ç°è±¡ã€‚(åŒæ—¶åº”è¯¥æ³¨æ„åˆ°çš„æ˜¯ï¼ŒReluè¿›å…¥è´ŸåŠåŒºçš„æ—¶å€™ï¼Œæ¢¯åº¦ä¸º0ï¼Œç¥ç»å…ƒæ­¤æ—¶ä¸ä¼šè®­ç»ƒï¼Œäº§ç”Ÿæ‰€è°“çš„ç¨€ç–æ€§ï¼Œè€ŒLeaky ReLuä¸ä¼šæœ‰è¿™é—®é¢˜) åœ¨ReLuçš„æ¢¯åº¦ä¸€åŠéƒ½æ˜¯0ï¼Œä½†æ˜¯ï¼Œæœ‰è¶³å¤Ÿçš„éšè—å±‚ä½¿å¾—zå€¼å¤§äº0ï¼Œæ‰€ä»¥å¯¹å¤§å¤šæ•°çš„è®­ç»ƒæ•°æ®æ¥è¯´å­¦ä¹ è¿‡ç¨‹ä»ç„¶å¯ä»¥å¾ˆå¿«ã€‚ sigmoidæ¿€æ´»å‡½æ•°ï¼šé™¤äº†è¾“å‡ºå±‚æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜åŸºæœ¬ä¸ä¼šç”¨å®ƒã€‚ tanhæ¿€æ´»å‡½æ•°ï¼štanhæ˜¯éå¸¸ä¼˜ç§€çš„ï¼Œå‡ ä¹é€‚åˆæ‰€æœ‰åœºåˆã€‚ ReLuæ¿€æ´»å‡½æ•°ï¼šæœ€å¸¸ç”¨çš„é»˜è®¤å‡½æ•°ï¼Œï¼Œå¦‚æœä¸ç¡®å®šç”¨å“ªä¸ªæ¿€æ´»å‡½æ•°ï¼Œå°±ä½¿ç”¨ReLuæˆ–è€…Leaky ReLuã€‚ é€šå¸¸çš„å»ºè®®æ˜¯ï¼šå¦‚æœä¸ç¡®å®šå“ªä¸€ä¸ªæ¿€æ´»å‡½æ•°æ•ˆæœæ›´å¥½ï¼Œå¯ä»¥æŠŠå®ƒä»¬éƒ½è¯•è¯•ï¼Œç„¶ååœ¨éªŒè¯é›†æˆ–è€…å‘å±•é›†ä¸Šè¿›è¡Œè¯„ä»·ã€‚ç„¶åçœ‹å“ªä¸€ç§è¡¨ç°çš„æ›´å¥½ï¼Œå°±å»ä½¿ç”¨å®ƒã€‚ C1W3L07 : Why non-linear activation Functions é€šè¿‡æ¨å¯¼å¯ä»¥å¾—å‡ºï¼Œå¦‚æœä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç›¸å½“äºæ²¡æœ‰éšè—å±‚ã€‚æ— è®ºä½ çš„ç¥ç»ç½‘ç»œæœ‰å¤šå°‘å±‚ä¸€ç›´åœ¨åšçš„åªæ˜¯è®¡ç®—çº¿æ€§å‡½æ•°ï¼Œæ‰€ä»¥ä¸å¦‚ç›´æ¥å»æ‰å…¨éƒ¨éšè—å±‚ã€‚å½“å½“ç„¶ï¼Œåœ¨output layeræ˜¯å¯ä»¥ä¸ç”¨activation functionï¼Œæˆ–è€…ç”¨linear activation functionï¼›è¿™ç§æƒ…å†µä¸€èˆ¬æ˜¯è¦æ±‚è¾“å‡ºå®æ•°é›†ç»“æœï¼ˆæ¯”å¦‚é¢„æµ‹æˆ¿ä»·ï¼‰ã€‚å³ä¾¿å¦‚æ­¤ï¼Œåœ¨hidden layerè¿˜æ˜¯è¦ç”¨non-linear activation functionã€‚ sigmoid activation function \frac{d}{d z} g(z)=\frac{1}{1+e^{-z}}\left(1-\frac{1}{1+e^{-z}}\right)=g(z)(1-g(z))tanh activation function g(z)=\tanh (z)=\frac{e^{z}-e^{-z}}{e^{x}+e^{-z}} \frac{d}{d z} g(z)=1-(\tanh (z))^{2}Rectified linear unit(RelU) g(z)^{\prime}=\left\{\begin{array}{ll}{0} & {\text { if } z0} \\ {\text {undefined}} & {\text { if } z=0}\end{array}\right.æ³¨ï¼šé€šå¸¸åœ¨z= 0çš„æ—¶å€™ç»™å®šå…¶å¯¼æ•°1,0ï¼›å½“ç„¶=0çš„æƒ…å†µå¾ˆå°‘ Leaky linear unit (Leaky ReLU) g(z)=\max (0.01 z, z) g(z)^{\prime}=\left\{\begin{array}{ll}{0.01} & {\text { if } z0} \\ {\text {undefined}} & {\text { if } z=0}\end{array}\right.æ³¨ï¼šé€šå¸¸åœ¨çš„z=0æ—¶å€™ç»™å®šå…¶å¯¼æ•°1,0.01ï¼›å½“ç„¶çš„æƒ…å†µå¾ˆå°‘ã€‚ C1W3L09 : Gradient Descent For Neural Networks gradient descentçš„å…³é”®æ˜¯æ±‚cost functionå¯¹å‚æ•°çš„åå¯¼æ•° æ±‚å¯¼è¿‡ç¨‹ä½¿ç”¨çš„æ˜¯Backpropagation é¦–å…ˆåšforward propagationï¼Œæ±‚è§£å‡ºæ¯ä¸€å±‚çš„è¾“å‡ºA (1) z^{[1]}=W^{[1]} x+b^{[1]}\\ (2) a^{[1]}=\sigma\left(z^{[1]}\right)\\(3) z^{[2]}=W^{[2]}=W^{[2]} a^{[1]}+b^{[2]}\\(4) a^{[2]}=g^{[2]}\left(z^{[z]}\right)=\sigma\left(z^{[2]}\right) ç„¶åå‘åï¼Œé€å±‚æ±‚è§£å¯¹æ¯ä¸€å±‚å‚æ•°çš„åå¯¼æ•° sumï¼Œkeepdimsæ˜¯é˜²æ­¢pythonè¾“å‡ºé‚£äº›å¤æ€ªçš„ç§©æ•°(n,)ï¼ŒåŠ ä¸Šè¿™ä¸ªç¡®ä¿é˜µçŸ©é˜µè¿™ä¸ªå‘é‡è¾“å‡ºçš„ç»´åº¦ä¸º(n,1ï¼‰è¿™æ ·æ ‡å‡†çš„å½¢å¼ã€‚ C1WL10: Backpropagation intuition (optional) å®ç°åå‘ä¼ æ’­æœ‰ä¸ªæŠ€å·§ï¼Œå°±æ˜¯è¦ä¿è¯çŸ©é˜µçš„ç»´åº¦ç›¸äº’åŒ¹é… å…¶å®ï¼Œå¯¹äºä¸€ä¸ªç¥ç»å…ƒï¼Œè¾“å…¥éƒ¨åˆ†ï¼šæ˜¯æƒé‡å’Œä¸Šä¸€å±‚è¾“å‡ºçš„çº¿æ€§ç»„åˆï¼›è¾“å‡ºï¼šæ¿€æ´»å‡½æ•°ä½œç”¨äºè¾“å…¥ï¼Œå› æ­¤å¯¹$W$æ±‚åå¯¼æ—¶ï¼Œå¯¹æ¿€æ´»å‡½æ•°æ±‚ä¸€æ¬¡ï¼Œå†å¯¹çº¿æ€§ç»„åˆæ±‚ä¸€æ¬¡ã€‚å¯¹$b$æ±‚åå¯¼æ˜¯ï¼Œå¯¹çº¿æ€§éƒ¨åˆ†æ±‚åå¯¼æ˜¯1,è¿™é‡Œç”¨æ±‚å’Œã€‚ C1W3L11: Random Initialization` ä¸logistic regressionä¸åŒï¼Œåˆå§‹åŒ–å‚æ•°ä¸å¯å›ºå®šä¸º0ï¼Œè€Œæ˜¯æ¯ä¸ªå‚æ•°éƒ½è¦éšæœºåˆå§‹åŒ–ã€‚ ä¸»è¦åŸå› æ˜¯ï¼šå¦‚æœæ¯ä¸ªå‚æ•°wå’Œbéƒ½æ˜¯0ï¼Œåˆ™åŒä¸€å±‚çš„æ¯ä¸ªneuronè®¡ç®—ç»“æœå®Œå…¨ä¸€æ ·ï¼ˆè¾“å…¥ä¸€æ ·aï¼Œå‚æ•°ä¸€æ ·wï¼Œåˆ™zä¸€æ ·,symmetry breaking problemï¼‰ï¼›æ¥ä¸‹æ¥åå‘ä¼ æ’­æ—¶çš„åå¯¼æ•°ä¹Ÿä¸€æ ·ï¼Œä¸‹ä¸€è½®è¿­ä»£åŒä¸€å±‚çš„æ¯ä¸ªneuronçš„wåˆæ˜¯ä¸€æ ·çš„ã€‚è¿™æ ·æ•´ä¸ªneural Networkä¸Šæ¯ä¸€å±‚çš„neuronæ˜¯åŒè´¨çš„ï¼Œè‡ªç„¶ä¸ä¼šæœ‰å¥½çš„performanceã€‚ .png) ä¸è¿‡ï¼Œå¯¹bå‚æ•°ï¼Œå¯ä»¥éƒ½åˆå§‹åŒ–ä¸º0ã€‚ å¦å¤–éœ€è¦æ³¨æ„ï¼Œè™½ç„¶wæ˜¯éšæœºåˆå§‹åŒ–ï¼Œä½†æœ€å¥½ä½¿ç”¨è¾ƒå°çš„éšæœºæ•°ã€‚ä¸»è¦æ˜¯é¿å…è®©zçš„è®¡ç®—å€¼è¿‡å¤§ï¼Œå¯¼è‡´activation functionå¯¹zçš„åå¯¼æ•°è¶‹äº0ï¼Œå¯¼è‡´Gradient descentä¸‹é™è¾ƒæ…¢ã€‚ é€šå¸¸çš„åšæ³•æ˜¯å¯¹randomçš„å€¼ä¹˜ä»¥ä¸€ä¸ªæ¯”ç‡ï¼Œæ¯”å¦‚0.01ï¼ˆä½†å…·ä½“æ€ä¹ˆé€‰è¿™ä¸ªæ¯”ç‡ï¼Œä¹Ÿè¦æ ¹æ®æƒ…å†µè€Œå®šï¼Œè¿™åº”è¯¥åˆæ˜¯ä¸€ä¸ªè¶…å‚äº†ï¼‰ï¼š $W[1]=np.random.randn((2,2))âˆ—0.01$ å› ä¸ºå¦‚æœä½ ç”¨tanhæˆ–è€…sigmoidæ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…è¯´åªåœ¨è¾“å‡ºå±‚æœ‰ä¸€ä¸ªSigmoidï¼Œå¦‚æœï¼ˆæ•°å€¼ï¼‰æ³¢åŠ¨å¤ªå¤§ï¼Œå½“ä½ è®¡ç®—æ¿€æ´»å€¼æ—¶å¦‚æœå¾ˆå¤§ï¼Œå°±ä¼šå¾ˆå¤§æˆ–è€…å¾ˆå°ï¼Œå› æ­¤è¿™ç§æƒ…å†µä¸‹ä½ å¾ˆå¯èƒ½åœåœ¨tanh/sigmoidå‡½æ•°çš„å¹³å¦çš„åœ°æ–¹ï¼Œè¿™äº›åœ°æ–¹æ¢¯åº¦å¾ˆå°ä¹Ÿå°±æ„å‘³ç€æ¢¯åº¦ä¸‹é™ä¼šå¾ˆæ…¢ï¼Œå› æ­¤å­¦ä¹ ä¹Ÿå°±å¾ˆæ…¢ã€‚ äº‹å®ä¸Šæœ‰æ—¶æœ‰æ¯”0.01æ›´å¥½çš„å¸¸æ•°ï¼Œå½“ä½ è®­ç»ƒä¸€ä¸ªåªæœ‰ä¸€å±‚éšè—å±‚çš„ç½‘ç»œæ—¶ï¼ˆè¿™æ˜¯ç›¸å¯¹æµ…çš„ç¥ç»ç½‘ç»œï¼Œæ²¡æœ‰å¤ªå¤šçš„éšè—å±‚ï¼‰ï¼Œè®¾ä¸º0.01å¯èƒ½ä¹Ÿå¯ä»¥ã€‚ä½†å½“ä½ è®­ç»ƒä¸€ä¸ªéå¸¸éå¸¸æ·±çš„ç¥ç»ç½‘ç»œï¼Œä½ å¯èƒ½è¦è¯•è¯•0.01ä»¥å¤–çš„å¸¸æ•°ã€‚ summaryå¦‚ä½•å»ºç«‹ä¸€ä¸ªä¸€å±‚çš„ç¥ç»ç½‘ç»œäº†ï¼Œåˆå§‹åŒ–å‚æ•°ï¼Œç”¨å‰å‘ä¼ æ’­é¢„æµ‹ï¼Œè¿˜æœ‰è®¡ç®—å¯¼æ•°ï¼Œç»“åˆåå‘ä¼ æ’­ç”¨åœ¨æ¢¯åº¦ä¸‹é™ä¸­ã€‚ 1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model's parameters 1. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent) C1W4C1W4L01 Deep-layer neural network1. logistics regression and shallow neural network and deep-layer neural network 2. notationç¥ç»ç½‘ç»œæ¨¡å‹ \begin{array}{l}{X \in \mathbb{R}^{n_{x} \times m}} ä»£è¡¨è¾“å…¥çš„çŸ©é˜µ\\{x^{(i)} \in \mathbb{R}^{n_{x}}} ä»£è¡¨ç¬¬ i ä¸ªæ ·æœ¬çš„åˆ—å‘é‡\\ {Y \in \mathbb{R}^{n_{y} \times n}} æ ‡è®°çŸ©é˜µ\\ {y^{(i)} \in \mathbb{R}^{n_{v}}}æ˜¯ç¬¬iæ ·æœ¬çš„è¾“å‡ºæ ‡ç­¾\\ W^{[l]} \in \mathbb{R}^{l \times(l-1)}ä»£è¡¨ç¬¬[l]å±‚çš„æƒé‡çŸ©é˜µ\\ b^{[l]} \in \mathbb{R}^{l}ä»£è¡¨ç¬¬[l]å±‚çš„åå·®çŸ©é˜µ\\ {\hat{y}^{(i)} \in \mathbb{R}^{n_{v}}}æ˜¯é¢„æµ‹è¾“å‡ºå‘é‡\end{array} é€šç”¨æ¿€æ´»å…¬å¼ï¼š a_{j}^{[l]}=g^{[l]}\left(z_{j}^{[l]}\right)=g^{ | l ]}\left(\sum_{k} w_{j k}^{[l]} a_{k}^{[l-1]}+b_{j}^{[l]}\right)C1W4L02ï¼š Forward and Backward propagation1. forward propagation 2. backward propagation \begin{array}{l}{d z^{[l]}=d a^{[l]} * g^{[l]}\left(z^{l l}\right)} \\ {d w^{[l]}=d z^{[l]} \cdot a^{[l-1]}}\\d b^{[l]}=d z^{[l]}\\ d a^{[l-1]}=w^{[l]} \cdot d z^{[l]}\\ d z^{[l]}=w^{[l+1] T} d z^{[l+1]} \cdot g^{[l]^{\prime}}\left(z^{[l]}\right)\end{array}å‘é‡åŒ– \begin{array}{l}{d Z^{[l]}=d A^{[l]} * g^{[l]}\left(Z^{[l]}\right)} \\ {d W^{[l]}=\frac{1}{m} d Z^{[l]} \cdot A^{[l-1] T}}\\ \begin{array}{l}{d b^{[l]}=\frac{1}{m} n p \cdot \operatorname{sum}\left(d z^{[l]}, \text { axis }=1, \text {keepdims}=\text {True}\right)} \\ {d A^{[l-1]}=W^{[l] T} \cdot d Z^{[l]}}\end{array}\end{array}summary C1W4L03 : Forward Propagation in d deep network è¿™é‡Œåªèƒ½ç”¨ä¸€ä¸ªæ˜¾å¼forå¾ªç¯ï¼Œä»1åˆ°ï¼Œç„¶åä¸€å±‚æ¥ç€ä¸€å±‚å»è®¡ç®—ã€‚ C1W4L04 Getting matrix dimension rightå½“å®ç°æ·±åº¦ç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œå…¶ä¸­ä¸€ä¸ªå¸¸ç”¨çš„æ£€æŸ¥ä»£ç æ˜¯å¦æœ‰é”™çš„æ–¹æ³•å°±æ˜¯æ‹¿å‡ºä¸€å¼ çº¸è¿‡ä¸€éç®—æ³•ä¸­çŸ©é˜µçš„ç»´æ•°ã€‚ $d_w^{[l]}$å’Œ$w^{[l]}$ç»´åº¦ç›¸åŒï¼Œ$db^{[l]}$å’Œ$b^{[l]}$ç»´åº¦ç›¸åŒï¼Œä¸”wå’Œbå‘é‡åŒ–ç»´åº¦ä¸å˜ï¼Œä½†z,aä»¥åŠxçš„ç»´åº¦ä¼šå‘é‡åŒ–åå‘ç”Ÿå˜åŒ–ã€‚ åå‘ä¼ æ’­çš„ç»´æ•°æ£€æŸ¥ åœ¨ä½ åšæ·±åº¦ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­æ—¶ï¼Œä¸€å®šè¦ç¡®è®¤æ‰€æœ‰çš„çŸ©é˜µç»´æ•°æ˜¯å‰åä¸€è‡´çš„ï¼Œå¯ä»¥å¤§å¤§æé«˜ä»£ç é€šè¿‡ç‡ã€‚ C1W4L05 Why deep representations?ç¥ç»ç½‘ç»œä¸éœ€è¦å¾ˆå¤§ï¼Œä½†æ˜¯å¾—æœ‰æ·±åº¦ï¼Œä¹Ÿå°±æ˜¯éšè—å±‚éœ€è¦å¾ˆå¤šï¼Œ 1. for example of face detector C1W4L06 :Building blocks of a deep neural network å¯ä»¥çœ‹å¾—å‡ºï¼Œå†åå‘ä¼ æ’­çš„æ—¶å€™ï¼Œéœ€è¦ç”¨åˆ°$Z^{[L]},W^{[L]},b^{[L]}$,å› æ­¤cash them æ­£å‘ä¼ æ’­ï¼š$Z^{[1]},A^{[1]}â€¦â€¦â€¦â€¦$,åå‘ä¼ æ’­ï¼š$dA^{[L]},dZ{[L]},dW^{[L]}dB^{[L]},dA^{[L-1]}$ C1W4L07ï¼šParameters vs Hyperparameters1 What 2 How Ideaâ€”Codeâ€”Experimentâ€”Ideaè¿™ä¸ªå¾ªç¯ï¼Œå°è¯•å„ç§ä¸åŒçš„å‚æ•°ï¼Œå®ç°æ¨¡å‹å¹¶è§‚å¯Ÿæ˜¯å¦æˆåŠŸï¼Œç„¶åå†è¿­ä»£ ä»Šå¤©çš„æ·±åº¦å­¦ä¹ åº”ç”¨é¢†åŸŸï¼Œè¿˜æ˜¯å¾ˆç»éªŒæ€§çš„è¿‡ç¨‹ï¼Œé€šå¸¸ä½ æœ‰ä¸ªæƒ³æ³•ï¼Œæ¯”å¦‚ä½ å¯èƒ½å¤§è‡´çŸ¥é“ä¸€ä¸ªæœ€å¥½çš„å­¦ä¹ ç‡å€¼ï¼Œå¯èƒ½è¯´æœ€å¥½ï¼Œæˆ‘ä¼šæƒ³å…ˆè¯•è¯•çœ‹ï¼Œç„¶åä½ å¯ä»¥å®é™…è¯•ä¸€ä¸‹ï¼Œè®­ç»ƒä¸€ä¸‹çœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚ç„¶ååŸºäºå°è¯•çš„ç»“æœä½ ä¼šå‘ç°ï¼Œä½ è§‰å¾—å­¦ä¹ ç‡è®¾å®šå†æé«˜åˆ°0.05ä¼šæ¯”è¾ƒå¥½ã€‚å¦‚æœä½ ä¸ç¡®å®šä»€ä¹ˆå€¼æ˜¯æœ€å¥½çš„ï¼Œä½ å¤§å¯ä»¥å…ˆè¯•è¯•ä¸€ä¸ªå­¦ä¹ ç‡ï¼Œå†çœ‹çœ‹æŸå¤±å‡½æ•°Jçš„å€¼æœ‰æ²¡æœ‰ä¸‹é™ã€‚ç„¶åä½ å¯ä»¥è¯•ä¸€è¯•å¤§ä¸€äº›çš„å€¼ï¼Œç„¶åå‘ç°æŸå¤±å‡½æ•°çš„å€¼å¢åŠ å¹¶å‘æ•£äº†ã€‚ç„¶åå¯èƒ½è¯•è¯•å…¶ä»–æ•°ï¼Œçœ‹ç»“æœæ˜¯å¦ä¸‹é™çš„å¾ˆå¿«æˆ–è€…æ”¶æ•›åˆ°åœ¨æ›´é«˜çš„ä½ç½®ã€‚ä½ å¯èƒ½å°è¯•ä¸åŒçš„å¹¶è§‚å¯ŸæŸå¤±å‡½æ•°è¿™ä¹ˆå˜äº†ï¼Œè¯•è¯•ä¸€ç»„å€¼ï¼Œç„¶åå¯èƒ½æŸå¤±å‡½æ•°å˜æˆè¿™æ ·ï¼Œè¿™ä¸ªå€¼ä¼šåŠ å¿«å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ä¸”æ”¶æ•›åœ¨æ›´ä½çš„æŸå¤±å‡½æ•°å€¼ä¸Šï¼ˆç®­å¤´æ ‡è¯†ï¼‰ï¼Œæˆ‘å°±ç”¨è¿™ä¸ªå€¼äº†ã€‚ åœ¨å‰é¢å‡ é¡µä¸­ï¼Œè¿˜æœ‰å¾ˆå¤šä¸åŒçš„è¶…å‚æ•°ã€‚ç„¶è€Œï¼Œå½“ä½ å¼€å§‹å¼€å‘æ–°åº”ç”¨æ—¶ï¼Œé¢„å…ˆå¾ˆéš¾ç¡®åˆ‡çŸ¥é“ï¼Œç©¶ç«Ÿè¶…å‚æ•°çš„æœ€ä¼˜å€¼åº”è¯¥æ˜¯ä»€ä¹ˆã€‚æ‰€ä»¥é€šå¸¸ï¼Œä½ å¿…é¡»å°è¯•å¾ˆå¤šä¸åŒçš„å€¼ï¼Œå¹¶èµ°è¿™ä¸ªå¾ªç¯ï¼Œè¯•è¯•å„ç§å‚æ•°ã€‚è¯•è¯•çœ‹5ä¸ªéšè—å±‚ï¼Œè¿™ä¸ªæ•°ç›®çš„éšè—å•å…ƒï¼Œå®ç°æ¨¡å‹å¹¶è§‚å¯Ÿæ˜¯å¦æˆåŠŸï¼Œç„¶åå†è¿­ä»£ã€‚è¿™é¡µçš„æ ‡é¢˜æ˜¯ï¼Œåº”ç”¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œä¸€ä¸ªå¾ˆå¤§ç¨‹åº¦åŸºäºç»éªŒçš„è¿‡ç¨‹ï¼Œå‡­ç»éªŒçš„è¿‡ç¨‹é€šä¿—æ¥è¯´ï¼Œå°±æ˜¯è¯•ç›´åˆ°ä½ æ‰¾åˆ°åˆé€‚çš„æ•°å€¼ã€‚ æ‰€ä»¥æˆ‘ç»å¸¸å»ºè®®äººä»¬ï¼Œç‰¹åˆ«æ˜¯åˆšå¼€å§‹åº”ç”¨äºæ–°é—®é¢˜çš„äººä»¬ï¼Œå»è¯•ä¸€å®šèŒƒå›´çš„å€¼çœ‹çœ‹ç»“æœå¦‚ä½•ã€‚ç„¶åä¸‹ä¸€é—¨è¯¾ç¨‹ï¼Œæˆ‘ä»¬ä¼šç”¨æ›´ç³»ç»Ÿçš„æ–¹æ³•ï¼Œç”¨ç³»ç»Ÿæ€§çš„å°è¯•å„ç§è¶…å‚æ•°å–å€¼ã€‚ç„¶åå…¶æ¬¡ï¼Œç”šè‡³æ˜¯ä½ å·²ç»ç”¨äº†å¾ˆä¹…çš„æ¨¡å‹ï¼Œå¯èƒ½ä½ åœ¨åšç½‘ç»œå¹¿å‘Šåº”ç”¨ï¼Œåœ¨ä½ å¼€å‘é€”ä¸­ï¼Œå¾ˆæœ‰å¯èƒ½å­¦ä¹ ç‡çš„æœ€ä¼˜æ•°å€¼æˆ–æ˜¯å…¶ä»–è¶…å‚æ•°çš„æœ€ä¼˜å€¼æ˜¯ä¼šå˜çš„ï¼Œæ‰€ä»¥å³ä½¿ä½ æ¯å¤©éƒ½åœ¨ç”¨å½“å‰æœ€ä¼˜çš„å‚æ•°è°ƒè¯•ä½ çš„ç³»ç»Ÿï¼Œä½ è¿˜æ˜¯ä¼šå‘ç°ï¼Œæœ€ä¼˜å€¼è¿‡ä¸€å¹´å°±ä¼šå˜åŒ–ï¼Œå› ä¸ºç”µè„‘çš„åŸºç¡€è®¾æ–½ï¼ŒCPUæˆ–æ˜¯GPUå¯èƒ½ä¼šå˜åŒ–å¾ˆå¤§ã€‚æ‰€ä»¥æœ‰ä¸€æ¡ç»éªŒè§„å¾‹å¯èƒ½æ¯å‡ ä¸ªæœˆå°±ä¼šå˜ã€‚å¦‚æœä½ æ‰€è§£å†³çš„é—®é¢˜éœ€è¦å¾ˆå¤šå¹´æ—¶é—´ï¼Œåªè¦ç»å¸¸è¯•è¯•ä¸åŒçš„è¶…å‚æ•°ï¼Œå‹¤äºæ£€éªŒç»“æœï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰æ›´å¥½çš„è¶…å‚æ•°æ•°å€¼ï¼Œç›¸ä¿¡ä½ æ…¢æ…¢ä¼šå¾—åˆ°è®¾å®šè¶…å‚æ•°çš„ç›´è§‰ï¼ŒçŸ¥é“ä½ çš„é—®é¢˜æœ€å¥½ç”¨ä»€ä¹ˆæ•°å€¼ã€‚ æœ‰ä¸€æ¡ç»éªŒè§„å¾‹ï¼šç»å¸¸è¯•è¯•ä¸åŒçš„è¶…å‚æ•°ï¼Œå‹¤äºæ£€æŸ¥ç»“æœï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰æ›´å¥½çš„è¶…å‚æ•°å–å€¼ï¼Œä½ å°†ä¼šå¾—åˆ°è®¾å®šè¶…å‚æ•°çš„ç›´è§‰ã€‚ æ€»ç»“ï¼šè¶…å‚æ•°çš„è®¾å®šï¼Œé ç»éªŒï¼Œå°è¯•ï¼Œå¹¶è°ƒï¼Œæ ¹æ®ç»“æœè°ƒï¼Œ C1W4L08 : What does this have to do with the brain?# summary : forward prop and back prop1. logistics regression,shallow neural network and deep neural networklogistics regression Z = W^TX+B\\ A = \frac{1}{1+e^{-Z}}\\ L(A,Y)=-\frac{1}{m}(Ylog^A+(1-Y)log^{1-A}\\ \frac{\partial L}{\partial Z}=(A-Y)\\ \frac{\partial L}{\partial W}=X(A-Y)\\è¯´æ˜ï¼šXæ˜¯æ ·æœ¬æŒ‰åˆ—å †ç§¯ï¼ŒWæ˜¯åˆ—å‘é‡ shallow neural network ä»¥äºŒåˆ†é—®é¢˜ä¸ºä¾‹ Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}\\ A^{[1]}=g^{[1]}(Z^{[1]})\\ \ \\ Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}\\ A^{[2]}=g^{[2]}(Z^{[2]})\\ \ \ \\ \ \\ L(A^{[2]},Y)=-\frac{1}{m}(Ylog^{A}+(1-Y)log^{1-A})\\ \frac{\partial L}{\partial Z^{[2]}}=(A^{[2]}-Y)\\ \frac{\partial L}{\partial W^{[2]}}=(A^{[2]}-Y)A^{[1]^T}\\ \frac{\partial L}{\partial b^{[2]}}=(A^{[2]}-Y)1_{1*m}^T\\ \frac{\partial L}{\partial a^{[1]}}=W^{[2]^T}(A^{[2]}-Y)\\ \ \\ \frac{\partial L}{\partial Z^{[1]}}=W^{[2]^T}(A^{[2]}-Y)* g^{'[1]}(Z^{[1]})\\è¯´æ˜ï¼šWæ˜¯æŒ‰åˆ—æ’$W^{[L]}$æ˜¯$n^{[L]}*n^{[L-1]}$çŸ©é˜µï¼ŒA,Zæ˜¯æŒ‰åˆ—å †ç§¯ï¼Œè®°å¾—æ£€æŸ¥çŸ©é˜µç»´æ•°å°±å¥½äº† deep neural network Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}\\ A^{[l]}=g^{[l]}(Z^{[l]})\\ \ \ \\ \ \\ \frac{\partial L}{\partial Z^{[l]}}=\partial A^*g^{'[l]}(Z^{l})\\ \frac{\partial L}{\partial W^{[l]}}=\partial Z^{[l]} A^{[1-1]^T}\\ \frac{\partial L}{\partial b^{[l]}}=\partial Z^{[l]}\\ \frac{\partial L}{\partial a^{[l-1]}}=W^{[l]^T}\partial Z^{[l]}\\ \ \\ \frac{\partial L}{\partial Z^{[l-1]}}=W^{[l]^T}\partial Z^{[l]}* g^{'[l-1]}(Z^{[l-1]})\\2. vectorization æ¨å¯¼çš„æ—¶å€™è¦å‘é‡åŒ–ï¼Œæ³¨æ„çŸ©é˜µç»´æ•°è¡¨ç¤ºï¼Œå¯ä»¥ä»å•ä¸ªæ¨å¯¼åˆ°mutli å……åˆ†åˆ©ç”¨pythonçš„å¹¿æ’­å±æ€§ï¼Œå’Œå†…ç½®å‡½æ•°çš„å¹¶è¡ŒåŒ– pythonä¸€ç»´ï¼ŒäºŒç»´æ•°ç»„çš„ç‰¹æ€§ 3. çŸ¥è¯†ç»“æ„]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep_learning.aiæ·±åº¦å­¦ä¹ ç¬”è®°]]></title>
    <url>%2F2019%2F04%2F11%2Fdeep-learning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[C5: Sequence ModelsW1 : Recurrent Neural Networks (å¾ªç¯åºåˆ—æ¨¡å‹)L1 ï¼š Why Sequence Models?å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ä¹‹ç±»çš„æ¨¡å‹åœ¨è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œå…¶ä»–é¢†åŸŸä¸­å¼•èµ·å˜é©ã€‚ åºåˆ—æ¨¡å‹çš„åˆ—å­ L2 : Notation æ•°å­¦ç¬¦å·NLP æˆ‘ä»¬ç”¨$X^{(i)}$æ¥è¡¨ç¤ºç¬¬ä¸ªiè®­ç»ƒæ ·æœ¬ï¼Œæ‰€ä»¥ä¸ºäº†æŒ‡ä»£ç¬¬ä¸ªtå…ƒç´ ï¼Œæˆ–è€…è¯´æ˜¯è®­ç»ƒæ ·æœ¬içš„åºåˆ—ä¸­ç¬¬tä¸ªå…ƒç´ ç”¨$X^{(i)}$è¿™ä¸ªç¬¦å·æ¥è¡¨ç¤ºã€‚å¦‚æœæ˜¯åºåˆ—é•¿åº¦$T_x$ï¼Œé‚£ä¹ˆä½ çš„è®­ç»ƒé›†é‡Œä¸åŒçš„è®­ç»ƒæ ·æœ¬å°±ä¼šæœ‰ä¸åŒçš„é•¿åº¦ï¼Œæ‰€ä»¥$T_x^{(i)}$å°±ä»£è¡¨ç¬¬ä¸ªè®­ç»ƒæ ·æœ¬çš„è¾“å…¥åºåˆ—é•¿åº¦ã€‚åŒæ ·$y^{(i)}$ä»£è¡¨ç¬¬iä¸ªè®­ç»ƒæ ·æœ¬ä¸­ç¬¬tä¸ªå…ƒç´ ï¼Œ$T_y^{(i)}$å°±æ˜¯ç¬¬iä¸ªè®­ç»ƒæ ·æœ¬çš„è¾“å‡ºåºåˆ—çš„é•¿åº¦ã€‚ é¢„å…ˆæœ‰ä¸€ä¸ªè¯å…¸ L3 : Recurrent Neural Network Model (å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹)ç°åœ¨æˆ‘ä»¬è®¨è®ºä¸€ä¸‹æ€æ ·æ‰èƒ½å»ºç«‹ä¸€ä¸ªæ¨¡å‹ï¼Œå»ºç«‹ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ Xåˆ°Yçš„æ˜ å°„ $a^{}$é€šå¸¸ æ˜¯é›¶å‘é‡ Næ¨¡å‹åŒ…å«ä¸‰ç±»æƒé‡ç³»æ•°ï¼Œåˆ†åˆ«æ˜¯Waxï¼ŒWaaï¼ŒWyaã€‚ä¸”ä¸åŒå…ƒç´ ä¹‹é—´åŒä¸€ä½ç½®å…±äº«åŒä¸€æƒé‡ç³»æ•°ã€‚ RNNçš„æ­£å‘ä¼ æ’­ï¼ˆForward Propagationï¼‰è¿‡ç¨‹ä¸ºï¼š å¾ªç¯ç¥ç»ç½‘ç»œç”¨çš„æ¿€æ´»å‡½æ•°ç»å¸¸æ˜¯tanhï¼Œä¸è¿‡æœ‰æ—¶å€™ä¹Ÿä¼šç”¨ReLUï¼Œä½†æ˜¯tanhæ˜¯æ›´é€šå¸¸çš„é€‰æ‹©ï¼Œæˆ‘ä»¬æœ‰å…¶ä»–æ–¹æ³•æ¥é¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨ä¹‹åè¿›è¡Œè®²è¿°ã€‚é€‰ç”¨å“ªä¸ªæ¿€æ´»å‡½æ•°æ˜¯å–å†³äºä½ çš„è¾“å‡ºyï¼Œå¦‚æœå®ƒæ˜¯ä¸€ä¸ªäºŒåˆ†é—®é¢˜ï¼Œé‚£ä¹ˆæˆ‘çŒœä½ ä¼šç”¨sigmoidå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¦‚æœæ˜¯kç±»åˆ«åˆ†ç±»é—®é¢˜çš„è¯ï¼Œé‚£ä¹ˆå¯ä»¥é€‰ç”¨softmaxä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚ä¸è¿‡è¿™é‡Œæ¿€æ´»å‡½æ•°çš„ç±»å‹å–å†³äºä½ æœ‰ä»€ä¹ˆæ ·ç±»å‹çš„è¾“å‡ºyï¼Œå¯¹äºå‘½åå®ä½“è¯†åˆ«æ¥è¯´yåªå¯èƒ½æ˜¯0æˆ–è€…1ï¼Œé‚£æˆ‘çŒœè¿™é‡Œç¬¬äºŒä¸ªæ¿€æ´»å‡½æ•°gå¯ä»¥æ˜¯sigmoidæ¿€æ´»å‡½æ•°ã€‚ c4: Backpropagation through time ( é€šè¿‡æ—¶é—´çš„åå‘ä¼ æ’­) å‚æ•°çš„å…³ç³»* å•ä¸ªå…ƒç´ çš„Loss function: è¯¥æ ·æœ¬æ‰€æœ‰å…ƒç´ çš„Loss functionä¸ºï¼š ç„¶åï¼Œåå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰è¿‡ç¨‹å°±æ˜¯ä»å³åˆ°å·¦åˆ†åˆ«è®¡ç®—L(y^,y)å¯¹å‚æ•°Waï¼ŒWyï¼Œbaï¼Œbyçš„åå¯¼æ•°ã€‚æ€è·¯ä¸åšæ³•ä¸æ ‡å‡†çš„ç¥ç»ç½‘ç»œæ˜¯ä¸€æ ·çš„ã€‚ä¸€èˆ¬å¯ä»¥é€šè¿‡æˆç†Ÿçš„æ·±åº¦å­¦ä¹ æ¡†æ¶è‡ªåŠ¨æ±‚å¯¼ï¼Œä¾‹å¦‚PyTorchã€Tensorflowç­‰ã€‚è¿™ç§ä»å³åˆ°å·¦çš„æ±‚å¯¼è¿‡ç¨‹è¢«ç§°ä¸ºBackpropagation through time L5: Different types of RNNs (ä¸åŒç±»å‹çš„å¾ªç¯ç¥ç»ç½‘ç»œ) L6 : Language model and sequence generation (è¯­è¨€æ¨¡å‹å’Œåºåˆ—ç”Ÿæˆ) L7 : Sampling novel sequences (å¯¹æ–°åºåˆ—é‡‡æ ·) Vanishing gradients with RNNs (å¾ªç¯ç¥ç»ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±)é¦–å…ˆä»å·¦åˆ°å³å‰å‘ä¼ æ’­ï¼Œç„¶ååå‘ä¼ æ’­ã€‚ä½†æ˜¯åå‘ä¼ æ’­ä¼šå¾ˆå›°éš¾ï¼Œå› ä¸ºåŒæ ·çš„æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œåé¢å±‚çš„è¾“å‡ºè¯¯å·®ï¼ˆä¸Šå›¾ç¼–å·6æ‰€ç¤ºï¼‰å¾ˆéš¾å½±å“å‰é¢å±‚ï¼ˆä¸Šå›¾ç¼–å·7æ‰€ç¤ºçš„å±‚ï¼‰çš„è®¡ç®—ã€‚è¿™å°±æ„å‘³ç€ï¼Œå®é™…ä¸Šå¾ˆéš¾è®©ä¸€ä¸ªç¥ç»ç½‘ç»œèƒ½å¤Ÿæ„è¯†åˆ°å®ƒè¦è®°ä½çœ‹åˆ°çš„æ˜¯å•æ•°åè¯è¿˜æ˜¯å¤æ•°åè¯ï¼Œç„¶ååœ¨åºåˆ—åé¢ç”Ÿæˆä¾èµ–å•å¤æ•°å½¢å¼çš„wasæˆ–è€…wereã€‚è€Œä¸”åœ¨è‹±è¯­é‡Œé¢ï¼Œè¿™ä¸­é—´çš„å†…å®¹ï¼ˆä¸Šå›¾ç¼–å·8æ‰€ç¤ºï¼‰å¯ä»¥ä»»æ„é•¿ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ä½ éœ€è¦é•¿æ—¶é—´è®°ä½å•è¯æ˜¯å•æ•°è¿˜æ˜¯å¤æ•°ï¼Œè¿™æ ·åé¢çš„å¥å­æ‰èƒ½ç”¨åˆ°è¿™äº›ä¿¡æ¯ã€‚ä¹Ÿæ­£æ˜¯è¿™ä¸ªåŸå› ï¼Œæ‰€ä»¥åŸºæœ¬çš„RNNæ¨¡å‹ä¼šæœ‰å¾ˆå¤šå±€éƒ¨å½±å“ http://www.ai-start.com/dl2017/html/lesson5-week1.html https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&amp;mid=2247484029&amp;idx=1&amp;sn=c93b5eddec33dc29dc172a5ea0d76822&amp;chksm=976fa7e0a0182ef61e36d1c32aa0706c4e81e1762a7ee2554165beecde929b72cf026c5b7a64&amp;scene=21#wechat_redirect]]></content>
      <categories>
        <category>å­¦ä¹ ã®å†ç¨‹(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>æˆ‘çš„è¯»ä¹¦ç¬”è®°</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearningvideo]]></title>
    <url>%2F2019%2F04%2F03%2Fdeeplearningvideo%2F</url>
    <content type="text"><![CDATA[Courseraæ·±åº¦å­¦ä¹ æ•™ç¨‹ä¸­æ–‡ç¬”è®° è¯¾ç¨‹æ¦‚è¿° https://mooc.study.163.com/university/deeplearning_ai#/c è¿™äº›è¯¾ç¨‹ä¸“ä¸ºå·²æœ‰ä¸€å®šåŸºç¡€ï¼ˆåŸºæœ¬çš„ç¼–ç¨‹çŸ¥è¯†ï¼Œç†Ÿæ‚‰Pythonã€å¯¹æœºå™¨å­¦ä¹ æœ‰åŸºæœ¬äº†è§£ï¼‰ï¼Œæƒ³è¦å°è¯•è¿›å…¥äººå·¥æ™ºèƒ½é¢†åŸŸçš„è®¡ç®—æœºä¸“ä¸šäººå£«å‡†å¤‡ã€‚ä»‹ç»æ˜¾ç¤ºï¼šâ€œæ·±åº¦å­¦ä¹ æ˜¯ç§‘æŠ€ä¸šæœ€çƒ­é—¨çš„æŠ€èƒ½ä¹‹ä¸€ï¼Œæœ¬è¯¾ç¨‹å°†å¸®ä½ æŒæ¡æ·±åº¦å­¦ä¹ ã€‚â€ åœ¨è¿™5å ‚è¯¾ä¸­ï¼Œå­¦ç”Ÿå°†å¯ä»¥å­¦ä¹ åˆ°æ·±åº¦å­¦ä¹ çš„åŸºç¡€ï¼Œå­¦ä¼šæ„å»ºç¥ç»ç½‘ç»œï¼Œå¹¶ç”¨åœ¨åŒ…æ‹¬å´æ©è¾¾æœ¬äººåœ¨å†…çš„å¤šä½ä¸šç•Œé¡¶å°–ä¸“å®¶æŒ‡å¯¼ä¸‹åˆ›å»ºè‡ªå·±çš„æœºå™¨å­¦ä¹ é¡¹ç›®ã€‚Deep Learning Specializationå¯¹å·ç§¯ç¥ç»ç½‘ç»œ (CNN)ã€é€’å½’ç¥ç»ç½‘ç»œ (RNN)ã€é•¿çŸ­æœŸè®°å¿† (LSTM) ç­‰æ·±åº¦å­¦ä¹ å¸¸ç”¨çš„ç½‘ç»œç»“æ„ã€å·¥å…·å’ŒçŸ¥è¯†éƒ½æœ‰æ¶‰åŠã€‚ ç¬”è®°æ˜¯æ ¹æ®è§†é¢‘å’Œå­—å¹•å†™çš„ï¼Œæ²¡æœ‰æŠ€æœ¯å«é‡ï¼Œåªéœ€è¦ä¸“æ³¨å’Œä¸¥è°¨ã€‚ 2018-04-14 æœ¬è¯¾ç¨‹è§†é¢‘æ•™ç¨‹åœ°å€ï¼šhttps://mooc.study.163.com/university/deeplearning_ai#/c ï¼ˆè¯¥è§†é¢‘ä»www.deeplearning.ai ç½‘ç«™ä¸‹è½½ï¼Œå› ä¼—æ‰€å‘¨çŸ¥çš„åŸå› ï¼Œå›½å†…ç”¨æˆ·è§‚çœ‹æŸäº›åœ¨çº¿è§†é¢‘éå¸¸ä¸å®¹æ˜“ï¼Œæ•…ä¸€äº›å­¦è€…ä¸€èµ·åˆ¶ä½œäº†ç¦»çº¿è§†é¢‘ï¼Œæ—¨åœ¨æ–¹ä¾¿å›½å†…ç”¨æˆ·ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œè¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”ã€‚è§†é¢‘å†…åµŒä¸­è‹±æ–‡å­—å¹•ï¼Œæ¨èä½¿ç”¨potplayeræ’­æ”¾ã€‚ç‰ˆæƒå±äºå´æ©è¾¾è€å¸ˆæ‰€æœ‰ï¼Œè‹¥åœ¨çº¿è§†é¢‘æµç•…ï¼Œè¯·åˆ°å®˜æ–¹ç½‘ç«™è§‚çœ‹ã€‚ï¼‰ ç¬”è®°ç½‘ç«™(é€‚åˆæ‰‹æœºé˜…è¯») å´æ©è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ç¬”è®°å’Œè§†é¢‘ï¼šhttps://github.com/fengdu78/Coursera-ML-AndrewNg-Notes æ·±åº¦å­¦ä¹ ç¬”è®°ç›®å½•ç¬¬ä¸€é—¨è¯¾ ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ (Neural Networks and Deep Learning)ç¬¬ä¸€å‘¨ï¼šæ·±åº¦å­¦ä¹ å¼•è¨€(Introduction to Deep Learning) 1.1 æ¬¢è¿(Welcome) 1.2 ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ(What is a Neural Network) 1.3 ç¥ç»ç½‘ç»œçš„ç›‘ç£å­¦ä¹ (Supervised Learning with Neural Networks) 1.4 ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œä¼šæµè¡Œï¼Ÿ(Why is Deep Learning taking off?) 1.5 å…³äºæœ¬è¯¾ç¨‹(About this Course) 1.6 è¯¾ç¨‹èµ„æº(Course Resources) 1.7 Geoffery Hinton ä¸“è®¿(Geoffery Hinton interview) ç¬¬äºŒå‘¨ï¼šç¥ç»ç½‘ç»œçš„ç¼–ç¨‹åŸºç¡€(Basics of Neural Network programming) 2.1 äºŒåˆ†ç±»(Binary Classification) 2.2 é€»è¾‘å›å½’(Logistic Regression) 2.3 é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°ï¼ˆLogistic Regression Cost Functionï¼‰ 2.4 æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰ 2.5 å¯¼æ•°ï¼ˆDerivativesï¼‰ 2.6 æ›´å¤šçš„å¯¼æ•°ä¾‹å­ï¼ˆMore Derivative Examplesï¼‰ 2.7 è®¡ç®—å›¾ï¼ˆComputation Graphï¼‰ 2.8 è®¡ç®—å›¾å¯¼æ•°ï¼ˆDerivatives with a Computation Graphï¼‰ 2.9 é€»è¾‘å›å½’çš„æ¢¯åº¦ä¸‹é™ï¼ˆLogistic Regression Gradient Descentï¼‰ 2.10 æ¢¯åº¦ä¸‹é™çš„ä¾‹å­(Gradient Descent on m Examples) 2.11 å‘é‡åŒ–(Vectorization) 2.12 æ›´å¤šçš„å‘é‡åŒ–ä¾‹å­ï¼ˆMore Examples of Vectorizationï¼‰ 2.13 å‘é‡åŒ–é€»è¾‘å›å½’(Vectorizing Logistic Regression) 2.14 å‘é‡åŒ–é€»è¾‘å›å½’çš„æ¢¯åº¦è®¡ç®—ï¼ˆVectorizing Logistic Regressionâ€™s Gradientï¼‰ 2.15 Pythonä¸­çš„å¹¿æ’­æœºåˆ¶ï¼ˆBroadcasting in Pythonï¼‰ 2.16 å…³äº Pythonä¸numpyå‘é‡çš„ä½¿ç”¨ï¼ˆA note on python or numpy vectorsï¼‰ 2.17 Jupyter/iPython Notebookså¿«é€Ÿå…¥é—¨ï¼ˆQuick tour of Jupyter/iPython Notebooksï¼‰ 2.18 é€»è¾‘å›å½’æŸå¤±å‡½æ•°è¯¦è§£ï¼ˆExplanation of logistic regression cost functionï¼‰ ç¬¬ä¸‰å‘¨ï¼šæµ…å±‚ç¥ç»ç½‘ç»œ(Shallow neural networks) 3.1 ç¥ç»ç½‘ç»œæ¦‚è¿°ï¼ˆNeural Network Overviewï¼‰ 3.2 ç¥ç»ç½‘ç»œçš„è¡¨ç¤ºï¼ˆNeural Network Representationï¼‰ 3.3 è®¡ç®—ä¸€ä¸ªç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼ˆComputing a Neural Networkâ€™s outputï¼‰ 3.4 å¤šæ ·æœ¬å‘é‡åŒ–ï¼ˆVectorizing across multiple examplesï¼‰ 3.5 å‘é‡åŒ–å®ç°çš„è§£é‡Šï¼ˆJustification for vectorized implementationï¼‰ 3.6 æ¿€æ´»å‡½æ•°ï¼ˆActivation functionsï¼‰ 3.7 ä¸ºä»€ä¹ˆéœ€è¦éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Ÿï¼ˆwhy need a nonlinear activation function?ï¼‰ 3.8 æ¿€æ´»å‡½æ•°çš„å¯¼æ•°ï¼ˆDerivatives of activation functionsï¼‰ 3.9 ç¥ç»ç½‘ç»œçš„æ¢¯åº¦ä¸‹é™ï¼ˆGradient descent for neural networksï¼‰ 3.10ï¼ˆé€‰ä¿®ï¼‰ç›´è§‚ç†è§£åå‘ä¼ æ’­ï¼ˆBackpropagation intuitionï¼‰ 3.11 éšæœºåˆå§‹åŒ–ï¼ˆRandom+Initializationï¼‰ ç¬¬å››å‘¨ï¼šæ·±å±‚ç¥ç»ç½‘ç»œ(Deep Neural Networks) 4.1 æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep L-layer neural networkï¼‰ 4.2 å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼ˆForward and backward propagationï¼‰ 4.3 æ·±å±‚ç½‘ç»œä¸­çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼ˆForward propagation in a Deep Networkï¼‰ 4.4 æ ¸å¯¹çŸ©é˜µçš„ç»´æ•°ï¼ˆGetting your matrix dimensions rightï¼‰ 4.5 ä¸ºä»€ä¹ˆä½¿ç”¨æ·±å±‚è¡¨ç¤ºï¼Ÿï¼ˆWhy deep representations?ï¼‰ 4.6 æ­å»ºç¥ç»ç½‘ç»œå—ï¼ˆBuilding blocks of deep neural networksï¼‰ 4.7 å‚æ•°VSè¶…å‚æ•°ï¼ˆParameters vs Hyperparametersï¼‰ 4.8 æ·±åº¦å­¦ä¹ å’Œå¤§è„‘çš„å…³è”æ€§ï¼ˆWhat does this have to do with the brain?ï¼‰ ç¬¬äºŒé—¨è¯¾ æ”¹å–„æ·±å±‚ç¥ç»ç½‘ç»œï¼šè¶…å‚æ•°è°ƒè¯•ã€æ­£åˆ™åŒ–ä»¥åŠä¼˜åŒ–(Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)ç¬¬ä¸€å‘¨ï¼šæ·±åº¦å­¦ä¹ çš„å®ç”¨å±‚é¢(Practical aspects of Deep Learning) 1.1 è®­ç»ƒï¼ŒéªŒè¯ï¼Œæµ‹è¯•é›†ï¼ˆTrain / Dev / Test setsï¼‰ 1.2 åå·®ï¼Œæ–¹å·®ï¼ˆBias /Varianceï¼‰ 1.3 æœºå™¨å­¦ä¹ åŸºç¡€ï¼ˆBasic Recipe for Machine Learningï¼‰ 1.4 æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰ 1.5 ä¸ºä»€ä¹ˆæ­£åˆ™åŒ–æœ‰åˆ©äºé¢„é˜²è¿‡æ‹Ÿåˆå‘¢ï¼Ÿï¼ˆWhy regularization reduces overfitting?ï¼‰ 1.6 dropout æ­£åˆ™åŒ–ï¼ˆDropout Regularizationï¼‰ 1.7 ç†è§£ dropoutï¼ˆUnderstanding Dropoutï¼‰ 1.8 å…¶ä»–æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆOther regularization methodsï¼‰ 1.9 æ ‡å‡†åŒ–è¾“å…¥ï¼ˆNormalizing inputsï¼‰ 1.10 æ¢¯åº¦æ¶ˆå¤±/æ¢¯åº¦çˆ†ç‚¸ï¼ˆVanishing / Exploding gradientsï¼‰ 1.11 ç¥ç»ç½‘ç»œçš„æƒé‡åˆå§‹åŒ–ï¼ˆWeight Initialization for Deep NetworksVanishing /Exploding gradientsï¼‰ 1.12 æ¢¯åº¦çš„æ•°å€¼é€¼è¿‘ï¼ˆNumerical approximation of gradientsï¼‰ 1.13 æ¢¯åº¦æ£€éªŒï¼ˆGradient checkingï¼‰ 1.14 æ¢¯åº¦æ£€éªŒåº”ç”¨çš„æ³¨æ„äº‹é¡¹ï¼ˆGradient Checking Implementation Notesï¼‰ ç¬¬äºŒå‘¨ï¼šä¼˜åŒ–ç®—æ³• (Optimization algorithms) 2.1 Mini-batch æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch gradient descentï¼‰ 2.2 ç†è§£Mini-batch æ¢¯åº¦ä¸‹é™ï¼ˆUnderstanding Mini-batch gradient descentï¼‰ 2.3 æŒ‡æ•°åŠ æƒå¹³å‡ï¼ˆExponentially weighted averagesï¼‰ 2.4 ç†è§£æŒ‡æ•°åŠ æƒå¹³å‡ï¼ˆUnderstanding Exponentially weighted averagesï¼‰ 2.5 æŒ‡æ•°åŠ æƒå¹³å‡çš„åå·®ä¿®æ­£ï¼ˆBias correction in exponentially weighted averagesï¼‰ 2.6 momentumæ¢¯åº¦ä¸‹é™ï¼ˆGradient descent with momentumï¼‰ 2.7 RMSpropâ€”â€”root mean square propï¼ˆRMSpropï¼‰ 2.8 Adamä¼˜åŒ–ç®—æ³•ï¼ˆAdam optimization algorithmï¼‰ 2.9 å­¦ä¹ ç‡è¡°å‡ï¼ˆLearning rate decayï¼‰ 2.10 å±€éƒ¨æœ€ä¼˜é—®é¢˜ï¼ˆThe problem of local optimaï¼‰ ç¬¬ä¸‰å‘¨è¶…å‚æ•°è°ƒè¯•ï¼Œbatchæ­£åˆ™åŒ–å’Œç¨‹åºæ¡†æ¶ï¼ˆHyperparameter tuning, Batch Normalization and Programming Frameworks) 3.1 è°ƒè¯•å¤„ç†ï¼ˆTuning processï¼‰ 3.2 ä¸ºè¶…å‚æ•°é€‰æ‹©å’Œé€‚åˆèŒƒå›´ï¼ˆUsing an appropriate scale to pick hyperparametersï¼‰ 3.3 è¶…å‚æ•°è®­ç»ƒçš„å®è·µï¼šPandas vs. Caviarï¼ˆHyperparameters tuning in practice: Pandas vs. Caviarï¼‰ 3.4 ç½‘ç»œä¸­çš„æ­£åˆ™åŒ–æ¿€æ´»å‡½æ•°ï¼ˆNormalizing activations in a networkï¼‰ 3.5 å°† Batch Normæ‹Ÿåˆè¿›ç¥ç»ç½‘ç»œï¼ˆFitting Batch Norm into a neural networkï¼‰ 3.6 ä¸ºä»€ä¹ˆBatch Normå¥æ•ˆï¼Ÿï¼ˆWhy does Batch Norm work?ï¼‰ 3.7 æµ‹è¯•æ—¶çš„Batch Normï¼ˆBatch Norm at test timeï¼‰ 3.8 Softmax å›å½’ï¼ˆSoftmax Regressionï¼‰ 3.9 è®­ç»ƒä¸€ä¸ªSoftmax åˆ†ç±»å™¨ï¼ˆTraining a softmax classifierï¼‰ 3.10 æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆDeep learning frameworksï¼‰ 3.11 TensorFlowï¼ˆTensorFlowï¼‰ ç¬¬ä¸‰é—¨è¯¾ ç»“æ„åŒ–æœºå™¨å­¦ä¹ é¡¹ç›® (Structuring Machine Learning Projects)ç¬¬ä¸€å‘¨ï¼šæœºå™¨å­¦ä¹ ç­–ç•¥ï¼ˆ1ï¼‰(ML Strategy (1)) 1.1 ä¸ºä»€ä¹ˆæ˜¯MLç­–ç•¥ï¼Ÿ (Why ML Strategy) 1.2 æ­£äº¤åŒ–(Orthogonalization) 1.3 å•ä¸€æ•°å­—è¯„ä¼°æŒ‡æ ‡(Single number evaluation metric) 1.4 æ»¡è¶³å’Œä¼˜åŒ–æŒ‡æ ‡ (Satisficing and Optimizing metric) 1.5 è®­ç»ƒé›†ã€å¼€å‘é›†ã€æµ‹è¯•é›†çš„åˆ’åˆ†(Train/dev/test distributions) 1.6 å¼€å‘é›†å’Œæµ‹è¯•é›†çš„å¤§å° (Size of the dev and test sets) 1.7 ä»€ä¹ˆæ—¶å€™æ”¹å˜å¼€å‘é›†/æµ‹è¯•é›†å’Œè¯„ä¼°æŒ‡æ ‡(When to change dev/test sets and metrics) 1.8 ä¸ºä»€ä¹ˆæ˜¯äººçš„è¡¨ç° (Why human-level performance?) 1.9 å¯é¿å…åå·®(Avoidable bias) 1.10 ç†è§£äººç±»çš„è¡¨ç° (Understanding human-level performance) 1.11 è¶…è¿‡äººç±»çš„è¡¨ç°(Surpassing human-level performance) 1.12 æ”¹å–„ä½ çš„æ¨¡å‹è¡¨ç° (Improving your model performance) ç¬¬äºŒå‘¨ï¼šæœºå™¨å­¦ä¹ ç­–ç•¥ï¼ˆ2ï¼‰(ML Strategy (2)) 2.1 è¯¯å·®åˆ†æ (Carrying out error analysis) 2.2 æ¸…é™¤æ ‡æ³¨é”™è¯¯çš„æ•°æ®(Cleaning up incorrectly labeled data) 2.3 å¿«é€Ÿæ­å»ºä½ çš„ç¬¬ä¸€ä¸ªç³»ç»Ÿï¼Œå¹¶è¿›è¡Œè¿­ä»£(Build your first system quickly, then iterate) 2.4 åœ¨ä¸åŒçš„åˆ†å¸ƒä¸Šçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›† (Training and testing on different distributions) 2.5 æ•°æ®åˆ†å¸ƒä¸åŒ¹é…çš„åå·®ä¸æ–¹å·®åˆ†æ (Bias and Variance with mismatched data distributions) 2.6 å¤„ç†æ•°æ®ä¸åŒ¹é…é—®é¢˜(Addressing data mismatch) 2.7 è¿ç§»å­¦ä¹  (Transfer learning) 2.8 å¤šä»»åŠ¡å­¦ä¹ (Multi-task learning) 2.9 ä»€ä¹ˆæ˜¯ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ ï¼Ÿ (What is end-to-end deep learning?) 2.10 æ˜¯å¦ä½¿ç”¨ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ–¹æ³• (Whether to use end-to-end deep learning) ç¬¬å››é—¨è¯¾ å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networksï¼‰ç¬¬ä¸€å‘¨ å·ç§¯ç¥ç»ç½‘ç»œ(Foundations of Convolutional Neural Networks) 1.1 è®¡ç®—æœºè§†è§‰ï¼ˆComputer visionï¼‰ 1.2 è¾¹ç¼˜æ£€æµ‹ç¤ºä¾‹ï¼ˆEdge detection exampleï¼‰ 1.3 æ›´å¤šè¾¹ç¼˜æ£€æµ‹å†…å®¹ï¼ˆMore edge detectionï¼‰ 1.4 Padding 1.5 å·ç§¯æ­¥é•¿ï¼ˆStrided convolutionsï¼‰ 1.6 ä¸‰ç»´å·ç§¯ï¼ˆConvolutions over volumesï¼‰ 1.7 å•å±‚å·ç§¯ç½‘ç»œï¼ˆOne layer of a convolutional networkï¼‰ 1.8 ç®€å•å·ç§¯ç½‘ç»œç¤ºä¾‹ï¼ˆA simple convolution network exampleï¼‰ 1.9 æ± åŒ–å±‚ï¼ˆPooling layersï¼‰ 1.10 å·ç§¯ç¥ç»ç½‘ç»œç¤ºä¾‹ï¼ˆConvolutional neural network exampleï¼‰ 1.11 ä¸ºä»€ä¹ˆä½¿ç”¨å·ç§¯ï¼Ÿï¼ˆWhy convolutions?ï¼‰ ç¬¬äºŒå‘¨ æ·±åº¦å·ç§¯ç½‘ç»œï¼šå®ä¾‹æ¢ç©¶(Deep convolutional models: case studies) 2.1 ä¸ºä»€ä¹ˆè¦è¿›è¡Œå®ä¾‹æ¢ç©¶ï¼Ÿï¼ˆWhy look at case studies?ï¼‰ 2.2 ç»å…¸ç½‘ç»œï¼ˆClassic networksï¼‰ 2.3 æ®‹å·®ç½‘ç»œï¼ˆResidual Networks (ResNets)ï¼‰ 2.4 æ®‹å·®ç½‘ç»œä¸ºä»€ä¹ˆæœ‰ç”¨ï¼Ÿï¼ˆWhy ResNets work?ï¼‰ 2.5 ç½‘ç»œä¸­çš„ç½‘ç»œä»¥åŠ 1Ã—1 å·ç§¯ï¼ˆNetwork in Network and 1Ã—1 convolutionsï¼‰ 2.6 è°·æ­Œ Inception ç½‘ç»œç®€ä»‹ï¼ˆInception network motivationï¼‰ 2.7 Inception ç½‘ç»œï¼ˆInception networkï¼‰ 2.8 ä½¿ç”¨å¼€æºçš„å®ç°æ–¹æ¡ˆï¼ˆUsing open-source implementationsï¼‰ 2.9 è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰ 2.10 æ•°æ®æ‰©å……ï¼ˆData augmentationï¼‰ 2.11 è®¡ç®—æœºè§†è§‰ç°çŠ¶ï¼ˆThe state of computer visionï¼‰ ç¬¬ä¸‰å‘¨ ç›®æ ‡æ£€æµ‹ï¼ˆObject detectionï¼‰ 3.1 ç›®æ ‡å®šä½ï¼ˆObject localizationï¼‰ 3.2 ç‰¹å¾ç‚¹æ£€æµ‹ï¼ˆLandmark detectionï¼‰ 3.3 ç›®æ ‡æ£€æµ‹ï¼ˆObject detectionï¼‰ 3.4 å·ç§¯çš„æ»‘åŠ¨çª—å£å®ç°ï¼ˆConvolutional implementation of sliding windowsï¼‰ 3.5 Bounding Boxé¢„æµ‹ï¼ˆBounding box predictionsï¼‰ 3.6 äº¤å¹¶æ¯”ï¼ˆIntersection over unionï¼‰ 3.7 éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNon-max suppressionï¼‰ 3.8 Anchor Boxes 3.9 YOLO ç®—æ³•ï¼ˆPutting it together: YOLO algorithmï¼‰ 3.10 å€™é€‰åŒºåŸŸï¼ˆé€‰ä¿®ï¼‰ï¼ˆRegion proposals (Optional)ï¼‰ ç¬¬å››å‘¨ ç‰¹æ®Šåº”ç”¨ï¼šäººè„¸è¯†åˆ«å’Œç¥ç»é£æ ¼è½¬æ¢ï¼ˆSpecial applications: Face recognition &amp;Neural style transferï¼‰ 4.1 ä»€ä¹ˆæ˜¯äººè„¸è¯†åˆ«ï¼Ÿ(What is face recognition?) 4.2 One-Shotå­¦ä¹ ï¼ˆOne-shot learningï¼‰ 4.3 Siamese ç½‘ç»œï¼ˆSiamese networkï¼‰ 4.4 Triplet æŸå¤±ï¼ˆTriplet æŸå¤±ï¼‰ 4.5 é¢éƒ¨éªŒè¯ä¸äºŒåˆ†ç±»ï¼ˆFace verification and binary classificationï¼‰ 4.6 ä»€ä¹ˆæ˜¯ç¥ç»é£æ ¼è½¬æ¢ï¼Ÿï¼ˆWhat is neural style transfer?ï¼‰ 4.7 ä»€ä¹ˆæ˜¯æ·±åº¦å·ç§¯ç½‘ç»œï¼Ÿï¼ˆWhat are deep ConvNets learning?ï¼‰ 4.8 ä»£ä»·å‡½æ•°ï¼ˆCost functionï¼‰ 4.9 å†…å®¹ä»£ä»·å‡½æ•°ï¼ˆContent cost functionï¼‰ 4.10 é£æ ¼ä»£ä»·å‡½æ•°ï¼ˆStyle cost functionï¼‰ 4.11 ä¸€ç»´åˆ°ä¸‰ç»´æ¨å¹¿ï¼ˆ1D and 3D generalizations of modelsï¼‰ ç¬¬äº”é—¨è¯¾ åºåˆ—æ¨¡å‹(Sequence Models)ç¬¬ä¸€å‘¨ å¾ªç¯åºåˆ—æ¨¡å‹ï¼ˆRecurrent Neural Networksï¼‰ 1.1 ä¸ºä»€ä¹ˆé€‰æ‹©åºåˆ—æ¨¡å‹ï¼Ÿï¼ˆWhy Sequence Models?ï¼‰ 1.2 æ•°å­¦ç¬¦å·ï¼ˆNotationï¼‰ 1.3 å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆRecurrent Neural Network Modelï¼‰ 1.4 é€šè¿‡æ—¶é—´çš„åå‘ä¼ æ’­ï¼ˆBackpropagation through timeï¼‰ 1.5 ä¸åŒç±»å‹çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆDifferent types of RNNsï¼‰ 1.6 è¯­è¨€æ¨¡å‹å’Œåºåˆ—ç”Ÿæˆï¼ˆLanguage model and sequence generationï¼‰ 1.7 å¯¹æ–°åºåˆ—é‡‡æ ·ï¼ˆSampling novel sequencesï¼‰ 1.8 å¾ªç¯ç¥ç»ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±ï¼ˆVanishing gradients with RNNsï¼‰ 1.9 GRUå•å…ƒï¼ˆGated Recurrent Unitï¼ˆGRUï¼‰ï¼‰ 1.10 é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼ˆlong short term memoryï¼‰unitï¼‰ 1.11 åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆBidirectional RNNï¼‰ 1.12 æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆDeep RNNsï¼‰ ç¬¬äºŒå‘¨ è‡ªç„¶è¯­è¨€å¤„ç†ä¸è¯åµŒå…¥ï¼ˆNatural Language Processing and Word Embeddingsï¼‰ 2.1 è¯æ±‡è¡¨å¾ï¼ˆWord Representationï¼‰ 2.2 ä½¿ç”¨è¯åµŒå…¥ï¼ˆUsing Word Embeddingsï¼‰ 2.3 è¯åµŒå…¥çš„ç‰¹æ€§ï¼ˆProperties of Word Embeddingsï¼‰ 2.4 åµŒå…¥çŸ©é˜µï¼ˆEmbedding Matrixï¼‰ 2.5 å­¦ä¹ è¯åµŒå…¥ï¼ˆLearning Word Embeddingsï¼‰ 2.6 Word2Vec 2.7 è´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰ 2.8 GloVe è¯å‘é‡ï¼ˆGloVe Word Vectorsï¼‰ 2.9 æƒ…ç»ªåˆ†ç±»ï¼ˆSentiment Classificationï¼‰ 2.10 è¯åµŒå…¥é™¤åï¼ˆDebiasing Word Embeddingsï¼‰ ç¬¬ä¸‰å‘¨ åºåˆ—æ¨¡å‹å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSequence models &amp; Attention mechanismï¼‰ 3.1 åŸºç¡€æ¨¡å‹ï¼ˆBasic Modelsï¼‰ 3.2 é€‰æ‹©æœ€å¯èƒ½çš„å¥å­ï¼ˆPicking the most likely sentenceï¼‰ 3.3 é›†æŸæœç´¢ï¼ˆBeam Searchï¼‰ 3.4 æ”¹è¿›é›†æŸæœç´¢ï¼ˆRefinements to Beam Searchï¼‰ 3.5 é›†æŸæœç´¢çš„è¯¯å·®åˆ†æï¼ˆError analysis in beam searchï¼‰ 3.6 Bleu å¾—åˆ†ï¼ˆé€‰ä¿®ï¼‰ï¼ˆBleu Score (optional)ï¼‰ 3.7 æ³¨æ„åŠ›æ¨¡å‹ç›´è§‚ç†è§£ï¼ˆAttention Model Intuitionï¼‰ 3.8æ³¨æ„åŠ›æ¨¡å‹ï¼ˆAttention Modelï¼‰ 3.9è¯­éŸ³è¯†åˆ«ï¼ˆSpeech recognitionï¼‰ 3.10è§¦å‘å­—æ£€æµ‹ï¼ˆTrigger Word Detectionï¼‰ 3.11ç»“è®ºå’Œè‡´è°¢ï¼ˆConclusion and thank youï¼‰ äººå·¥æ™ºèƒ½å¤§å¸ˆè®¿è°ˆ å´æ©è¾¾é‡‡è®¿ Geoffery Hinton å´æ©è¾¾é‡‡è®¿ Ian Goodfellow å´æ©è¾¾é‡‡è®¿ Ruslan Salakhutdinov å´æ©è¾¾é‡‡è®¿ Yoshua Bengio å´æ©è¾¾é‡‡è®¿ æ—å…ƒåº† å´æ©è¾¾é‡‡è®¿ Pieter Abbeel å´æ©è¾¾é‡‡è®¿ Andrej Karpathy é™„ä»¶ æ·±åº¦å­¦ä¹ ç¬¦å·æŒ‡å—ï¼ˆåŸè¯¾ç¨‹ç¿»è¯‘ï¼‰]]></content>
      <categories>
        <category>è§†é¢‘å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è´å¶æ–¯åˆ†ç±»å™¨]]></title>
    <url>%2F2019%2F03%2F28%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
    <content type="text"><![CDATA[[TOC] æ¦‚ç‡è®ºçš„çŸ¥è¯† æ¡ä»¶æ¦‚ç‡ P(A|B)=P(A\cap B)/P(B)å·²çŸ¥Bå‘ç”Ÿçš„æ¦‚ç‡ï¼Œæ±‚Aå‘ç”Ÿçš„æ¦‚ç‡ å…¨æ¦‚ç‡ P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i)è´å¶æ–¯æ¨æ–­ P(A|B)=P(A)\frac{P(B|A)}{P(B)} P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)}$P(A)$ï¼šPrior probability å…ˆéªŒæ¦‚ç‡ï¼Œåœ¨Bäº‹ä»¶å‘ç”Ÿä¹‹å‰ï¼Œå¯¹Aäº‹ä»¶åšä¸€ä¸ªåˆ¤æ–­ $P(A|B)$:Posterior probability åéªŒæ¦‚ç‡ï¼Œåœ¨Bäº‹ä»¶å‘ç”Ÿä¹‹åï¼Œå¯¹Aäº‹ä»¶çš„æ¦‚ç‡é‡æ–°è¯„ä¼° $P(B|A)/P(B)$:ç§°ä¸ºå¯èƒ½æ€§å‡½æ•°ï¼Œä¸€ä¸ªè°ƒæ•´å› å­ åéªŒæ¦‚ç‡=å…ˆéªŒæ¦‚ç‡*è°ƒæ•´å› å­ ï¼ˆå¯çŸ¥ï¼Œè°ƒæ•´å› æ­¤&gt;1,å‘ç”Ÿæ¦‚ç‡å¢å¤§äº†ï¼Œ è´å¶æ–¯å†³ç­–è®ºè‹±æ–‡ï¼šBayesian decision theory è®¾æœ‰$N$ç§å¯èƒ½çš„ç±»åˆ«, å³Î³=${c_1,c_2,â€¦,c_N}$. $Î»_ij$æ˜¯å°†ä¸€ä¸ªçœŸå®ç±»åˆ«ä¸º$c_j$çš„æ ·æœ¬åˆ¤ä¸º$c_x$çš„æŸå¤±ã€‚ åŸºäºåéªŒæ¦‚ç‡å¯å¾—å°†æ ·æœ¬åˆ†ç±»æ‰€äº§ç”Ÿçš„æœŸæœ›æŸå¤±, æˆ–è€…æˆä¸ºæ¡ä»¶é£é™©(Conditional Risk) R(C_i|x)=âˆ‘_{j=1}^NÎ»_{ij}P(c_j|x)äºæ˜¯ï¼Œ æˆ‘ä»¬çš„ä»»åŠ¡å°±æ˜¯å¯»æ‰¾åˆ¤å®šå‡†åˆ™hï¼Œ ä»¤$Ï‡â†’Î³$ ä½¿å¾—æœ€å°åŒ–æ€»ä½“é£é™©ï¼Œ$R(h)=E_x[R(h(x)|x]$æœ€å°. å¯¹äºæ¯ä¸€ä¸ª$x$ï¼Œè‹¥$h$éƒ½èƒ½æœ€å°åŒ–æ¡ä»¶é£é™©ï¼Œé‚£ä¹ˆæ€»ä½“ä¹Ÿè¢«æœ€å°åŒ–äº†ã€‚ å¯ä»¥ç®€åŒ–ä¸ºå¯¹æ¯ä¸ªæ ·æœ¬é€‰æ‹©å…¶æ¡ä»¶é£é™©æœ€å°çš„åˆ†ç±», å³: h(x)=arg \min_{câŠ‚Î»}R(c|x)æ­¤$h(x)$å°±æ˜¯è´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨ã€‚ $R(h)$ä¸ºè´å¶æ–¯é£é™©(Bayes Risk), $1âˆ’R(h)$åæ˜ äº†åˆ†ç±»å™¨çš„æœ€ä¼˜æ€§èƒ½. å…·ä½“æ¥è¯´ï¼Œå¦‚æœç›®æ ‡æ˜¯æœ€å°åŒ–åˆ†ç±»é”™è¯¯ç‡ï¼Œ \lambda_{ij}=\begin{cases} 0\ \ i==j\\1 \ \ \ i!=j \end{cases}åˆ™$R(c|x)=1-p(c|x)$ï¼Œå› æ­¤å¯çŸ¥ï¼Œ$h(x)=\max_{c\in C} p(c|x)$ å¯¹äºæ ·æœ¬$x$,é€‰æ‹©åéªŒæ¦‚ç‡$P(c|X)$æœ€å¤§çš„ç±»åˆ«ä¸ºæ ‡è®°ã€‚ é—®é¢˜è½¬æ¢ä¸º P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)}æ±‚å…ˆéªŒæ¦‚ç‡å’Œä¼¼ç„¶($P(x|c)$) å…¶ä¸­ $P(c)$è¡¨è¾¾äº†æ ·æœ¬ç©ºé—´ç§å„ç±»æ ·æœ¬æ‰€å çš„æ¯”åˆ—ï¼Œæ ¹æ®å¤§æ•°å®šå¾‹ï¼Œå½“æ ·æœ¬è¶³å¤Ÿå……åˆ†çš„ç‹¬ç«‹åŒåˆ†å¸ƒæ ·æœ¬æ˜¯ï¼Œå¯ä»¥é¢‘ç‡ä¼°è®¡ $P(x|c)$,æ¶‰åŠå…³äºxæ‰€ä»¥å±æ€§çš„è”åˆæ¦‚ç‡ï¼Œç”¨é¢‘ç‡ä¼°è®¡æ¦‚ç‡å¯èƒ½ä¸å¤ªå¥½ï¼Œå¯¹äºä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡çš„ä¸€ç§å® ç”¨ç­–ç•¥æ˜¯å…ˆå‡è®¾å…·æœ‰æŸç§ç¡®å®šçš„æ¦‚ç‡åˆ†å¸ƒå½¢å¼ï¼Œå†åŸºäºè®­ç»ƒæ ·æœ¬å¯¹æ¦‚ç‡åˆ†å¸ƒçš„å‚æ•°è¿›è¡Œä¼°è®¡ã€‚ $P(x|c)$æ˜¯ç±»æ¡ä»¶æ¦‚ç‡ï¼Œç”±æŸä¸ªåˆ†å¸ƒå†³å®šï¼Œ$P(x|\theta_c)$æ¥è¡¨ç¤ºäº† é¢‘ç‡æ³¨æ„æ´¾è®¤ä¸ºå¯ä»¥é€šè¿‡ä¼˜åŒ–ä¼¼ç„¶å‡½æ•°ä¼°è®¡å‚æ•°ã€‚$D_c$ç±»åˆ«cçš„æ ·æœ¬é›†åˆï¼Œç‹¬ç«‹åŒåˆ†å¸ƒ P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c) LL(\theta_c)=log P(D_c|\theta_c)æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è‹±æ–‡ï¼šnaive Bayes classifier å‡è®¾ï¼šå±æ€§æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼Œæ¯ä¸ªå±æ€§ç‹¬ç«‹æ€§å¯¹åˆ†ç±»ç»“æœå‘ç”Ÿå½±å“ P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)\Pi_{i=1}^{d}P(x_i|c)}{P(x)}å¯¹äºä¸€ä¸ª$x$ï¼Œ$P(x)$éƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤è´å¶æ–¯æ¨¡å‹å¯å†™ä¸º h_{nb}(x)=arg max_{c\in y}P(c)\Pi_{i=1}^{d}P(x_i|c)è®¡ç®—è¿‡ç¨‹å‡è®¾$D_{c_i}$è¡¨ç¤ºç¬¬iç±»çš„æ ·æœ¬é›†åˆï¼Œ $P(c_i)=\frac{|D_{c_i}|}{|D|}$ å¦‚æœæ˜¯ç¦»æ•£å±æ€§ P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|}å¦‚æœæ˜¯è¿ç»­å±æ€§ï¼Œ$P(x_i|c_i)$æœä»$N(u_{c,i},\theta_{c,i}^2)$çš„åˆ†å¸ƒ P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2}) $P(c_i)\Pi_{i=1}^{N}P(x_i|c_i)$ æ³¨æ„ä¸ºäº†é¿å…å…¶ä»–å±æ€§æºå¸¦çš„ä¿¡æ¯è¢«è®­ç»ƒé›†ä¸­æœªå‡ºç°çš„å±æ€§å€¼æŠ¹å»ï¼Œå› æ­¤ç”¨æ‹‰æ™®æ‹‰æ–¯ä¿®æ­£ï¼ˆLaplacian correction) P(c)=\frac{|D_{c_i}|+1}{|D|+N}\\ P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}$N$:è®­ç»ƒé›†å¯èƒ½å‡ºç°çš„ç±»åˆ«æ•° $N_i$:ç¬¬iä¸ªå±æ€§å¯èƒ½çš„å–å€¼æ•° æ˜¾ç„¶ï¼Œæ‹‰æ™®æ‹‰æ–¯ä¿®æ­£é¿å…å› è®­ç»ƒé›†ä¸å……åˆ†å¯¼å‡ºçš„æ¦‚ç‡ä¼°å€¼ä¸º0çš„æƒ…å†µ æœ´ç´ è´å¶æ–¯çš„ç§ç±»å†scikit-learnä¸­ï¼Œä¸€å…±æœ‰ä¸‰ä¸ªæœ´ç´ è´å¶æ–¯ï¼Œåˆ†åˆ«æ˜¯ GaussianNB P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})12345678910111213141516171819202122#å¯¼å…¥åŒ…import pandas as pdfrom sklearn.naive_bayes import GaussianNBfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_score#å¯¼å…¥æ•°æ®é›†from sklearn import datasetsiris=datasets.load_iris()#åˆ‡åˆ†æ•°æ®é›†Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, random_state=42)#å»ºæ¨¡clf = GaussianNB()clf.fit(Xtrain, ytrain)#åœ¨æµ‹è¯•é›†ä¸Šæ‰§è¡Œé¢„æµ‹ï¼Œprobaå¯¼å‡ºçš„æ˜¯æ¯ä¸ªæ ·æœ¬å±äºæŸç±»çš„æ¦‚ç‡clf.predict(Xtest)clf.predict_proba(Xtest) #æ¯ä¸€ç±»è®¡ç®—ç»“æœéƒ½è¾“å‡º#æµ‹è¯•å‡†ç¡®ç‡accuracy_score(ytest, clf.predict(Xtest)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npimport pandas as pdimport randomdataSet =pd.read_csv('iris.txt',header = None)dataSet.head()def randSplit(dataSet, rate): l = list(dataSet.index) #æå–å‡ºç´¢å¼• random.shuffle(l) #éšæœºæ‰“ä¹±ç´¢å¼• dataSet.index = l #å°†æ‰“ä¹±åçš„ç´¢å¼•é‡æ–°èµ‹å€¼ç»™åŸæ•°æ®é›† n = dataSet.shape[0] #æ€»è¡Œæ•° m = int(n * rate) #è®­ç»ƒé›†çš„æ•°é‡ train = dataSet.loc[range(m), :] #æå–å‰mä¸ªè®°å½•ä½œä¸ºè®­ç»ƒé›† test = dataSet.loc[range(m, n), :] #å‰©ä¸‹çš„ä½œä¸ºæµ‹è¯•é›† dataSet.index = range(dataSet.shape[0]) #æ›´æ–°åŸæ•°æ®é›†çš„ç´¢å¼• test.index = range(test.shape[0]) #æ›´æ–°æµ‹è¯•é›†çš„ç´¢å¼•train,test=randSplit(dataSet, 0.8)def gnb_classify(train,test): labels = train.iloc[:,-1].value_counts().index #æå–è®­ç»ƒé›†çš„æ ‡ç­¾ç§ç±» mean =[] #å­˜æ”¾æ¯ä¸ªç±»åˆ«çš„å‡å€¼ std =[] #å­˜æ”¾æ¯ä¸ªç±»åˆ«çš„æ–¹å·® result = [] #å­˜æ”¾æµ‹è¯•é›†çš„é¢„æµ‹ç»“æœ for i in labels: item = train.loc[train.iloc[:,-1]==i,:] #åˆ†åˆ«æå–å‡ºæ¯ä¸€ç§ç±»åˆ« m = item.iloc[:,:-1].mean() #å½“å‰ç±»åˆ«çš„å¹³å‡å€¼ s = np.sum((item.iloc[:,:-1]-m)**2)/(item.shape[0]) #å½“å‰ç±»åˆ«çš„æ–¹å·® mean.append(m) #å°†å½“å‰ç±»åˆ«çš„å¹³å‡å€¼è¿½åŠ è‡³åˆ—è¡¨ std.append(s) #å°†å½“å‰ç±»åˆ«çš„æ–¹å·®è¿½åŠ è‡³åˆ—è¡¨ means = pd.DataFrame(mean,index=labels) #å˜æˆDFæ ¼å¼ï¼Œç´¢å¼•ä¸ºç±»æ ‡ç­¾ stds = pd.DataFrame(std,index=labels) #å˜æˆDFæ ¼å¼ï¼Œç´¢å¼•ä¸ºç±»æ ‡ç­¾ for j in range(test.shape[0]): iset = test.iloc[j,:-1].tolist() #å½“å‰æµ‹è¯•å®ä¾‹ iprob = np.exp(-1*(iset-means)**2/(stds*2))/(np.sqrt(2*np.pi*stds)) #æ­£æ€åˆ†å¸ƒå…¬å¼ prob = train.iloc[:,-1].value_counts()/len(train.iloc[:,-1]) #åˆå§‹åŒ–å½“å‰å®ä¾‹æ€»æ¦‚ç‡ for k in range(test.shape[1]-1): #éå†æ¯ä¸ªç‰¹å¾ prob *= iprob[k] #ç‰¹å¾æ¦‚ç‡ä¹‹ç§¯å³ä¸ºå½“å‰å®ä¾‹æ¦‚ç‡ cla = prob.index[np.argmax(prob.values)] #è¿”å›æœ€å¤§æ¦‚ç‡çš„ç±»åˆ« result.append(cla) test['predict']=result acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean() #è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡ print(f'æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡ä¸º&#123;acc&#125;') return testgnb_classify(train,test)for i in range(20): train,test= randSplit(dataSet, 0.8) gnb_classify(train,test) MultinomialNBå…ˆéªŒæ¦‚ç‡å¤šé¡¹å¼åˆ†å¸ƒçš„æœ´ç´ è´å¶æ–¯ï¼Œå‡è®¾ç‰¹å¾æ˜¯ç”±ä¸€å…±ç®€å•å¤šé¡¹å¼åˆ†å¸ƒç”Ÿæˆï¼Œå¤šé¡¹åˆ†å¸ƒå¯ä»¥æè¿°å„ç§ç±»å‹æ ·æœ¬å‡ºç°çš„é¢‘ç‡ï¼Œè¯¥æ¨¡å‹å¸¸ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œç‰¹åˆ«è¡¨ç¤ºæ¬¡æ•°ã€‚$\lambda$å¸¸å–å€¼1 P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda}12345678910def loadDataSet(): dataSet=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] #åˆ‡åˆ†å¥½çš„è¯æ¡ classVec = [0,1,0,1,0,1] #ç±»åˆ«æ ‡ç­¾å‘é‡ï¼Œ1ä»£è¡¨ä¾®è¾±æ€§è¯æ±‡ï¼Œ0ä»£è¡¨éä¾®è¾±æ€§è¯æ±‡ return dataSet,classVecdataSet,classVec = loadDataSet() 12345678def createVocabList(dataSet): vocabSet = set() #åˆ›å»ºä¸€ä¸ªç©ºçš„é›†åˆ for doc in dataSet: #éå†dataSetä¸­çš„æ¯ä¸€æ¡è¨€è®º vocabSet = vocabSet | set(doc) #å–å¹¶é›† vocabList = list(vocabSet) return vocabListvocabList = createVocabList(dataSet) 12345678def setOfWords2Vec(vocabList, inputSet): returnVec = [0] * len(vocabList) #åˆ›å»ºä¸€ä¸ªå…¶ä¸­æ‰€å«å…ƒç´ éƒ½ä¸º0çš„å‘é‡ for word in inputSet: #éå†æ¯ä¸ªè¯æ¡ if word in vocabList: #å¦‚æœè¯æ¡å­˜åœ¨äºè¯æ±‡è¡¨ä¸­ï¼Œåˆ™å˜ä¸º1 returnVec[vocabList.index(word)] = 1 else: print(f" &#123;word&#125; is not in my Vocabulary!" ) return returnVec #è¿”å›æ–‡æ¡£å‘é‡ 12345678def get_trainMat(dataSet): trainMat = [] #åˆå§‹åŒ–å‘é‡åˆ—è¡¨ vocabList = createVocabList(dataSet) #ç”Ÿæˆè¯æ±‡è¡¨ for inputSet in dataSet: #éå†æ ·æœ¬è¯æ¡ä¸­çš„æ¯ä¸€æ¡æ ·æœ¬ returnVec=setOfWords2Vec(vocabList, inputSet) #å°†å½“å‰è¯æ¡å‘é‡åŒ– trainMat.append(returnVec) #è¿½åŠ åˆ°å‘é‡åˆ—è¡¨ä¸­ return trainMattrainMat = get_trainMat(dataSet) 1234567891011121314151617181920def trainNB(trainMat,classVec): n = len(trainMat) #è®¡ç®—è®­ç»ƒçš„æ–‡æ¡£æ•°ç›® m = len(trainMat[0]) #è®¡ç®—æ¯ç¯‡æ–‡æ¡£çš„è¯æ¡æ•° pAb = sum(classVec)/n #æ–‡æ¡£å±äºä¾®è¾±ç±»çš„æ¦‚ç‡ p0Num = np.zeros(m) #è¯æ¡å‡ºç°æ•°åˆå§‹åŒ–ä¸º0 p1Num = np.zeros(m) #è¯æ¡å‡ºç°æ•°åˆå§‹åŒ–ä¸º0 p0Denom = 0 #åˆ†æ¯åˆå§‹åŒ–ä¸º0 p1Denom = 0 #åˆ†æ¯åˆå§‹åŒ–ä¸º0 for i in range(n): #éå†æ¯ä¸€ä¸ªæ–‡æ¡£ if classVec[i] == 1: #ç»Ÿè®¡å±äºä¾®è¾±ç±»çš„æ¡ä»¶æ¦‚ç‡æ‰€éœ€çš„æ•°æ® p1Num += trainMat[i] p1Denom += sum(trainMat[i]) else: #ç»Ÿè®¡å±äºéä¾®è¾±ç±»çš„æ¡ä»¶æ¦‚ç‡æ‰€éœ€çš„æ•°æ® p0Num += trainMat[i] p0Denom += sum(trainMat[i]) p1V = p1Num/p1Denom p0V = p0Num/p0Denom return p0V,p1V,pAb #è¿”å›å±äºéä¾®è¾±ç±»,ä¾®è¾±ç±»å’Œæ–‡æ¡£å±äºä¾®è¾±ç±»çš„æ¦‚ç‡p0V,p1V,pAb=trainNB(trainMat,classVec) 1234567891011121314151617181920212223from functools import reducedef classifyNB(vec2Classify, p0V, p1V, pAb): p1 = reduce(lambda x,y:x*y, vec2Classify * p1V) * pAb #å¯¹åº”å…ƒç´ ç›¸ä¹˜ p0 = reduce(lambda x,y:x*y, vec2Classify * p0V) * (1 - pAb) print('p0:',p0) print('p1:',p1) if p1 &gt; p0: return 1 else: return 0def testingNB(testVec): dataSet,classVec = loadDataSet() #åˆ›å»ºå®éªŒæ ·æœ¬ vocabList = createVocabList(dataSet) #åˆ›å»ºè¯æ±‡è¡¨ trainMat= get_trainMat(dataSet) #å°†å®éªŒæ ·æœ¬å‘é‡åŒ– p0V,p1V,pAb = trainNB(trainMat,classVec) #è®­ç»ƒæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ thisone = setOfWords2Vec(vocabList, testVec) #æµ‹è¯•æ ·æœ¬å‘é‡åŒ– if classifyNB(thisone,p0V,p1V,pAb): print(testVec,'å±äºä¾®è¾±ç±»') #æ‰§è¡Œåˆ†ç±»å¹¶æ‰“å°åˆ†ç±»ç»“æœ else: print(testVec,'å±äºéä¾®è¾±ç±»') #æ‰§è¡Œåˆ†ç±»å¹¶æ‰“å°åˆ†ç±»ç»“æœ testVec1 = ['love', 'my', 'dalmation']testingNB(testVec1) BernoulliNBä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œå¦‚æœæ˜¯äºŒå…ƒä¼¯åŠªåˆ©åˆ†å¸ƒ P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il})å¦‚æœæ ·æœ¬å±æ€§å¤§å¤šæ•°å±äºè¿ç»­ï¼ŒGaussionNB å¦‚æœæ˜¯ç¦»æ•£å€¼ï¼Œä½¿ç”¨MultinomialNB å¦‚æœæ ·æœ¬ç‰¹å¾æ˜¯äºŒå…ƒç¦»æ•£å€¼æˆ–è€…ç¨€ç–ç¦»æ•£å€¼ï¼ŒBernoulliNB åŠæœ´ç´ è´å¶æ–¯ä¿¡æ¯é‡ã€ç†µã€è”åˆç†µã€æ¡ä»¶ç†µã€äº’ä¿¡æ¯ä¿¡æ¯é‡ååº”äº†éšæœºå˜é‡å–æŸä¸ªå€¼å«çš„å¯èƒ½æ€§å¤§å°ï¼Œæˆ–è€…æ˜¯å«æœ‰çš„ä¿¡æ¯å¤šå°‘ I(X=x)=-log_2^{p(xï¼‰}ç†µ(entropy)ååº”äº†ä¿¡æºå¹³å‡æ¯ä¸ªç¬¦å·çš„ä¿¡æ¯é‡,æˆ–è€…æ˜¯éšæœºå˜é‡ä¸ç¡®å®šæ€§çš„è¡¡é‡ H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)})è”åˆç†µååº”äº†å¤šä¸ªéšæœºå˜é‡çš„å¹³å‡ä¿¡æ¯é‡ H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)})æ¡ä»¶ç†µï¼ˆConditional entropyï¼‰ååº”äº†å·²çŸ¥ä¸€ä¸ªéšæœºå˜é‡ä¸‹ï¼Œå¦ä¸€ä¸ªéšæœºå˜é‡çš„ä¸ç¡®å®šæ€§ H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)}äº’ä¿¡æ¯(mutual information)ååº”äº†å·²çŸ¥ä¸€ä¸ªéšæœºå˜é‡çš„æƒ…å†µä¸‹ï¼Œå¦å¤–ä¸€ä¸ªéšæœºå˜é‡ä¸ç¡®å®šæ€§å‡å°‘äº†å¤šå°‘,å¯ä»¥æŠŠäº’ä¿¡æ¯çœ‹æˆç”±äºçŸ¥é“ y å€¼è€Œé€ æˆçš„ x çš„ä¸ç¡®å®šæ€§çš„å‡å° I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\\ =H(X)-H(X|Y)=H(Y)-H(Y|X)å¦‚æœä¸¤ä¸ªéšæœºå˜é‡ç‹¬ç«‹ï¼Œåˆ™äº’ä¿¡æ¯ä¸º0,å› æ­¤ï¼Œäº’ä¿¡æ¯å¯ä»¥è¡¡é‡ä¸¤ä¸ªéšæœºå˜é‡çš„ç›¸å…³ç¨‹åº¦ æ¡ä»¶äº’ä¿¡æ¯åœ¨æ¡ä»¶zå‘ç”Ÿæ—¶çš„æ¡ä»¶äº’ä¿¡æ¯ I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}} åŠæœ´ç´ è´å¶æ–¯é€‚å½“çš„è€ƒè™‘ä¸€éƒ¨åˆ†å±æ€§é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ï¼Œè¿™ä¸ªå…³ç³»å¯ä»¥ç”¨äº’ä¿¡æ¯æè¿° ç‹¬ä¾èµ–å‡è®¾æ¯ä¸ªå±æ€§åªæœ‰ä¸€ä¸ªå…¶ä»– çš„å±æ€§.åˆ™è®¡ç®—å…¬å¼æ”¹ä¸‹å¦‚ä¸‹ p(C)\Pi_{i=1}^{d} P(x_i|C_i,pa_i)$pa_i$æ˜¯å±æ€§$x_i$æ‰€ä¾èµ–çš„å±æ€§ï¼Œè¢«ç§°ä¸º$x_i$çš„çˆ¶å±æ€§ 1) SPODE æœ€ç®€å•çš„æ–¹æ³•æ˜¯ï¼šéƒ½é€‰ä¸€ä¸ªå±æ€§ä½œä¸ºçˆ¶å±æ€§ å¯ä»¥é€šè¿‡äº¤å‰éªŒè¯çš„æ–¹æ³• 2) TAN :æœ€å¤§å¸¦æƒç”Ÿæˆæ ‘ æƒé‡ï¼šå½“yåˆ’åˆ†ä¸º$c_k$ç±»æ—¶æ¡ä»¶ç†µ I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}}step 1: è®¡ç®—ä»»æ„ä¸¤ä¸ªå±æ€§ä¹‹é—´æ¡ä»¶äº’ä¿¡æ¯ I(X;Y|Y)=\sum_{i}I(X;Y|c_i)step 2: ä»¥å±æ€§ä¸ºç»“ç‚¹æ„å»ºå®Œå…¨å›¾ step 3: æœ€å¤§å¸¦æƒç”Ÿæˆæ ‘ï¼ŒæŒ‘é€‰æ ¹å˜é‡ step 4: åŠ å…¥ç±»åˆ«ç»“ç‚¹y,å¢åŠ åˆ°æ¯ä¸ªå±æ€§çš„æœ‰å‘è¾¹ æ¡ä»¶äº’ä¿¡æ¯ååº”äº†å±æ€§åœ¨å·²çŸ¥ç±»åˆ«ä¸‹çš„ç›¸å…³æ€§å¤§å° é›†æˆå­¦ä¹ AODEé€‰æ‹©æ¨¡å‹å°è¯•å°†æ¯ä¸ªå±æ€§ä½œä¸ºè¶…çˆ¶æ„å»ºSPODE P(c_i|X)æ­£æ¯”äº \sum_{i=1,|D_{x_i}>=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i)$m$é€šå¸¸å–30, P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\\ P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j}è´å¶æ–¯ç½‘(Bayesian network)å€ŸåŠ©æœ‰å‘æ— ç¯å›¾æ¥åˆ»ç”»å±æ€§ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œæ¡ä»¶æ¦‚ç‡è¡¨æ¥æè¿°å±æ€§çš„è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚ ä¸€ä¸ªè´å¶æ–¯ç½‘ç»œ$B$,åŒ…æ‹¬ç»“æ„$G$å’Œå‚æ•°$\Theta$ ,$B(G,\Theta)$,å¦‚æœä¸¤ä¸ªå±æ€§æœ‰ç›´æ¥ä¾èµ–å…³ç³»ï¼Œç”¨è¾¹è¿æ¥ï¼Œå¯¹äºå±æ€§$x_i$,å…¶çˆ¶èŠ‚ç‚¹é›†åˆ$G_i$,åˆ™$\Theta$åŒ…æ‹¬æ¯ä¸ªå±æ€§æ¡ä»¶æ¦‚ç‡$\Theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$ ç»“æ„ p(x_1,x_2,...,x_n)=\Pi_{i=1}^{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}^{d}\Theta_{xi|\pi_i}\\ =\Pi_{i=1}^{d}P(x_i|Parents(x_i))æ¨æ–­ä¸€æ—¦è®­ç»ƒå¥½è´å¶æ–¯ç½‘åï¼Œå°±èƒ½å›ç­”query,é€šè¿‡ä¸€äº›å±æ€§çš„è§‚æµ‹è€…æ¥æ¨æ–­å…¶ä»–å±æ€§å˜é‡çš„å–å€¼ï¼Œå…¶ä¸­ï¼Œå·²çŸ¥å˜é‡çš„å€¼è§‚æµ‹æ¨æµ‹å¾…æŸ¥è¯¢çš„è¿‡ç¨‹â€œæ¨æ–­â€,å·²çŸ¥å˜é‡çš„è§‚æµ‹è€…â€è¯æ®â€œ]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>è´å¶æ–¯åˆ†ç±»å™¨</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[äºŒæ¬¡è§„åˆ’]]></title>
    <url>%2F2019%2F03%2F25%2F%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[[TOC] KKT(Karush-Kuhn-Tucher)æ¡ä»¶ ç»™å®šä¼˜åŒ–é—®é¢˜ \min f(x)\\ subject\ to \begin{cases} g_i(x) = 0 (i=1,,,,m\\ h_i(x) =0 (i=m+1,...,n)\\ \lambda_i h_i(x)=0(i=m+1,..,n)äºŒæ¬¡è§„åˆ’é—®é¢˜é—®é¢˜çš„æ•°å­¦è¡¨è¾¾ \min Q(x) = \frac{1}{2}x^THx+g^Tx\\ s.t. a_i^Tx = b_i (i=1,..,m)\\ \ \ \ \ \ \ \ a_i^Tx =x^{*T}H(x-x^{*})+g^T(x-x^{*})=\lambda^TA(x-x^{*})http://www.hankcs.com/ml/lagrange-duality.html#h3-7 SMO ï¼šSequential minimal optimizationæ”¯æŒå‘é‡æœºçš„å¯¹å¶é—®é¢˜ \min \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^{m}\alpha_i\\ s.t. \sum_{i=1}^{m}\alpha_iy_i=0\\ 0]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
        <category>æ•°å­¦</category>
      </categories>
      <tags>
        <tag>äºŒæ¬¡è§„åˆ’</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle]]></title>
    <url>%2F2019%2F03%2F24%2Fkaggle%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>ç«èµ›</category>
      </categories>
      <tags>
        <tag>ç«èµ›</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scikit-learn]]></title>
    <url>%2F2019%2F03%2F23%2Fscikit-learn%2F</url>
    <content type="text"><![CDATA[Cross-validation: evaluating estimator performanceÂ¶ 12345import numpy as npfrom sklearn.model_selection import train_test_split# è°ƒç”¨train_test_splitå‡½æ•° è‡ªåŠ¨åˆ’åˆ†æ•°æ®é›† 40%for testingX_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, test_size=0.4, random_state=0) corss validation 1234567from sklearn.model_selection import cross_validatefrom sklearn.metrics import recall_scorescoring = [&apos;precision_macro&apos;, &apos;recall_macro&apos;]clf = svm.SVC(kernel=&apos;linear&apos;, C=1, random_state=0)scores = cross_validate(clf, iris.data, iris.target, scoring=scoring, cv=5, return_train_score=False)sorted(scores.keys()) Cross validation of time series data Tuning the hyper-parameters of an estimatorA search consists of: an estimator (regressor or classifier such as sklearn.svm.SVC()); a parameter space; a method for searching or sampling candidates; a cross-validation scheme; and a score function. Grid Search1234param_grid = [ &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;kernel&apos;: [&apos;linear&apos;]&#125;, &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;gamma&apos;: [0.001, 0.0001], &apos;kernel&apos;: [&apos;rbf&apos;]&#125;, ] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from __future__ import print_functionfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.model_selection import GridSearchCVfrom sklearn.metrics import classification_reportfrom sklearn.svm import SVCprint(__doc__)# Loading the Digits datasetdigits = datasets.load_digits()# To apply an classifier on this data, we need to flatten the image, to# turn the data in a (samples, feature) matrix:n_samples = len(digits.images)X = digits.images.reshape((n_samples, -1))y = digits.target# Split the dataset in two equal partsX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=0)# Set the parameters by cross-validationtuned_parameters = [&#123;'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]&#125;, &#123;'kernel': ['linear'], 'C': [1, 10, 100, 1000]&#125;]scores = ['precision', 'recall']for score in scores: print("# Tuning hyper-parameters for %s" % score) print() clf = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='%s_macro' % score) clf.fit(X_train, y_train) print("Best parameters set found on development set:") print() print(clf.best_params_) print() print("Grid scores on development set:") print() means = clf.cv_results_['mean_test_score'] stds = clf.cv_results_['std_test_score'] for mean, std, params in zip(means, stds, clf.cv_results_['params']): print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params)) print() print("Detailed classification report:") print() print("The model is trained on the full development set.") print("The scores are computed on the full evaluation set.") print() y_true, y_pred = y_test, clf.predict(X_test) print(classification_report(y_true, y_pred)) print()# Note the problem is too easy: the hyperparameter plateau is too flat and the# output model is the same for precision and recall with ties in quality. Randomized Parameter Optimization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566print(__doc__)import numpy as npfrom time import timefrom scipy.stats import randint as sp_randintfrom sklearn.model_selection import GridSearchCVfrom sklearn.model_selection import RandomizedSearchCVfrom sklearn.datasets import load_digitsfrom sklearn.ensemble import RandomForestClassifier# get some datadigits = load_digits()X, y = digits.data, digits.target# build a classifierclf = RandomForestClassifier(n_estimators=20)# Utility function to report best scoresdef report(results, n_top=3): for i in range(1, n_top + 1): candidates = np.flatnonzero(results['rank_test_score'] == i) for candidate in candidates: print("Model with rank: &#123;0&#125;".format(i)) print("Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)".format( results['mean_test_score'][candidate], results['std_test_score'][candidate])) print("Parameters: &#123;0&#125;".format(results['params'][candidate])) print("")# specify parameters and distributions to sample fromparam_dist = &#123;"max_depth": [3, None], "max_features": sp_randint(1, 11), "min_samples_split": sp_randint(2, 11), "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run randomized searchn_iter_search = 20random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, cv=5)start = time()random_search.fit(X, y)print("RandomizedSearchCV took %.2f seconds for %d candidates" " parameter settings." % ((time() - start), n_iter_search))report(random_search.cv_results_)# use a full grid over all parametersparam_grid = &#123;"max_depth": [3, None], "max_features": [1, 3, 10], "min_samples_split": [2, 3, 10], "bootstrap": [True, False], "criterion": ["gini", "entropy"]&#125;# run grid searchgrid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)start = time()grid_search.fit(X, y)print("GridSearchCV took %.2f seconds for %d candidate parameter settings." % (time() - start, len(grid_search.cv_results_['params'])))report(grid_search.cv_results_) step1ï¼š äº¤å‰éªŒè¯ï¼ˆè¯„ä»·æ¨¡å‹ï¼‰ step2: è¶…å‚æ•°é€‰æ‹©ï¼Œæ¯ä¸€ç»„å‚æ•°ï¼šå¯¹åº”ä¸€æ¬¡äº¤å‰éªŒè¯ step 3: é›†æˆå­¦ä¹  ä¹Ÿå¯è¿›è¡Œå‚æ•°çš„è°ƒè§£ 12345678from sklearn.model_selection import cross_val_scorefrom sklearn.datasets import load_irisfrom sklearn.ensemble import AdaBoostClassifieriris = load_iris()clf = AdaBoostClassifier(n_estimators=100)scores = cross_val_score(clf, iris.data, iris.target, cv=5)scores.mean() 1234567891011121314151617181920212223from sklearn import datasetsfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCfrom itertools import productfrom sklearn.ensemble import VotingClassifier# Loading some example datairis = datasets.load_iris()X = iris.data[:, [0, 2]]y = iris.target# Training classifiersclf1 = DecisionTreeClassifier(max_depth=4)clf2 = KNeighborsClassifier(n_neighbors=7)clf3 = SVC(gamma=&apos;scale&apos;, kernel=&apos;rbf&apos;, probability=True)eclf = VotingClassifier(estimators=[(&apos;dt&apos;, clf1), (&apos;knn&apos;, clf2), (&apos;svc&apos;, clf3)], voting=&apos;soft&apos;, weights=[2, 1, 2])clf1 = clf1.fit(X, y)clf2 = clf2.fit(X, y)clf3 = clf3.fit(X, y)eclf = eclf.fit(X, y)]]></content>
      <categories>
        <category>ç¼–ç¨‹è¯­è¨€</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boosting]]></title>
    <url>%2F2019%2F03%2F22%2FBoosting%2F</url>
    <content type="text"><![CDATA[[TOC] BoostingåŸç†Boostingç®—æ³•æ˜¯å°†â€œå¼±å­¦ä¹ ç®—æ³•â€œæå‡ä¸ºâ€œå¼ºå­¦ä¹ ç®—æ³•â€çš„è¿‡ç¨‹ã€‚ åŠ æ³•æ¨¡å‹ F_n(x;P) = \sum_{t=1}^{n}\alpha_th_t(x;a_t) å‰å‘åˆ†æ­¥ F_m(x) = F_{m-1}(x)+\alpha_mh_m(x,a_m)å¦‚æœé€‰å–ä¸åŒæŸå¤±å‡½æ•°ï¼Œåˆ™äº§ç”Ÿä¸åŒçš„ç±»å‹ AdaBoostAdaBoostå°±æ˜¯æŸå¤±å‡½æ•°ä¸ºæŒ‡æ•°æŸå¤±çš„Boostingç®—æ³•ã€‚ æ¯ä¸€æ¬¡è¿­ä»£çš„å¼±å­¦ä¹ $h(x;a_m)$æœ‰ä½•ä¸ä¸€æ ·ï¼Œå¦‚ä½•å­¦ä¹ ï¼Ÿ AdaBoostæ”¹å˜äº†è®­ç»ƒæ•°æ®çš„æƒå€¼ï¼Œä¹Ÿå°±æ˜¯æ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…¶æ€æƒ³æ˜¯å°†å…³æ³¨ç‚¹æ”¾åœ¨è¢«é”™è¯¯åˆ†ç±»çš„æ ·æœ¬ä¸Šï¼Œå‡å°ä¸Šä¸€è½®è¢«æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æƒå€¼ï¼Œæé«˜é‚£äº›è¢«é”™è¯¯åˆ†ç±»çš„æ ·æœ¬æƒå€¼ã€‚ å¼±åˆ†ç±»å™¨æƒå€¼$Î²_m$å¦‚ä½•ç¡®å®šï¼Ÿ AdaBoosté‡‡ç”¨åŠ æƒå¤šæ•°è¡¨å†³çš„æ–¹æ³•ï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œå‡å°åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ã€‚è¿™ä¸ªå¾ˆå¥½ç†è§£ï¼Œæ­£ç¡®ç‡é«˜åˆ†å¾—å¥½çš„å¼±åˆ†ç±»å™¨åœ¨å¼ºåˆ†ç±»å™¨ä¸­å½“ç„¶åº”è¯¥æœ‰è¾ƒå¤§çš„å‘è¨€æƒã€‚ åŸç†ç†è§£åŸºäºBoostingçš„ç†è§£ï¼Œå¯¹äºAdaBoostï¼Œæˆ‘ä»¬è¦ææ¸…æ¥šä¸¤ç‚¹ï¼š æ¯ä¸€æ¬¡è¿­ä»£çš„å¼±å­¦ä¹ h(x;am)æœ‰ä½•ä¸ä¸€æ ·ï¼Œå¦‚ä½•å­¦ä¹ ï¼Ÿå¼±åˆ†ç±»å™¨æƒå€¼Î²må¦‚ä½•ç¡®å®šï¼Ÿå¯¹äºç¬¬ä¸€ä¸ªé—®é¢˜ï¼ŒAdaBoostæ”¹å˜äº†è®­ç»ƒæ•°æ®çš„æƒå€¼ï¼Œä¹Ÿå°±æ˜¯æ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…¶æ€æƒ³æ˜¯å°†å…³æ³¨ç‚¹æ”¾åœ¨è¢«é”™è¯¯åˆ†ç±»çš„æ ·æœ¬ä¸Šï¼Œå‡å°ä¸Šä¸€è½®è¢«æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æƒå€¼ï¼Œæé«˜é‚£äº›è¢«é”™è¯¯åˆ†ç±»çš„æ ·æœ¬æƒå€¼ã€‚ç„¶åï¼Œå†æ ¹æ®æ‰€é‡‡ç”¨çš„ä¸€äº›åŸºæœ¬æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œå­¦ä¹ ï¼Œæ¯”å¦‚é€»è¾‘å›å½’ã€‚ å¯¹äºç¬¬äºŒä¸ªé—®é¢˜ï¼ŒAdaBoosté‡‡ç”¨åŠ æƒå¤šæ•°è¡¨å†³çš„æ–¹æ³•ï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œå‡å°åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ã€‚è¿™ä¸ªå¾ˆå¥½ç†è§£ï¼Œæ­£ç¡®ç‡é«˜åˆ†å¾—å¥½çš„å¼±åˆ†ç±»å™¨åœ¨å¼ºåˆ†ç±»å™¨ä¸­å½“ç„¶åº”è¯¥æœ‰è¾ƒå¤§çš„å‘è¨€æƒã€‚ å…¬å¼æ¨å¯¼æŒ‡æ•°æŸå¤±å‡½æ•° L(Y,f(x))=exp(-Yf(x))æƒé‡æ›´æ–°å…¬å¼: é‡‡ç”¨çš„æŒ‡æ•°è¯¯å·®å‡½æ•° l_{exp}(a_th_t|D_t)=E(exp(-f(x)a_th_t(x)))\\ =p(f(x)=h_t(x))e^{-at}+p(f(x)!=h_t(x))e^{at}\\ =e^{-at}(1-\xi)+e^{at}\xi a_t=\frac{1}{2}ln \frac{1-\xi}{\xi}åˆ†å¸ƒæ›´æ–°å…¬å¼ \begin{aligned} l\left(H_{t-1}(x)+\alpha h_{t}(x) | D\right) &=E_{X \sim D}\left(\exp \left(-y(x)\left(H_{t-1}(x)+\alpha h_{t}(x)\right)\right)\right) \\ &=E_{x \sim D}\left(\exp \left(-y(x) H_{t-1}(x)\right) \exp \left(-y(x) \alpha h_{t}(x)\right)\right) \end{aligned}åœ¨æ³°å‹’å±•å¼€$exp(-y(x)h_t(x))$ \begin{aligned} l\left(H_{t-1}(x)+h_{t}(x) | D\right) & \approx E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-\alpha y(x) h_{t}(x)+\frac{\alpha^{2} y^{2}(x) h_{t}^{2}(x)}{2}\right)\right] \\ &=E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-y(x) h_{t}(x)+0.5 \alpha^{2}\right)\right] \end{aligned} \begin{aligned} h(x) &=\arg \min _{h} l\left(H_{t-1}(x)+\alpha h_{t} | D\right) \\ &=\arg \max _{h} E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right) \alpha y(x) h_{t}(x)\right] \\ &=\arg \max _{h}\left[\frac{\exp \left(-y(x) H_{t-1}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} y(x) h(x)\right] \end{aligned} ä»¤ä¸€ä¸ªæ–°åˆ†å¸ƒ,æ³¨æ„åˆ†å­æ˜¯å¸¸æ•° D_{t}(x)=\frac{D(x) \exp \left(-y(x) H_{t-1}(x)\right)^{L}}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} \begin{aligned} h(x) &=\arg \max _{h} E_{x \sim D,}(y(x) h(x)) \\ &=\arg \max _{h} E_{x \sim D_{t}}(1-2 \mathcal{I}(y(x) \neq h(x))) \\ &=\arg \min _{h} E_{x \sim D_{i}}(\mathcal{I}(y(x) \neq h(x))) \end{aligned}åŒç†å¯å¾— \begin{aligned} D_{t+1} &=\frac{D(x) \exp \left(-y(x) H_{t}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=\frac{D_{t}(x) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right] \cdot \exp \left(-y(x) H_{t}(x)\right)}{\exp \left(-y(x) H_{t-1}(x)\right) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=D_{t}(x) \exp \left(-y(x) \alpha h_{t}(x)\right) \cdot C . \quad(C i s a \text {constant}) \end{aligned} Z_{t}=\sum_{i}^{m} D_{t}(x) \exp \left(-y(x) \alpha_{t} h_{y}(x)\right)æŒ‡æ•°è¯¯å·®å‡½æ•° \begin{aligned} l(H(x) | D) &=\frac{1}{m} \sum_{i}^{m} \exp \left(-y_{i} H\left(x_{i}\right)\right) \\ &=\frac{1}{m} \sum_{i}^{m} \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=\sum_{i}^{m} D_{1}\left(x_{i}\right) \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=Z_{1} Z_{2}\left(x_{i}\right) \exp \left(-\sum_{j=2}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ & \vdots \\ &=\prod_{i=1}^{T} Z_{i} \end{aligned}ç®—æ³•æè¿°æ€»ç»“ä¸€ä¸‹ï¼Œå¾—åˆ°AdaBoostçš„ç®—æ³•æµç¨‹ï¼š è¾“å…¥ï¼šè®­ç»ƒæ•°æ®é›†$T={(x1,y1),(x2,y2),(xN,yN)}T={(x1,y1),(x2,y2),(xN,yN)}$ï¼Œå…¶ä¸­ï¼Œ$xiâˆˆXâŠ†RnxiâˆˆXâŠ†Rnï¼ŒyiâˆˆY=âˆ’1,1yiâˆˆY=âˆ’1,1ï¼Œ$è¿­ä»£æ¬¡æ•°M åˆå§‹åŒ–è®­ç»ƒæ ·æœ¬çš„æƒå€¼åˆ†å¸ƒï¼š$D1=(w1,1,w1,2,â€¦,w1,i),w,i=1,2,â€¦,N$ã€‚ å¯¹äº$m=1,2,â€¦,M$ (a) ä½¿ç”¨å…·æœ‰æƒå€¼åˆ†å¸ƒ$D_m$çš„è®­ç»ƒæ•°æ®é›†è¿›è¡Œå­¦ä¹ ï¼Œå¾—åˆ°å¼±åˆ†ç±»å™¨$h_m(x)$ (b) è®¡ç®—$h_m(x)$åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„åˆ†ç±»è¯¯å·®ç‡ï¼š $e_m=âˆ‘_{i=1}^{N}w_m,iI(h_m(xi)â‰ y_i)$ (c) è®¡ç®—$h_m(x)$åœ¨å¼ºåˆ†ç±»å™¨ä¸­æ‰€å çš„æƒé‡ï¼š $\alpha_m=\frac{1}{2}log(\frac{1âˆ’e_m}{e_m})$ (d) æ›´æ–°è®­ç»ƒæ•°æ®é›†çš„æƒå€¼åˆ†å¸ƒï¼ˆè¿™é‡Œï¼Œ$z_mæ˜¯å½’ä¸€åŒ–å› å­ï¼Œä¸ºäº†ä½¿æ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒå’Œä¸º1ï¼‰ï¼š w_{m+1,i}=\frac{w_{m,i}}exp(âˆ’Î±_my_ih_m(xi))ï¼Œi=1,2,â€¦,10z_m=âˆ‘_{i=1}^{N}w_{m,i}exp(âˆ’Î±_my_ih_m(xi)) å¾—åˆ°æœ€ç»ˆåˆ†ç±»å™¨ï¼š F(x)=sign(âˆ‘_{i=1}^{N}Î±_mh_m(x))é¢ç»ä»Šå¹´8æœˆå¼€å§‹æ‰¾å·¥ä½œï¼Œå‚åŠ å¤§å‚é¢è¯•é—®åˆ°çš„ç›¸å…³é—®é¢˜æœ‰å¦‚ä¸‹å‡ ç‚¹ï¼š æ‰‹æ¨AdaBoost ä¸GBDTæ¯”è¾ƒ AdaBoostå‡ ç§åŸºæœ¬æœºå™¨å­¦ä¹ ç®—æ³•å“ªä¸ªæŠ—å™ªèƒ½åŠ›æœ€å¼ºï¼Œå“ªä¸ªå¯¹é‡é‡‡æ ·ä¸æ•æ„Ÿï¼Ÿ ç®—æ³•æµç¨‹å®ä¾‹è®¡ç®—Pythonå®ç°https://www.cnblogs.com/davidwang456/articles/8927029.html é›†æˆå­¦ä¹ ]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>Boosting, AdaBoost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ”¯æŒå‘é‡å›å½’]]></title>
    <url>%2F2019%2F03%2F19%2FSVR%2F</url>
    <content type="text"><![CDATA[[TOC] æ”¯æŒå‘é‡æœºç”¨äºåˆ†ç±»:ç¡¬é—´éš”å’Œè½¯ä»¶é—´éš”æ”¯æŒå‘é‡æœºã€‚å°½å¯èƒ½åˆ†å¯¹ æ”¯æŒå‘é‡æœºå›å½’ï¼š å¸Œæœ›$f(x)$ä¸$y$å°½å¯èƒ½çš„æ¥è¿‘ã€‚ æ”¯æŒå‘é‡æœºåŸºæœ¬æ€æƒ³è‹±æ–‡å:support vector regression ç®€è®°ï¼šSVR æ ‡å‡†çš„çº¿æ€§æ”¯æŒå‘é‡å›å½’æ¨¡å‹å­¦ä¹ çš„æ¨¡å‹: f(x)=w^Tx+bå‡è®¾èƒ½å®¹å¿$f(x)$ä¸$y$ä¹‹é—´å·®åˆ«ç»å¯¹å€¼$\xi$,è¿™å°±ä»¥$f(x)=w^Tx+b$å½¢æˆäº†ä¸€ä¸ª$2\xi$çš„é—´éš”å¸¦ï¼Œå› æ­¤æ¨¡å‹ \min \frac{1}{2}w^Tw\\ s.t -\xi]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>æ”¯æŒå‘é‡æœºå›å½’</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ”¯æŒå‘é‡æœº(SVM) ----- åˆ†ç±»å™¨]]></title>
    <url>%2F2019%2F03%2F17%2FSVMClassifiar%2F</url>
    <content type="text"><![CDATA[[TOC] é¢„å¤‡çš„æ•°å­¦çŸ¥è¯†çº¦æŸä¼˜åŒ–é—®é¢˜åŸé—®é¢˜,å¸¦ç­‰å¼çº¦æŸï¼Œä¹Ÿå¸¦ä¸ç­‰å¼çº¦æŸçš„ä¸€èˆ¬çº¦æŸé—®é¢˜ \begin{cases} \min_{x}f(x)\\ s.t \begin{cases} m_i(x)>=0, i=1,..,m\\ n_j(x)=0ï¼Œj=1,..,m\\ \end{cases} \end{cases}\tag{1}æ„é€ lagrangeä¹˜å­æ³• L(x,\lambda_i,\eta_j)= f(x)-\sum_{i=1}^{m}\lambda_im_i(x)-\sum_{j=1}^{n}\eta_j \tag{2} \begin{cases} \min_{x} max_{\lambda_i,\eta_j} L(R^p)\\ s.t \lambda_i>=0 \end{cases}ä¸Šè¿°ä¸¤ä¸ªé—®é¢˜çš„ç­‰ä»·æ€§è¯æ˜ å¦‚æœxä¸æ»¡è¶³çº¦æŸ$m_i(x)$,åˆ™$\lambda_i&gt;=0$,åŒæ—¶$m_i(x)&lt;$,åˆ™$L(R^{p},\lambda,\eta)$è¶‹è¿‘æ— ç©·ï¼Œåä¹‹ï¼Œåˆ™å­˜åœ¨æœ€å¤§å€¼ min_{x} max_{\lambda,\eta}=min_{x}(max fæ»¡è¶³æ¡ä»¶,max fä¸æ»¡è¶³çº¦æŸ)\\=min_{x} max_{\lambda,\eta}{fæ»¡è¶³æ¡ä»¶}å¯¹å¶é—®é¢˜: å…³äº$\lambda,\eta$çš„æœ€å¤§åŒ–é—®é¢˜ max min L(x,\lambda,\eta)\\ s.t \lambda_i>=0å¼±å¯¹å¶é—®é¢˜ï¼šå¯¹å¶é—®é¢˜&lt;=åŸé—®é¢˜ è¯æ˜: $max_{x} min(\lambda \eta ) L&lt;=min_{\eta,\lambda } max_{x} L$ \underbrace{\min_{x}L(x,\lambda,\eta)}_{A(\lambda,\eta)}0\end{cases}æ³¨æ„ï¼Œ$y_i(w^Tx_i+b)&gt;0$,æ‰€ä»¥$\exists r&gt;0, min(y_i(w^Tx_i+b))=r$,å¯ä»¤$r=1$,è¿™æ˜¯å¯¹è¶…å¹³é¢èŒƒæ•°çš„å›ºå®šä½œç”¨ï¼Œå› ä¸º$y=w^Tx+b$å’Œ$y=2w^T+2b$æ˜¯åŒä¸€ä¸ªè¶…å¹³é¢ï¼Œæ€»èƒ½æ‰¾åˆ°ç¼©æ”¾$w,b$ä½¿å¾—ï¼Œå¯ä»¥å°†$r$ç¼©æ”¾åˆ°1 \Longrightarrow\begin{cases} max \frac{1}{||w||}\\ st. y_i(w^Tx_i+b)>=1\end{cases}\Longrightarrow\begin{cases} \min \frac{1}{2}w^Tw\\ st. y_i(w^Tx_i+b)>=1\end{cases}è¿™æ˜¯ä¸€ä¸ªåœŸäºŒæ¬¡è§„åˆ’é—®é¢˜ ç¬¬äºŒå® å¯¹å¶åˆ©ç”¨lagrangeä¹˜å­æ³•å¾—å‡ºå¯¹å¶é—®é¢˜ å¸¦çº¦æŸ \begin{cases} \min \frac{1}{2}w^Tw\\ st. y_i(w^Tx_i+b)-1>=0\end{cases}\Longrightarrow L(w,b,\lambdaï¼‰=\frac{1}{2}w^Tw-\sum_{i=1}^{N}\lambda_i(1-y_i(w^Tx_i+b)æ— çº¦æŸ \begin{cases}min_{w,b} max_{\lambda}L(w,b,\lambda) \\ s.t \lambda_i>=0\end{cases}æ­¤æ—¶å…³äº$w,b$æ— çº¦æŸçš„ã€‚ å¯¹$(L(w,b,\lambda))$ å¯¹$w$,$b$æ±‚åå¯¼ \frac{\partial L}{\partial w}=w+\sum_{i=1}^{N}y_ix_i\lambda_i=0 \Longrightarrow w=-\sum_{i=1}^{N}y_ix_i\lambda_i\\ \frac{\partial L}{\partial b}=-\sum_{i=1}^{N}\lambda_iy_i=0å¸¦å›$L(w,b,\lambda)$,å¯å¾—å¯¹å¶é—®é¢˜ \begin{cases} max_{\lambda}L(w,b,\lambda ) =-\frac{1}{2}\sum_i^N\sum_j^N\lambda_i \lambda_jy_iy_jx_i^Tx_j +\sum_i^N\lambda_i \\ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i>=0\end{cases} \Longrightarrow\\\begin{cases} min_{\lambda}L(w,b,\lambda ) =\frac{1}{2}\sum_i^N\sum_j^N\lambda_i \lambda_jy_iy_jx_i^Tx_j -\sum_i^N\lambda_i \\ s .t. \sum_{i=1}^N\lambda_iy_i,\lambda_i>=0\end{cases}åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜æœ‰ç›¸åŒè§£çš„å……è¦æ¡ä»¶æ»¡è¶³ KKT \begin{cases} \frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0,\frac{\partial L}{\partial \lambda}=0\\ \lambda_i(y_i(w^Tx_i+b)-1)=0\\ \lambda_i>=0\\ y_i(w^Tx_i+b)-1>=0 \end{cases}å¦‚æœå­˜åœ¨$(x_k,y_k)=+1or -1$ä½¿å¾—$y_i(w^Tx_i+b)-1=0$å³å¯æ±‚è§£$b=y_k-\sum_{i=0}^{N}\lambda_ix_i^Tx_k$ ä»£å…¥æ¨¡å‹ f(x)=sign(\sum_i^Na_iy_ix_i^Tx+y_k-\sum_{i=0}^{N}\lambda_ix_i^Tx_k)æ³¨æ„ï¼Œå¯¹äºä»»æ„çš„è®­ç»ƒæ ·æœ¬ï¼Œæ€»æœ‰$\lambda_i=0$æˆ–è€…$y_if(x_i)=1$,å¦‚æœ$\lambda_i&gt;0$,è¯´æ˜æ ·æœ¬ç‚¹è½åœ¨æœ€å¤§é—´éš”çš„è¾¹ç•Œä¸Šï¼Œè¿™äº›ç‚¹å°±æ˜¯æ”¯æŒå‘é‡ï¼Œè¿™æ¡è¾¹ç•Œ$w^Tx+b=1or-1$ soft-marign è½¯é—´éš” æƒ³æ³•ï¼šå…è®¸ä¸€éƒ¨åˆ†æ ·æœ¬å¯ä»¥ä¸è¢«æ­£ç¡®åˆ†ç±» ä¼˜åŒ–ç›®æ ‡ \min_{w,b} \frac{1}{2}w^Tw+lossä¸€äº›æŸå¤±å‡½æ•° 0-1æŸå¤± ä¸ªæ•° loss=\sum_{i=1}^NI\{y_i(w^Tx+b)=0,\\ 1-y_i(w^tx_i+b), y_i(w^Tx_i+b)=1-\xi_i\\ \xi_i>=0 \end{cases} æŒ‡æ•°æŸå¤±ï¼ˆexponential loss ) l_{exp}(z)=exp(-z) å¯¹ç‡æŸå¤±logistic loss l_{log}(z)=log(1+exp(-z)ï¼‰ æ ¸æ–¹æ³•æ ¸å‡½æ•°çš„å®šä¹‰è®¾ $\chi$ä¸ºè¾“å…¥ç©ºé—´ï¼ˆInput Spaceï¼‰ï¼Œ $\mathrm{H}$ä¸ºç‰¹å¾ç©ºé—´(Feature Space,ä¸€å®šæ˜¯å¸Œå°”ä¼¯ç‰¹ç©ºé—´ï¼‰ï¼Œå­˜åœ¨ä¸€ä¸ªæ˜ å°„ \varphi : \chi \rightarrow \mathrm{H}å¯¹ä»»æ„çš„ $x, y \in \mathrm{X}$ï¼Œå‡½æ•° $K(x, y)$ï¼Œæ»¡è¶³ K(x, y)=åˆ™ç§° $K(x, y)$ä¸ºæ ¸å‡½æ•°ã€‚å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦çŸ¥é“è¾“å…¥ç©ºé—´å’Œç‰¹å¾ç©ºé—´æ»¡è¶³çš„æ˜ å°„å…³ç³» ï¼Œåªéœ€è¦çŸ¥é“æ ¸å‡½æ•°å°±å¯ä»¥ç®—å‡ºï¼Œè¾“å…¥ç©ºé—´ä¸­ä»»æ„ä¸¤ç‚¹æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´çš„å†…ç§¯ã€‚]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>æ”¯æŒå‘é‡æœº</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å›å½’æ ‘]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%9B%9E%E5%BD%92%E6%A0%91%2F</url>
    <content type="text"><![CDATA[[TOC] åˆ†ç±»æ ‘ä¸å›å½’æ ‘åˆ†ç±»æ ‘ç”¨äºåˆ†ç±»é—®é¢˜ã€‚åˆ†ç±»å†³ç­–æ ‘åœ¨é€‰å–åˆ’åˆ†ç‚¹ï¼Œç”¨ä¿¡æ¯ç†µã€ä¿¡æ¯å¢ç›Šã€æˆ–è€…ä¿¡æ¯å¢ç›Šç‡ã€æˆ–è€…åŸºå°¼ç³»æ•°ä¸ºæ ‡å‡†ã€‚Classification tree analysis is when the predicted outcome is the class to which the data belongs. å›å½’å†³ç­–æ ‘ç”¨äºå¤„ç†è¾“å‡ºä¸ºè¿ç»­å‹çš„æ•°æ®ã€‚å›å½’å†³ç­–æ ‘åœ¨é€‰å–åˆ’åˆ†ç‚¹ï¼Œå°±å¸Œæœ›åˆ’åˆ†çš„ä¸¤ä¸ªåˆ†æ”¯çš„è¯¯å·®è¶Šå°è¶Šå¥½ã€‚ Regression tree analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patientâ€™s length of stay in a hospital)ã€‚ å›å½’æ ‘è‹±æ–‡åå­—ï¼šRegression Tree åŸç†ä»‹ç»å†³ç­–æ ‘æœ€ç›´è§‚çš„ç†è§£å…¶å®å°±æ˜¯ï¼Œè¾“å…¥ç‰¹å¾ç©ºé—´($R^n$)ï¼Œç„¶åå¯¹ç‰¹å¾ç©ºé—´åšåˆ’åˆ†ï¼Œæ¯ä¸€ä¸ªåˆ’åˆ†å±äºåŒä¸€ç±»æˆ–è€…å¯¹äºä¸€ä¸ªè¾“å‡ºçš„é¢„æµ‹å€¼ã€‚é‚£ä¹ˆè¿™ä¸ªç®—æ³•éœ€è¦è§£å†³çš„é—®é¢˜æ˜¯1. å¦‚ä½•å†³ç­–è¾¹ç•Œ(åˆ’åˆ†ç‚¹)ï¼Ÿ2. å°½å¯èƒ½å°‘çš„æ¯”è¾ƒæ¬¡æ•°(å†³ç­–æ ‘çš„å½¢çŠ¶) å¦‚ä¸Šå›¾ï¼Œæ¯ä¸€ä¸ªéå¶å­å¯¹äºæŸä¸ªç‰¹å¾çš„åˆ’åˆ†ã€‚ æœ€å°äºŒä¹˜å›å½’æ ‘ç”Ÿæˆç®—æ³•Q1: é€‰æ‹©åˆ’åˆ†ç‚¹ï¼Ÿéå†æ‰€æœ‰çš„ç‰¹å¾($n$),å¯¹äºæ¯ä¸€ä¸ªç‰¹å¾å¯¹åº”$s_i$ä¸ªå–å€¼ï¼Œå°è¯•å®Œæ‰€æœ‰ç‰¹å¾ï¼Œä»¥åŠç‰¹å¾æ‰€ä»¥æœ‰åˆ’åˆ†ï¼Œé€‰æ‹©ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„é‚£ç»„ç‰¹å¾ä»¥åŠç‰¹å¾çš„åˆ’åˆ†å–å€¼ã€‚ Q2: å¶èŠ‚ç‚¹çš„è¾“å‡ºï¼Ÿå–æ¯ä¸ªåŒºåŸŸæ‰€ä»¥ç»“æœçš„å¹³å‡æ•°ä½œä¸ºè¾“å‡º èŠ‚ç‚¹çš„æŸå¤±å‡½æ•°çš„å½¢å¼ \min _{j, s}\left[\min _{c_{1}} Loss(y_i,c_1)+\min _{c_{2}} Loss(y_i,c_2)\right]èŠ‚ç‚¹æœ‰ä¸¤æ¡åˆ†æ”¯ï¼Œ$c1$æ˜¯å·¦èŠ‚ç‚¹çš„å¹³å‡å€¼ï¼Œ$c2$æ˜¯å³èŠ‚ç‚¹çš„å¹³å‡å€¼ï¼Œæ¢å¥è¯è¯´ï¼Œåˆ†ä¸€æ¬¡åˆ’åˆ†éƒ½æ˜¯ä½¿å¾—åˆ’åˆ†å‡ºçš„ä¸¤ä¸ªåˆ†æ”¯çš„è¯¯å·®å’Œæœ€å°ã€‚æœ€ç»ˆå¾—åˆ°å‡½æ•°æ˜¯åˆ†æ®µå‡½æ•° CARTç®—æ³•è¾“å…¥ï¼š è®­ç»ƒæ•°æ®é›† è¾“å‡ºï¼šå›å½’æ ‘$f(x)$ é€‰æ‹©æœ€ä¼˜çš„ç‰¹å¾$j$å’Œåˆ†åˆ‡ç‚¹$s$ \min _{j, s}\left[\min _{c_{1}} \sum_{x_{i} \in R_{1}(j, s)}\left(y_{i}-c_{1}\right)^{2}+\min _{c_{2}} \sum_{x_{i} \in R_{2}(j, s)}\left(y_{i}-c_{2}\right)^{2}\right] å¯¹äºé€‰å®šçš„$(j,s)$åˆ’åˆ†åŒºåŸŸï¼Œå¹¶ç¡®å®šè¯¥åŒºåŸŸçš„é¢„æµ‹å€¼ å¯¹ä¸¤ä¸ªåŒºåŸŸé€’å½’1. 2. ç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ è¿”å›ç”Ÿæˆæ ‘ æ³¨ï¼šåˆ†åˆ‡ç‚¹é€‰æ‹©ï¼šå…ˆæ’åºï¼ŒäºŒåˆ†ã€‚ Pythonä»£ç èŠ‚ç‚¹ç±»å±æ€§ï¼šå·¦å³èŠ‚ç‚¹ã€lossã€ç‰¹å¾ç¼–å·æˆ–è€…ç‰¹å¾ã€åˆ†å‰²ç‚¹ 12345678class Node(object): def __init__(self, score=None): # æ„é€ å‡½æ•° self.score = score self.left = None self.right = None self.feature = None self.split = None å›å½’æ ‘ç±»æ„é€ æ–¹æ³• 1234class RegressionTree(object): def __init__(self): self.root = Node() self.height = 0 ç»™å®šç‰¹å¾ã€åˆ’åˆ†ç‚¹ï¼Œè¿”å›è®¡ç®—MAPE 12345678910111213141516def _get_split_mse(self, X, y, idx, feature, split): ''' X:è®­ç»ƒæ ·æœ¬è¾“å…¥ y:è®­ç»ƒæ ·æœ¬è¾“å‡º idx:è¯¥åˆ†æ”¯å¯¹åº”çš„æ ·æœ¬ç¼–å· feaure: ç‰¹å¾ split: åˆ’åˆ†ç‚¹ ''' split_x1=X[X[idex,feature]&lt;split] split_y1=y[X[idex,feature]&lt;split] split_x2=X[X[idex,feature]&gt;=split] split_y2=y[X[idex,feature]&gt;=split] split_avg = [np.mean(split_y1), np.mean(split_y2)] split_mape = [np.sum((split_y1-split_avg[0])**2),np.sum((split_y2-split_avg[1])**2)] return split_mse, split, split_avg è®¡ç®—ç»™å®šç‰¹å¾çš„æœ€ä½³åˆ†å‰²ç‚¹ éå†ç‰¹å¾æŸä¸€åˆ—çš„æ‰€æœ‰çš„ä¸é‡å¤çš„ç‚¹ï¼Œæ‰¾å‡ºMAPEæœ€å°çš„ç‚¹ä½œä¸ºæœ€ä½³åˆ†å‰²ç‚¹ã€‚å¦‚æœç‰¹å¾ä¸­æ²¡æœ‰ä¸é‡å¤çš„å…ƒç´ åˆ™è¿”å›Noneã€‚ 12345678910def _choose_split_point(self, X, y, idx, feature): feature_x = X[idx,feature] uniques = np.unique(feature_x) if len(uniques)==1: return Noe mape, split, split_avg = min( (self._get_split_mse(X, y, idx, feature, split) for split in unique[1:]), key=lambda x: x[0]) return mape, feature, split, split_avg é€‰æ‹©ç‰¹å¾éå†å…¨éƒ¨ç‰¹å¾ï¼Œè®¡ç®—mape,ç„¶åç¡®å®šç‰¹å¾å’Œå¯¹åº”çš„åˆ‡å‰²ç‚¹ï¼Œæ³¨æ„å¦‚æœæŸä¸ªç‰¹å¾çš„å€¼æ˜¯ä¸€æ ·çš„ï¼Œåˆ™è¿”å›None12345678910111213141516171819def _choose_feature(self, X, y, idx): m = len(X[0]) split_rets = [x for x in map(lambda x: self._choose_split_point( X, y, idx, x), range(m)) if x is not None] if split_rets == []: return None _, feature, split, split_avg = min( split_rets, key=lambda x: x[0]) idx_split = [[], []] while idx: i = idx.pop() xi = X[i][feature] if xi &lt; split: idx_split[0].append(i) else: idx_split[1].append(i) return feature, split, split_avg, idx_split å¯¹åº”å¶å­èŠ‚ç‚¹ï¼Œæ‰“å°ç›¸å…³çš„ä¿¡æ¯1234def _expr2literal(self, expr): feature, op, split = expr op = "&gt;=" if op == 1 else "&lt;" return "Feature%d %s %.4f" % (feature, op, split) å»ºç«‹å¥½äºŒå‰æ ‘ä»¥åï¼Œéå†æ“ä½œ12345678910111213141516171819def _get_rules(self): que = [[self.root, []]] self.rules = [] while que: nd, exprs = que.pop(0) if not(nd.left or nd.right): literals = list(map(self._expr2literal, exprs)) self.rules.append([literals, nd.score]) if nd.left: rule_left = [] rule_left.append([nd.feature, -1, nd.split]) que.append([nd.left, rule_left]) if nd.right: rule_right =[] rule_right.append([nd.feature, 1, nd.split]) que.append([nd.right, rule_right]) å»ºç«‹äºŒå‰æ ‘çš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯è®­ç»ƒçš„è¿‡ç¨‹ æ§åˆ¶æ·±åº¦ æ§åˆ¶èŠ‚å¶å­èŠ‚ç‚¹çš„æœ€å°‘æ ·æœ¬æ•°é‡ è‡³å°‘æœ‰ä¸€ä¸ªç‰¹å¾æ˜¯ä¸é‡å¤çš„12345678910111213141516171819202122232425def fit(self, X, y, max_depth=5, min_samples_split=2): self.root = Node() que = [[0, self.root, list(range(len(y)))]] while que: depth, nd, idx = que.pop(0) if depth == max_depth: break if len(idx) &lt; min_samples_split or set(map(lambda i: y[i,0], idx)) == 1: continue feature_rets = self._choose_feature(X, y, idx) if feature_rets is None: continue nd.feature, nd.split, split_avg, idx_split = feature_rets nd.left = Node(split_avg[0]) nd.right = Node(split_avg[1]) que.append([depth+1, nd.left, idx_split[0]]) que.append([depth+1, nd.right, idx_split[1]]) self.height = depth self._get_rules() æ‰“å°å¶å­èŠ‚ç‚¹12345def print_rules(self): for i, rule in enumerate(self.rules): literals, score = rule print("Rule %d: " % i, ' | '.join( literals) + ' =&gt; split_hat %.4f' % score) é¢„æµ‹å•æ ·æœ¬ 123456789101112def _predict(self, row): nd = self.root while nd.left and nd.right: if row[nd.feature] &lt; nd.split: nd = nd.left else: nd = nd.right return nd.score # é¢„æµ‹å¤šæ¡æ ·æœ¬def predict(self, X): return [self._predict(Xi) for Xi in X] 1234567891011121314 def main(): print("Tesing the accuracy of RegressionTree...") X_train=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]) y_train=np.array([[5.56 ],[5.7],[5.91],[6.4 ],[6.8],[7.05],[8.9],[8.7 ],[9 ],[9.05]]) reg = RegressionTree() print(reg) reg.fit(X=X_train, y=y_train, max_depth=3) reg.print_rules()main() ç®€å•çš„ä¾‹å­è®­ç»ƒæ•°æ® x 1 2 3 4 5 6 7 8 9 10 y 5.56 5.7 5.91 6.4 6.8 7.05 8.9 8.7 9 9.05 æ ¹æ®ä¸Šè¡¨ï¼Œåªæœ‰ä¸€ä¸ªç‰¹å¾$x$. é€‰æ‹©æœ€ä¼˜çš„ç‰¹å¾$j$å’Œåˆ†åˆ‡ç‚¹$s$ | åˆ†åˆ‡ç‚¹(s) | 1.5 | 2.5 | 3.5 | 4.5 | 5.5 | 6.5 | 7.5 | 8.5 | 9.5 || â€”â€”â€”â€”- | â€”â€”- | â€”â€”- | â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€”- | â€”â€”- || $c_1$ | 5.56 | 5.63 | 5.72 | 5.89 | 6.07 | 6.24 | 6.62 | 6.88 | 7.11 || $c_2$ | 7.5 | 7.73 | 7.99 | 8.25 | 8.54 | 8.91 | 8.92 | 9.03 | 9.05 || loss | 15.72 | 12.07 | 8.36 | 5.78 | 3.91 | 1.93 | 8.01 | 11.73 | 15.74 | å½“åˆ†åˆ‡ç‚¹å–$s=6.5$,æŸå¤±æœ€å°$l(s=6.5)=1.93$,æ­¤æ—¶åˆ’åˆ†å‡ºä¸¤ä¸ªåˆ†æ”¯ï¼Œåˆ†åˆ«æ˜¯$R_1=\{1,2,3,4,5,6\}$,$c_1=6.42$,$R_2=\{7,8,9,10\}$,$c_2=8.91$ a) å¯¹R1ç»§ç»­åˆ’åˆ† | x | 1 | 2 | 3 | 4 | 5 | 6 || â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€” || y | 5.56 | 5.7 | 5.91 | 6.4 | 6.8 | 7.05 | | åˆ†åˆ‡ç‚¹(s) | 1.5 | 2.5 | 3.5 | 4.5 | 5.5 || â€”â€”â€”â€”- | â€”â€”â€” | â€”â€”- | â€”â€”â€” | â€”â€”â€” | â€”â€”â€” || $c_1$ | 5.56 | 5.63 | 5.72 | 5.89 | 6.07 || $c_2$ | 6.37 | 6.54 | 6.75 | 6.93 | 7.05 || loss | 1.3087 | 0.754 | 0.2771 | 0.4368 | 1.0644 | å½“åˆ†åˆ‡ç‚¹å–$s=3.5$,æŸå¤±å‡½æ•°$l(s=3.6)=0.2771$(å‡è®¾æ­¤æ—¶æ»¡è¶³åœæ­¢æ¡ä»¶ï¼‰,æ­¤æ—¶å¾—åˆ°ä¸¤ä¸ªåˆ†æ”¯ï¼Œåˆ†åˆ«æ˜¯$R_1=\{1,2,3\}$ï¼Œ$c_1=5.72$,$R_2={4,,5,6}$,$c_2=6.75$ b) å¯¹R2ç»§ç»­åˆ’åˆ† | x | 7 | 8 | 9 | 10 || â€”â€” | â€”â€” | â€”â€” | â€”â€” | â€”â€” || y | 8.9 | 8.7 | 9 | 9.05 | | åˆ†åˆ‡ç‚¹(s) | 7.5 | 8.5 | 9.5 || â€”â€”â€”â€”- | â€”â€”â€” | â€”â€”â€” | â€”â€”â€” || $c_1$ | 8.9 | 8.8 | 8.87 || $c_2$ | 8.92 | 9.03 | 9.05 || loss | 0.0717 | 0.0213 | 0.0467 | å½“åˆ†åˆ‡ç‚¹å–$s=8.5$,æŸå¤±å‡½æ•°$l(s=8,5)=0.0213$(å‡è®¾æ­¤æ—¶æ»¡è¶³åœæ­¢æ¡ä»¶ï¼‰,æ­¤æ—¶å¾—åˆ°ä¸¤ä¸ªåˆ†æ”¯ï¼Œåˆ†åˆ«æ˜¯$R_1=\{7,8\}$ï¼Œ$c_1=8.8$,$R_2=\{9,10\}$,$c_2=9.03$ å‡½æ•°è¡¨è¾¾å¼ $$ \begin{equation} f(x)=\left\{ \begin{aligned} 5.72 &amp; &amp; x&lt;3.5\\ 6.7 5&amp; &amp;3.5&lt;=x&lt;6.5\\ 8.8&amp; &amp;6.5&lt;=x&lt;8.5\\ 9.03&amp; &amp;8.5&lt;=x&lt;10\\ \end{aligned} \right. \end{equation} $$ Pythonåº“1class sklearn.tree.DecisionTreeClassifier(criterion=â€™giniâ€™, splitter=â€™bestâ€™, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False) 12345678910111213141516171819202122232425262728293031323334353637# -*- coding: utf-8 -*-"""Created on Wed Mar 13 19:59:53 2019@author: 23230"""import numpy as npfrom sklearn.tree import DecisionTreeRegressorimport matplotlib.pyplot as pltX=np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])y=np.array([[5.56 ],[5.7],[5.91],[6.4],[6.8],[7.05],[8.9],[8.7],[9 ],[9.05]])# Fit regression modelregr_1 = DecisionTreeRegressor(max_depth=2)regr_2 = DecisionTreeRegressor(max_depth=3)regr_3 = DecisionTreeRegressor(max_depth=4)regr_1.fit(X, y)regr_2.fit(X, y)regr_3.fit(X, y)X_test = np.copy(X)y_1 = regr_1.predict(X_test)y_2 = regr_2.predict(X_test)y_3 = regr_3.predict(X_test) # Plot the resultsplt.figure()plt.scatter(X, y, s=20, edgecolor="black",c="darkorange", label="data")plt.plot(X_test, y_1, color="cornflowerblue",label="max_depth=2", linewidth=2)plt.plot(X_test, y_2, color="yellowgreen", label="max_depth=4", linewidth=2)plt.plot(X_test, y_3, color="r", label="max_depth=8", linewidth=2)plt.xlabel("data")plt.ylabel("target")plt.title("Decision Tree Regression")plt.legend()]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>å›å½’æ ‘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BPç®—æ³•]]></title>
    <url>%2F2019%2F03%2F05%2FBP%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[TOC] 1. éœ€è¦çš„å¾®ç§¯åˆ†çŸ¥è¯†1.1 å¯¼æ•°å¯¹äºä¸€å…ƒå‡½æ•°ï¼Œåœ¨å¯¼æ•°å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œåœ¨æŸä¸€ç‚¹çš„å¯¼æ•°ï¼Œä¹Ÿå°±æ˜¯è¯¥ç‚¹çš„æ–œç‡ã€‚å¯¹äºå¤šå…ƒå‡½æ•°ï¼Œå¯¹äºæŸä¸€ç‚¹æ±‚å¯¼ï¼Œåˆ™éœ€è¦æŒ‡æ˜æ–¹å‘ï¼Œä¸¤ä¸ªç‰¹æ®Šçš„æ–¹å‘ï¼Œ1. åå¯¼ï¼šåœ¨åæ ‡è½´æ–¹å‘çš„å¯¼æ•° 2. æ¢¯åº¦çš„æ–¹å‘:æ€»æœ‰ä¸€ä¸ªæ–¹å‘æ˜¯å˜åŒ–æœ€å¿«çš„ã€‚ 1.2 æ±‚å¯¼çš„é“¾å¼æ³•åˆ™ $x \in R$, $z=g(f(x))$, $y=f(x)$ \frac{\partial z}{\partial x}=\frac{\partial z}{\partial y} \frac{\partial y}{\partial x} $ x \in R^m $, $f(x)$æ˜¯$R^M$åˆ°$R^n$çš„æ˜ å°„ï¼Œ$g(f)$æ˜¯$R^n$åˆ°Rçš„æ˜ å°„ \frac{\partial g}{\partial x_i}=\sum_j^n \frac{\partial g}{\partial f_i} \frac{\partial f_i}{\partial x_i} å¦‚æœä½¿ç”¨å‘é‡è¡¨ç¤º \nabla_x^z=(\frac{\partial f}{\partial x})^T \nabla_y^z2. æ¢¯åº¦ä¸‹é™æ³•2.1 æ¢¯åº¦æ¢¯åº¦å…¶å®æœ¬è´¨ä¹Ÿæ˜¯ä¸€ä¸ªå‘é‡ï¼Œå¯¹äºå‡½æ•°$f(X,y)$åœ¨$(W,y)$è¿™ä¸€ç‚¹çš„æ¢¯åº¦ $(\frac{\partial f}{\partial X},\frac{\partial f}{\partial y})$æ¢¯åº¦çš„å‡ ä½•æ„ä¹‰ï¼šåœ¨è¯¥åº—å˜åŒ–å¢åŠ æœ€å¿«çš„åœ°æ–¹ 2.2 æ¢¯åº¦ç®—æ³•çš„è§£é‡Šå›¾æ¥è‡ªå´æ©è¾¾çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹é¢œè‰²åçº¢(A)çš„åœ°æ–¹å¼€å§‹ï¼Œæ ¹æ®æ¢¯åº¦çš„è´Ÿæ–¹å‘é€šè¿‡9æ¬¡æ›´æ–°ï¼Œè¾¾åˆ°äº†æœ€å°å€¼(B)ã€‚ç°åœ¨ç»™å®šä¸€ä¸ªç‚¹$A(\theta_0,\theta_1)$,å¹²å˜›å‘¢ï¼Œæˆ‘ä»¬æƒ³ä»Aåˆ°Bç‚¹ï¼ˆæœ€å°å€¼ç‚¹),ç±»ä¼¼äººç±»ä¸‹å±±ï¼Œéœ€è¦çŸ¥é“å¾€é‚£ä¸ªæ–¹å‘å§ã€èµ°å¤§å¤šä¸€æ­¥å‘¢ï¼Ÿæ–¹å‘ï¼šæ¢¯åº¦çš„è´Ÿæ–¹å‘ $ \delta=(\frac{\partial L}{\partial \theta_0},\frac{\partial L}{\partial \theta_1})$)æ­¥é•¿ï¼šå­¦ä¹ ç‡ï¼ˆ$\alpha$)å› æ­¤ï¼Œè®¡ç®—ä¸€æ¬¡é‡Œç›®æ ‡æ›´è¿‘äº† $(\theta_0,\theta_1)=(\theta_0,\theta_1)-\alpha \dot (\delta)$åœ¨é‡å¤ä¸Šä¸¤æ­¥ï¼Œç›´åˆ°æ»¡æ„ä¸ºæ­¢ã€‚ 3.è¯¯å·®åå‘ä¼ æ’­ç®—æ³•3.1 ç†è®ºæ¨å¯¼ 3.1.1 ç¬¦å·è¯´æ˜ä¸Šå›¾æ˜¯ä¸€ä¸ªLå±‚çš„ç¥ç»ç½‘ç»œï¼Œè¾“å…¥å±‚ä¸ºç¬¬ä¸€å±‚ï¼Œéšè—å±‚ï¼š2è‡³$L-1$å±‚ï¼Œè¾“å‡ºå±‚L ä»¤ è¾“å…¥å‘é‡ $\vec{X}$ \vec{X} = (x_1,x_2,...,x_{m-1},x_m)è¾“å‡ºå‘é‡ $\vec{Y}$ \vec{Y}=(y_1,y_2,...,y_{n-1},y_n)$$a ç¬¬jå±‚éšè—å±‚çš„è¾“å‡ºå‘é‡ $\vec{h^{(j)}}$ $$\vec{h^{(j)}}=(h_1^{(j)},h_2^,...,h_{t-1}^{(j)},h_tj^{(j)})å…¶ä¸­ï¼Œ$tj$:è¡¨ç¤ºç¬¬jçš„éšè—å±‚ä¸ªæ•°ç¬¬$(l-1)$å±‚çš„ç¬¬iä¸ªç¥ç»å…ƒåˆ°ç¬¬$l$å±‚çš„ç¬¬jä¸ªç¥ç»å…ƒçš„è¿æ¥æƒé‡ï¼š$w_{ij}^{(l)}$ï¼Œåˆ™ç¬¬$(l-1)$å±‚ç¥ç»å…ƒåˆ°ç¬¬$l$å±‚ç¥ç»å…ƒçš„è¿æ¥æƒé‡çŸ©é˜µ W^{(l)}=\left( \begin{matrix}w_{11}^{(l)}& \cdots & w_{1(tj)}\\ & \dots &\\ w_{s(l-1)}^{l}&\cdots&w_{s(l-1)s(l)}^{l} \end{matrix}\right)3.1.2 æ¨å¯¼è¿‡ç¨‹3.1.2.1 è¯¯å·®å®šä¹‰çš„è¯¯å·®å‡½æ•°,å¸¸è§çš„è¡¡é‡æ€§æŒ‡æ ‡è§ æˆ³æˆ‘,è¿™é‡Œé€‰æ‹©çš„è¯¯å·®å¹³æ–¹å’Œæœ€å°ç¬¬$i$ä¸ªè¾“å‡ºçš„è¯¯å·®,å‡è®¾å®é™…è¾“å‡º$(d(1),d(2),â€¦,d(n))$ï¼š,ä¸€ä¸ªè¾“å…¥æ ·æœ¬å¯¹åº”çš„è¯¯å·® E(i)=\frac{1}{2}\sum_{k=1}^n(y(i)-d(i))^2=\frac{1}{2}||y-d||^2æ‰€æœ‰è®­ç»ƒæ ·æœ¬($N$)çš„è¯¯å·®ï¼š E(i)=\frac{1}{2}\sum_{j=1}^{N}(\sum_{k=1}^n(y(i)-d(i))^2)=\frac{1}{2N}\sum_{j=1}^{N}(||y(i)-d(i)||^2)å› æ­¤ï¼Œ E = \frac{1}{2N}\sum_{i=1}^N(||y(i)-d(i)||^2)å…¶å®ï¼Œç¥ç»ç½‘ç»œçš„è¾“å‡ºæ˜¯å…³äºèŠ‚ç‚¹çš„å¤åˆå‡½æ•°ã€‚ä»£ä»·å‡½æ•°æ˜¯å…³äº$W$å’Œ$b$çš„å‡½æ•°ã€‚ 3.1.2.2 æ­£å‘ä¼ æ’­è¾“å…¥å±‚$\hat{X}$ï¼š X =(x_1,x_2,x_3,...,x_m)å½“æœ‰$N$ä¸ªè®­ç»ƒæ ·æœ¬æ—¶ï¼Œå¯ç”¨çŸ©é˜µè¡¨ç¤º X=\left( \begin{matrix} x_{11} &x_{12}&...&x_{1m}\\ x_{21} & x_{22}&...&x_{2m}\\ \vdots & \vdots&\dots&\vdots\\ x_{N1} & \vdots&\vdots&x_{Nm}\\ \end{matrix} \right)ç¬¬äºŒå±‚ $h^{(2)}$,ä¸€å…±$s2$ä¸ªèŠ‚ç‚¹:ç¬¬iä¸ªèŠ‚ç‚¹çš„è®¡ç®— h^{(2)}(i)=f(\sum_{j=1}^{s2}x(j)*w_{ji}^{(l)}+b_i)=f(x*w(:,i)+b_i)çŸ©é˜µè¡¨ç¤º h^{(2)}=f(x*W^{(l)}+b^{(2)})ç¬¬iå±‚ çŸ©é˜µå½¢å¼ h^{(l)}=f(h^{(l-1)}*W^{(l)}+b)3.1.2.3 åå‘ä¼ æ’­æ¢¯åº¦ä¸‹é™æ³•æ›´æ–°æƒé‡ï¼Œä¸æ–­è¿­ä»£åˆ°æœ€ä¼˜è§£ã€‚å¯¹$w_{ij}$æ±‚å¯¼æ•°å¯å¾—,å¯æ›´æ–°$w_{ij}$æ›´æ–°å…¬å¼ï¼š w_{ij}=w_{ij}-\alpha \frac{\partial E}{\partial w_{ij}}å½“ç„¶ç®€å•çš„æƒ…å†µä¸‹ï¼Œå¯ç›´æ¥å†™å‡ºå…¬å¼ï¼Œå½“å¤ªå¤æ‚çš„æ—¶å€™ï¼Œå¼•å…¥BPç®€åŒ–æ±‚å¯¼ æ–¹ä¾¿ä¹¦å†™å…¬å¼ï¼Œå¯¹äºç¬¬içš„è¾“å…¥$h^{(i-1)}*W^{(i)}+b^{(i)}$è®°ä½œ$net^{(i)}$,å…¶ä¸­ï¼Œç¬¬$i$çš„è¾“å…¥å’Œè¾“å‡ºçš„å…³ç³»ï¼Œ$è¾“å…¥=f(è¾“å‡º)$ä¸‹é¢å¼€å§‹æ¨å¯¼ é¦–å…ˆï¼Œå¯¹äº$L$å±‚ï¼Œ å¯¹äº$W^{(L)}$ï¼Œå…ˆçœ‹å¯¹$W_{ij}^{(L)}$æ±‚å¯¼ï¼Œ \frac{\partial E}{\partial W_{ij}^{(L)}} =\frac{\partial E}{\partial y(j)} * \frac{\partial y(i)}{\partial net_{j}^{L}} * \frac{\partial net_{j}^{L}}{\partial W_{ij}^{(L)}}\\ =(y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}h_i^{(L-1)}ä»¤$\delta_i^{(L)}=y(i)-d(i)$ ä¸Šè¿°ç»™å‡ºäº†å•ä¸ªåˆ†é‡çš„æ±‚åå¯¼çš„ç»“æœï¼Œå¯¹äº$W^{(L)}$ \frac{\partial E}{\partial W^{(L)}} =\left[\begin{matrix} \frac{\partial E}{\partial W_{11}^{(L)}} & \frac{\partial E}{\partial W_{12}^{(L)}}&\dots & \frac{\partial E}{\partial W_{1n}^{(L)}}\\ \frac{\partial E}{\partial W_{21}^{(L)}} & \frac{\partial E}{\partial W_{22}^{(L)}}&\dots& \frac{\partial E}{\partial W_{2n}^{(L)}}\\ \vdots& \dots& \dots& \dots\\ \frac{\partial E}{\partial W_{sL,1}^{(L)}} & \frac{\partial E}{\partial W_{sL,2}^{(L)}}&\dots& \frac{\partial E}{\partial W_{sL,n}^{(L)}} \end{matrix}\right] \\= \left[ \begin{matrix} h^{(L-1)}_1\\h^{(L-1)}_2\\ \dots\\h^{(L-1)}_n \end{matrix} \right] *\left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right] ^T =h^{(L-1)}S^{(L)}å…¶ä¸­ï¼Œ S^{(L)}=\left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right]^TåŒç†å¯å¾—ï¼Œ \frac{\partial E}{\partial b_k^{(L)}}=(y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}å…¶æ¬¡ï¼Œå¯¹äºéšå«å±‚$L-1$å±‚ï¼Œå¯¹$W_{ij}^{(L)}$æ±‚å¯¼ \frac{\partial E}{\partial W_{ij}^{(L-1)}} =\sum_{k=1}^{n}\frac{\partial E}{\partial y(k)} * \frac{\partial y(k)}{\partial net_{k}^{L}} * \frac{\partial net_{k}^{L}}{\partial f(net_j^{(L-1)})}*\frac{\partial f(net_j^{(L-1)})}{\partial net_j^{(L-1)}}*\frac{\partial net_j^{(L-1)}}{\partial W_{ij}^{(L-1)}}\\ =\sum_{k=1}^{n} (y(j)-d(j))*f(x)^{'}|_{x=net_j^{(L)}}W_{kj}^{(L)}f(x)^{'}|_{x=net_j^{L-1}}h_i^{L-2}\\ =\sum_{k=1}^{n}S_i^{(L)}W_{kj}^{(L)}f(x)^{'}|_{x=net_j^{L-1}}h_i^{L-2}\\å†™å‡ºçŸ©é˜µå½¢å¼,å¯¹$W^{(L-1)}$ \frac{\partial E}{\partial W^{(L-1)}}=\left[\begin{matrix} h^{(L-2)}_1\\h^{(L-2)}_2\\\vdots\\h^{(L-2)}_{s(L-2)}\end{matrix}\right] \left[\begin{matrix} \delta_1^{(L)}f(x)^{'}|_{x=net_1^{(L)}}\\ \delta_2^{(L)}f(x)^{'}|_{x=net_2^{(L)}}\\ \dots\\ \delta_n^{(L)}f(x)^{'}|_{x=net_n^{(L)}} \end{matrix}\right]^T \left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)} \end{matrix}\right]^T \\ \left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\\ =h^{(L-2)}S^{(L-1)} S^{(L-1)}=\left(\left[\begin{matrix} f(x)^{'(L)}|_{x=net_1^{(L)}}&0& \dots& 0\\ 0&f(x)^{'}|_{x=net_2^{(L)}}0& \dots& 0\\ 0&\dots&\dots&0\\ 0&0&0&f(x)^{'(L)}|_{x=net_n^{(L)}} \end{matrix}\right]\left[\begin{matrix} \delta_1^{(L)}\\\delta_2^{(L)}\\\vdots\\\delta_n^{(L)}\end{matrix}\right] \right)^T\\ \left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T \left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]\\ =S^{(L)}\left[\begin{matrix} W_{11}^{(L)} & W_{12}^{(L)}&\dots & W_{1n}^{(L)}\\ W_{21}^{(L)} & W_{22}^{(L)}&\dots& W_{2n}^{(L)}\\ \vdots& \dots& \dots& \dots\\ W_{s(L-1),1}^{(L)} & W_{s(L-1),2}^{(L)}&\dots& W_{s(L-1),n}^{(L)}* \end{matrix}\right]^T\left[ \begin{array}{ccc}{f^{'(L-1)}\left(net^{(L-1)}_{(1)}\right)} & {0} & {0}&{0} \\ {0} & {f^{'(L-1)}\left(net^{(L-1)}_{(2)}\right)} & {0} &{0}\\ 0 & \dots & \vdots & 0\\{0} & {0} & {0}&{f^{(L-1)}\left(ne t_{s(L-1)}^{(L-1)}\right)}\end{array}\right]*\\å¯¹$1&lt;l&lt;L$,æ±‚$W^{(l)}$çš„åå¯¼, æœ€åï¼Œæ ¹æ®ä¸Šè¿°çš„æ¨å¯¼å–”ï¼Œå¾ˆå®¹æ˜“å¾—å‡º$S^{(l)}$å’Œ$S^{(l+1)}$, S^{(l)}=S^{(l+1)}W^{(l+1)^T}F^{'(l)}(net^{(l)})\\ S^{(L)}=(Y-\hat{Y})F^{'(L)}(net^{(L)}) \frac{\partial E}{\part W^{(l)}}=\left[\begin{matrix}h^{(l-1)}_1\\h^{(l-1)}_2 \\\dots \\h^{(l-1)}_{sl}\end{matrix}\right]S^{(l+1)} \left[\begin{matrix}W_{11}^{(l+1)}&W_{12}^{(l+1)} &\dots& W_{2(sl+1)}^{(l+1)}\\ W_{21}^{(l+1)}&W_{22}^{(l+1)} &\dots& W_{2(sl+1)}^{(l+1)}\\ \dots&\dots&\dots&\dots\\ W_{sl1}^{(l+1)}&W_{sl2}^{(l+1)} &\dots& W_{sl(sl+1)}^{(l+1)}\\ \end{matrix} \right]^T\left[\begin{matrix} \part f^{'(l)}(net_1^{l})&0&\dots & 0\\ 0\\0 &\part f^{'(l)}(net_2^{l})&\dots&0\\ 0 & 0&\dots&0\\ 0&0&\dots&\part f^{'(l)}(net_l^{l})\end{matrix}\right]3.2 BPç®—æ³•çš„å°ç»“ç®—æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå‰å‘é˜¶æ®µå’Œåå‘ä¼ æ’­é˜¶æ®µ åå‘é˜¶æ®µç®—æ³•ï¼š Step 1: è®¡ç®—$\hat{y}^{(L)}$ Step 2: for l =L:2 â€‹ è®¡ç®—$S^{(l)}=S^{(l+1)}W^{(l+1)}Fâ€™(net^{(l)})$ â€‹ è®¡ç®— $\Delta W^{(l)}=h^{(l-1)}S^{(l)} $ â€‹ è®¡ç®—$W^{(l)}=W^{(l)}-\delta \Delta W^{(l)}$ 3.3 Pythonå®ç°3.3.1 æœ€ç®€å•ä¸‰å±‚ç½‘ç»œ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071'''ä¸ç”¨ä»»ä½•æ¡†æ¶ï¼Œè‡ªå·±å†™ä¸€ä¸ªä¸‰å±‚çš„ç¥ç»ç½‘ç»œ# input-3,hidden-4 output-1'''import numpy as npnp.random.seed(1)# Input MatrixX = np.array([[0, 0, 1], [0, 1, 1], [1, 0 ,1], [1, 1, 1],])# Output Matrixy = np.array([[0], [1], [1], [0]])# Nonlinear functiondef sigmoid(X,derive=False): if not derive: return 1 / (1 + np.exp(-X)) else: return X*(1-X)# reludef relu(X,derive = False): if not derive: return np.maximum(0,X) else: return (X&gt;0).astype(float) # Weight biasW1 = 2 * np.random.random((3, 4))-1b1 = 0.1 * np.ones((4,)) W2 = 2 * np.random.random((4,1))-1b2 = 0.1 * np.ones((1,)) rate = 0.1noline = relu# Trainingtrain_times = 200 for time in range(train_times): # Layer one A1 = np.dot(X,W1)+b1 Z1 = noline(A1) # Layer two A2 = np.dot(Z1, W2)+b2 Z2 = noline(A2) cost = -y+Z2 # Calc deltas S2= cost*noline(A2,True) delta_W2 = np.dot(Z1.T,S2) bias2 = S2.sum(axis=0) S1 = np.dot(S2, W2.T)*noline(A1,True) delta_W1= np.dot(X.T, S1) bias1 = S1.sum(axis=0) # update W1 = W1-rate*delta_W1 b1 = b1-rate*bias1 W2 = W2-rate*delta_W2 b2 = b2-rate*bias2 print('error',np.mean(((y-Z2)*(y-Z2))**2))print("prediction",Z2) 3.4 é™„å½•ï¼š Name Abbreviation Mean absolute percentage error MAPE Root mean squares percentage error RMSPE Mean absolute percentage error MAE Mean squares error MSE Index of agreement IA Theil U statistic 1 U1 Theil U statistic 2 U2 Correlation coefficient R MAPE = $\frac{1}{n} \sum_{k=1}^{n}\left|\frac{x^{(0)}(k)-\hat{x}^{(0)}(k)}{x^{(0)}(k)}\right| \times 100$RMSPE = $\sqrt{\frac{1}{n} \sum_{k=1}^{n}\left(\frac{\hat{x}^{(0)}(k)-x^{(0)}(k)}{x^{(0)}(k)}\right)^{2}} \times 100$MAE = $\frac{1}{n} \sum_{k=1}^{n}\left|\hat{x}^{(0)}(k)-x^{(0)}(k)\right|$MSE = $\frac{1}{n} \sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}$IA = $1-\frac{\sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}}{\sum_{k=1}^{n} \left( \left| \hat{x}^{(0)}(k)-\overline{x} \right|+\left| x^{(0)}(k)-\overline{x}\right| \right)^{2}}$U1 = $\frac{\sqrt{\frac{1}{n} \sum_{k=1}^{n}\left(x^{(0)}(k)-x^{(0)}(k)\right)^{2}}}{\sqrt{\frac{1}{n} \sum_{k=1}^{n} x^{(0)}(k)^{2}}+\sqrt{\frac{1}{n} \sum_{k=1}^{n} x^{(0)}(k)^{2}}}$U2 = $\frac{\left[\sum_{k=1}^{n}\left(\hat{x}^{(0)}(k)-x^{(0)}(k)\right)^{2}\right]^{1 / 2}}{\left[\sum_{k=1}^{n} x^{(0)}(k)^{2}\right]^{1 / 2}}$R = $\frac{\operatorname{Cov}(\hat{x}^{(0)}, x^{(0)})}{\sqrt{\operatorname{Var}[\hat{x}^{(0)}] \operatorname{Var}[x^{(0)}]}}$]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>BP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å´æ©è¾¾]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%90%B4%E6%81%A9%E8%BE%BE%2F</url>
    <content type="text"><![CDATA[Neural Networks and Deep Learning 4 å‘¨]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>å†³ç­–æ ‘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å¸Œè…Šå­—æ¯]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D%2F</url>
    <content type="text"><![CDATA[$\alpha$ $\beta$ $\gamma$ $\Gamma$ $\delta$ $\Delta$ $\epsilon$ $\varepsilon$ $\zeta$ $\eta$ $\theta$ $\Theta$ $\vartheta$ $\iota$ $\kappa$ $\lambda$ $\Lambda$ $\mu$ $\nu$ $\xi$ $\Xi$ $\pi$ $\Pi$ $\varpi$ $\rho$ $\varrho$ $\sigma$ $\Sigma$ $\varsigma$ $\tau$ $\upsilon$ $\Upsilon$ $\phi$ $\Phi$ $\varphi$ $\chi$ $\psi$ $\Psi$ $\Omega$ $\omega$ alpha beta gamma delta epsilon theta]]></content>
      <categories>
        <category>æ‚é¡¹</category>
      </categories>
      <tags>
        <tag>å¸Œè…Šå­—æ¯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å†³ç­–æ ‘]]></title>
    <url>%2F2019%2F03%2F03%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[ä¸»è¦æ˜¯åˆ†äº«å†³ç­–çš„åŸºæœ¬çŸ¥è¯†ç‚¹ï¼Œé‡ç‚¹åœ¨åˆ†ç±»å†³ç­–æ ‘ä¸Šï¼Œå¯¹äºå›å½’çš„å†³ç­–æ ‘åé¢åœ¨ç»™å‡ºã€‚å¸Œæœ›å¤§å®¶å’Œæˆ‘ä¸€èµ·åšçŸ¥è¯†çš„ä¼ æ’­è€…å•¦ï¼:smile: :smiley: :grin: :open_mouth: [TOC] å†³ç­–æ ‘è‹±æ–‡åå­—ï¼šDescision Tree ä»€ä¹ˆæ˜¯å†³ç­–æ ‘ä¸¾ä¸ªæ ¡å›­ç›¸äº²çš„ä¾‹å­ï¼Œä»Šå¤©æ ¡å›­çš„å°çŒ«(å¥³)å’Œå°ç‹—(ç”·)å‡†å¤‡é…å¯¹ï¼Œå°çŒ«å¦‚ä½•æ‰èƒ½åœ¨ä¼—å¤šçš„ä¼˜è´¨ğŸ¶çš„å¿ƒä»ªçš„ç‹—å‘¢ï¼Ÿäºæ˜¯å‘¢ï¼Ÿæœ‰ä¸€åªç‰¹ä¹–å·§çš„å°çŒ«æ‰¾åˆ°äº†ä½ ï¼Œä½ æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œåˆšå¥½å­¦ä¹ äº†å†³ç­–æ ‘ï¼Œå‡†å¤‡ç»™è¿™åªçŒ«çŒ«æŒ‘é€‰ä¼˜è´¨ç‹—ï¼Œå½“ç„¶ï¼Œä½ ä¸ä»…ä»…æ˜¯ç›´æ¥å‘Šè¯‰çŒ«å“ªäº›ç‹—æ˜¯åˆé€‚ä½ çš„ï¼Ÿä½ æ›´åº”è¯¥è¯¦ç»†çš„ç»™çŒ«è®²è§£å†³ç­–æ ‘æ˜¯å¦‚ä½•æ ¹æ®å®ƒæå‡ºçš„æ ‡å‡†é€‰å‡ºçš„ç¬¦åˆè¦æ±‚çš„ç‹—å‘¢ï¼ŸçŒ«ç»™å‡ºå¦‚ä¸‹ä¿¡æ¯ï¼šå¹´é¾„=0.5 6.5&lt;=ä½“é‡&lt;=8.5;å¿ƒä»ª; å¹´é¾„&gt;=0.5 ä½“é‡&gt;8.5 é•¿ç›¸å¥½ å¿ƒä»ª;å…¶ä½™æƒ…å†µä¸å¿ƒä»ª; æ ¹æ®ä¸Šè¿°æ¡ä»¶å¯ä»¥æ„é€ ä¸€é¢—æ ‘ï¼šä¸Šé¢çš„å›¾å°±æ˜¯å†³ç­–æ ‘ï¼Œæœ€ç»ˆçš„ç»“æœæ˜¯å¿ƒä»ªæˆ–è€…ä¸å¿ƒä»ªã€‚å†³ç­–æ ‘ç®—æ³•ä»¥æ ‘å½¢ç»“æ„è¡¨ç¤ºæ•°æ®åˆ†ç±»çš„ç»“æœ åŸºæœ¬æ¦‚å¿µå†³ç­–æ ‘å±äºä¹Ÿåªèƒ½éå‚æ•°å­¦ä¹ ç®—æ³•ã€å¯ä»¥ç”¨äºè§£å†³(å¤š)åˆ†ç±»é—®é¢˜ï¼Œå›å½’é—®é¢˜ã€‚ å›å½’é—®é¢˜çš„ç»“æœï¼Œå¶å­ç»“ç‚¹çš„å¹³å‡å€¼æ˜¯å›å½’é—®é¢˜çš„è§£ã€‚æ ¹èŠ‚ç‚¹ï¼šå†³ç­–æ ‘å…·æœ‰æ•°æ®ç»“æ„é‡Œé¢çš„äºŒå‰æ ‘ã€æ ‘çš„å…¨éƒ¨å±æ€§éå¶å­èŠ‚ç‚¹ ï¼šï¼ˆå†³ç­–ç‚¹ï¼‰ ä»£è¡¨æµ‹è¯•çš„æ¡ä»¶ï¼Œæ•°æ®çš„å±æ€§çš„æµ‹è¯•å¶å­èŠ‚ç‚¹ ï¼šåˆ†ç±»åè·å¾—åˆ†ç±»æ ‡è®°åˆ†æ”¯ï¼š æµ‹è¯•çš„ç»“æœ æ•°å­¦é—®é¢˜-ç†µ-Giniç³»æ•°ä»€ä¹ˆæ˜¯ç†µï¼šç†µçš„æ¦‚å¿µæºäºç‰©ç†å­¦ï¼Œç”¨äºåº¦é‡ä¸€ä¸ªçƒ­åŠ›å­¦ç³»ç»Ÿçš„æ— åºç¨‹åº¦ã€‚ä¿¡æ¯ç†µï¼šä¸å¾—ä¸æé¦™å†œè¿™ä¸ªå¤§å†™çš„äººå•¦ï¼ä¿¡æ¯è®ºé‡Œé¢çš„çŸ¥è¯†ã€‚åœ¨ä¿¡æ¯è®ºé‡Œé¢ï¼Œä¿¡æ¯ç†µè¡¡é‡ä¿¡æ¯é‡çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯å¯¹éšæœºå˜é‡ä¸ç¡®å®šåº¦çš„ä¸€ä¸ªè¡¡é‡ã€‚ç†µè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ï¼›å¯¹äºæŸä¸ªå•ç¬¦å·æ— è®°å¿†ä¿¡æºï¼Œå‘å‡ºç¬¦å·($x_i$)çš„æ¦‚ç‡æ˜¯$p_i$,æ¦‚ç‡è¶Šå¤§ï¼Œç¬¦å·çš„ä¿¡æ¯é‡å°±è¶Šå°ï¼Œé¦™å†œå…¬å¼ $I(x_i)=-log_{p_i}$ã€‚ä¿¡æºæ‰€å«çš„ä¿¡æ¯ç†µå°±æ˜¯ä¿¡æ¯é‡çš„æœŸæœ›]$H(x)=-\sum p_i*log_{p_i}$Giniç³»æ•°ï¼š $Gimi(p) = 1-\sum_{k=1}^{K}p_k^2$ å†³ç­–æ ‘å¦‚ä½•æ„å»ºçš„é—®é¢˜è‡ªæˆ‘æé—®é˜¶æ®µï¼š æ¯ä¸ªèŠ‚ç‚¹çš„ä½ç½®å¦‚ä½•ç¡®å®šï¼Ÿç‰¹å¾çš„é€‰æ‹©ï¼šæ¯æ¬¡é€‰å…¥çš„ç‰¹å¾ä½œä¸ºåˆ†è£‚çš„æ ‡å‡†ï¼Œéƒ½æ˜¯ä½¿å¾—å†³ç­–æ ‘åœ¨è¿™ä¸ªèŠ‚ç‚¹çš„æ ¹æ®ä½ è‡ªå·±é€‰æ‹©çš„æ ‡å‡†ï¼ˆä¿¡æ¯ç†µæœ€å°ã€ä¿¡æ¯å¢ç›Šæœ€å¤§ã€giniç³»æ•°æœ€å°ï¼‰. æ¯ä¸ªèŠ‚ç‚¹åœ¨å“ªä¸ªå€¼ä¸Šåšåˆ’åˆ†ï¼Œç¡®å®šåˆ†æ”¯ç»“æ„å‘¢ï¼Ÿéå†åˆ’åˆ†çš„èŠ‚ç‚¹çš„åˆ†ç•Œå€¼æ“ä½œæ¥è§£å†³è¿™ä¸ªé—®é¢˜ å¯ä»¥æƒ³è±¡ï¼Œæˆ‘ä»¬æ„é€ çš„å†³ç­–æ ‘è¶³å¤Ÿåºå¤§ï¼Œå†³ç­–æ ‘å¯ä»¥æŠŠæ¯ä¸€ä¸ªæ ·æœ¬éƒ½åˆ†å¯¹ï¼Œé‚£ä¹ˆå†³ç­–æ ‘çš„æ³›åŒ–èƒ½åŠ›å°±å¯ä»¥å¾ˆå·®äº†ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±éœ€è¦å‰ªææ“ä½œäº† è®­ç»ƒç®—æ³•åŸºäºä¿¡æ¯ç†µçš„æ„é€ å½“é€‰æ‹©æŸä¸ªç‰¹å¾ä½œä¸ºèŠ‚ç‚¹æ—¶ï¼Œæˆ‘ä»¬å°±å¸Œæœ›è¿™ä¸ªç‰¹å¾çš„ä¿¡æ¯ç†µè¶Šå°è¶Šå¥½ï¼Œé‚£ä¹ˆä¸ç¡®å®šæ€§è¶Šå°ã€‚è®¡ç®—ç‰¹å¾çš„ä¿¡æ¯ç†µå…¬å¼å¦‚ä¸‹ï¼š H(x) = -p_i(x)log^{p_i(x)} = -\frac{n_j}{S}log^{\frac{n_j}{S}}$n_j$: ç¬¬jä¸ªç±»åˆ«ï¼Œåœ¨æ ·æœ¬ä¸­å‡ºç°çš„é¢‘æ•°$S$: æ ·æœ¬ä¸ªæ•°å¯¹äºç¦»æ•£å±æ€§ï¼Œç›´æ¥è®¡ç®—ä¿¡æ¯ç†µï¼Œè¿ç»­å±æ€§ï¼Œå°±éœ€è¦åˆ’åˆ†åŒºé—´ï¼ŒæŒ‰åŒºé—´è®¡ç®—ä¿¡æ¯ç†µã€‚ åŸºäºæŸä¸€å±‚çš„æ•°æ®é›† a. éå†è®¡ç®—æ‰€æœ‰å±æ€§ï¼Œéå†ç›¸åº”å±æ€§ä»¥ä¸åŒå€¼ä¸ºåˆ†æˆªç‚¹çš„ä¿¡æ¯ç†µ b. é€‰æ‹©ä¿¡æ¯ç†µæœ€å°çš„ä½œä¸ºèŠ‚ç‚¹ å¦‚æœåˆ°è¾¾ç»ˆæ­¢æ¡ä»¶ï¼Œè¿”å›ç›¸åº”ä¿¡æ¯ï¼Œå¦åˆ™ï¼ŒæŒ‰ç…§åˆ†æ”¯é‡å¤æ­¥éª¤1ID3ç®—æ³•ï¼š ä¿¡æ¯å¢ç›Šæœ€å¤§åŒ–C:ç±»åˆ«H(C)=-\sum_{i=1}^{m}p_i log _2^{p_i}æŒ‰ç…§Dç»„åˆ’åˆ†CH(C/D)=\sum_{i=1}^{v}\frac{|C_i|}{|C|}H(C_i)ä¿¡æ¯å¢ç›Šgain(D) = gain(C)-H(C/D)è¿™é‡Œæˆ‘å°±ä»¥ç½‘ä¸Šç»™å‡ºçš„æ•°æ®ä¸ºä¾‹ï¼Œç»™å‡ºæ ¹æ®ä¿¡æ¯ç†µæ„æˆå†³ç­–æ ‘çš„è®¡ç®—è¿‡ç¨‹ã€‚ ç¡®å®šç‰¹å¾ï¼Œç»Ÿè®¡å±æ€§å€¼å’Œåˆ†è§£ç»“æœï¼Œæ€»å…±å››ä¸ªç‰¹å¾ï¼Œå››ç§ç‰¹å¾çš„ç»Ÿè®¡ç»“æœå¦‚ä¸‹å›¾ï¼š æ ¹æ®å†å²æ•°æ®ï¼Œåœ¨ä¸çŸ¥åˆ°ä»»ä½•æƒ…å†µä¸‹ï¼Œè®¡ç®—æ•°æ®æœ¬èº«çš„ç†µä¸º - \frac{9}{14}log_2 \frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940 è®¡ç®—æ¯ä¸ªç‰¹å¾åšä¸ºèŠ‚ç‚¹çš„ä¿¡æ¯ç†µä»¥å¤©æ°”ä¸ºä¾‹ï¼Œå¤©æ°”ä¸‰ç§å±æ€§ï¼Œå½“Outlook = sunnyæ—¶ï¼ŒH(x) = $-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}$; å½“Outlook= overcast,$H(x)=0$,å½“Outlook = rainy ,$H(x) = 0.971$æ‰€ä»¥ï¼Œå½“é€‰å¤©æ°”ä½œä¸ºèŠ‚ç‚¹æ—¶ï¼Œæ­¤æ—¶$H(x)=\frac{5}{14}0.971+\frac{4}{14}0+\frac{5}{14}*0.971 = 0.693$,gain(å¤©æ°”) = 0.247åŒç†ï¼Œå¯å¾—gain(æ¸©åº¦) =0.029 gain(æ¹¿åº¦)=0.152ï¼Œgain(é£)=0.048å› æ­¤é€‰æ‹©å¤©æ°”èŠ‚ç‚¹ï¼Œåœ¨é€’å½’å®ç°å…¶ä»–èŠ‚ç‚¹çš„é€‰æ‹©ã€‚ä¿¡æ¯å¢ç›Šçš„æ–¹æ³•åå‘é€‰æ‹©å…·æœ‰å¤§é‡å€¼çš„å±æ€§ï¼Œä¹Ÿå°±æ˜¯è¯´æŸä¸ªå±æ€§ç‰¹å¾ç´¢å–çš„ä¸åŒå€¼è¶Šå¤šï¼Œé‚£ä¹ˆè¶Šæœ‰å¯èƒ½ä½œä¸ºåˆ†è£‚å±æ€§ï¼Œè¿™æ ·æ˜¯ä¸åˆç†çš„ï¼› C4.5: ä¿¡æ¯å¢ç›Šç‡å¦‚æœè¿™é‡Œè€ƒè™‘äº†ä¸€åˆ—ID,æ¯ä¸ªIDå‡ºç°ä¸€æ¬¡ï¼Œæ‰€ä»¥ç®—å‡ºçš„ä¿¡æ¯å¢ç›Šå¤§ã€‚$ H(x) = 0$,ä¿¡æ¯å¢ç›Šæœ€å¤§åŒ–äº†ï¼Œå¯ä»¥å¼•å…¥ä¿¡æ¯å¢ç›Šç‡ C(T) = \frac{ä¿¡æ¯å¢ç›Š}{H(T)} =\frac{H(C)-H(C/T)}{H(T)}CART:åŸºå°¼(Gini)ç³»æ•°G = 1-\sum_{i=l_k}^{k}p_i^2$$,ä¹Ÿæ˜¯å¯¹éšæœºå˜é‡ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªè¡¡é‡ï¼Œginiè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ ### è¿ç»­å±æ€§çš„å¤„ç†æ–¹æ³• é€‰å–åˆ†è§£ç‚¹çš„é—®é¢˜ï¼š åˆ†æˆä¸åŒçš„åŒºé—´ï¼ˆäºŒåˆ†ã€ä¸‰åˆ†....)ï¼Œåˆ†åˆ«è®¡ç®—å¢ç›Šå€¼ï¼Œç„¶åæ¯”è¾ƒé€‰æ‹©ã€‚ å°†éœ€è¦å¤„ç†çš„æ ·æœ¬ï¼ˆå¯¹åº”æ ¹èŠ‚ç‚¹ï¼‰æˆ–æ ·æœ¬å­é›†ï¼ˆå¯¹åº”å­æ ‘ï¼‰æŒ‰ç…§è¿ç»­å˜é‡çš„å¤§å°ä»å°åˆ°å¤§è¿›è¡Œæ’åº å‡è®¾è¯¥å±æ€§å¯¹åº”ä¸åŒçš„å±æ€§å€¼å…±Nä¸ªï¼Œé‚£ä¹ˆæ€»å…±æœ‰N-1ä¸ªå¯èƒ½çš„å€™é€‰åˆ†å‰²å€¼ç‚¹ï¼Œæ¯ä¸ªå€™é€‰çš„åˆ†å‰²é˜ˆå€¼ç‚¹çš„å€¼ä¸ºä¸Šè¿°æ’åºåçš„å±æ€§å€¼ä¸­ä¸¤ä¸¤å‰åè¿ç»­å…ƒç´ çš„ä¸­ç‚¹ ## è¯„ä»· è¯„ä»·å‡½æ•°ï¼š $$C(T) = \sum_{releaf} N_t*H(T)$ N_t$ï¼šæ¯ä¸ªå¶å­èŠ‚ç‚¹é‡Œé¢å«æœ‰çš„æ ·æœ¬ä¸ªæ•°$H(T)$:å¶å­èŠ‚ç‚¹å«æœ‰çš„ä¿¡æ¯ç†µ è¿‡æ‹Ÿåˆå¦‚æœå†³ç­–æ ‘è¿‡äºåºå¤§ï¼Œåˆ†æ”¯å¤ªå¤šï¼Œå¯èƒ½é€ æˆè¿‡æ‹Ÿåˆã€‚å¯¹åº”è®­ç»ƒæ ·æœ¬éƒ½å°½å¯èƒ½çš„åˆ†å¯¹ï¼Œä¹Ÿè®¸æ ·æœ¬æœ¬èº«å°±å­˜åœ¨å¼‚å¸¸ç‚¹å‘¢ï¼ŸI. é¢„å‰ªæï¼šè¾¹æ„å»ºï¼Œè¾¹å‰ªæ æŒ‡å®šæ·±åº¦d èŠ‚ç‚¹çš„min_sample èŠ‚ç‚¹ç†µå€¼æˆ–è€…giniå€¼å°äºé˜™å€¼ç†µå’ŒåŸºå°¼å€¼çš„å¤§å°è¡¨ç¤ºæ•°æ®çš„å¤æ‚ç¨‹åº¦ï¼Œå½“ç†µæˆ–è€…åŸºå°¼å€¼è¿‡å°æ—¶ï¼Œè¡¨ç¤ºæ•°æ®çš„çº¯åº¦æ¯”è¾ƒå¤§ï¼Œå¦‚æœç†µæˆ–è€…åŸºå°¼å€¼å°äºä¸€å®šç¨‹åº¦æ•°ï¼ŒèŠ‚ç‚¹åœæ­¢åˆ†è£‚ã€‚ å½“æ‰€ä»¥ç‰¹å¾éƒ½ç”¨å®Œäº† æŒ‡å®šèŠ‚ç‚¹ä¸ªæ•°å½“èŠ‚ç‚¹çš„æ•°æ®é‡å°äºä¸€ä¸ªæŒ‡å®šçš„æ•°é‡æ—¶ï¼Œä¸ç»§ç»­åˆ†è£‚ã€‚ä¸¤ä¸ªåŸå› ï¼šä¸€æ˜¯æ•°æ®é‡è¾ƒå°‘æ—¶ï¼Œå†åšåˆ†è£‚å®¹æ˜“å¼ºåŒ–å™ªå£°æ•°æ®çš„ä½œç”¨ï¼›äºŒæ˜¯é™ä½æ ‘ç”Ÿé•¿çš„å¤æ‚æ€§ã€‚æå‰ç»“æŸåˆ†è£‚ä¸€å®šç¨‹åº¦ä¸Šæœ‰åˆ©äºé™ä½è¿‡æ‹Ÿåˆçš„å½±å“ã€‚ II. åå‰ªæï¼š æ„å»ºå¥½åï¼Œç„¶åæ‰å¼€å§‹è£å‰ª C_\alpha(T) = C(T)+\alpha|T_{leaf}|åœ¨æ„é€ å«ä¸€æ£µæ ‘åï¼Œé€‰ä¸€äº›èŠ‚ç‚¹åšè®¡ç®—ï¼Œçœ‹æ˜¯å¦éœ€è¦å‰ªæ å†³ç­–æ ‘å•ä¸ªèŠ‚ç‚¹é€‰æ‹©çš„ä»£ç å®ç°ç®€å•å®ç°äº†å•ä¸ªèŠ‚ç‚¹å†³ç­–æ„é€ è¿‡ç¨‹12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def split(X,y,d,value):'''åœ¨dçº¬åº¦ä¸Šï¼ŒæŒ‰ç…§valueè¿›è¡Œåˆ’åˆ†''' index_a =(X[:,d]&lt;=value) index_b =(X[:,d]&gt;value) return X[index_a],X[index_b],y[index_a],y[index_b]from collections import Counterfrom math import log from numpy as npdef entropy(y): counter = Counter(y) # å­—å…¸ res = 0.0 for num in counter.values(): p = num/len(y) res+=-p*log(p) return resdef gain(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) e = len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return (entropy(y)-e)def gainratio(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) gain =entropy(y) - len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return gain/(entropy(y_l)+entropy(y_r))def gini(y): counter = Counter(y) res = 1.0 for num in counter.values(): p = num / len(y) res += -p**2 return res #X_l,X_r,y_l,y_r = split(X,y,d,v) #return 1-(len(y_l)/len(y))**2-(len(y_r)/len(y))**2def try_split(X,y): best_entropy = float('inf') best_d,best_v=-1,-1 for d in range(X.shape[1]): sorted_index = np.argsort(X[:,d]) for i in range(1, len(X)): if (X[sorted_index[i],d] != X[sorted_index[i-1],d]): v = (X[sorted_index[i-1],d]+X[sorted_index[i],d])/2 X_l,X_r,y_l,y_r = split(X,y,d,v) # ä¿¡æ¯ç†µ e = entropy(y_l)+entropy(y_r) #gini e = gini(y_l) + gini(y_r) # ä¿¡æ¯å¢ç›Š e = -gain(X,y,d,v) if e &lt; best_entropy: best_entropy, best_d,best_v = e,d,v return best_entropy, best_d, best_v# æ‰‹åŠ¨æ¥åˆ’åˆ†data =np.array([[ 0.3 , 5 , 2 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.5 , 6.5 , 1 , 1 ],[ 0.6 , 6 , 0 , 0 ],[ 0.7 , 9 , 2 , 1 ],[ 0.5 , 7 , 1 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.6 , 8.5 , 0 , 1 ],[ 0.3 , 5.5 , 2 , 0 ],[ 0.9 , 10 , 0 , 1 ],[ 1 , 12 , 1 , 0 ],[ 0.6 , 9 , 1 , 0 ],])X =data[:,0:3]y = data[:,-1]# æ‰‹åŠ¨æ¥åˆ’åˆ†best_entropy, best_d, best_v = try_split(X, y)print(best_entropy, best_d, best_v)X1_l, X1_r, y1_l, y1_r = split(X,y,best_d,best_v)print(X1_l, X1_r, y1_l, y1_r)best_entropy2, best_d2, best_v2 = try_split(X1_r, y1_r)X2_l, X2_r, y2_l, y2_r = split(X1_r,y1_r,best_d2,best_v2)entropy(y2_l) Python skleané‡Œé¢treeæ¨¡å—é‡Œé¢çš„DecisionTreeClassifier1234from sklearn import treeclf =tree.DecisionTreeClassifier(max_depth=1,criterion ='gini') # criterion='entropy|gini'clf = clf.fit(X,y) è®­ç»ƒå¥½ä¸€é¢—å†³ç­–æ ‘ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨export_graphvizå¯¼å‡ºå™¨ä»¥Graphvizæ ¼å¼å¯¼å‡ºæ ‘ã€‚1234import graphviz dot_data = tree.export_graphviz(clf, out_file=None,) graph = graphviz.Source(dot_data) graph.render("data") åœ¨è¿è¡Œæ—¶å¯ä»¥å‡ºé”™ï¼šExecutableNotFound: failed to execute [â€˜dotâ€™, â€˜-Tpdfâ€™, â€˜-Oâ€™, â€˜dataâ€™], make sure the Graphviz executables are on your systemsâ€™ PATHåŸå› ï¼šgraphvizæœ¬èº«æ˜¯ä¸€ä¸ªè½¯ä»¶ï¼Œéœ€è¦é¢å¤–ä¸‹è½½ï¼Œå¹¶å°†å…¶binåŠ å…¥ç¯å¢ƒå˜é‡ä¹‹ä¸­ã€‚ä¸‹è½½]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>å†³ç­–æ ‘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å†³ç­–æ ‘]]></title>
    <url>%2F2019%2F03%2F03%2F%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%2F%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[ä¸»è¦æ˜¯åˆ†äº«å†³ç­–çš„åŸºæœ¬çŸ¥è¯†ç‚¹ï¼Œé‡ç‚¹åœ¨åˆ†ç±»å†³ç­–æ ‘ä¸Šï¼Œå¯¹äºå›å½’çš„å†³ç­–æ ‘åé¢åœ¨ç»™å‡ºã€‚å¸Œæœ›å¤§å®¶å’Œæˆ‘ä¸€èµ·åšçŸ¥è¯†çš„ä¼ æ’­è€…å•¦ï¼:smile: :smiley: :grin: :open_mouth: [TOC] å†³ç­–æ ‘è‹±æ–‡åå­—ï¼šDescision Tree ä»€ä¹ˆæ˜¯å†³ç­–æ ‘ä¸¾ä¸ªæ ¡å›­ç›¸äº²çš„ä¾‹å­ï¼Œä»Šå¤©æ ¡å›­çš„å°çŒ«(å¥³)å’Œå°ç‹—(ç”·)å‡†å¤‡é…å¯¹ï¼Œå°çŒ«å¦‚ä½•æ‰èƒ½åœ¨ä¼—å¤šçš„ä¼˜è´¨ğŸ¶çš„å¿ƒä»ªçš„ç‹—å‘¢ï¼Ÿäºæ˜¯å‘¢ï¼Ÿæœ‰ä¸€åªç‰¹ä¹–å·§çš„å°çŒ«æ‰¾åˆ°äº†ä½ ï¼Œä½ æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œåˆšå¥½å­¦ä¹ äº†å†³ç­–æ ‘ï¼Œå‡†å¤‡ç»™è¿™åªçŒ«çŒ«æŒ‘é€‰ä¼˜è´¨ç‹—ï¼Œå½“ç„¶ï¼Œä½ ä¸ä»…ä»…æ˜¯ç›´æ¥å‘Šè¯‰çŒ«å“ªäº›ç‹—æ˜¯åˆé€‚ä½ çš„ï¼Ÿä½ æ›´åº”è¯¥è¯¦ç»†çš„ç»™çŒ«è®²è§£å†³ç­–æ ‘æ˜¯å¦‚ä½•æ ¹æ®å®ƒæå‡ºçš„æ ‡å‡†é€‰å‡ºçš„ç¬¦åˆè¦æ±‚çš„ç‹—å‘¢ï¼ŸçŒ«ç»™å‡ºå¦‚ä¸‹ä¿¡æ¯ï¼šå¹´é¾„=0.5 6.5&lt;=ä½“é‡&lt;=8.5;å¿ƒä»ª; å¹´é¾„&gt;=0.5 ä½“é‡&gt;8.5 é•¿ç›¸å¥½ å¿ƒä»ª;å…¶ä½™æƒ…å†µä¸å¿ƒä»ª; æ ¹æ®ä¸Šè¿°æ¡ä»¶å¯ä»¥æ„é€ ä¸€é¢—æ ‘ï¼š ä¸Šé¢çš„å›¾å°±æ˜¯å†³ç­–æ ‘ï¼Œæœ€ç»ˆçš„ç»“æœæ˜¯å¿ƒä»ªæˆ–è€…ä¸å¿ƒä»ªã€‚å†³ç­–æ ‘ç®—æ³•ä»¥æ ‘å½¢ç»“æ„è¡¨ç¤ºæ•°æ®åˆ†ç±»çš„ç»“æœ åŸºæœ¬æ¦‚å¿µå†³ç­–æ ‘å±äºä¹Ÿåªèƒ½éå‚æ•°å­¦ä¹ ç®—æ³•ã€å¯ä»¥ç”¨äºè§£å†³(å¤š)åˆ†ç±»é—®é¢˜ï¼Œå›å½’é—®é¢˜ã€‚ å›å½’é—®é¢˜çš„ç»“æœï¼Œå¶å­ç»“ç‚¹çš„å¹³å‡å€¼æ˜¯å›å½’é—®é¢˜çš„è§£ã€‚æ ¹èŠ‚ç‚¹ï¼šå†³ç­–æ ‘å…·æœ‰æ•°æ®ç»“æ„é‡Œé¢çš„äºŒå‰æ ‘ã€æ ‘çš„å…¨éƒ¨å±æ€§éå¶å­èŠ‚ç‚¹ ï¼šï¼ˆå†³ç­–ç‚¹ï¼‰ ä»£è¡¨æµ‹è¯•çš„æ¡ä»¶ï¼Œæ•°æ®çš„å±æ€§çš„æµ‹è¯•å¶å­èŠ‚ç‚¹ ï¼šåˆ†ç±»åè·å¾—åˆ†ç±»æ ‡è®°åˆ†æ”¯ï¼š æµ‹è¯•çš„ç»“æœ æ•°å­¦é—®é¢˜-ç†µ-Giniç³»æ•°ä»€ä¹ˆæ˜¯ç†µï¼šç†µçš„æ¦‚å¿µæºäºç‰©ç†å­¦ï¼Œç”¨äºåº¦é‡ä¸€ä¸ªçƒ­åŠ›å­¦ç³»ç»Ÿçš„æ— åºç¨‹åº¦ã€‚ä¿¡æ¯ç†µï¼šä¸å¾—ä¸æé¦™å†œè¿™ä¸ªå¤§å†™çš„äººå•¦ï¼ä¿¡æ¯è®ºé‡Œé¢çš„çŸ¥è¯†ã€‚åœ¨ä¿¡æ¯è®ºé‡Œé¢ï¼Œä¿¡æ¯ç†µè¡¡é‡ä¿¡æ¯é‡çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯å¯¹éšæœºå˜é‡ä¸ç¡®å®šåº¦çš„ä¸€ä¸ªè¡¡é‡ã€‚ç†µè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ï¼›æ ·æœ¬çº¯åº¦è¶Šå¤§è¶Šå¥½ã€‚å¯¹äºæŸä¸ªå•ç¬¦å·æ— è®°å¿†ä¿¡æºï¼Œå‘å‡ºç¬¦å·($x_i$)çš„æ¦‚ç‡æ˜¯$p_i$,æ¦‚ç‡è¶Šå¤§ï¼Œç¬¦å·çš„ä¿¡æ¯é‡å°±è¶Šå°ï¼Œé¦™å†œå…¬å¼ $I(x_i)=-log_{p_i}$ã€‚ä¿¡æºæ‰€å«çš„ä¿¡æ¯ç†µå°±æ˜¯ä¿¡æ¯é‡çš„æœŸæœ›]$H(x)=-\sum p_i*log_{p_i}$Giniç³»æ•°ï¼š $Gimi(p) = 1-\sum_{k=1}^{K}p_k^2$ å†³ç­–æ ‘å¦‚ä½•æ„å»ºçš„é—®é¢˜è‡ªæˆ‘æé—®é˜¶æ®µï¼š æ¯ä¸ªèŠ‚ç‚¹çš„ä½ç½®å¦‚ä½•ç¡®å®šï¼Ÿç‰¹å¾çš„é€‰æ‹©ï¼šæ¯æ¬¡é€‰å…¥çš„ç‰¹å¾ä½œä¸ºåˆ†è£‚çš„æ ‡å‡†ï¼Œéƒ½æ˜¯ä½¿å¾—å†³ç­–æ ‘åœ¨è¿™ä¸ªèŠ‚ç‚¹çš„æ ¹æ®ä½ è‡ªå·±é€‰æ‹©çš„æ ‡å‡†ï¼ˆä¿¡æ¯ç†µæœ€å°ã€ä¿¡æ¯å¢ç›Šæœ€å¤§ã€giniç³»æ•°æœ€å°ï¼‰. é€‰å–çš„æ ‡å‡†ï¼šå°½å¿«èƒ½çš„åˆ’åˆ†å‡ºç»“æœï¼Œä½¿å¾—åˆ†çš„ç»“æœæœ€å¥½ã€‚ æ¯ä¸ªèŠ‚ç‚¹åœ¨å“ªä¸ªå€¼ä¸Šåšåˆ’åˆ†ï¼Œç¡®å®šåˆ†æ”¯ç»“æ„å‘¢ï¼Ÿéå†åˆ’åˆ†çš„èŠ‚ç‚¹çš„åˆ†ç•Œå€¼æ“ä½œæ¥è§£å†³è¿™ä¸ªé—®é¢˜ å¯ä»¥æƒ³è±¡ï¼Œæˆ‘ä»¬æ„é€ çš„å†³ç­–æ ‘è¶³å¤Ÿåºå¤§ï¼Œå†³ç­–æ ‘å¯ä»¥æŠŠæ¯ä¸€ä¸ªæ ·æœ¬éƒ½åˆ†å¯¹ï¼Œé‚£ä¹ˆå†³ç­–æ ‘çš„æ³›åŒ–èƒ½åŠ›å°±å¯ä»¥å¾ˆå·®äº†ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±éœ€è¦å‰ªææ“ä½œäº† è®­ç»ƒç®—æ³•åŸºäºä¿¡æ¯ç†µçš„æ„é€ å½“é€‰æ‹©æŸä¸ªç‰¹å¾ä½œä¸ºèŠ‚ç‚¹æ—¶ï¼Œæˆ‘ä»¬å°±å¸Œæœ›è¿™ä¸ªç‰¹å¾çš„ä½¿å¾—åˆ†ç±»ç»“æœä¿¡æ¯ç†µè¶Šå°è¶Šå¥½ï¼Œé‚£ä¹ˆä¸ç¡®å®šæ€§è¶Šå°ã€‚è®¡ç®—ç‰¹å¾çš„ä¿¡æ¯ç†µå…¬å¼å¦‚ä¸‹ï¼š H(x) = -p_i(x)log^{p_i(x)} = -\frac{n_j}{S}log^{\frac{n_j}{S}}$n_j$: ç¬¬jä¸ªç±»åˆ«ï¼Œåœ¨æ ·æœ¬ä¸­å‡ºç°çš„é¢‘æ•°$S$: æ ·æœ¬ä¸ªæ•°å¯¹äºç¦»æ•£å±æ€§ï¼Œç›´æ¥è®¡ç®—ä¿¡æ¯ç†µï¼Œè¿ç»­å±æ€§ï¼Œå°±éœ€è¦åˆ’åˆ†åŒºé—´ï¼ŒæŒ‰åŒºé—´è®¡ç®—ä¿¡æ¯ç†µã€‚ åŸºäºæŸä¸€å±‚çš„æ•°æ®é›† a. éå†è®¡ç®—æ‰€æœ‰å±æ€§ï¼Œéå†ç›¸åº”å±æ€§ä»¥ä¸åŒå€¼ä¸ºåˆ†æˆªç‚¹çš„ä¿¡æ¯ç†µ b. é€‰æ‹©ä¿¡æ¯ç†µæœ€å°çš„ä½œä¸ºèŠ‚ç‚¹ å¦‚æœåˆ°è¾¾ç»ˆæ­¢æ¡ä»¶ï¼Œè¿”å›ç›¸åº”ä¿¡æ¯ï¼Œå¦åˆ™ï¼ŒæŒ‰ç…§åˆ†æ”¯é‡å¤æ­¥éª¤1ID3 ç®—æ³•ï¼š ä¿¡æ¯å¢ç›Šæœ€å¤§åŒ– å»ºç«‹åœ¨å¥¥å¡å§†å‰ƒåˆ€çš„åŸºç¡€ä¸Šã€‚ æ€æƒ³ é›†åˆCçš„ä¿¡æ¯ç†µ H(C)=-\sum_{i=1}^{m}p_i log _2^{p_i}æŒ‰ç…§Dç»„åˆ’åˆ†Cï¼Œæ•°æ®é›†Cçš„æ¡ä»¶ç†µï¼Œ H(C/D)=\sum_{i=1}^{v}\frac{|C_i|}{|C|}H(C_i) = \sum_{i=1}^{v}\frac{|C_i|}{|C|}\sum_{j = 1}^{m}\frac{|C_{ik}|}{|C_i|}log_2\frac{|C_{ik}|}{|C_2|}ä¿¡æ¯å¢ç›Š = ä¿¡æ¯ç†µ-æ¡ä»¶ç†µ gain(C,D) = gain(C)-H(C/D)è¿™é‡Œæˆ‘å°±ä»¥ç½‘ä¸Šç»™å‡ºçš„æ•°æ®ä¸ºä¾‹ï¼Œç»™å‡ºæ ¹æ®ä¿¡æ¯ç†µæ„æˆå†³ç­–æ ‘çš„è®¡ç®—è¿‡ç¨‹ã€‚ ç¡®å®šç‰¹å¾ï¼Œç»Ÿè®¡å±æ€§å€¼å’Œåˆ†è§£ç»“æœï¼Œæ€»å…±å››ä¸ªç‰¹å¾ï¼Œå››ç§ç‰¹å¾çš„ç»Ÿè®¡ç»“æœå¦‚ä¸‹å›¾ï¼š æ ¹æ®å†å²æ•°æ®ï¼Œåœ¨ä¸çŸ¥åˆ°ä»»ä½•æƒ…å†µä¸‹ï¼Œè®¡ç®—æ•°æ®æœ¬èº«çš„ç†µä¸º- \frac{9}{14}log_2 \frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940 è®¡ç®—æ¯ä¸ªç‰¹å¾åšä¸ºèŠ‚ç‚¹çš„ä¿¡æ¯ç†µä»¥å¤©æ°”ä¸ºä¾‹ï¼Œå¤©æ°”ä¸‰ç§å±æ€§ï¼Œå½“Outlook = sunnyæ—¶ï¼ŒH(x) = $-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5}$; å½“Outlook= overcast,$H(x)=0$,å½“Outlook = rainy ,$H(x) = 0.971$æ‰€ä»¥ï¼Œå½“é€‰å¤©æ°”ä½œä¸ºèŠ‚ç‚¹æ—¶ï¼Œæ­¤æ—¶$H(x)=\frac{5}{14}0.971+\frac{4}{14}0+\frac{5}{14}*0.971 = 0.693$,gain(å¤©æ°”) = 0.247åŒç†ï¼Œå¯å¾—gain(æ¸©åº¦) =0.029 gain(æ¹¿åº¦)=0.152ï¼Œgain(é£)=0.048å› æ­¤é€‰æ‹©å¤©æ°”èŠ‚ç‚¹ï¼Œåœ¨é€’å½’å®ç°å…¶ä»–èŠ‚ç‚¹çš„é€‰æ‹©ã€‚ä¿¡æ¯å¢ç›Šçš„æ–¹æ³•åå‘é€‰æ‹©å…·æœ‰å¤§é‡å€¼çš„å±æ€§ï¼Œä¹Ÿå°±æ˜¯è¯´æŸä¸ªå±æ€§ç‰¹å¾ç´¢å–çš„ä¸åŒå€¼è¶Šå¤šï¼Œé‚£ä¹ˆè¶Šæœ‰å¯èƒ½ä½œä¸ºåˆ†è£‚å±æ€§ï¼Œè¿™æ ·æ˜¯ä¸åˆç†çš„ï¼› ç¼ºç‚¹ æ²¡æœ‰å‰ªçº¸ç­–ç•¥ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ ä¿¡æ¯å¢ç›Šå‡†åˆ™è¡¨ç°å‡ºå¯¹å–å€¼è¾ƒå¤šçš„ç‰¹å¾ï¼Œåˆ—å¦‚ç¼–å·ï¼Œç”Ÿæ—¥è¿™ç§ æ²¡æœ‰è€ƒè™‘ç¼ºå¤±å€¼ C4.5: ä¿¡æ¯å¢ç›Šç‡C4.5 ç›¸å¯¹äºID3çš„ç¼ºç‚¹æ”¹è¿›å¦‚ä¸‹ï¼š å¼•å…¥äº†å‰ªçº¸ç­–ç•¥ å¯¹äºå…·æœ‰ç¼ºå¤±å€¼ç‰¹å¾ï¼Œç”¨æ²¡æœ‰ç¼ºå¤±çš„æ ·æœ¬å­é›†æ‰€å æ¯”é‡æ¥æŠ˜ç®—ï¼› å¼•å…¥ä¿¡æ¯å¢ç›Šç‡ä½œä¸ºåˆ’åˆ†æ ‡å‡† è¿ç»­ç‰¹å¾ç¦»æ•£åŒ– ç¼ºå¤±å€¼å¤„ç†ã€‚ ä»¥ä¸åŒæ¦‚ç‡åˆ’åˆ†åˆ°ä¸åŒèŠ‚ç‚¹ä¸­ å¦‚æœè¿™é‡Œè€ƒè™‘äº†ä¸€åˆ—ID,æ¯ä¸ªIDå‡ºç°ä¸€æ¬¡ï¼Œæ‰€ä»¥ç®—å‡ºçš„ä¿¡æ¯å¢ç›Šå¤§ã€‚$ H(x) = 0$,ä¿¡æ¯å¢ç›Šæœ€å¤§åŒ–äº†ï¼Œå¯ä»¥å¼•å…¥ä¿¡æ¯å¢ç›Šç‡ C(T) = \frac{ä¿¡æ¯å¢ç›Š}{H(T)} =\frac{H(C)-H(C/T)}{H(T)}CART:åŸºå°¼(Gini)ç³»æ•°G = 1-\sum_{i=l_k}^{k}p_i^2$$,ä¹Ÿæ˜¯å¯¹éšæœºå˜é‡ä¸ç¡®å®šæ€§çš„ä¸€ä¸ªè¡¡é‡ï¼Œginiè¶Šå¤§ï¼Œä¸ç¡®å®šæ€§è¶Šå¤§ ### è¿ç»­å±æ€§çš„å¤„ç†æ–¹æ³• é€‰å–åˆ†è§£ç‚¹çš„é—®é¢˜ï¼š åˆ†æˆä¸åŒçš„åŒºé—´ï¼ˆäºŒåˆ†ã€ä¸‰åˆ†....)ï¼Œåˆ†åˆ«è®¡ç®—å¢ç›Šå€¼ï¼Œç„¶åæ¯”è¾ƒé€‰æ‹©ã€‚ å°†éœ€è¦å¤„ç†çš„æ ·æœ¬ï¼ˆå¯¹åº”æ ¹èŠ‚ç‚¹ï¼‰æˆ–æ ·æœ¬å­é›†ï¼ˆå¯¹åº”å­æ ‘ï¼‰æŒ‰ç…§è¿ç»­å˜é‡çš„å¤§å°ä»å°åˆ°å¤§è¿›è¡Œæ’åº å‡è®¾è¯¥å±æ€§å¯¹åº”ä¸åŒçš„å±æ€§å€¼å…±Nä¸ªï¼Œé‚£ä¹ˆæ€»å…±æœ‰N-1ä¸ªå¯èƒ½çš„å€™é€‰åˆ†å‰²å€¼ç‚¹ï¼Œæ¯ä¸ªå€™é€‰çš„åˆ†å‰²é˜ˆå€¼ç‚¹çš„å€¼ä¸ºä¸Šè¿°æ’åºåçš„å±æ€§å€¼ä¸­ä¸¤ä¸¤å‰åè¿ç»­å…ƒç´ çš„ä¸­ç‚¹ã€‚ é˜™å€¼ï¼šthreshold ## è¯„ä»· è¯„ä»·å‡½æ•°ï¼š $$C(T) = \sum_{releaf} N_t*H(T)$ N_t$ï¼šæ¯ä¸ªå¶å­èŠ‚ç‚¹é‡Œé¢å«æœ‰çš„æ ·æœ¬ä¸ªæ•°$H(T)$:å¶å­èŠ‚ç‚¹å«æœ‰çš„ä¿¡æ¯ç†µ è¿‡æ‹Ÿåˆå¦‚æœå†³ç­–æ ‘è¿‡äºåºå¤§ï¼Œåˆ†æ”¯å¤ªå¤šï¼Œå¯èƒ½é€ æˆè¿‡æ‹Ÿåˆã€‚å¯¹åº”è®­ç»ƒæ ·æœ¬éƒ½å°½å¯èƒ½çš„åˆ†å¯¹ï¼Œä¹Ÿè®¸æ ·æœ¬æœ¬èº«å°±å­˜åœ¨å¼‚å¸¸ç‚¹å‘¢ï¼ŸI. é¢„å‰ªæï¼šè¾¹æ„å»ºï¼Œè¾¹å‰ªæ æŒ‡å®šæ·±åº¦d èŠ‚ç‚¹çš„min_sample èŠ‚ç‚¹ç†µå€¼æˆ–è€…giniå€¼å°äºé˜™å€¼ç†µå’ŒåŸºå°¼å€¼çš„å¤§å°è¡¨ç¤ºæ•°æ®çš„å¤æ‚ç¨‹åº¦ï¼Œå½“ç†µæˆ–è€…åŸºå°¼å€¼è¿‡å°æ—¶ï¼Œè¡¨ç¤ºæ•°æ®çš„çº¯åº¦æ¯”è¾ƒå¤§ï¼Œå¦‚æœç†µæˆ–è€…åŸºå°¼å€¼å°äºä¸€å®šç¨‹åº¦æ•°ï¼ŒèŠ‚ç‚¹åœæ­¢åˆ†è£‚ã€‚ å½“æ‰€æœ‰7ç‰¹å¾éƒ½ç”¨å®Œäº† æŒ‡å®šèŠ‚ç‚¹ä¸ªæ•°å½“èŠ‚ç‚¹çš„æ•°æ®é‡å°äºä¸€ä¸ªæŒ‡å®šçš„æ•°é‡æ—¶ï¼Œä¸ç»§ç»­åˆ†è£‚ã€‚ä¸¤ä¸ªåŸå› ï¼šä¸€æ˜¯æ•°æ®é‡è¾ƒå°‘æ—¶ï¼Œå†åšåˆ†è£‚å®¹æ˜“å¼ºåŒ–å™ªå£°æ•°æ®çš„ä½œç”¨ï¼›äºŒæ˜¯é™ä½æ ‘ç”Ÿé•¿çš„å¤æ‚æ€§ã€‚æå‰ç»“æŸåˆ†è£‚ä¸€å®šç¨‹åº¦ä¸Šæœ‰åˆ©äºé™ä½è¿‡æ‹Ÿåˆçš„å½±å“ã€‚ II. åå‰ªæï¼š æ„å»ºå¥½åï¼Œç„¶åæ‰å¼€å§‹è£å‰ª C_\alpha(T) = C(T)+\alpha|T_{leaf}|åœ¨æ„é€ å«ä¸€æ£µæ ‘åï¼Œé€‰ä¸€äº›èŠ‚ç‚¹åšè®¡ç®—ï¼Œçœ‹æ˜¯å¦éœ€è¦å‰ªæã€‚ åå‰ªæå†³ç­–æ ‘çš„æ¬ æ‹Ÿåˆé£é™©å¾ˆå°ï¼Œæ³›åŒ–æ€§èƒ½å¾€å¾€ä¼˜äºé¢„å‰ªæå†³ç­–æ ‘ã€‚ä½†åŒæ—¶å…¶è®­ç»ƒæ—¶é—´ä¼šå¤§çš„å¤š ç†µ biasç”Ÿæ—¥è¿™ç§å±æ€§ï¼ŒæŠŠå±æ€§åˆ†çš„å¤ªå¤šäº†ï¼Œåˆ†çš„è¶Šç»†ï¼Œå¾€å¾€ç†µè¶Šå¤§ã€‚ å†³ç­–æ ‘å•ä¸ªèŠ‚ç‚¹é€‰æ‹©çš„ä»£ç å®ç°ç®€å•å®ç°äº†å•ä¸ªèŠ‚ç‚¹å†³ç­–æ„é€ è¿‡ç¨‹12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def split(X,y,d,value):'''åœ¨dçº¬åº¦ä¸Šï¼ŒæŒ‰ç…§valueè¿›è¡Œåˆ’åˆ†''' index_a =(X[:,d]&lt;=value) index_b =(X[:,d]&gt;value) return X[index_a],X[index_b],y[index_a],y[index_b]from collections import Counterfrom math import log from numpy as npdef entropy(y): counter = Counter(y) # å­—å…¸ res = 0.0 for num in counter.values(): p = num/len(y) res+=-p*log(p) return resdef gain(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) e = len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return (entropy(y)-e)def gainratio(X,y,d,v): X_l,X_r,y_l,y_r = split(X,y,d,v) gain =entropy(y) - len(y_l)/len(y)*entropy(y_l)+len(y_r)/len(y)*entropy(y_r) return gain/(entropy(y_l)+entropy(y_r))def gini(y): counter = Counter(y) res = 1.0 for num in counter.values(): p = num / len(y) res += -p**2 return res #X_l,X_r,y_l,y_r = split(X,y,d,v) #return 1-(len(y_l)/len(y))**2-(len(y_r)/len(y))**2def try_split(X,y): best_entropy = float('inf') best_d,best_v=-1,-1 for d in range(X.shape[1]): sorted_index = np.argsort(X[:,d]) for i in range(1, len(X)): if (X[sorted_index[i],d] != X[sorted_index[i-1],d]): v = (X[sorted_index[i-1],d]+X[sorted_index[i],d])/2 X_l,X_r,y_l,y_r = split(X,y,d,v) # ä¿¡æ¯ç†µ e = entropy(y_l)+entropy(y_r) #gini e = gini(y_l) + gini(y_r) # ä¿¡æ¯å¢ç›Š e = -gain(X,y,d,v) if e &lt; best_entropy: best_entropy, best_d,best_v = e,d,v return best_entropy, best_d, best_v# æ‰‹åŠ¨æ¥åˆ’åˆ†data =np.array([[ 0.3 , 5 , 2 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.5 , 6.5 , 1 , 1 ],[ 0.6 , 6 , 0 , 0 ],[ 0.7 , 9 , 2 , 1 ],[ 0.5 , 7 , 1 , 0 ],[ 0.4 , 6 , 0 , 0 ],[ 0.6 , 8.5 , 0 , 1 ],[ 0.3 , 5.5 , 2 , 0 ],[ 0.9 , 10 , 0 , 1 ],[ 1 , 12 , 1 , 0 ],[ 0.6 , 9 , 1 , 0 ],])X =data[:,0:3]y = data[:,-1]# æ‰‹åŠ¨æ¥åˆ’åˆ†best_entropy, best_d, best_v = try_split(X, y)print(best_entropy, best_d, best_v)X1_l, X1_r, y1_l, y1_r = split(X,y,best_d,best_v)print(X1_l, X1_r, y1_l, y1_r)best_entropy2, best_d2, best_v2 = try_split(X1_r, y1_r)X2_l, X2_r, y2_l, y2_r = split(X1_r,y1_r,best_d2,best_v2)entropy(y2_l) Python skleané‡Œé¢treeæ¨¡å—é‡Œé¢çš„DecisionTreeClassifier1234from sklearn import treeclf =tree.DecisionTreeClassifier(max_depth=1,criterion ='gini') # criterion='entropy|gini'clf = clf.fit(X,y) è®­ç»ƒå¥½ä¸€é¢—å†³ç­–æ ‘ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨export_graphvizå¯¼å‡ºå™¨ä»¥Graphvizæ ¼å¼å¯¼å‡ºæ ‘ã€‚1234import graphviz dot_data = tree.export_graphviz(clf, out_file=None,) graph = graphviz.Source(dot_data) graph.render("data") åœ¨è¿è¡Œæ—¶å¯ä»¥å‡ºé”™ï¼šExecutableNotFound: failed to execute [â€˜dotâ€™, â€˜-Tpdfâ€™, â€˜-Oâ€™, â€˜dataâ€™], make sure the Graphviz executables are on your systemsâ€™ PATHåŸå› ï¼šgraphvizæœ¬èº«æ˜¯ä¸€ä¸ªè½¯ä»¶ï¼Œéœ€è¦é¢å¤–ä¸‹è½½ï¼Œå¹¶å°†å…¶binåŠ å…¥ç¯å¢ƒå˜é‡ä¹‹ä¸­ã€‚ä¸‹è½½]]></content>
      <categories>
        <category>æœºå™¨å­¦ä¹ </category>
      </categories>
      <tags>
        <tag>å†³ç­–æ ‘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æˆ‘çš„è¯»ä¹¦ç¬”è®°]]></title>
    <url>%2F2019%2F02%2F28%2FSVD%2F</url>
    <content type="text"><![CDATA[ç›®å½• :smile::one: ç®€å•è¯´ä¸€ä¸‹ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ä¸ç‰¹å¾åˆ†è§£&nbsp;&nbsp; I. ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ä¸ç‰¹å¾åˆ†è§£&nbsp;&nbsp; II. å‡ ä½•æ„ä¹‰&nbsp;&nbsp; III. å¦‚ä½•å®ç°é€šè¿‡Matlabã€Pythonå®ç°:two:è¯¦ç»†è§£è¯´SVD&nbsp;&nbsp; I. å‡ ä½•æ„ä¹‰&nbsp;&nbsp; I. å¥‡å¼‚å€¼åˆ†è§£çš„æ¨å¯¼è¿‡ç¨‹&nbsp;&nbsp; I. SVDç®—ä¾‹&nbsp;&nbsp; I. å¦‚ä½•é€šè¿‡Matlabå’ŒPython:three:åº”ç”¨ä¸¾ä¾‹&nbsp;&nbsp; I. ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ä¸ç‰¹å¾åˆ†è§£:four:ç‰¹å¾åˆ†è§£ã€å¥‡å¼‚å€¼åˆ†è§£çš„åŒºåˆ«&nbsp;&nbsp; I. ç‰¹å¾åˆ†è§£ã€å¥‡å¼‚å€¼åˆ†è§£çš„åŒºåˆ« ç®€å•è¯´ä¸€ä¸‹ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ä¸ç‰¹å¾åˆ†è§£ ç‰¹å¾å€¼ã€ç‰¹å¾å‘é‡ä¸ç‰¹å¾åˆ†è§£Theory:å¯¹äºä¸€ä¸ªæ­£é˜µ$M$ï¼Œæ»¡è¶³å¦‚ä¸‹ï¼š Mx=\lambda xå…¶ä¸­$\lambda$è¢«æˆä¸ºç‰¹å¾å€¼ï¼Œæ»¡è¶³$||M-\lambda E||=0$å†æœ‰$(M-\lambda E)x=0$ï¼Œå¯è®¡ç®—å…¶ç‰¹å¾å‘é‡ã€‚å¦‚æœæœ‰äº†ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡åå‘¢ï¼Œåˆ™å¯ä»¥å°†çŸ©é˜µ$M$ç”¨ç‰¹å¾åˆ†è§£ï¼š M=W\sum W^{-1}$W={w_1,w_2,â€¦,w_n}$åˆ†åˆ«æ˜¯ç‰¹å¾å€¼$\lambda_1,\lambda_2,â€¦,\lambda_n$å¯¹åº”çš„ç‰¹å¾å‘é‡æ„æˆçš„æ–¹é˜µ å‡ ä½•æ„ä¹‰ å¯¹åº”çŸ©é˜µM,å…¶å¯¹åº”çš„çº¿æ€§å˜åŒ– Mx = x'ä¸Šé¢è¿™ä¸ªå¼å­ï¼Œ$Mxï¼Œxâ€™$æ˜¯ä¸€ä¸ªå‘é‡ï¼Œ$x,xâ€™$å¯èƒ½æ˜¯ä¸å…±çº¿çš„(å¦‚å›¾(b))ï¼Œå¦‚æœå‘é‡$Mx,xâ€™$æ»¡è¶³$Mx=xâ€™=\lambda x$,åˆ™å¦‚å›¾(b)ï¼Œè¿™è¯´æ˜äº†è¿™ä¸ªå˜æ¢å°±æ˜¯å¯¹å‘é‡xåšä¸€ä¸ªæ‹‰ä¼¸æˆ–è€…å‹ç¼©ã€‚ å¦‚ä½•å®ç°é€šè¿‡Matlabã€Pythonå®ç°æ•°å­¦æ¨å¯¼ï¼š Mx = \lambda xMx-\lambda x=(M-\lambda E)x=0é½æ¬¡çº¿æ€§æ–¹ç¨‹ç»„æœ‰éé›¶è§£ï¼Œåˆ™$||M-\lambda E||=0$å¯æ±‚å¾—ç‰¹å¾å‘é‡å†å¸¦å›ï¼Œå¯å¾—ç‰¹å¾å‘é‡ã€‚Matlab:123d = eig(M) % æ±‚å–çŸ©é˜µMçš„ç‰¹å¾å€¼ï¼Œå‘é‡å½¢å¼å­˜å‚¨[V,D] = eig(M) % è®¡ç®—Mçš„ç‰¹å¾å€¼å¯¹è§’é˜µDå’Œç‰¹å¾å‘é‡Vï¼Œä½¿å¾—MV = VDæˆç«‹[V,D] = eig(M,'nobalance') %å½“çŸ©é˜µMä¸­æœ‰ä¸æˆªæ–­è¯¯å·®æ•°é‡çº§ç›¸å·®ä¸è¿œçš„å€¼æ—¶ï¼Œè¯¥æŒ‡ä»¤å¯èƒ½æ›´ç²¾ç¡®ã€‚'nobalance'èµ·è¯¯å·®è°ƒèŠ‚ä½œç”¨ Pythonnumpyç§‘å­¦è®¡ç®—åº“æä¾›ç›¸åº”çš„æ–¹æ³•1234import numpy as npx = np.diag((1,2,3)) # è¿™æ˜¯ä½ æƒ³è¦æ±‚å–ç‰¹å¾å€¼çš„æ•°ç»„a,b = numpy.linalg.elg(x) # ç‰¹å¾å€¼èµ‹å€¼ç»™a,å¯¹åº”çš„ç‰¹å¾å‘é‡èµ‹å€¼ç»™b è¯¦ç»†è§£è¯´SVDSVDçš„è‹±æ–‡å…¨ç§°ï¼š Singular Value Decompositionï¼Œä¸­æ–‡åå­—ï¼šå¥‡å¼‚å€¼åˆ†è§£ å‡ ä½•æ„ä¹‰å›¾æ¥æºä»¥äºŒç»´ç©ºé—´ä¸ºä¾‹å‡ ä½•æ„ä¹‰å°±æ˜¯æŠŠä¸€ä¸ªå•ä½æ­£äº¤çš„ç½‘æ ¼ï¼Œè½¬æ¢ä¸ºå¦å¤–ä¸€ä¸ªå•ä½æ­£äº¤çš„ç½‘æ ¼ å‡å¦‚é€‰å–äº†ä¸€ç»„å•ä½æ­£äº¤åŸº{$\vec{v}_1$,$\vec{v}_2$},åˆšå¥½çŸ©é˜µ$M$çš„çº¿æ€§å˜åŒ–$M\vec{v}_1 $,$M\vec{v}_2 $ ä¹Ÿæ­£äº¤ï¼Œç”¨$\vec{u}_1,\vec{u}_2 $åˆ†åˆ«è¡¨ç¤º$M\vec{v}_1 $,$M\vec{v}_2 $ çš„å•ä½å‘é‡ï¼Œç”¨$\lambda_1,\lambda_2 $è¡¨ç¤º$M\vec{v}_1 $,$M\vec{v}_2$çš„é•¿åº¦ï¼Œæè¿°ç½‘æ ¼åœ¨è¿™äº›ç‰¹å®šæ–¹å‘ä¸Šçš„æ‹‰ä¼¸é‡ï¼Œä¹Ÿè¢«ç§°ä½œçŸ©é˜µMçš„å¥‡å¼‚å€¼ã€‚$M\vec{v}_1 =\lambda_1\vec{u}_1 $$M\vec{v}_2 =\lambda_2\vec{u}_2 $å¯¹ä»»æ„ç»™å®šçš„å‘é‡ $\vec{x}$ ,åˆ™æœ‰ \mathbf{x}=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) \mathbf{v}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) \mathbf{v}_{2} å†å°†Mçš„çº¿æ€§å˜æ¢ \begin{aligned} M \mathbf{x} &=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) M \mathbf{N}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) M \mathbf{v}_{2} \\ M \mathbf{x} &=\left(\mathbf{v}_{1} \cdot \mathbf{x}\right) \sigma_{1} \mathbf{u}_{1}+\left(\mathbf{v}_{2} \cdot \mathbf{x}\right) \sigma_{2} \mathbf{u}_{2} \end{aligned} \begin{array}{c}{M \mathbf{x}=\mathbf{u}_{1} \sigma_{1} \mathbf{v}_{1}^{\top} \mathbf{x}+\mathbf{u}_{2} \sigma_{2} \mathbf{v}_{2}^{\top} \mathbf{x}} \\ {M=\mathbf{u}_{1} \sigma_{1} \mathbf{v}_{1}^{\top}+\mathbf{u}_{2} \sigma_{2} \mathbf{v}_{2}^{\top}}\end{array} so M=U \Sigma V^{T}å¥‡å¼‚å€¼åˆ†è§£çš„æ¨å¯¼è¿‡ç¨‹$u=(u_1,u_2,â€¦,u_m)$$v=(v_1,v_2,â€¦,v_n)$$u,v$éƒ½æ˜¯ç©ºé—´çš„åŸº,æ˜¯æ­£äº¤çŸ©é˜µ $u^Tu=E,v^Tv = E$ä»»ä½•ä¸€ä¸ªçŸ©é˜µ$M_{m*n}$ï¼Œ$rank(M)=k$ï¼Œä¸€å®šå­˜åœ¨ï¼³ï¼¶ï¼¤,æ¢å¥è¯è¯´ï¼ŒMå¯ä»¥å°†ä¸€ç»„å•ä½æ­£äº¤åŸºæ˜ å°„åˆ°å¦ä¸€ç»„å•ä½æ­£äº¤åŸºã€‚ç­”æ¡ˆæ˜¯è‚¯å®šçš„è¯æ˜å¦‚ä¸‹ï¼šåœ¨nä¸ºç©ºé—´ä¸­ï¼Œæœ‰ä¸€ç»„å•ä½æ­£äº¤åŸº{$\vec{v}_1,\vec{v}_2,â€¦,\vec{v}_n$},çº¿æ€§å˜åŒ–ä½œç”¨ä»¥å {M\vec{v}_1,M\vec{v}_2,...,M\vec{v}_n}ä¹Ÿæ˜¯æ­£äº¤çš„ï¼Œåˆ™æœ‰ (M\vec{v}_i,M\vec{v}_j) = (M\vec{x}_i)^TM\vec{v}_j=\vec{v}_i^TM^TM\vec{v}_j=0æ³¨æ„å–”ï¼Œ$M^TM$æ˜¯çŸ©é˜µå–”ï¼Œåˆ™ä¼šæœ‰$M^TM\vec{v}_j=\lambda \vec{v}_j$æ¥ä¸‹å»ï¼Œ \begin{aligned} v_{i}^{T} M^{T} \mathrm{M} v_{j}=& v_{i}^{T} \lambda_{j} v_{j} \\ &=\lambda_{j} v_{i}^{T} v_{j} \\ &=\lambda_{j} v_{i}\dot v_{j}=0 \end{aligned} ä¸Šè¿°å°±è¯æ˜äº†æ˜¯æœ‰çš„ï¼šä»»ä½•ä¸€ä¸ªçŸ©é˜µï¼Œéƒ½å¯ä»¥å°†ä¸€ç»„å•ä½æ­£äº¤åŸºè½¬æ¢æˆå¦å¤–ä¸€ç»„æ­£äº¤åŸºã€‚ å½“$i=j$,$=\lambda_i \vec{v}_i \vec{v}_i=\lambda_i$ è¿›è¡Œä¸€äº›å•ä½åŒ–ï¼Œè®°$u_i=\frac{A\vec{v}_i}{|M\vec{v}_i|}=\frac{1}{\sqrt{\lambda_i}}M\vec{v}_i$åˆ™ A v_{i}=\sigma_{i} u_{i}, \sigma_{i}(\operatorname{å¥‡å¼‚å€¼})=\sqrt{\lambda_{i}}, 0 \leq i \leq \mathrm{k}, \mathrm{k}=\operatorname{Rank}(\mathrm{A}) å½“$k &lt; i &lt;= m$æ—¶ï¼Œå¯¹$u1ï¼Œu2ï¼Œâ€¦ï¼Œuk$è¿›è¡Œæ‰©å±•$u(k+1),â€¦,um$ï¼Œä½¿å¾—$u1ï¼Œu2ï¼Œâ€¦ï¼Œum$ä¸º$m$ç»´ç©ºé—´ä¸­çš„ä¸€ç»„æ­£äº¤åŸº.ä¹Ÿå¯å¯¹$\vec{v}_1,\vec{v}_2,â€¦,\vec{v}_k$è¿›è¡Œæ‰©å±•ï¼Œæ‰©å±•çš„$\vec{v}_{k+1},â€¦,\vec{v}_{n}$å­˜åœ¨é›¶å­ç©ºé—´é‡Œé¢ã€‚ M\left[ \begin{array}{lll}{\vec{v}_{1}} & {\cdots} & {\vec{v}_{k}}\end{array}\right| \vec{v}_{k+1} \quad \cdots \quad \vec{v}_{m} ]= \left[ \begin{array}{c}{\vec{u}_{1}^{T}} \\ {\vdots} \\ {\frac{\vec{u}_{k}^{T}}{\vec{u}_{k+1}}} \\ {\vdots} \\ {\vec{u}_{n}^{T}}\end{array}\right] \left[ \begin{array}{ccc|c}\sigma_{1} & & 0 & 0\\ & {\ddots} & \sigma_{k} & 0 \\ \hline 0 & & 0 &0\end{array}\right] M=\left[ \begin{array}{lll}{\vec{u}_{1}} & {\cdots} & {\vec{u}_{k}}\end{array}\right] \left [ \begin{array}{ccc}\sigma_{1} & & \\ & {\ddots} & \\ & & {\sigma_{k}}\end{array}\right] \left[ \begin{array}{c}{\vec{v}_{1}^{T}} \\ {\vdots} \\ {\vec{v}_{k}^{T}}\end{array}\right]+ \left[ \begin{array}{ccc}{\vec{u}_{k+1}} & {\cdots} & {\vec{u}_{m}}\end{array}\right] \left[\begin{array}{c} 0 \end{array} \right] \left[ \begin{array}{c}{\vec{v}_{k+1}^{T}} \\ {\vdots} \\ {\vec{v}_{n}^{T}}\end{array}\right]SVDç®—ä¾‹Uï¼š$AA^T$çš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œç”¨å•ä½åŒ–çš„ç‰¹å¾å‘é‡æ„æˆ UV: $A^TA$ çš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œç”¨å•ä½åŒ–çš„ç‰¹å¾å‘é‡æ„æˆ V$\sum_{mn} $ :å°†$ AA^{T} $æˆ–è€… A^{T}A çš„ç‰¹å¾å€¼æ±‚å¹³æ–¹æ ¹ï¼Œç„¶åæ„æˆ Î£ä»¥çŸ©é˜µ$A = \left[\begin{matrix} 1 &amp; 1\\1 &amp;1\\ 0 &amp;0\\\end{matrix} \right]$ç¬¬ä¸€æ­¥ U ï¼Œä¸‹é¢æ˜¯ä¸€ç§è®¡ç®—æ–¹æ³•å¯¹çŸ©é˜µ A A^{T}=\left[ \begin{array}{lll}{2} & {2} & {0} \\ {2} & {2} & {0} \\ {0} & {0} & {0}\end{array}\right] ç‰¹å¾åˆ†è§£ï¼Œ ç‰¹å¾æ˜¯4ï¼Œ0ï¼Œ0 ç‰¹å¾å‘é‡æ˜¯ $\left[\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]^{T},\left[-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0\right]^{T},[0,0,1]^{T}$,å¯å¾—åˆ° U=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} & {0} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}} & {0} \\ {0} & {0} & {1}\end{array}\right] ç¬¬äºŒæ­¥ è®¡ç®—çŸ©é˜µ$A^TA$çš„ç‰¹å¾åˆ†è§£ï¼Œå¯å¾— ç‰¹å¾å€¼4ï¼Œ0ï¼Œ V=\left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}}\end{array}\right]ç¬¬ä¸‰æ­¥è®¡ç®—$\sum_{mn}$ \Sigma=\left[ \begin{array}{ll}{2} & {0} \\ {0} & {0} \\ {0} & {0}\end{array}\right] æœ€åï¼Œ A=U \Sigma V^{T}=\left[ \begin{array}{ccc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} & {0} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}} & {0} \\ {0} & {0} & {1}\end{array}\right] \left[ \begin{array}{ll}{2} & {0} \\ {0} & {0} \\ {0} & {0}\end{array}\right] \left[ \begin{array}{cc}{\frac{1}{\sqrt{2}}} & {-\frac{1}{\sqrt{2}}} \\ {\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{2}}}\end{array}\right]^{T}=\left[ \begin{array}{cc}{1} & {1} \\ {1} & {1} \\ {0} & {0}\end{array}\right]å¦‚ä½•é€šè¿‡Matlabå’ŒPythonMatlabï¼š1234567891011s = svd(A)[U,S,V] = svd(A)[U,S,V] = svd(A,'econ')[U,S,V] = svd(A,0)input: A çŸ©é˜µoutput: s:å¥‡å¼‚å€¼ï¼Œä»¥åˆ—å‘é‡å½¢å¼è¿”å›ã€‚å¥‡å¼‚å€¼æ˜¯ä»¥é™åºé¡ºåºåˆ—å‡ºçš„éè´Ÿå®æ•° Sï¼š U:å·¦å¥‡å¼‚å‘é‡ï¼Œä»¥çŸ©é˜µçš„åˆ—å½¢å¼è¿”å›ã€‚ V:å¥‡å¼‚å€¼ï¼Œä»¥å¯¹è§’çŸ©é˜µå½¢å¼è¿”å›ã€‚S çš„å¯¹è§’å…ƒç´ æ˜¯ä»¥é™åºæ’åˆ—çš„éè´Ÿå¥‡å¼‚å€¼ã€‚ å³å¥‡å¼‚å‘é‡ï¼Œä»¥çŸ©é˜µçš„åˆ—å½¢å¼è¿”å›ã€‚ Python123import numpy as npM = np.array([ [1,1,2],[0,0,1]])U,S,V = np.linalg.svd(M) åº”ç”¨ä¸¾ä¾‹åº”ç”¨ 2.1 ä¿¡æ¯æ£€ç´¢ 2.2 æ¨èç³»ç»Ÿ 2.3 åŸºäºååŒè¿‡æ»¤çš„æ¨èç³»ç»Ÿ 2.4 å›¾åƒå‹ç¼© ç‰¹å¾å€¼åˆ†è§£å’Œå¥‡å¼‚å€¼åˆ†è§£çš„åŒºåˆ« ç‰¹å¾å€¼åˆ†è§£åªèƒ½æ˜¯æ–¹é˜µï¼Œè€Œå¥‡å¼‚å€¼åˆ†è§£æ˜¯çŸ©é˜µå°±å¯ä»¥ ç‰¹å¾å€¼åˆ†è§£åªè€ƒè™‘äº†å¯¹çŸ©é˜µç¼©æ”¾æ•ˆæœï¼Œå¥‡å¼‚å€¼åˆ†è§£å¯¹çŸ©é˜µæœ‰é€‰æ‹©ã€æ”¶ç¼©ã€æŠ•å½±çš„æ•ˆæœ]]></content>
      <categories>
        <category>æ•°å­¦</category>
      </categories>
      <tags>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pythonåº“]]></title>
    <url>%2F2019%2F02%2F24%2Fpython%E5%BA%93%2F</url>
    <content type="text"><![CDATA[å¼€å§‹æ¥è§¦Pythonæ˜¯å¤§äºŒç»“æŸçš„æ—¶å€™ï¼Œåˆ°ç°åœ¨éƒ½å¿«ä¸¤å¹´äº†ï¼Œå…¶å®ä¸€ç›´å¹¶ä¸æ˜¯å¾ˆç»†èŠ‚çš„å­¦ä¹ ï¼Œåªæ˜¯å¸Œæœ›èƒ½å¤Ÿè·‘ä¸ªç»“æœã€‚ä¸è¿‡å‘¢ï¼Ÿï¼Œä»¥åè‚¯å®šæ˜¯ä¼šç»å¸¸ç”¨Pythonï¼Œæ‰€ä»¥å‘¢ï¼Ÿæˆ‘æ¥ä¸‹æ¥ä¼šè®¤çœŸå­¦ä¹ Python Python é«˜çº§ç”¨æ³•æ€»ç»“åŸºæœ¬æ•°æ®ç±»å‹ï¼šæ•´å‹ã€æµ®ç‚¹å‹ã€å¸ƒå°”ç±»å‹ å®¹å™¨ï¼š Containerså®¹å™¨æ˜¯ä¸€ç§æŠŠå¤šä¸ªå…ƒç´ ç»„ç»‡åœ¨ä¸€èµ·çš„æ•°æ®ç»“æ„ï¼Œå®¹å™¨ä¸­çš„å…ƒç´ å¯ä»¥é€ä¸ªåœ°è¿­ä»£è·å–ï¼Œå¯ä»¥ç”¨in, not inå…³é”®å­—åˆ¤æ–­å…ƒç´ æ˜¯å¦åŒ…å«åœ¨å®¹å™¨ä¸­ã€‚é€šå¸¸è¿™ç±»æ•°æ®ç»“æ„æŠŠæ‰€æœ‰çš„å…ƒç´ å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼ˆä¹Ÿæœ‰ä¸€äº›ç‰¹ä¾‹ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„å…ƒç´ éƒ½æ”¾åœ¨å†…å­˜ï¼Œæ¯”å¦‚è¿­ä»£å™¨å’Œç”Ÿæˆå™¨å¯¹è±¡ï¼‰åœ¨Pythonä¸­ï¼Œå¸¸è§çš„å®¹å™¨å¯¹è±¡æœ‰ï¼šlist, dequeset, frozensetsdict, defaultdict, OrderedDict, Countertuple, namedtuplestr listæ¨å¯¼ï¼ˆlist comprehensions)å®˜æ–¹è§£é‡Šï¼šåˆ—è¡¨è§£æå¼æ˜¯Pythonå†…ç½®çš„éå¸¸ç®€å•å´å¼ºå¤§çš„å¯ä»¥ç”¨æ¥åˆ›å»ºlistçš„ç”Ÿæˆå¼ã€‚ 1å¯¹äºä¸€ä¸ªåˆ—è¡¨ï¼Œæ—¢è¦éå†ç´¢å¼•åˆè¦éå†å…ƒç´ ã€‚ 123array = ['I', 'love', 'Python']for i, element in enumerate(array): array[i] = '%d: %s' % (i, seq[i]) 12345def getitem(index, element): return '%d: %s' % (index, element)array = ['I', 'love', 'Python']arrayIndex = [getitem(index, element) for index, element in enumerate(array)] è¿­ä»£å™¨å’Œç”Ÿæˆå™¨å¯è¿­ä»£å¯¹è±¡ï¼šå‡¡æ˜¯å¯ä»¥è¿”å›ä¸€ä¸ªè¿­ä»£å™¨çš„å¯¹è±¡éƒ½å¯ç§°ä¹‹ä¸ºå¯è¿­ä»£å¯¹è±¡ä¾‹å¦‚ï¼šlist dic str set tuple range() enumerate(æšä¸¾) f=open()ï¼ˆæ–‡ä»¶å¥æŸ„ï¼‰123456789### è¿­ä»£å™¨(iterator)æ˜¯ä¸€ä¸ªå¸¦çŠ¶æ€çš„å¯¹è±¡ï¼Œä»–èƒ½åœ¨ä½ è°ƒç”¨next()æ–¹æ³•çš„æ—¶å€™è¿”å›å®¹å™¨ä¸­çš„ä¸‹ä¸€ä¸ªå€¼ï¼Œä»»ä½•å®ç°äº†__iter__å’Œ__next__()ï¼ˆpython2ä¸­å®ç°next()ï¼‰æ–¹æ³•çš„å¯¹è±¡éƒ½æ˜¯è¿­ä»£å™¨ï¼Œ__iter__è¿”å›è¿­ä»£å™¨è‡ªèº«ï¼Œ__next__è¿”å›å®¹å™¨ä¸­çš„ä¸‹ä¸€ä¸ªå€¼ï¼Œå¦‚æœå®¹å™¨ä¸­æ²¡æœ‰æ›´å¤šå…ƒç´ äº†ï¼Œåˆ™æŠ›å‡ºStopIterationå¼‚å¸¸### ç”Ÿæˆå™¨(generator)ç”Ÿæˆå™¨å…¶å®æ˜¯ä¸€ç§ç‰¹æ®Šçš„è¿­ä»£å™¨ï¼Œä¸è¿‡è¿™ç§è¿­ä»£å™¨æ›´åŠ ä¼˜é›…ã€‚å®ƒä¸éœ€è¦å†åƒä¸Šé¢çš„ç±»ä¸€æ ·å†™__iter__()å’Œ__next__()æ–¹æ³•äº†ï¼Œåªéœ€è¦ä¸€ä¸ªyiledå…³é”®å­—ã€‚ ç”Ÿæˆå™¨ä¸€å®šæ˜¯è¿­ä»£å™¨ï¼ˆåä¹‹ä¸æˆç«‹ï¼‰#åˆ—è¡¨ç”Ÿæˆå¼lis = [x*x for x in range(10)]# å—åˆ°å†…å­˜é™åˆ¶ï¼Œåˆ—è¡¨å®¹é‡è‚¯å®šæ˜¯æœ‰é™çš„#ç”Ÿæˆå™¨è¡¨è¾¾å¼generator_ex = (x*x for x in range(10)) ç”Ÿæˆå™¨ï¼š ä¸ç”¨åˆ›å»ºå®Œæ•´çš„listï¼Œä¸ºèŠ‚çœå¤§é‡çš„ç©ºé—´ï¼Œåœ¨Pythonä¸­ï¼Œè¿™ç§ä¸€è¾¹å¾ªç¯ä¸€è¾¹è®¡ç®—çš„æœºåˆ¶ï¼Œç§°ä¸ºç”Ÿæˆå™¨ï¼šgeneratorTuples:() å­—å…¸ï¼š{ï¼šï¼Œ} Sets: {,}å‡½æ•°ç±» Pythonåº“â€”â€”numpyWhatNumPy=Numerical+Pythonä¸»è¦æ˜¯æä¾›äº†é«˜æ€§èƒ½å¤šç»´æ•°ç»„è¿™ä¸ªå¯¹è±¡ï¼Œä»¥åŠå¤„ç†ç›¸å…³çš„æ–¹æ³• How è‡ªå®šä¹‰ä¸€ä¸ªï¼ˆ1D or MD)æ•°ç»„æˆ–è€…ç‰¹æ®Šçš„æ•°ç»„,ä¸€ç»´ï¼ŒäºŒç»´ æ•°ç»„åˆ‡ç‰‡ï¼ˆä¹Ÿå°±æ˜¯æå–æ•°ç»„å…ƒç´ ï¼‰ï¼Œæ³¨æ„ a[:,0]å’Œa[:,0:1]æ˜¯ä¸åŒçš„å–” å…³äºæ•°ç»„å±æ€§çš„æ–¹æ³• æ•°ç»„è¿ç®— ç´¢å¼• where å‡½æ•° ç´¢å¼•çš„å¸ƒå°”æ•°ç»„ å¹¿æ’­ï¼ˆBroadcastingï¼‰ç”¨äºå¤„ç†ä¸åŒæ€§çŠ¶çš„ æ•°ç»„ã€‚ Broadcastingæä¾›äº†ä¸€ç§çŸ¢é‡åŒ–æ•°ç»„æ“ä½œçš„æ–¹æ³•ï¼Œä½¿å¾—å¾ªç¯å‘ç”Ÿåœ¨Cè€Œä¸æ˜¯Pythonã€‚æ ‡é‡ä¹˜ä»¥ä¸€ä¸ªçŸ¢é‡çš„æ—¶å€™ï¼Œç”¨Boradcastingæ›´å¿«ï¼Œå› ä¸º broadcastingåœ¨ä¹˜æ³•æœŸé—´ç§»åŠ¨è¾ƒå°‘çš„å†…å­˜ array å’Œ matrix é€‰æ‹©å“ªä¸ª? æˆ³æˆ‘ çŸ¢é‡åŒ–å’Œå¹¿æ’­ã€ç´¢å¼•åœ¨Pythonä¸­å¾ªç¯æ•°ç»„æˆ–ä»»ä½•æ•°æ®ç»“æ„æ—¶ï¼Œä¼šæ¶‰åŠå¾ˆå¤šå¼€é”€ã€‚ NumPyä¸­çš„å‘é‡åŒ–æ“ä½œå°†å†…éƒ¨å¾ªç¯å§”æ‰˜ç»™é«˜åº¦ä¼˜åŒ–çš„Cå’ŒFortranå‡½æ•°ï¼Œä»è€Œå®ç°æ›´æ¸…æ™°ï¼Œæ›´å¿«é€Ÿçš„Pythonä»£ç ã€‚stack|vstack|hstack 1234567891011121314151617181920212223242526272829303132a = np.array([1, 2, 3])b = np.array([2, 3, 4])np.stack((a, b))array([[1, 2, 3], [2, 3, 4]])% hstacka = np.array((1,2,3))b = np.array((2,3,4))np.hstack((a,b))array([1, 2, 3, 2, 3, 4])a = np.array([[1],[2],[3]])b = np.array([[2],[3],[4]])np.hstack((a,b))array([[1, 2], [2, 3], [3, 4]])% vstacka = np.array([1, 2, 3])b = np.array([2, 3, 4])np.vstack((a,b))array([[1, 2, 3], [2, 3, 4]])a = np.array([[1], [2], [3]])b = np.array([[2], [3], [4]])np.vstack((a,b))array([[1], [2], [3], [2], [3], [4]]) mean123456a = np.array([[1, 2], [3, 4]])np.mean(a)np.mean(a, axis=0)np.mean(a, axis=1) reshapereshape(x, y)ï¼Œå…¶ä¸­xè¡¨ç¤ºè½¬æ¢åæ•°ç»„çš„è¡Œæ•°ï¼Œyè¡¨ç¤ºè½¬æ¢åæ•°ç»„çš„åˆ—æ•°ã€‚å½“xæˆ–è€…yä¸º-1æ—¶ï¼Œè¡¨ç¤ºè¯¥å…ƒç´ éšæœºåˆ†é…ï¼Œå¦‚reshape(2, -1)è¡¨ç¤ºåˆ—æ•°éšæœºï¼Œè¡Œæ•°ä¸ºä¸¤è¡Œã€‚ 123456789æ ¼å¼ï¼šnp.reshape((x, y, z))å‚æ•°çš„å«ä¹‰ï¼šxï¼šè¡¨ç¤ºç”Ÿæˆçš„ä¸‰ç»´æ•°ç»„ä¸­äºŒç»´æ•°ç»„çš„ä¸ªæ•°yï¼šè¡¨ç¤ºå•ä¸ªäºŒç»´æ•°ç»„ä¸­ä¸€ç»´æ•°ç»„çš„ä¸ªæ•°zï¼šè¡¨ç¤ºä¸‰ç»´æ•°ç»„çš„åˆ—æ•° numpyæ•°ç»„å»æ‰å†—ä½™çš„ç»´åº¦â€”â€”-squeeze()å‡½æ•°import numpy as np a = [[[10, 2, 3]]] a = np.array(a) a_sque = np.squeeze(a) print(a) print(a_sque) Pythonåº“â€”â€”pandasè®°å¾—å­¦ä¹ pandasæ˜¯åœ¨å¤§ä¸‰æ—¶å€™çš„ç¾èµ›ï¼ŒèŠ±äº†ä¸€å¤©å¤šæ—¶é—´å­¦ä¹ pandasï¼Œç„¶åé¢„å¤„ç†æ•°æ®ï¼Œå½“æ—¶ä¸‰ä¸ªé˜Ÿå‹éƒ½æ˜¯å„è‡ªçš„å®¶ï¼Œæ˜¯éå¸¸æ„‰å¿«çš„ï¼ï¼ï¼ whatPython Data Analysis Library ä¸‰ç§æ•°æ®ç»“æ„åºåˆ—ï¼š Series 1Dæ•°æ®å¸§ï¼š DataFrame 2Dé¢æ¿ï¼š Panel &gt;2D è‡ªå®šä¹‰åˆ›å»º å¯ä»¥é€šè¿‡å­—æ®µã€æ•°æ®ã€seriesã€åˆ—è¡¨ åˆ—è¡¨ä¼ å…¥çš„æ—¶å€™ï¼Œä¸»è¦è¡Œåˆ—ï¼Œå¦‚æœå•ä¸ªåˆ—è¡¨ï¼šåˆ—ï¼›å¦‚æœæ˜¯[[],[]]æ˜¯æŒ‰è¡Œ[] å¦‚æœä½ç½®ä¸å¯¹å¯è½¬ç½® åˆ›å»ºç©º pd.DataFrame() é€‰æ‹©åŒºå— a) Series [] b) DataFrame åˆ—é€‰æ‹© [â€˜columsçš„åå­—â€™] è¡Œåˆ—é€‰æ‹©ï¼š.loc[åˆ—å,è¡Œå]åç§° .iloc[åˆ—ç´¢å¼•,è¡Œç´¢å¼•]æ•´æ•° array.value ç»Ÿè®¡æè¿° .descibe(include = â€˜allâ€™) .head() .tail() .select_dtype(include=[]) .columns .dtype ç¼ºå°‘æ•°æ® æŸ¥çœ‹ç¼ºå¤±å€¼isnull() notnull() ä¹Ÿå¯ä»¥ åšä¸€äº›ç»Ÿè®¡ï¼Œsum, any,all æ¸…ç†ç¼ºå¤±å€¼ dropna(axis=0)ï¼šaxis = 0:index axis=1,columns å¡«å……ç¼ºå°‘æŒ‡ fillna() æ ‡é‡æ›¿æ¢ æ›¿æ¢ ç»Ÿè®¡å‡½æ•° Pandas å‡½æ•°åº”ç”¨è¡¨åˆç†å‡½æ•°åº”ç”¨ï¼špipe()è¡Œæˆ–åˆ—å‡½æ•°åº”ç”¨ï¼šapply()å…ƒç´ å‡½æ•°åº”ç”¨ï¼šapplymap()egï¼š pd.pipe(lambda x: x*100) ç±»åˆ«å˜é‡å‘é‡åŒ–éæ•°å€¼ç±»å‹çš„å¤„ç†æ–¹æ³• æ—¶é—´åºåˆ—ç”Ÿæˆ data_range pandas.date_range(â€œ11:00â€, â€œ21:30â€, freq=â€30minâ€) å‚æ•°1Return a fixed frequency DatetimeIndex. Parametersstartstr or datetime-like, optionalLeft bound for generating dates. endstr or datetime-like, optionalRight bound for generating dates. periodsint, optionalNumber of periods to generate. freqstr or DateOffset, default â€˜Dâ€™Frequency strings can have multiples, e.g. â€˜5Hâ€™. See here for a list of frequency aliases. tzstr or tzinfo, optionalTime zone name for returning localized DatetimeIndex, for example â€˜Asia/Hong_Kongâ€™. By default, the resulting DatetimeIndex is timezone-naive. normalizebool, default FalseNormalize start/end dates to midnight before generating date range. namestr, default NoneName of the resulting DatetimeIndex. closed{None, â€˜leftâ€™, â€˜rightâ€™}, optionalMake the interval closed with respect to the given frequency to the â€˜leftâ€™, â€˜rightâ€™, or both sides (None, the default). **kwargsFor compatibility. Has no effect on the result. ReturnsrngDatetimeIndex12345678910111213141516171819202111. DataFrame.stackParameterslevelint, str, list, default -1Level(s) to stack from the column axis onto the index axis, defined as one index or label, or a list of indices or labels.dropnabool, default TrueWhether to drop rows in the resulting Frame/Series with missing values. Stacking a column level onto the index axis can create combinations of index and column values that are missing from the original dataframe. See Examples section.ReturnsDataFrame or SeriesStacked dataframe or series.â€‹```pythondf_single_level_cols weight heightcat 0 1dog 2 3df_single_level_cols.stack()cat weight 0 height 1dog weight 2 height DataFrame.value_connts()è¿”å›åºåˆ—ï¼Œindex=ç»Ÿè®¡å€¼ï¼Œå€¼ï¼šç»Ÿè®¡ä¸ªæ•° Matplotlibmatplotlib.pyplot as plt çª—å£ï¼šfigure: ä¸€ä¸ªçª—å£ï¼Œplt.figure(num=,figsize=(h,w))ä¸‹é¢æ•°æ®éƒ½å±äºå½“å‰çš„figure,æœ‰ä¸€å®šçš„é¡ºåºå–” ç”»å›¾ï¼šplt.plot(x,y,color=,linewidth=,linestyle,label=) æ ‡æ³¨ä¿¡æ¯ï¼š plt.xlim((,)), plt.yxlim((,)),plt.xlabel(),plt.ylabel(),ticks:å›¾åƒçš„å°æ ‡ï¼Œplt.xticks(),plt.yticks([å€¼1ï¼Œå€¼2],[râ€™$å€¼1\ å¯¹åº”çš„æ–‡å­—$â€™,râ€™å€¼2çš„æ–‡å­— \alpha]) åæ ‡è½´ï¼šaxis gac=â€™get current axisâ€™ax = plt.gca() # è½´# è·å–å››ä¸ªè½´ax.spines[â€˜right|left|top|â€™].set_color(â€˜noneâ€™)ax.xaxis.set_ticks_position(â€˜bottomâ€™)ax.spines[â€˜bottomâ€™].set_position((â€˜dataâ€™,-1)) å›¾ä¾‹ï¼šlegend: a. plt.plot(,label=), plt.legend() b. l1, = plt.plot() plt.legend(handles=[l1,],labels=[,],loc=â€™best|upper right|â€™) æ³¨è§£ annotationa. ç‚¹çš„ä½ç½®(x0ï¼Œy0) plt.scatter(). plt.plot([x0,y0],[y0,0],â€™kâ€”â€˜,lw=)b . method 1:plt.annotate(râ€™nameâ€™,xy=(,)èµ·å§‹ç‚¹ï¼Œxycoords=â€™dataâ€™//åŸºäºxy,xytext=(+30,30),textcoords=â€™offseet pointsâ€™//æ–‡æœ¬åŸºäºxy,arrowprops=dict(arrowstyle=â€™-&gt;â€™ç®­å¤´,connectionstyle=â€™arc3,rad=.2â€™)å¼§åº¦) Bar æŸ±çŠ¶å›¾plt.bar(x,+|-y,facecolor=â€â€,edgecolor,)|# ha horizontal alignment å¯¹é½æ–¹å¼for x,y in zip(x,y): plt.text(x+0,4,y+0.05,â€™%.2fâ€™%y,ha=â€™centerâ€™,va=â€™bottomâ€™) å¾ˆå¤šè‡ªåŠ¨ subplot(æ€»è¡Œï¼Œå½“å‰è¡Œçš„åˆ—ï¼Œæ€»çš„æŒ‰æœ€å°åˆ†çš„ç¬¬å‡ ä¸ª)subplot(,,)index reset_index:é™äºDataFrame set_index index scikit-learnå®˜æ–¹æ•™ç¨‹ç»å¯¹æ˜¯æœ€å¥½æœ€æ£’çš„é€‰æ‹©ï¼Œæœ‰ç®€å•æ•°å­¦æ¨å¯¼ã€ç›´è§‚ç«‹é©¬å°±èƒ½ä¸Šæ‰‹çš„æ¡ˆä¾‹ï¼Œè¿˜èƒ½æé˜…è¯»è‹±æ–‡çš„èƒ½åŠ›å–”ï¼Œå®åœ¨æ˜¯ä¸€ä¸¾å¤šå¾—å•Šï¼ï¼ï¼ï¼ scikit-learn.org regressionFeature selectionMethod from sklearn.feature_selection import VarianceThresholdsklearn.feature_selection.SelectFromModelclass sklearn.feature_selection.SelectFromModel(estimator, , threshold=None, prefit=False, norm_order=1, max_features=None) seabornseaborn.jointplot(x, y, data=None, kind=â€™scatterâ€™, stat_func=None, color=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs) Parameters x, ystrings or vectorsData or names of variables in data.dataDataFrame, optionalDataFrame when x and y are variable names.kind{ â€œscatterâ€ | â€œregâ€ | â€œresidâ€ | â€œkdeâ€ | â€œhexâ€ }, optionalKind of plot to draw.stat_funccallable or None, optionalDeprecated**colormatplotlib color, optionalColor used for the plot elements.heightnumeric, optionalSize of the figure (it will be square).rationumeric, optionalRatio of joint axes height to marginal axes height.spacenumeric, optionalSpace between the joint and marginal axesdropnabool, optionalIf True, remove observations that are missing from x and y.{x, y}limtwo-tuples, optionalAxis limits to set before plotting.{joint, marginal, annot}_kwsdicts, optionalAdditional keyword arguments for the plot components.kwargs**key, value pairingsAdditional keyword arguments are passed to the function used to draw the plot on the joint Axes, superseding items in the joint_kws dictionary. Returns gridJointGridJointGrid object with the plot on it. http://seaborn.pydata.org/generated/seaborn.JointGrid.html#seaborn.JointGrid g = sns.jointplot(x=â€xâ€, y=â€yâ€, kind = â€˜regâ€™ , space=0,color = â€˜gâ€™, data=df11,stat_func=sci.pearsonr) sns.set() sns.axes_style(â€œdarkgridâ€) sns.set_context(â€œpaperâ€) https://blog.mazhangjing.com/2018/03/29/learn_seaborn/ https://blog.csdn.net/weiyudang11/article/details/51549672 123456789101112131415#åˆå§‹åŒ–ç±»g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)g=g.plot_marginals(sns.distplot,kde=False)from scipy import statsg=sns.JointGrid(x=&apos;v_ma5&apos;,y=&apos;price_change&apos;,data=stock,space=0.5,ratio=5)g=g.plot_joint(plt.scatter,color=&apos;.3&apos;,edgecolor=&apos;r&apos;)_=g.ax_marg_x.hist(stock.v_ma10,color=&apos;r&apos;,alpha=.6,bins=50)_=g.ax_marg_y.hist(stock.low,color=&apos;y&apos;,orientation=&quot;horizontal&quot;,bins=20)rquare=lambda a,b:stats.pearsonr(a,b)[0]**2g=g.annotate(rquare,template=&apos;&#123;stat&#125;:&#123;val:.2f&#125;&apos;,stat=&apos;$R^2$&apos;,loc=&apos;upper left&apos;,fontsize=12) é¢œè‰²å’Œé£æ ¼è®¾ç½®è°ƒè‰²æ¿ä¸»è¦ä½¿ç”¨ä»¥ä¸‹å‡ ä¸ªå‡½æ•°è®¾ç½®é¢œè‰²ï¼šcolor_palette() èƒ½ä¼ å…¥ä»»ä½•Matplotlibæ‰€æœ‰æ”¯æŒçš„é¢œè‰²color_palette() ä¸å†™å‚æ•°åˆ™é»˜è®¤é¢œè‰² current_palette = sns.color_palette() sns.palplot(current_palette) plt.show() set_palette() è®¾ç½®æ‰€æœ‰å›¾çš„é¢œè‰² sns.palplot(sns.color_palette(â€œhlsâ€,8)) plt.show() é¢œè‰²çš„äº®åº¦åŠé¥±å’Œåº¦l-å…‰åº¦ lightnesss-é¥±å’Œ saturation sns.palplot(sns.hls_palette(8,l=.7,s=.9)) plt.show() xkcdé€‰å–é¢œè‰²xkcdåŒ…å«äº†ä¸€å¥—ä¼—åŒ…åŠªåŠ›çš„é’ˆå¯¹éšæœºRGBè‰²çš„å‘½åã€‚äº§ç”Ÿäº†954ä¸ªå¯ä»¥éšæ—¶é€šè¿‡xkcd_rgbå­—å…¸ä¸­è°ƒç”¨çš„å‘½åé¢œè‰² plt.plot([0,1],[0,1],sns.xkcd_rgb[â€˜pale redâ€™],lw = 3) #lw = çº¿å®½åº¦plt.plot([0,1],[0,2],sns.xkcd_rgb[â€˜medium greenâ€™],lw = 3)plt.plot([0,1],[0,3],sns.xkcd_rgb[â€˜denim blueâ€™],lw = 3)plt.show() æ±‡æ€»http://seaborn.pydata.org/api.html# https://github.com/mwaskom/seaborn/blob/master/seaborn/rcmod.py https://xkcd.com/color/rgb/]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æˆ‘çš„è¯»ä¹¦ç¬”è®°]]></title>
    <url>%2F2019%2F02%2F22%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[2019 ç¬¬åäº”å‘¨ä¸‰æœˆä»½è‡³2019.4.9è¿™æ®µæ—¶é—´ï¼Œæ‰å‘ç°æˆ‘æ˜¯å¦‚æ­¤æ²¡æœ‰è‡ªå¾‹çš„äººï¼Œå……åˆ†ä½“ç°äº†æˆ‘æ˜¯äººçš„ç‰¹æ€§ï¼Œé‚£å°±æ˜¯æˆ‘æ˜¯ç¾¤ä½“åŠ¨ç‰©ï¼Œè‹¦ç¬‘.jpg,è‹¦ç¬‘.jpg, en, æœ€è¿‘çªç„¶æƒ³ç»™è‡ªå·±æ‰“ä¸Šå¨å¨˜çš„èº«ä»½ï¼Œå¦‚æœå¯ä»¥æ¯å¤©èŠ±ä¸¤ä¸ªå°æ—¶åšé¥­å°±å¥½äº† æ„¿ä½ è¢«ä¸–ç•Œæ¸©æŸ”çš„ç›¸å¾… æ¥è§¦çš„ä¸œè¥¿è¶Šå¤šï¼Œè¶Šæ·±å…¥ï¼Œå°±ä¼šå‘ç°æˆ‘æ˜¯å¦‚æ­¤çš„èœï¼Œå¼€å§‹æœ‰äº›çŸ¥è¯†ç„¦è™‘äº†ï¼ŒçŸ¥è¯†é‚£ä¹ˆå¤š~ï¼Œå¯æ˜¯æˆ‘åªæœ‰ä¸€ä¸ªå¤´è„‘å•Š~ å¼€å§‹ä¸æƒ³å†™ä¸€äº›ç‰¹åˆ«ä½ä¿—çš„åšå®¢äº†ï¼Œä¸€æ˜¯è§‰å¾—æµªè´¹æ—¶é—´ï¼ŒäºŒæ˜¯è¾“å‡ºæ•ˆæœå¤ªå·®ï¼Œå¼•ä¸èµ·ç‰¹åˆ«å¤§çš„å…³æ³¨ï¼Œè™½ç„¶æˆ‘å†™åšå®¢ï¼Œå®Œå…¨æ˜¯ç«™åœ¨è‡ªå·±çš„è§’åº¦ï¼Œæ²¡æœ‰è€ƒè™‘è¯»è€…çš„æ„æ„¿ï¼Œï¼ˆæ»‘ç¨½.jpg)ã€‚ ç°åœ¨çš„è‡ªå·±ï¼Œä¸æ˜¯åœç•™åœ¨åŸºæœ¬çš„é—®é¢˜ä¸Šï¼Œæ›´åº”è¯¥å»æ¢ç´¢æœªçŸ¥ çš„çŸ¥è¯†ä¸–ç•Œï¼Œè™½ç„¶ç¦»è¿™ä¸ªflagå¯èƒ½è¿˜æœ‰å‡ å¹´çš„æ—¶é—´ï¼Œèƒ½å¤Ÿç»™ä¸–ç•Œçš„çŸ¥è¯†åˆ›é€ ä¸€ç‚¹ç‚¹ä»·å€¼ï¼Œå“ªæ€•åªæ˜¯ä¸€å°ç‚¹ç‚¹ã€‚ç¦»è¿™ä¸ªç›®æ ‡è¿˜éœ€è¦åŠªåŠ›å•Šï¼ï¼ï¼ï¼ï¼ æˆ‘æƒ³æˆ‘åº”è¯¥å»è®°å½•å­¦ä¹ çŸ¥è¯†çš„è¿‡ç¨‹ï¼Œçªç ´æ›´å¤§çš„æ›´å›°éš¾çš„é—®é¢˜ã€‚ 2019-ç¬¬å››å‘¨è¯»ä¹¦ç¬”è®° è¿™å‘¨è¯»äº†ä¸€æœ¬å°è¯´ï¼Œæ˜¯å¼ çˆ±ç²çš„ã€Šå€¾åŸä¹‹æ‹ã€‹ï¼ŒåŸæ¥å’Œç”µè§†å‰§çš„ä½•æ™Ÿé“­ä¸»æ¼”ã€Šå€¾åŸä¹‹æ‹ã€‹ä¸æ˜¯åŒä¸€ä¸ªäº‹æƒ…å•Šï¼ çœ‹äº†ã€Šé˜¿ç”˜æ­£ä¼ ã€‹ï¼Œâ€œç”Ÿæ´»å°±åƒä¸€ç›’å·§å…‹åŠ›ï¼Œä½ æ°¸è¿œä¸çŸ¥é“ä¸‹ä¸€é¢—æ˜¯ä»€ä¹ˆå‘³é“ã€‚â€œè¿™æ˜¯é˜¿ç”˜å¯¹ç”Ÿæ´»æœ€å¥½çš„è¯ é‡Šã€‚å°æ—¶å€™ï¼Œæœ‰äººéª‘ç€è‡ªè¡Œè½¦ç¾è¾±ä»–ï¼Œä»–åªä¼šè·‘ï¼Œæ‹¼å‘½çš„è·‘ï¼Œåªä¼šå†å…¬è·¯ä¸Šè·‘ã€‚é•¿å¤§åï¼Œåˆ«äººéª‘ç€è½¦æƒ³æ‰“ä»–ï¼Œé˜¿ç”˜è¿˜æ˜¯è·‘ï¼Œä½†æ˜¯è¿™æ¬¡é˜¿ç”˜å­¦ä¼šäº†ç½‘è‰åªä¸Šè·‘ï¼å°±è¢«å¤§å­¦çœ‹ä¸Šï¼Œè¿›å…¥è¿åŠ¨å¤§å­¦ï¼Œè¿˜é€šè¿‡å‚åŠ æ¯”èµ›èµ¢å¾—äº†å† å†›ï¼Œç„¶åï¼Œé˜¿ç”˜å½“å…µäº†ï¼Œå†åæ¥ï¼Œæ‰“ä¹’ä¹“çƒå¾ˆå‡ºè‰²ã€‚é˜¿ç”˜ä¼¼ä¹åšä»€ä¹ˆéƒ½èƒ½æˆåŠŸï¼Œä¹Ÿè®¸å¿ƒæ— æ—éª›ï¼Œæœ€ç¬¨çš„æ–¹æ³•+æ—¶é—´=æ”¶è·ã€‚ æˆ‘è§‰å¾—å¾ˆå¿ƒé…¸çš„æ˜¯ï¼Œå½“çå¦®å‘Šè¯‰ä»–æœ‰å„¿å­æ—¶å€™ï¼Œé˜¿ç”˜é—®ï¼Œâ€ä»–èªæ˜å—â€œï¼Ÿ 2019ç¬¬å››å‘¨å®‰æ’ æ”¹è®ºæ–‡ï¼Œæ”¹å˜è‡ªå·±çš„åŠäº‹æ•ˆç‡å–”ï¼Œæ‹’ç»é‡å¤å·¥ä½œ ç¼–ç¨‹èƒ½åŠ› æ…¢æ…¢çš„åšäº‹æƒ…ï¼Œå…ˆæ…¢åå¿«ï¼Œ ç”Ÿæ´»ã€å­¦ä¹ ã€äº¤å‹ã€æ–‡é‡‡2019-ç¬¬ä¸‰å‘¨è¯»ä¹¦ç¬”è®°è¿™æ¬¡è¯»äº†ã€Šæç®€æ€ç»´ï¼šé¢ è¦†ä¼ ç»Ÿæ€ç»´æ¨¡å¼çš„æç®€æ³•åˆ™ã€‹ä½œè€…ï¼šS.Jæ–¯ç§‘ç‰¹ å·´é‡Œ.è¾¾æ–‡æ³¢ç‰¹ æˆ‘ä»¬ç”Ÿæ´»å……æ»¡äº†å„ç§è¯±æƒ‘ã€æ‚ä¹±ä¿¡æ¯ã€å¯¼è‡´äº†ç”Ÿæ´»çš„æ··ä¹±ï¼Œäº§ç”ŸçŸ¥è¯†ç„¦è™‘ã€å¹´é¾„å±æœºã€äººé™…å…³ç³»çš„æ·¡åŒ–ã€‚ä½œè€…ç»™æˆ‘ä»¬ä»‹ç»äº†è®¸å¤šé—®é¢˜ã€è®¸å¤šçš„è§£å†³æ–¹æ³•ï¼Œè®©æˆ‘ä»¬è¿™ä¸ªä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£å¯ä»¥è¿‡çš„å……å®äº›ã€‚ æ¯å¤©ç¡8ä¸ªå°æ—¶ã€è¿˜å‰©ä¸‹16ä¸ªå°æ—¶ï¼Œåœ¨å‡å»2ä¸ªå°æ—¶è§£å†³ä¸ªäººå«ç”Ÿå’Œé¥®é£Ÿï¼Œé‚£ä¹ˆè¿˜æœ‰14ä¸ªå°æ—¶ï¼Œä¸€ä¸ªæ˜ŸæœŸ98ä¸ªå°æ—¶ã€‚é‚£ä¹ˆ98ä¸ªå°æ—¶ï¼Œä½ æŠ•å…¥åœ¨å“ªé‡Œå‘¢ï¼Ÿ æ€»çš„æ¥è¯´ï¼Œè¿™æœ¬ä¹¦ä¼ è¾¾çš„ä¸œè¥¿ï¼Œæˆ‘è¿˜æ˜¯å¾ˆå–œæ¬¢çš„ï¼Œæç®€ä¸»ä¹‰è€…ï¼Œå°‘ä¸å¾—ä¹Ÿå¤šä¸å¾—ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ è¯»ã€Šæ‹†æ‰æ€ç»´é‡Œçš„å¢™ã€‹æ‘˜å½• ï¼šæˆ‘ä»¬çš„ç”Ÿæ´»ä¹Ÿç”±ä¸‰ä¸ªæ”¯æ¶ç»„æˆï¼šè‡ªæˆ‘ã€å®¶åº­ä¸å›¢ä½“å’ŒèŒä¸šã€‚è¿™æ ·çš„æ”¯æ¶æ”¯æ’‘ç€æˆ‘ä»¬çš„çµé­‚ï¼Œå®ƒåœ¨è®°å½•æˆ‘ä»¬çš„ç”Ÿå‘½ã€‚æˆ‘ä»¬ä¸€ç›´éƒ½åœ¨è°ƒæ•´ç€ä¸‰ä¸ªä½ç½®çš„å¹³ç¨³ï¼Œä½¿ä¹‹æˆä¸ºæœ€ç¨³å›ºçš„è”åŠ¨ä¸‰è„šæ¶ã€‚ è¿™å¥å¤§æ¦‚æ˜¯ç»“åˆæˆ‘çš„ç»å†ï¼Œæœ€å…·æœ‰æ„Ÿæ‚Ÿçš„ã€‚å› ä¸ºä¸€æ—¦èµ°å‡ºå¤§å­¦ï¼Œè¿™ä¸‰è€…æ‰å¼€å§‹çœŸæ­£çš„ç»„æˆæˆ‘ä»¬çš„ç”Ÿæ´»ã€‚ å¤å…¸è€å¸ˆï¼Œä»èŒä¸šã€æˆåŠŸå­¦ã€çˆ±æƒ…ã€å®¶åº­ç­‰ç­‰ä¸åŒçš„æ¡ˆä¾‹ï¼Œç»™æˆ‘åˆ†æäº†å¤§å¤šæ•°äººä¼šé¢ä¸´çš„æ— å½¢çš„â€å¢™â€œï¼Œç»™äº†æˆ‘ä»¬å¦‚ä½•æ‹†æ‰è¿™äº›å¢™çš„æ–¹æ³•ã€‚ä½†æ˜¯å‘¢ï¼Œå¯¹äºå¤å…¸è€å¸ˆçš„çˆ±æƒ…è§‚ç‚¹ï¼Œæˆ‘å¹¶ä¸æ˜¯å¾ˆèµåŒï¼Œå› ä¸ºå‘¢ï¼Œé‚£äº›æ„¿æ„é™ªä½ åº¦è¿‡ä½™ç”Ÿçš„äººä»˜å‡ºçš„æ„Ÿæƒ…ï¼Œæ˜¯å¦‚æ­¤çš„å»‰ä»·å—ï¼Ÿæœ‰çš„äººæ—¢å¯ä»¥æ˜¯ç™½ç«ç‘°ï¼Œä¹Ÿå¯ä»¥çº¢ç«ç‘°å•Šï¼ 2019å¹´ç¬¬äºŒå‘¨å®‰Tæ’æ¯å¤©ä¸¤ä¸ªå°æ—¶é˜…è¯»è®ºæ–‡æˆ–è€…ä¸“ä¸šä¹¦ç±çš„é˜…è¯»å¼€é¢˜æŠ¥å‘Šä¿®æ”¹å’ŒPPTåˆ¶ä½œï¼ˆ3h)ã€Šæ‹†æ‰æ€ç»´é‡Œé¢çš„å¢™ã€‹ï¼ˆ3h)çœ‹å“ˆåˆ©æ³¢ç‰¹ï¼ˆä¸€é›†ï¼‰ â€”-2018å¹´çš„æ€»ç»“ å°å°çš„æ‚”æ¨ä¸é—æ†¾ å¤§ä¸‰ä¸‹ï¼Œåœ¨è¯¾å ‚ä¸Šï¼Œæ‰“äº†åŠå­¦æœŸçš„æ¸¸æˆ ç”Ÿæ´»è¿˜æ˜¯ä¸è§„å¾‹ï¼Œè¶…å–œæ¬¢æ·±å¤œé€›çŸ¥ä¹ã€åˆ·Bç«™ é¢å¤´ä¸Šï¼Œä¸åœçš„å†’ç€ç—˜ç—˜å•Š è‹±è¯­å•è¯é‡åœ¨ä¸‹é™ing è¿åŠ¨é‡åœ¨é™ä½å–” å¾ˆè®¨åŒæ´—è¡£æœ ç›¸æ¯”äºä¸Šä¸€å¹´è¿›æ­¥çš„æ–¹é¢ æ„¿æ„å»æ‰¿æ‹…æ›´å¤šçš„è´£ä»» æ›´ä¹æ„å»äº¤æµ è¶Šæ¥è¶Šé‡è§†å¥åº·style ä¸ä¼šéšæ„å‘æ³„è‡ªå·±çš„æƒ…ç»ªäº† æ›´åŠ è®¤è¯†åˆ°è‡ªèº«çš„ä¼˜åŠ¿ä¸åŠ£åŠ¿äº†æ„Ÿåˆ°æ„‰å¿«çš„äº‹æƒ… çŸ¥é“è‡ªå·±æƒ³è¦ä»€ä¹ˆï¼ŒçŸ¥é“è‡ªå·±åœ¨åšä»€ä¹ˆ æ•´ç†å®Œäº†å¤§å­¦æœŸé—´æ‰€æœ‰çš„ä¸œè¥¿ï¼Œå¾€äº‹ä¸å ªå›é¦–ï¼Œ ä½†ä¹Ÿåªèƒ½æ˜¯æŸ³æš—èŠ±æ˜åˆä¸€æ‘ã€‚ èƒ½è¯»ç ”ç©¶ç”Ÿäº† èŠèŠ2019å¹´çš„ç‚¹ç‚¹æœŸè®¸å­¦ä¹ ä¸Š å¤šçœ‹19åœºçŸ¥ä¹live é˜…è¯»10æœ¬ä¹¦ç±ï¼Œä¹¦å•ä¹Ÿæœ‰äº† åœ¨ä¸“ä¸šå­¦ä¹ ä¸Šï¼Œå¸Œæœ›æœ‰æ‰€æå‡å’¯ç”Ÿæ´»ä¸­ æ—©ç¡æ—©èµ·èº«ä½“å¥½ çœ‹åéƒ¨ç¾å‰§ï¼Œå°½ç®¡æˆ‘æœ€å¤§çš„å…´è¶£æ˜¯ç¡è§‰ æ—¶å¸¸æ›´æ–°æ­Œå•ï¼Œä¸æƒ³åœ¨ä¸€å¹´é‡Œé¢éƒ½æ˜¯ç›¸åŒçš„æ—‹å¾‹ é™é™é™é™é™é™é™ åˆç†å®‰æ’ æŠ˜æ˜Ÿæ˜Ÿ ç•ªèŒ„é—¹é’Ÿ å¶å°”å¬å¬ TEDæŠ€æœ¯ æ¸…ç†ä¸‹äº†github ä»“åº“ é‡æ–°æ›´æ–°äº† github page å¤šè¯»ã€å¤šå†™ã€å¤šæƒ³]]></content>
      <categories>
        <category>è¯»ä¹¦æ—¥å¸¸</category>
      </categories>
      <tags>
        <tag>è¯»ä¹¦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MayMay]]></title>
    <url>%2F2019%2F02%2F22%2FMayMay%2F</url>
    <content type="text"><![CDATA[https://www.kaggle.com/dgawlik/house-prices-eda/datahttps://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python]]></content>
      <tags>
        <tag>wan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å­¦ä¹ ã®å†ç¨‹]]></title>
    <url>%2F2019%2F02%2F22%2F%E5%AD%A6%E4%B9%A0Daily%2F</url>
    <content type="text"><![CDATA[20200822 æˆ‘ç´¯äº† è¿™ä¸ªä¸–ç•ŒçœŸçš„å¾ˆæ®‹é…·ï¼Œä½ æœ‰æœ¬äº‹ï¼Œå°±èƒ½å¾—åˆ°å°Šé‡ï¼Œå¦åˆ™å°±ä¼šè¢«æ·˜æ±°ï¼ å“ªæœ‰ä»€ä¹ˆå¥½äººï¼Œå¤©ä¸‹æ”˜æ”˜çš†ä¸ºåˆ©æ¥ï¼Œå¤©ä¸‹ç†™ç†™çš†ä¸ºåˆ©å¾€ï¼Œäººå’Œäººä¹‹é—´çš„æƒé‡ï¼Œè§‰å¾—ä½ ä»¬è”ç³»å¼ºåº¦ã€‚æ”¶é½é‚£é¢—æ‚²æ‚¯çš„å¿ƒï¼Œçº¯ç²¹çš„å¿ƒï¼Œè¿™ä¸ªåäººæœ€å¤šäº†ï¼Œå½“ä½ å˜å¾—è‡ªç§çš„ï¼Œæ¶å°±ç”±æ­¤è€Œç”Ÿäº† å…«æœˆè¦å‡†å¤‡è€ƒè¯•äº† ç°ä»£å¯†ç ç†è®ºï¼ˆæå‘æ ¹è€å¸ˆæˆè¯¾ï¼‰è€ƒè¯•æ—¶é—´ï¼š2020-08-28ï¼Œ09:30-11:30 è½¯ä»¶å®‰å…¨æ€§åˆ†æï¼ˆé™ˆå…è€å¸ˆæˆè¯¾ï¼‰è€ƒè¯•æ—¶é—´ï¼š2020-09-03ï¼Œ09:30-11:30 æ­»è®°ç¡¬èƒŒå§ï¼Œ å®åœ¨æ˜¯æ¼ç« 20200814 æ‰¾ç‚¹ä¹å­ ä»Šå¤©æ—©ä¸Šç¡è§‰ ä»Šå¤©ä¸‹åˆæ”¹äº†ä¼šç»¼è¿°ï¼Œæ€è€ƒäº†ä¼šè‡ªå·±æ‰¾ç‚¹ä»€ä¹ˆä¸œè¥¿ç©ç© æ‰¾ä¸€äº›å…¬å¼€çš„é¡¹ç›®ï¼ˆå¤ç°ä¸€ä¸‹ç»“æœï¼Œè¡¥å……ä¸€ä¼š)ï¼Œç©ç©æ•°æ®åˆ†æï¼ˆçˆ¬å–æ•°æ®-&gt;æ•°æ®åˆ†æ-&gt;æ•°æ®å»ºæ¨¡ï¼‰æ„Ÿè§‰è¿™ä¸ªè¿‡ç¨‹æ»¡å¥½ç©çš„å–” ä¸çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ç‰¹åˆ«å–œæ¬¢å¯è§†åŒ–ï¼Œä½†ç°åœ¨é‡åˆ°çš„ç“¶é¢ˆæ˜¯æ€ä¹ˆæŠŠå›¾ç”»å¥½çœ‹, å­—ä½“ï¼Œå­—å·ï¼Œé¢œè‰²çš„é…ç½®)ï¼Œå‡†å¤‡å¥½å¥½ç©ç©è¿™ä¸ªï¼Œexcel, echart, Pythonå„ç§åº“ï¼ŒRï¼Œ BI(tableau)éƒ½å»æ°´ä¸€æŠŠå•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦ 20200812 å¸Œæœ›ä½ çœ¼ç›é‡Œæ˜¯æ¸©æŸ”ï¼Œéª¨å­é‡Œæ˜¯åšæŒï¼ŒåŠªåŠ›æˆä¸ºæ‰€çˆ±ä¹‹äººéœ€è¦çš„å°å¤ªé˜³ï¼ æˆ‘æ²¡æœ‰åœ¨ä½ æœ€è‰°éš¾çš„æ—¶å€™é™ªä¼´ä½ ï¼Œæ€ä¹ˆèƒ½åœ¨ä½ å¾—æ„çš„æ—¶å€™å‡ºç°å‘¢ï¼Ÿ ä»Šå¤©ä¸‹åˆæ—¶é—´åºåˆ— ä»Šå¤©æ™šä¸Š 20200811 å¥½æƒ³åƒå†°æ·‡æ·‹å•Šï¼Œå†°æ·‡æ·‹ï¼Œå†°æ·‡æ·‹ï¼Œå†°æ·‡æ·‹ï¼Œå†°æ·‡æ·‹ ã€æ¯æ—¥ä¸€é—®ã€‘çº¿æ€§å›å½’å’Œé€»è¾‘æ–¯ç‰¹å›å½’çš„å¼‚åŒï¼Ÿé€»è¾‘æ–¯ç‰¹ä¸ºä»€ä¹ˆsigmodå‡½æ•°ï¼Ÿ ã€ä½ çœ‹äº†å‡ ä¸ªä¸“ä¸šè§†é¢‘ï¼Ÿçœ‹äº†å‡ æœ¬ä¸“ä¸šä¹¦ç±ï¼Ÿåšä¸ªå‡ ä¸ªä¸“ä¸šå†…çš„å¼€æºé¡¹ç›®ï¼Ÿä¸“ä¸šå·¥å…·éƒ½ä¼šäº†å—ï¼Ÿä½ åŠ ä¸ªå‡ ä¸ªäº¤æµç¾¤ï¼Ÿä½ è®¤è¯†å‡ ä¸ªé¢†åŸŸä¼™ä¼´ï¼Ÿåˆ·äº†å¤šå°‘é¢è¯•é¢˜ï¼Ÿã€‘çœ‹çœ‹è‡ªå·±ï¼Œèƒ½ä¸æ˜¯åºŸäººå—? è¾“å…¥æ‰æœ‰è¾“å‡ºå•Šï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼è¿™ä¸ªè·¨ç•Œåä¸‡å…«åƒé‡Œå•Šï¼ï¼ï¼ 20200809 å‡†å¤‡è°ƒæ•´ç”Ÿç†é’Ÿ åŒ å¿ƒç²¾ç¥ã€‚æœ€è¿‘è¿·ä¸Šäº†å¤®è§†boysï¼Œå››ä¸ªä¸ªæ€§è¿¥å¼‚çš„boys, æœ€å–œæ¬¢åº·åº·çš„å£°éŸ³äº†ï¼Œå¤ªæœ‰ç£æ€§äº†ï¼æˆ‘æœ€å–œæ¬¢å°æ’’è€å¸ˆäº†ï¼Œèº«ä¸Šé‚£ç§è°ƒçš®å§ã€‚ ä»–ä»¬çœ‹èµ·æ¥éå¸¸å…‰é²œäº®ä¸½ï¼Œå‡ºå£æˆç« ï¼Œæ¸©æ–‡å„’é›…ã€‚å…¶å®ï¼Œæ¯ä¸€æ¬¡ä¸»æŒï¼Œæ¯ä¸€æ¬¡å¼€å£ï¼Œéƒ½æ˜¯æ—¶é—´çš„ç§¯æ·€ï¼Œç²¾å¿ƒçš„å‡†å¤‡ã€‚ å¸Œæœ›æœªæ¥ï¼Œé¢å¯¹èŒä¸šï¼Œé¢å¯¹è€æ¿çš„æ—¶å€™ï¼Œéƒ½èƒ½æŠŠæ¯ä¸€ä¸ªç»†èŠ‚åšåˆ°æè‡´ã€‚ è·¨ç•Œç²¾è‹±ã€‚æˆ‘å‘ç°æˆ‘äº¤å‰çš„ä¸œè¥¿è¿˜è›®å¤šçš„ï¼Œå„ä¸ªå­æ¨¡å—åªèƒ½æ˜¯åŠæ ¼çš„åˆ†æ•°ã€‚ä¸è¿‡ï¼Œå¹²æˆ‘è¿™è¡Œï¼Œèƒ½å¤Ÿäº¤å‰çš„ä¸œè¥¿ä¹Ÿå°±é‚£äº›ï¼Œæ¥ä¸‹æ¥ï¼Œè¦ä¸è¿™äº›ä¸œè¥¿å­¦çš„ç¨‹åº¦éƒ½è¾¾åˆ°80åˆ†ã€‚ ä»Šå¤©çœ‹ä¹¦å»äº†ã€‚å¦‚ä½•æ‰èƒ½å†ä¸€ä¸ªåœˆå­é‡Œå˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼šèªæ˜å’Œä¸»åŠ¨ï¼Œç¼ºä¸€ä¸å¯ã€‚ä»¥å‰ï¼Œæ€»è§‰å¾—åšå¥½è‡ªå·±å°±å¤Ÿäº†ï¼Œç®¡ç†å¥½è‡ªå·±ï¼Œä¸ç»™åˆ«äººå¢åŠ éº»çƒ¦å°±å¥½äº†ã€‚æ¸æ¸çš„ï¼Œå‘è§‰åœˆå­å¾ˆé‡è¦ï¼Œäººä¸äººä¹‹é—´çœŸçš„é çš„æ˜¯å…±æ€§å’Œå¸å¼•ã€‚ç¦»ä½ æœ€è¿‘çš„äººï¼Œå¾€å¾€ä½ å°±æ˜¯å¹³å‡æ°´å¹³ï¼ˆå¤§å­¦è®¤è¯†çš„äººä¹Ÿæ˜¯å¦‚æ­¤ï¼‰ï¼Œå¾—å¾—ç¡®ç¡®æ˜¯å¦‚æ­¤ï¼Œé…å¾—ä¸Šï¼Œç©å¾—èµ·ã€‚å¦‚æœè§‰å¾—ä¸è¡Œï¼Œè¿˜å¯ä»¥è·³åœˆå˜›ã€‚ è·³åˆ°è‡ªå·±å¯ä»¥å‘æŒ¥ä»·å€¼ï¼Œè‡ªå·±æ„Ÿå…´è¶£ï¼Œä¸è¢«ç¤¾ä¼šæ·˜æ±°çš„åœˆå­é‡Œï¼Œæˆé•¿çš„è¿‡ç¨‹å¤§æ¦‚å°±æ˜¯æŒ–æ˜åˆ°äº†è‡ªå·±çš„å…´è¶£ï¼Œå¤©èµ‹æ‰€åœ¨ä¹‹å¤„ã€‚ é‚£äº›æŠ±æ€¨è¢«ç”Ÿæ´»æ¯’æ‰“çš„äººï¼Œæƒ³æƒ³è§‰å¾—å¯æ€œï¼Œåä¸æ­£ï¼Œåˆ™è¨€ä¸é¡ºï¼›è¨€ä¸é¡ºï¼Œåˆ™äº‹ä¸æˆã€‚äººä¸è¦å­˜æœ‰éåˆ†ä¹‹æƒ³ï¼Œå½“ä½ é…ä¸ä¸Šï¼Œç”šè‡³å¾—ä¸åˆ°çš„æ—¶å€™ã€‚ç¤¾ä¼šå°±æ˜¯è¿™ä¹ˆè¿è½¬çš„ï¼Œåªæœ‰é¡ºåŠ¿è¡Œèµ°ï¼Œé¡ºåº”è§„åˆ™ï¼Œå¹¶å®ç°ä»·å€¼å’Œåˆ©ç›Šæœ€å¤§åŒ–ã€‚ æ™šä¸Šé™ªå®¶äººåƒçƒ§çƒ¤ã€‚èƒ½å¤Ÿå¹¸å¹¸ç¦ç¦çš„å’Œå®¶äººåƒé¥­ï¼Œæ˜¯æœ€å¼€å¿ƒçš„æ—¶å€™ã€‚æˆ‘ä¹°å•ï¼Œä»–ä»¬è´Ÿè´£åƒï¼Œè¿™æ˜¯æˆ‘è¿™è¾ˆå­å¥‹æ–—çš„ç›®æ ‡ä¹‹ä¸€ã€‚å¸Œæœ›æ—©æ—¥åœ¨æˆéƒ½èƒ½å¤Ÿæœ‰ä¸€å¸­ä¹‹åœ°ï¼Œæœ‰ä¸ªé®é£æŒ¡é›¨çš„åœ°æ–¹ã€‚åŠ æ²¹ï¼ŒåŠ æ²¹ï¼ŒåŠ æ²¹ã€‚ æˆ‘ä¸ºä»€ä¹ˆåœ¨æ„åˆ«äººçš„çœ‹æ³•ã€‚ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæˆ‘åƒä»€ä¹ˆï¼Œåšä»€ä¹ˆï¼Œç©¿ä»€ä¹ˆéƒ½æ„Ÿè§‰è¦é­åˆ°åˆ«äººçš„è¯„ä»·ã€‚æˆ‘æœ€è®¨åŒåˆ«äººå¯¹æˆ‘æŒ‡æ‰‹ç”»è„šäº†ã€‚å§‘å¨˜ï¼Œä»€ä¹ˆæ—¶å€™ï¼Œæˆ‘ä¸åœ¨åœ¨ä¹åˆ«äººçš„çœ¼å…‰äº†ã€‚è¶Šæ˜¯è¿™æ ·ï¼Œæˆ‘è¶Šåœ¨æ„ã€‚æˆ‘å°±åœ¨æ„åˆ«äººå‡­ä»€ä¹ˆè¦å…³æ³¨æˆ‘åšä»€ä¹ˆï¼Œæˆ‘è·Ÿæˆ‘ä»€ä¹ˆå…³ç³»å•Šï¼ä¿æ•æ´ªæ›¾ç»è¯´è¿‡ï¼šæˆ‘å†…å¿ƒç°åœ¨æ‹¥æœ‰ä»€ä¹ˆæ ·çš„ææƒ§ï¼Œæˆ‘å†…å¿ƒç°åœ¨æ‹¥æœ‰ä»€ä¹ˆæ ·çš„å®³æ€•ï¼Œæˆ‘æ˜¯ä¸æ˜¯å¤ªåœ¨æ„åˆ«äººçš„çœ¼å…‰ï¼Œå› ä¸ºè¿™äº›ä¸œè¥¿ï¼Œæˆ‘çš„ç”Ÿå‘½è´¨é‡æ˜¯ä¸æ˜¯å—åˆ°å½±å“ï¼Œå› ä¸ºè¿™äº›ä¸œè¥¿ï¼Œæˆ‘ä¸æ•¢è¿ˆå‡ºæˆ‘ç”Ÿå‘½çš„ç¬¬ä¸€æ­¥ï¼Œä»¥è‡³äºæˆ‘ç”Ÿå‘½ä¹‹è·¯å†ä¹Ÿèµ°ä¸è¿œã€‚å¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œè¯·åŒå­¦ä»¬å‹‡æ•¢åœ°å¯¹ä½ ä»¬çš„ææƒ§å’Œå‹‡æ•¢åœ°å¯¹åˆ«äººçš„çœ¼ç¥ï¼Œè¯´ä¸€å£°Noï¼Because I am myselfã€‚ 20200808 ç»§ç»­é¢„ä¹  ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œå·®ä¸å¤šæ˜¯æ—¶å€™è°ƒç†ä¸€ä¸‹ç”Ÿç‰©é’Ÿäº†ã€‚è¿˜æ˜¯è¦æ—©ç¡æ—©èµ·å‘€ã€‚æœ€è¿‘æ™šä¸Šè€æ˜¯å–œæ¬¢åˆ·è§†é¢‘ï¼Œè¶Šé€›è¶Šå¼€å¿ƒã€‚å°¤å…¶æ˜¯vlogã€‚æˆ‘è§‰å¾—æˆ‘ä»€ä¹ˆæ—¶å€™å¼€ä¸ªè´¦å·ï¼Œåšç‚¹ä»€ä¹ˆç”Ÿæ´»å°è§†é¢‘ï¼Œå°æ•™ç¨‹ä»€ä¹ˆçš„ã€‚ç­‰æˆ‘å­¦æœ‰æˆå°±çš„æ—¶å€™ï¼Œæˆ‘å‡ºç‚¹å¥½ç©çš„å°è§†é¢‘ã€‚ ä»Šå¤©ä¸‹åˆå¤ä¹ äº†numpyï¼Œæˆ‘è§‰å¾—å…ˆç”¨ï¼ˆåˆæ­¥å®è·µåï¼‰å†å»å†™å…¨é¢çš„åŸºç¡€æ•™ç¨‹ï¼Œè¿™æ ·å­çš„æ•ˆæœå¥½å¾ˆå¤šï¼ˆç°åœ¨åŸºæœ¬ä¸ŠæŒæ¡numpyäº†ï¼ŒåŒ…æ‹¬ç»†èŠ‚ï¼Œå—¯å—¯)ã€‚è¿˜å¤ä¹ äº†è½¯ä»¶å®‰å…¨æ€§åˆ†æã€‚ ç¼ºé™·(è®¾è®¡å’Œä»£ç ) å’Œæ¼æ´çš„åŒºåˆ«å’Œè”ç³» ç¬¬ä¸‰ç« ï¼ˆæµè§ˆå™¨æ”»å‡») ä»Šå¤©æ™šä¸Šçœ‹äº†bilibili (æˆ‘çš„é’æ˜¥æ‹çˆ±ç‰©è¯­æœç„¶æœ‰é—®é¢˜) å…³äºæ—¶é—´å¤„ç†numpy, pandas è¦å•ç‹¬å­¦ä¹ ä¸€ä¸‹ï¼Œè¿™ä¸ªå­¦å¥½äº†ï¼Œå¤„ç†æ•°æ®å°±å¥½å¹²äº† 20200807 ä»Šå¤©æ—©ä¸Šç¡è§‰ ä»Šå¤©ä¸‹åˆï¼Œå®¶é‡Œç½‘å¤ªå·®äº†ã€‚å¤ä¹ å¯†ç å­¦æ•°å­—ç­¾åå’Œæ•´æ•°æº¢å‡ºã€‚ ä»Šå¤©æ™šä¸Šï¼Œå­¦ä¹ æ–°çŸ¥è¯†â€”â€”æ•°æ®æŒ–æ˜+è¯»æ–‡ç« ï¼ˆç¤¾ç§‘ç±»æ–‡ç« ï¼Œè¶Šå¾€å†…æ·±å…¥è¶Šæœ‰æ„æ€ï¼Œçªç„¶è§‰å¾—äººç”Ÿç™¾æ€å’¯) æƒ³æ³•ï¼š å®ç°ä¸€ä¸ªpythonç»˜å›¾æ¨¡æ¿ï¼Œä¸»è¦æ˜¯æƒ³æ”¹pythonæä¾›çš„é»˜è®¤å‚æ•°ï¼Œå› ä¸ºå®˜æ–¹æä¾›çš„ç»˜å›¾æ–¹å¼ï¼Œä¸å’‹æ»´å¥½çœ‹ã€‚ 20200806 ä»Šå¤©å¤ä¹ è€ƒè¯•äº†ï¼ 20200801-20200806 ç”µè„‘ç»´ä¿® å…³ç”µè„‘çš„æ—¶å€™ï¼Œå±…ç„¶å‘ç”Ÿäº†æ„å¤–ï¼Œç¿»ç›–é”™ä½ï¼Œç„¶åæˆ‘çŒ›åŠ›ä¸€ç›–ï¼Œç”µè„‘åäº†ã€‚åªèƒ½å¿«é€’å»ä¸“å–åº—ç»´ä¿®ã€‚å°±æ˜¯ç¿»ç›–é‚£é‡Œæœ‰ç‰¹è‰²ï¼Œç„¶è€Œå´æ˜¯æœ€å®¹æ˜“åæ‰çš„ã€‚è¿™ä¹Ÿç»™æˆ‘ä¸€ä¸ªæ•™è®­ï¼šé‡è¦çš„æ–‡ä»¶æ—¶å¸¸è¦å¤‡ä»½ã€‚ä¸çŸ¥é“ä»€ä¹ˆæ—¶å€™å°±è¦å‘ç”Ÿæ„å¤–ï¼Œé˜²æ‚£äºæœªç„¶ã€‚ æˆ‘æœ€è¿‘é€›äº†ä¸å°‘çŸ¥ä¹ã€å¾®ä¿¡å…¬ä¼—å·å’ŒCSDNï¼Œæˆ‘æ­¤æ—¶å‘ç°æˆ‘åˆ°åº•æƒ³åšä»€ä¹ˆã€‚ç¬¬ä¸€ï¼Œæˆ‘å¸Œæœ›æœ‰ä¸€ä¸ªè‡ªå·±çš„å…¬ä¼—å¹³å°ï¼Œä¹Ÿå°±æ˜¯åˆ†äº«è‡ªå·±æ‰€å­¦çš„çŸ¥è¯†ç¬”è®°ï¼ŒåŒæ—¶æˆ‘å¸Œæœ›æ˜¯ç³»ç»Ÿçš„ã€é«˜å¯†åº¦å’Œé«˜å«é‡‘é‡çš„å¼€æ”¾è´¦å·ã€‚github â€” githubpage â€”CSDN â€” çŸ¥ä¹ä¸“æ  â€”å¾®ä¿¡å…¬ä¼—å·æµæ°´çº¿ã€‚ ç¬¬äºŒï¼Œå­¦ä¹ è½¯æŠ€èƒ½ã€‚è¿™æ–¹é¢ä¸»è¦æ˜¯æ¥è‡ªä¹¦ç±ï¼Œæˆ‘è‡ªå·±ä¹è¶£è¯»ä¸€äº›å…³äºç®¡ç†å­¦ã€ç»æµå­¦ã€å†å²ã€ç§‘æ™®æ–¹é¢çš„å¥½ç©çš„æœ‰è¶£çš„ä¸œè¥¿ã€‚å¸Œæœ›æ¯æœˆè´­ä¹°ä¸€æœ¬ä¹¦ç±ï¼ŒåšæŒé˜…è¯»ã€‚è¿™ä¸ªæœˆè¯»ã€Šä¸‡å†åäº”å¹´ã€‹ã€‚ç¬¬ä¸‰ï¼Œæˆ‘æƒ³å­¦å½©é“…å’Œæ¼«ç”»ã€‚ä¸å¾—ä¸æ‰¿è®¤æˆ‘åœ¨è¿™æ–¹é¢æ¯«æ— å¤©èµ‹ï¼Œåªæ˜¯çº¯ç²¹çš„æ¬£èµå’Œç¾¡æ…•è‰ºæœ¯ä½œå“ã€‚ä½†æ˜¯è¿˜æ˜¯æƒ³å­¦ä¹ å•Šï¼ å…«æœˆä»½å¤§äº‹ä»¶ï¼š 1. å…«æœˆäºŒåå¼€å­¦ 2. å¯†ç å­¦ 3. è½¯ä»¶å®‰å…¨æ€§åˆ†æï¼ˆè¯¾ç¨‹è®¾è®¡ï¼‰ 4. å…­çº§è€ƒè¯• ä¸€åˆ‡å¦‚æœŸè¿›è¡Œ 8ï¼š00- 11ï¼š00 14ï¼š00-17ï¼š00 19ï¼š00-22ï¼š00 å¥½å›°å•Šï¼Œç¡è§‰ï¼Œç¡è§‰ï¼Œç¡è§‰ğŸ˜´ğŸ˜´ğŸ˜´ğŸ˜´ 20200731 ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œçœ‹è§†é¢‘ã€‚ ä»Šå¤©ä¸‹åˆå»å¸‚é‡Œï¼Œåƒäº†å°é¾™è™¾ï¼Œä¹°äº†ä¸€å¤§å †åƒé£Ÿ ä»Šå¤©æ™šä¸Šçœ‹å‰§ 20200730 è¶³å¤Ÿçƒ­çˆ±ï¼Œè¶³å¤ŸåšæŒ ä»Šå¤©æ—©ä¸Šï¼Œç»§ç»­ç¡è§‰ï¼Œæ˜¨å¤©æ™šä¸Šç¡å¾—å¤ªæ™šäº† ä»Šå¤©ä¸‹åˆï¼Œç»§ç»­å®ç°æ—¶é—´åºåˆ—é¡¹ç›®ï¼å®æˆ˜æœºå™¨å­¦ä¹  ä»Šå¤©æ™šä¸Šï¼Œçœ‹äº†æ¨èçš„nature paperï¼ŒåŸåˆ›å¤ªå‰å®³äº†ã€‚ç»§ç»­è¿½çºªæ™“å²šå’Œå’Œç…ã€‚ 20200729 é¢æœå¤§æµ·ï¼Œæ˜¥æš–èŠ±å¼€ ä»Šå¤©æ—©ä¸Šï¼Œçœ‹äº†ã€ŠäºŒåä¸æƒ‘ã€‹ã€‚æ¯ä¸ªäººä¼¼ä¹éƒ½æ˜¯å¤šå¹´åª³å¦‡ç†¬æˆå©†ã€‚å®ä¹ å¤ªä¸å®¹æ˜“äº†ï¼ ä»Šå¤©ä¸‹åˆï¼Œæ—¶é—´åºåˆ—åˆ†æã€‚ ä»Šå¤©æ™šä¸Šï¼Œå­¦ä¹ æ•°æ®æŒ–æ˜+python ç»ˆæœ‰ä¸€å¤©ï¼Œè‡ªå·±ä¹Ÿè¦å˜å¾—å¾ˆæˆç†Ÿä¸€äº›ï¼Œç©¿ä¸Šåˆ«æ‰­çš„åˆ¶æœï¼Œç”»ä¸Šåˆ«æ‰­çš„å¦†å®¹ï¼Œæˆä¸ºä¸€ä¸ªæ‰€è°“çš„æ°”åœºå¼ºå¤§çš„äººï¼Œè™½ç„¶æˆ‘æå…¶ä¸æ„¿æ„ã€‚æˆ‘ä¸å–œæ¬¢åŒ…ï¼Œä¸å–œæ¬¢æ¼‚äº®çš„è¡£æœï¼Œä¸å–œæ¬¢è°ˆæ—¶å°šï¼Œæˆ‘åªå…³å¿ƒå°æ—¥å­è¿‡çš„æ˜¯å¦å®‰é€¸ï¼Œå…³å¿ƒèº«ä½“æ˜¯å¦å¥åº·ï¼Œå…³å¿ƒå·¥ä½œæ˜¯å¦å‡ºè‰²ã€‚ åªæœ‰åŠªåŠ›æ‰èƒ½é…çš„ä¸Šè‡ªå·±çš„é‡å¿ƒã€‚ å½“ç»™ä¸–ç•Œå…³ä¸Šä¸€é“çª—çš„æ—¶å€™ï¼Œå¤–é¢çš„é£æ™¯è·Ÿæˆ‘ä¹Ÿæ²¡ä»€ä¹ˆå…³ç³»ã€‚ 20200728 æŒ–æ˜å†…å¿ƒéœ€è¦çš„ä¸œè¥¿ ä»Šå¤©æ—©ä¸Šï¼Œé€›äº†çŸ¥ä¹ ä»Šå¤©ä¸‹åˆï¼Œè·‘æ—¶é—´åºåˆ—ã€‚ ä»Šå¤©æ™šä¸Šï¼Œçœ‹pythonï¼Œè§„åˆ’è‡ªå·±çš„èŒä¸šè§„åˆ’ã€‚ï¼ˆèƒ½ä¸èƒ½åƒä¸ªæˆå¹´äººå•Šï¼‰ ç¦» æ•°æ®åˆ†æ + æœºå™¨å­¦ä¹  çš„ç›®æ ‡è¶Šæ¥è¶Šè¿‘ï¼ˆå·®ä¸å¤šæ˜¯æ—¶å€™å¯ä»¥å‡ºå»å®ä¹ äº†ï¼‰ ç¼–ç¨‹ã€‚pythonå„ç±»åº“ã€‚ åŠå…¬è½¯ä»¶ã€‚ æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ å¥½å¥½å·¥ä½œï¼Œå¥èº«ï¼Œçœ‹å‰§ï¼Œæ—…è¡Œï¼Œç‹¬å±…ï¼Œç¾é£Ÿï¼Œè¿½å‰§ï¼Œçœ‹ä¹¦ã€‚æˆ‘éå¸¸æ¸´æœ›çš„ç”Ÿæ´»æ—¥å¸¸ã€‚æˆ‘ä¸å–œæ¬¢å·¥ä½œå‹åŠ›å¤ªçš„ç¯å¢ƒï¼Œå–œæ¬¢ç¨å¾®è½»æ¾ç‚¹çš„ç¯å¢ƒã€‚ å¯¹ä¸èµ·å•Šï¼Œå¯¹ä¸èµ·å•Šï¼Œå¯¹ä¸èµ·å•Šã€‚ 20200727 æ”¾ä¸‹è®¸å¤šä¸ç¡®å®šå› ç´ ä»¥åï¼Œå°±ä¼šè½»æ¾å¾ˆå¤šã€‚ ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œåˆ·è§†é¢‘ aaaaaaaa ä»Šå¤©ä¸‹åˆï¼Œç»§ç»­ç å­—ã€‚ ä»Šå¤©æ™šä¸Šï¼Œsklearnå¤ªå¥½ç©äº†å‘€ï¼ é—®é¢˜å°±åœ¨äºä½ æƒ³å¤ªå¤šï¼Œè€Œè¯»çš„ä¹¦å¤ªå°‘äº†ï¼ï¼ï¼ï¼ï¼é˜…è¯»çš„ç¡®ç»™äººå¾ˆå¤šå¯å‘ï¼Œå°¤å…¶æ˜¯äººç‰©ä¼ è®°ç±»ã€‚ å¸®åˆ«äººå¡«ä¸ªå¿—æ„¿ï¼Œè¿˜å¾—åˆ°ä¸€ä¸ªç“œç“œç“œï¼ åœ¨è¿™ä¹ˆè¿½å‰§ä¸‹å»ï¼Œçˆ±å¥‡è‰ºéƒ½è¦çœ‹å®Œäº†å•Šï¼ 2020-7-26 çŠ¹è±«çš„è‡ªå·±ï¼ŒèŒåœºç”Ÿæ¶¯ï¼ ä»Šå¤©æ—©ä¸Šç¡è§‰ ä»Šå¤©ä¸‹åˆæ•°æ®åˆ†æ ä»Šå¤©æ™šä¸Šæ—¶é—´åºåˆ—ã€‚è·‘ç¨‹åº çƒ­æ­»äººäº†ï¼å¡ç¿å¤±é©¬ç„‰çŸ¥éç¦ï¼ä¸è¿‡ç›¸å¯¹äºæŠŠæ¯•ä¸šè®¾è®¡æå‰åšå¥½äº†ã€‚ä¹Ÿä¸æ˜¯ä»€ä¹ˆæŸå¤±ã€‚å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦å•¦ï¼ é…¸æ­»äº†ã€‚æˆ‘ç°åœ¨çŸ¥é“äº†ã€‚å¼€å­¦å¥½å¥½æ²Ÿé€šä¸€ä¸‹ï¼Œæˆ‘çš„æƒ³æ³•å§ï¼ 2020-7-25 ä»Šå¤©æ—©ä¸Šå»å¤–å©†å®¶åƒé¥­ã€‚å¥½åƒå‘¢ ä»Šå¤©ä¸‹åˆçœ‹äº†ä¸€ä¸‹å»ºæ¨¡ã€‚å»ºæ¨¡æœç„¶å¾ˆå‰å®³å•Šï¼çœ‹äº†çºªæ™“å²šå’Œå’Œç…(å¤ªå¥½çœ‹äº†) ä»Šå¤©æ™šä¸Šçœ‹å›é¡¾äº†æ•°æ®åˆ†æ 2020-7-24 ä»Šå¤©æ—©ä¸Šå­¦ç»˜å›¾ã€‚ ä»Šå¤©ä¸‹åˆè·‘æ—¶é—´åºåˆ— ä»Šå¤©æ™šä¸Šæ€»ç»“ç»˜å›¾æ¨¡æ¿ï¼ˆseaborn ,matplotlibï¼‰çœ‹å‰§ å¼Ÿå¼Ÿå¤ªå‰å®³äº†ï¼Œæ–‡è¯¾è€ƒçš„å¤ªå¥½äº† 2020-7-23 çœŸæ­£çš„è‹±é›„ä¸»ä¹‰è€…æ˜¯çœ‹æ¸…ç”Ÿæ´»çš„çœŸç›¸ï¼Œä¾ç„¶çƒ­çˆ±ç”Ÿæ´»ã€‚ ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œçœ‹å‰§ã€‚èˆ’æœ ä»Šå¤©ä¸‹åˆæ—¶é—´åºåˆ— ä»Šå¤©æ™šä¸Šå†™åˆ†ææŠ¥å‘Šã€‚ 2020-7-22 å¯¹ä¸èµ·ï¼Œæˆ‘ä¸æƒ³åœ¨åšå­©å­äº† ä»Šå¤©æ—©ä¸Šç»ˆäºæŠŠé‡åŒ–ç»“æœå¼„å¥½äº†ï¼ŒåŸºæœ¬ä¸Šå¯ä»¥è¯´æ˜å¾ˆå¤šé—®é¢˜ã€‚ç»“æœä¹Ÿä¸é”™ã€‚ã€‚ã€‚ã€‚è‡³å°‘æ˜¯å¥‘åˆç°å®çš„ ä»Šå¤©ä¸‹åˆå†™åˆ†ææŠ¥å‘Šï¼Œè¯ç©·ã€‚ ä»Šå¤©æ™šä¸Šæ—¶é—´åºåˆ— ä»Šå¤©å¤–å©†åˆ°æˆ‘å®¶é‡Œï¼Œè«åçš„æ‚²ä¼¤äº†ï¼Œæƒ³æƒ³ï¼Œæˆ‘èƒ½åœ¨å’Œå¤–å…¬å’Œå¤–å©†è§é¢çš„æ¬¡æ•°å’Œç›¸å¤„æ—¶é—´ä¸å¤šäº†ã€‚ 2020-7-21 ä»Šå¤©æ—©ä¸Šæ”¹ä»£ç  ä»Šå¤©ä¸‹åˆå­¦ä¹ 3ç»˜å›¾seaborn,ä¸å¥½ç”¨å•Šï¼Œå­—ä½“å’Œå­—å·çš„è®¾ç½®ï¼Œä¸å¯¹å¤´ã€‚originå¯èƒ½ä»¥åä¸èƒ½ç”¨äº†ï¼Œmatplotlib searborn æ‰æ˜¯ç‹é“ã€‚ç»˜å›¾è‰²å½©æ­é…å¾ˆé‡è¦ ä»Šå¤©æ™šä¸Šå­¦ä¹ äº†æ•°æ®åˆ†æã€‚æˆ‘å‘ç°æˆ‘å¤ªå–œæ¬¢æ•°æ®åˆ†æäº†ï¼Œä»¥åè¦ä»äº‹è¿™è¡Œäº†ã€‚ 2020-7-20 ä»Šå¤©æ—©ä¸Šç¡è§‰ ä»Šå¤©ä¸‹åˆæµ‹è¯•æ•°æ®ï¼ˆæ„Ÿè§‰åº”è¯¥æ²¡ä»€ä¹ˆé—®é¢˜äº†ï¼‰ ä»Šå¤©æ™šä¸Šè·‘äº†xgboost 2020 30å‘¨ æœ€è¿‘åå¤©ï¼ŒæŠŠå…«æœˆä»½è¦å¹²çš„äº‹æƒ…å¹²å®Œï¼Œå…«æœˆä»½è¦å‡†å¤‡å…­çº§å’ŒæœŸæœ«è€ƒè¯•äº†ï¼ŒæŠ¥å‘Šå’Œæµ‹è¯•ï¼Œæˆ‘çš„ä¸ªå¤©ï¼Œå¿ƒå¡å•Šï¼Œæˆ‘é€‰äº†ä»€ä¹ˆè¯¾å•Šï¼å…¨å¿ƒå…¨æ„å‡†å¤‡è€ƒè¯•ã€‚ Input âœ”ï¸âŒ Output âŒâŒâœ”ï¸ å…³é”®æœ€è¿‘è€æ˜¯æƒ³ç¡è§‰ã€‚ è®ºæ–‡ä¸å†æ˜¯æˆ‘çš„ä¸»æ—‹å¾‹ã€‚å°é—®é¢˜æ²¡ä»€ä¹ˆæ„æ€ï¼Œå¤§é—®é¢˜åšä¸å‡ºæ¥ã€‚å°±æ˜¯å¹²ä»€ä¹ˆæ–¹å‘ä¸æ˜¯é—®é¢˜ã€‚å“ªæ€•åˆ«äººå‘äº†nature ,science æˆ‘æ ¹æœ¬æ— åŠ¨äºè¡·ã€‚ Input time series æ•°æ®åˆ†ææŠ€èƒ½ Output æ¯ä¸¤å¤©äº¤æ¥ä¸€ä¸‹ å¢é‡å’Œå·®å€¼å­¦ä¹ ä¸€ä¸‹ å­¦ä¹ äººé™…äº¤å¾€çš„æœ¬è´¨ 2020-7-19 ä½ å¦‚ä»Šçš„æ°”è´¨é‡Œï¼Œè—ç€ä½ èµ°è¿‡çš„è·¯ï¼Œè¯»è¿‡çš„ä¹¦ï¼Œå’Œçˆ±è¿‡çš„äººã€‚ ä»Šå¤©æ—©ä¸Šç¡è§‰ ä¸‹åˆè·‘æ—¶é—´åºåˆ— æ™šä¸Šå¤„ç†æ•°æ®ï¼ˆä¸æ˜¾è‘—å•Šï¼‰å…³é”®èšç±»æ ‡å‡†ç¨³å¥è¯¯å·®ï¼ŒåŠ äº†ä¹‹åã€‚æ•°æ®æœ¬èº«ä¹Ÿä¸è¡Œã€‚ç®—äº†ï¼Œç®—äº† æ— äº‰æ— å¿§ï¼ 2020-7-18 ä½ å¦‚ä»Šçš„æ°”è´¨é‡Œï¼Œè—ç€ä½ èµ°è¿‡çš„è·¯ï¼Œè¯»è¿‡çš„ä¹¦ï¼Œå’Œçˆ±è¿‡çš„äººã€‚ ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œç…®é¥­ã€‚ ä»Šå¤©ä¸‹åˆæ—¶é—´åºåˆ—&amp;å¤„ç†æ•°æ® ä»Šå¤©æ™šä¸Šçœ‹ã€Šè°è¯´æˆ‘ç»“ä¸äº†å©šã€‹ ã€Šé¢æœå¤§æµ·ï¼Œæ˜¥æš–èŠ±å¼€ã€‹åšä¸ªå¹¸ç¦çš„äººã€ç§èœã€åŠˆæŸ´ï¼Œå‘¨æ¸¸ä¸–ç•Œï¼ 2020-7-17 ä»Šå¤©æ—©ä¸Šï¼Œç¡è§‰ ä»Šå¤©ä¸‹åˆï¼Œè°ƒç ”äº†å¾ˆå¤šä¸œè¥¿ã€‚è·‘äº†æ—¶é—´åºåˆ—ï¼Œäº¤æ¥äº†å·¥ä½œï¼Œä¸‹é¢éƒ½å¥½å¹²äº† ä»Šå¤©æ™šä¸Šï¼Œæ¸…æ´—æ•°æ®ã€‚æ„Ÿè§‰åº”è¯¥å¿«äº† 2020-7-16 å¤§å¤´å„¿å­å’Œå°å¤´çˆ¸çˆ¸ï¼› ç»ˆæœ‰ä¸€å¤©å›å¤´çœ‹ä»Šå¤©ï¼Œæˆ‘æ‰å‘ç°æˆ‘ç ”ä¸€2019.11-2020.07è¿™å‡ ä¸ªæœˆï¼Œè¯»è®ºæ–‡ï¼Œå…¥é—¨æŸä¸ªä¸“é¢˜çš„ç ”ç©¶ï¼Œæ‰å‘ç°è½¬äº†å¥½å¤§ä¸€ä¸ªå¼¯é“äº†ã€‚æƒ³èµ·æœ‰ä¸ªäººçš„ç§‘ç ”ç»å†ï¼Œå½“ä½ åšå£«æ¯•ä¸šçš„æ—¶å€™å›å¤´çœ‹ï¼Œæ˜æ˜å‡ ä¸ªæœˆï¼Œç”šè‡³æ›´çŸ­å°±å¯ä»¥åšå®Œï¼Œç»“æœèŠ±äº†å¾ˆé•¿å¾ˆé•¿çš„æ—¶é—´ã€‚è¿™å°±æ˜¯ç§¯ç´¯ç»éªŒçš„è¿‡ç¨‹ã€‚ä»ä¸å¯èƒ½åˆ°å¯èƒ½ã€‚ è€¶è€¶å…¨éƒ¨æå®šäº†ï¼ŒåŸºå‡†åˆæ­¥ç»“æœè¿˜OKï¼Œå•¦å•¦å•¦å•¦å•¦!!!!!!!! é—®é¢˜æ˜¯æ ·æœ¬æœ¬èº«çš„é—®é¢˜äº†ã€‚ ä½ å¦‚ä»Šçš„æ°”è´¨é‡Œï¼Œè—ç€ä½ èµ°è¿‡çš„è·¯ï¼Œè¯»è¿‡çš„ä¹¦ï¼Œå’Œçˆ±è¿‡çš„äººã€‚ 2020-7-15 ä»Šå¤©æ—©ä¸Šå¤„ç†æ•°æ®ã€‚ ä»Šå¤©ä¸‹åˆææ—¶é—´åºåˆ—åˆ†æã€‚[]å€’ç€ç´¢å¼• ä»Šå¤©æ™šä¸Šçœ‹è®ºæ–‡ï¼Œå¯¹æ¯”åˆ†æäº†ä¸¤ç¯‡åŒç±»çš„æ–‡ç« ã€‚ æ˜å¤©ï¼š â€‹ å‘ä»£ç  â€‹ æŠŠåŸºå‡†ç»“æœå’Œå­¦ä½èšé›†é‡åŒ–ä¸€ä¸‹ï¼Œå¸Œæœ›å‡ºä¸ªå¥½ç»“æœã€‚æ…¢æ…¢æ‘¸ç´¢å‡ºä¸€æ¡é“è·¯ã€‚æŒºå¥½çš„ï¼ 2020-7-14 ä»Šå¤©æ—©ä¸Šè¯»äº†å‡ é¡µä¹¦ç±ï¼Œæ„Ÿæ‚Ÿé¢‡å¤šã€‚æ¡æ¡å¤§è·¯é€šç½—é©¬ï¼Œè¶Šæ¥è¶Šå€¼é’±ã€‚æ‰¯ä¸‹å† å†•å ‚çš‡çš„ç†ç”±ï¼Œæˆ‘ä¹‹æ‰€ä»¥æ‹¼å‘½ï¼Œä¸å°±æ˜¯ä¸ºäº†å¯Œå…»æˆ‘è‡ªå·±å—ï¼Ÿè‡ªå§‹è‡³ç»ˆéƒ½æ˜¯æˆ‘çš„å¥‹æ–—ç›®æ ‡ã€‚åªè¦æ˜¯æ­£å½“çš„æ±‚ç”Ÿæ‰‹æ®µï¼Œé è‡ªå·±çš„æœ¬äº‹åƒé¥­ï¼Œæˆ‘å°±å¹²ã€‚ ä»Šå¤©ä¸‹åˆï¼ˆåˆç¡äº†å¾ˆä¹…ï¼‰å­¦äº†ç©ºé—´åˆ†æå·¥å…·ï¼Œå·¥å…·è¿˜æŒºå¥½ç”¨çš„å“‡ã€‚ç»§ç»­sklearn ä»Šå¤©æ™šä¸Šç»§ç»­å¤„ç†æ•°æ®ï¼Œè·‘çš„æ—¶å€™è¯»äº†åˆ«äººçš„æ–‡çŒ®ï¼Œçªç„¶è§‰æ‚Ÿã€‚ç§‘ç ”çš„è¿‡ç¨‹å°±æ˜¯æµªè´¹æ—¶é—´çš„è¿‡ç¨‹ã€‚ é—®é¢˜ï¼šæˆ‘ç°åœ¨æ˜¯æ²¦ä¸ºå·¥å…·çš„åº”ç”¨è€…å—ï¼Ÿæˆ‘åŸå…ˆä¸€ç›´è‡´åŠ›äºæˆä¸ºè¿™æ–¹é¢çš„åˆ›é€ è€…ï¼Œæ²¡æœ‰æˆåŠŸã€‚å’³å’³ï¼Œç°æˆä¸ºå·¥å…·çš„åº”ç”¨è€…ï¼Œè§£é‡Šä¸€äº›ç°è±¡ä¹Ÿæ˜¯ååˆ†å¥½çš„ã€‚ 2020-7-13 ç”Ÿå­˜è¿˜æ˜¯æ¯ç­ï¼Ÿè¿™æ˜¯ä¸ªé—®é¢˜ã€‚ç©¶ç«Ÿå“ªæ ·æ›´é«˜è´µï¼è¦æ›´åŠ å‰å®³ï¼ ä»Šå¤©æ—©ä¸Šåˆ·è§†é¢‘ï¼Œå­¦è‹±è¯­ï¼ä»Šå¤©ä¸‹åˆç¡è§‰&amp;å­¦è½¯ä»¶&amp;è·‘ç¨‹åº ä»Šå¤©æ™šä¸Šè¯»è®ºæ–‡ã€‚è™½ç„¶æ˜¯åŒ—å¤§çš„è®ºæ–‡ï¼Œä½†æ˜¯æ€»è§‰æ„ä¹‰å’Œä»·å€¼æ„Ÿä¸é«˜ã€‚æˆ‘ç°åœ¨æçš„ç§‘ç ”é—®é¢˜ä¹Ÿæ˜¯è¿™ä¸ªæ¯›ç—…ã€‚æ²¡æœ‰ä¹è¶£å¾€ä¸‹è¿›è¡Œäº†ã€‚åƒåœ¾ä¸­çš„æˆ˜æ–—æœºå“‡ï¼ æ˜å¤©ï¼š1. æ—¶é—´åºåˆ—è°ƒå‚ï¼Œäº¤æ¥å·¥ä½œã€‚2. è°ƒç ”ä¸€ä¸‹æ•°æ®å½’ä¸€åŒ–çš„æ–¹æ³•ã€‚3. è¯»è®ºæ–‡ 2020 29å‘¨ Input å°è¯•è°ƒç ”å°é¢†åŸŸï¼ˆæ„Ÿè§‰ä¸‹è½½çš„æ–‡çŒ®è´¨é‡éå¸¸é«˜ï¼‰ å­¦ä¹ å†™ä½œ æ—¶é—´åºåˆ—ï¼ˆæœºå™¨å­¦ä¹ ç®—æ³•ï¼‰ Output PPT å¤šè®°ç‚¹ä¸“ä¸šè¯æ±‡å’Œå¥å¼ï¼ˆæˆ‘å°±æ˜¯ç…§ç€åˆ«äººå†™çš„ï¼Œä½†æ˜¯è¯»èµ·æ¥ä¸å¯¹åŠ²ï¼Œä¸é€šç•…ï¼‰ 2020-7-12 å½“ä½ çŸ¥é“è‡ªå·±çš„éœ€æ±‚ï¼Œä¹ŸçŸ¥æ™“åˆ«äººçš„éœ€æ±‚ï¼Œæ‰€æœ‰çš„äº‹æƒ…éƒ½ååˆ†å¥½å¹²äº†ã€‚å¦‚æœå‡ºç°äº†é—®é¢˜ï¼Œä¸€å®šæ˜¯æˆ‘åšçš„ä¸å¥½ã€‚ ä»Šå¤©æ‰¾äº†å‡ ç¯‡éå¸¸å¥½çš„æ–‡çŒ®ï¼Œå¯ä»¥åšè¿™æ–¹é¢çš„ç»†è°ƒç ”ï¼Œå¤§æ¦‚å°±10ç¯‡å·¦å³ã€‚ ä»Šå¤©å¤„ç†äº†æ•°æ®ï¼Œå®åœ¨æ˜¯éº»çƒ¦ã€‚ çªç„¶å‘ç°æ–‡ç« æœ€éš¾çš„æ˜¯æ–‡çŒ®ç»¼è¿°ã€‚ Input âœ”ï¸âŒ Output âŒâŒâœ”ï¸ 2020-7-11 çœ‹å‰§ï¼Œè·‘ç¨‹åº ä»Šå¤©æ—©ä¸Šç¡è§‰ï¼Œçœ‹è§†é¢‘ ä»Šå¤©ä¸‹åˆå’Œæ™šä¸Šï¼Œå¤„ç†æ•°æ®ï¼Œå•Šéº»çƒ¦ ç²¾è‹±ç²¾ç¥ï¼š 1. ã€Šè°è¯´æˆ‘ç»“ä¸äº†å©šã€‹ åˆ©ç›Šï¼šè¦ä¸è¦åšï¼›é£é™©ï¼šè¯¥ä¸è¯¥åšï¼› èƒ½åŠ›ï¼šè¯¥ä¸è¯¥å¹²ï¼›ç»“æœï¼šåˆ’ä¸åˆ’ç®—ï¼›è€Œä¸æ˜¯åˆ«äººå‘Šè¯‰æˆ‘ï¼šå¯¹ä¸å¯¹ã€‚ 2. æ˜ç¡®å„è‡ªéœ€æ±‚ 2020-7-10 è·‘ç¨‹åº ä»Šå¤©æ—©ä¸Šè·‘ç¨‹åºï¼ˆå°è£…æ¥å£ï¼‰ ä»Šå¤©ä¸‹åˆè·‘ç¨‹åºï¼Œå­¦ä¹ å†™ä½œçš„æ€ç»´ ä»Šå¤©æ™šä¸Šè·‘ç¨‹åºï¼Œçœ‹çºªæ™“å²šå’Œå’Œç…ã€‚ 2020-7-9 ç§‘ç ”å†™ä½œå¥½ç—›è‹¦ ä»Šå¤©æ—©ä¸Šå¬äº†å¬åŠ›ï¼Œåˆ·Bç«™ ä»Šå¤©ä¸‹åˆå­¦ä¹ äº†å¦‚ä½•è¿›è¡Œç§‘ç ”å†™ä½œã€‚å¤ªä¸å®¹æ˜“äº†ã€‚ã€ŠSome Tips on Writingã€‹ã€‚åŸå› å¦‚ä¸‹ï¼šè¯æ±‡ç¼ºä¹ï¼›ç›´è¯‘ï¼›æ¯«æ— è®²æ•…äº‹çš„æ€è·¯ï¼›äº¤ä»£ä¸æ¸…æ™°ï¼Œå«ç³Šã€‚æ›´åˆ«æé€»è¾‘äº†ï¼Œæˆ‘è§‰å¾—ä¸­æ–‡è®ºæ–‡çš„é€»è¾‘å…³ç³»éƒ½æŠŠæ¡ä¸å¥½ã€‚ 2020-7-8 ä½ è¦è‡ªå·±æ‘¸çˆ¬æ‰“æ»šçš„åº¦è¿‡è‰°éš¾æ—¶æœŸï¼Œä½ å¯ä»¥æ‰¾äººï¼Œä½†ç»ä¸èƒ½ä¾é ä»»ä½•ä¸€ä¸ªäººã€‚æˆ‘ä»¬æ˜¯å­¤ç‹¬çš„ä¸ªä½“ï¼Œæ›´æ˜¯æ— æ•°å…³ç³»è¿è¾¹ä¸­çš„ä¸€æ¡ã€‚è¦å­¦ä¼šå’Œè¿™ä¸ªä¸–ç•Œäº§ç”Ÿå…±é¸£ã€‚ ä»Šå¤©æ—©ä¸Šå•ƒäº†ä¸€ä¸ªğŸã€‚ åˆ·åˆ·å°çº¢ä¹¦ï¼ŒBç«™ã€‚ ä¸‹åˆå†™äº†ä»£ç æ³¨é‡Šã€‚å°è£…æˆæ¥å£ã€‚è§„åˆ’äº†ä¸‹ä¸€æ­¥æ–¹æ¡ˆã€‚ æ™šä¸Šè¯»äº†ä¸€ç¯‡Data Scienceçš„æ–‡ç« ï¼Œæ•°æ®å¥½æ‰èƒ½è®²å¥½æ•…äº‹å•Šã€‚å¼•åŠ›æ¨¡å‹ã€çº¿æ€§å›å½’æ¨¡å‹ã€‚å˜é‡çš„æ„é€ æ˜¯äº®ç‚¹ã€‚æ¯å¤©åšæŒå†™ä½œï¼ˆè‹±æ–‡å†™ä½œå¥½éš¾ï¼‰ 2020-7-7 å½“å¼€å¯**ï¼Œå°±åƒå¼€å¯äº†é—¯å…³æ¸¸æˆï¼Œè¦ä¸€å…³ä¸€å…³çš„æ‰“æ€ªå‡çº§ï¼Œæ¢å…ˆè¿›è£…å¤‡ã€‚ä¸æˆåŠŸä¾¿æˆä»ã€‚ä¸æˆåŠŸä¾¿æˆä»ã€‚ä¸æˆåŠŸä¾¿æˆä»ã€‚ ä»Šå¤©æ—©ä¸Šåˆè¢«åˆºæ¿€åˆ°äº†ã€‚ ä¸‹åˆå®ç°äº†xgboost, æ•°æ®-&gt;æ¨¡å‹-&gt;è°ƒè¶…å‚æ•° æ™šä¸Šæ”¶æ‹¾äº†è®ºæ–‡ï¼Œæ„Ÿè§‰å°±åƒä¿„ç½—æ–¯æ–¹å—ï¼Œåº•å±‚æ²¡æœ‰åšå¥½ï¼Œè¶Šå¾€ä¸Šå †ï¼Œå°±è¦å›å½’åº•å±‚ã€‚å†™äº†1000å¤šç‚¹çš„å°è®ºæ–‡ï¼Œä¹Ÿä¸çŸ¥é“æ¯ä¸€ä¸ªä¼˜ç§€çš„åšå£«è¦ç»å†ä»€ä¹ˆæ‰èƒ½åˆ›é€ å‡ºè¿™ä¹ˆå¤šçš„æ–‡å­—ã€‚å€¼å¾—å­¦ä¹ ã€‚ é‡Šæ”¾å…‰èŠ’ï¼ 2020-7-6 ç»§ç»­åŠªåŠ›çš„ä¸€å¤© ä»Šå¤©æ—©å¬äº†è‹±è¯­è®¿è°ˆ ä»Šå¤©ä¸‹åˆå¤ä¹ äº†å¯†ç å­¦ç¬¬1-2ç« ï¼ˆ1h); æŠŠé«˜é“çš„æè¿°æ€§ç»Ÿè®¡åšäº†ï¼Œæ„Ÿè§‰ç»“æœè¿˜æ˜¯ä¸é”™ï¼(ç”¨æ—¶è¾ƒé•¿) 2020 28å‘¨ 2020-7-5 è¦åšçš„äº‹æƒ…è¿˜å¾ˆå¤šï¼Œæˆ‘åŠªåŠ›åšæˆ‘å–œæ¬¢çš„ä¸€åˆ‡ï¼Œå¹¶ä¸æ˜¯ä¸ºäº†èµ¢åˆ«äººï¼Œè€Œæ˜¯è¦è‡ªå·±æ»¡è¶³ã€‚ ä»Šå¤©åˆæ˜¯ç¡å¾—æ™šèµ·çš„æ—©çš„ä¸€å¤©ã€‚a. æˆ‘æŠŠtrfershå®Œå…¨ææ‡‚äº†ã€‚b. è°ˆæ•´åˆèµ„æ–™çš„é‡è¦æ€§ï¼Œä¸ºä»€ä¹ˆæˆ‘æ€»æ˜¯ä¸€ä¸ªä¸“é¢˜çš„èµ„æ–™ï¼Œæ¯æ¬¡éƒ½è¦é‡å¤å¼„å‘¢ã€‚ä¸å¥½ä¸å¥½ä¸å¥½ã€‚ è¿™ä¸€å‘¨è¿˜æ˜¯ä¸é”™çš„ï¼Œåœ¨ç²¾ç¥ä¸Šï¼Œæ¯å¤©ç¡è¶³äº†10hï¼Œå•Šå“ˆå“ˆå“ˆå“ˆå“ˆã€‚æ—¶é—´åºåˆ—åŸºæœ¬ä¸Šæé€šäº†ã€‚è¯»äº†å‡ ç¯‡ä¸é”™çš„è®ºæ–‡ï¼Œè¿˜æŠŠstataè½¯ä»¶å­¦ä¼šäº†ï¼Œå…¶å®è®¡é‡ç»æµå­¦æ— éå°±æ˜¯è¦è§£å†³å› æœå…³ç³»ï¼Œé—æ¼å˜é‡ï¼Œåºåˆ—ç›¸å…³æ€§ï¼Œå¼‚æ–¹å·®æ€§ç­‰ç­‰ï¼Œå‡ ä¸ªé—®é¢˜ï¼Œè¦è§£å†³æ˜¯ä¸å®¹æ˜“çš„ã€‚sklearnç”¨çš„ä¸ç†Ÿç»ƒ Input âœ”ï¸ Output âŒâœ”ï¸ è¿™å‘¨ä¸»è¦æŠŠç»Ÿè®¡å­¦é‡Œé¢çš„åŸºç¡€å¤ä¹ äº†ï¼Œæ€»æ„Ÿè§‰æ²¡æ‰¾åˆ°æˆ‘æƒ³è¦çš„é‚£ç§æ·±åº¦ã€‚æˆ‘ä¹Ÿä¸çŸ¥é“æˆ‘åˆ°åº•éœ€è¦æ€ä¹ˆæ ·çš„æ·±åº¦ã€‚æ„Ÿè§‰è‡ªå·±åˆèƒ–äº†ï¼ Input å¯†ç å­¦å¤ä¹ ä¸¤ç« ï¼ˆPPT+ä¹ é¢˜+ç™¾åº¦ï¼‰ ç½‘ç»œå®‰å…¨å¤ä¹ ä¸¤ç« ï¼ˆè§†é¢‘+ç¬”è®°+æ¦‚å¿µï¼‰ å†™1000å­—å·¦å³çš„ç»“è¯¾è®ºæ–‡ï¼ˆå…³äºå¤§æ•°æ®ä¸‹å­•è‚²è€Œç”Ÿçš„è®¡ç®—ç¤¾ä¼šç»æµå­¦ï¼ŒæŠ„è¢­æŠ„è¢­ï¼Œå€Ÿé‰´å’¯ï¼‰ å°è£…ç‰¹å¾æå– è®ºæ–‡æ•°æ®åˆ†æ(ç°åœ¨å°±å·®åˆ†æç»“æœ)ï¼ˆä¸çŸ¥é“æˆ‘æ€ä¹ˆä¼šç»™é€ æˆä¸€ç§ï¼Œæˆ‘å¾ˆä¼šå†™è®ºæ–‡çš„æ ·å­ï¼Œæƒ³å¤ªå¤šäº†å§) ç°åœ¨è¿˜æ˜¯æ•°æ®é©±åŠ¨ç ”ç©¶ï¼Œå¹¶éç ”ç©¶é—®é¢˜é©±åŠ¨æ•°æ®çš„é˜¶æ®µ å‡†å¤‡å…­çº§ reading record Output åŸºæœ¬çš„æ•°æ®åˆ†æç»“æœ è®ºæ–‡é˜…è¯»ï¼šä¸€å®šè¦ä»¥PPTçš„å½¢å¼ç»™å‡ºï¼ˆæ¯å‘¨ç»™è‡ªå·±åšä¸ª1-3é¡µçš„PPT) çœ‹ä¸€é“å»ºæ¨¡é¢˜ å­¦ä¹ æœºå™¨å­¦ä¹ é›†æˆç®—æ³• 2020-7-4 æ‡’å¾—çš„æˆ‘ ä»Šå¤©æ—©ä¸Šåˆç¡äº†å¾ˆä¹…ï¼å¯ä»¥æ˜¯æ˜¨å¤©æ™šä¸Šçœ‹åˆ«äººçš„vlogå¤ªä¹…äº†ï¼Œç¾¡æ…•é‚£ç§ç‹¬å±…ç”Ÿæ´»ã€‚æˆ‘ä»€ä¹ˆæ—¶å€™å¯ä»¥è¿‡ä¸Šç‹¬å±…çš„æ—¥å­å•Šï¼ ä»Šå¤©ä¸‹åˆå­¦äº†stataè¿™ä¸ªå·¥å…·ï¼ŒåŸºæœ¬ä¸Šå­¦ä¼šäº†ï¼Œæˆ‘å‘ç°æœºå™¨å­¦ä¹ å¼€æºå·¥å…·ï¼Œæœ‰äº›ä¸è‰¯å¿ƒå•Šï¼ ä»Šå¤©æ™šä¸Šçœ‹äº†ä¼šç”µè§†å‰§ã€‚è·Ÿè¸ªå…¬ä¼—å·ã€‚å­¦ä¹ ç»Ÿè®¡å­¦ã€‚ 2020-7-3 ç¡é¥±å–è¶³ï¼Œè¯»ä¼šè®ºæ–‡ï¼Œ&amp; æ•²ä»£ç  ä»Šå¤©ä¸‹åˆç©äº†xgboost,é›†æˆå­¦ä¹ æœ‰ç‚¹éš¾ï¼Œä½†ä¹Ÿè¦æ‰‹åŠ¨æ¨å¯¼ï¼Œè¿™å¯ä»¥åŠ æ·±å¯¹ç®—æ³•å†…æ¶µçš„ç†è§£ã€‚ æ™šä¸Šç»Ÿè®¡å­¦ä¹ ï¼Œstataå’Œè®¡é‡ç»æµå­¦ï¼ˆå­¦çš„å¾ˆåŸºç¡€ï¼Œä½†å®é™…åº”ç”¨ä¸æ˜¯é‚£ä¹ˆå›äº‹äº†ï¼‰ã€‚åšæ•°æ®ç§‘å­¦ï¼Œè‚¯å®šè¦å­¦ä¹ Rè¯­è¨€ æ²‰æ€ï¼šğŸ˜”ğŸ˜”ğŸ˜”ã€‚ 2020-7-2 é™·å…¥æ·±æ¸Šçš„æˆ‘ ä»Šå¤©åˆæ˜¯ä¸Šè¯¾ï¼Œä¸çŸ¥é“è€å¸ˆæ‰¯äº†äº›ä»€ä¹ˆï¼Œå¬ç€å¬ç€å°±å…³æˆé™éŸ³äº†ã€‚(é˜´é™©.jpg) å®ç°äº†æ—¶é—´åºåˆ—çš„ç‰¹å¾å·¥ç¨‹ï¼Œè¯»äº†ä¸€ç¯‡å¥½æ–‡ç« ï¼ˆå…³äºå¥³æ€§æ”¿æ²»åœ°ä½çš„æé«˜ï¼‰ï¼Œè¿˜æ‰¾åˆ°äº†ä¸€ç¯‡EPJ data scienceä¸Šçš„å¥½æ–‡ç« ï¼ˆè¿½è¸ªæ–‡çŒ®çš„é‡è¦æ€§ï¼‰ æ˜å¤©ï¼š1ï¼‰å®ç°xgboost 2) æ¨¡å‹è®¾ç½®ï¼ˆä¸­æ–‡ï¼‰ç»¼è¿°å’Œå˜é‡ 2020-7-1 æ— èŠçš„æˆ‘ ä»Šå¤©ç©äº†tsfreshåº“ï¼Œæ€ä¹ˆé‚£ä¹ˆéš¾ç†è§£å•Šï¼å®åœ¨æ˜¯ä¸çŸ¥é“åˆ«äººæ€ä¹ˆç¼–ç¨‹çš„ï¼å…³é”®æ˜¯è¿”å›çš„æ•°æ®ç»“æ„ï¼Œå’Œåº•å±‚å®ç°æœ‰å…³ç³»ï¼å†æ¬¡å­¦ä¹ äº†å‚æ•°ä¼°è®¡ï¼ˆæå¤§ä¼¼ç„¶ä¼°è®¡ï¼Œæœ€å¤§åéªŒä¼°è®¡ï¼‰ã€‚æˆ‘å¯èƒ½è¦æ‰‹æŠŠæ‰‹æ•™é‚£ç§ã€‚ 2020-6-30 å¿ƒç´¯çš„ä¸€å¤© ä»Šå¤©æ—©ä¸Šï¼Œä¸‹åˆä¸Šè¯¾ï¼Œæ˜¯å¼ è€å¸ˆçš„è¯¾ï¼Œè¯¾ç¨‹éš¾åº¦å¾ˆå¤§ã€‚æˆ‘ä¹Ÿæ˜¯åŠå¬åŠç©è€ã€‚å¯èƒ½æ˜¯æ•°å­¦å­¦å¤šäº†ï¼Œå¯¹è¿™ä¸ªç¤¾ä¼šé—®é¢˜æ„Ÿæ‚Ÿèƒ½åŠ›è·Ÿä¸ä¸Šã€‚å°±ä¸€å¥è¯å­˜åœ¨å³åˆç†ï¼é¡ºé“çœ‹äº†tsfreshçš„doc æ™šä¸Šï¼Œè¯»äº†ä¸€ç¯‡scienceï¼Œå¼€åˆ›æ€§å·¥ä½œå°±æ˜¯å‰å®³å•Šï¼ä»0åˆ°1æ˜¯é£è·ƒï¼Œ1åˆ°2ï¼Œ3â€¦æ˜¯å‘å±•ã€‚è¿˜æœ‰è·¨ç•Œçš„ç²¾è‹±ã€‚æ¸©ä¹ äº†æœºå™¨å­¦ä¹ é‡Œé¢çš„åŸºæœ¬æ¦‚å¿µï¼ 2020-6-29 ä»Šå¤©æ—©ä¸Šï¼Œä¸‹åˆä¸Šè¯¾å»äº†ã€‚è¿˜å»çœ‹äº†å›å½’åˆ†æsklearnçš„å®ç°ã€‚ å…³é”®ç‚¹ç›¸å…³æ€§åˆ†æ-&gt;å› æœåˆ†æï¼Œ correlation ï¼ causality - prediction - controlã€‚è§£é‡Šå‹ç ”ç©¶ï¼ˆæè¿°ï¼Œç»Ÿè®¡æ–¹æ³•)â€”â€”&gt;å……åˆ†è§£é‡Šï¼ˆå› æœå…³ç³»ï¼‰ç§‘å­¦ç ”ç©¶ï¼š è§£é‡Šï¼Œé¢„æµ‹ï¼Œæ§åˆ¶é—­ç¯ï¼ˆå¹²é¢„ï¼‰ï¼Œæ‰¾ä¸åˆ°å› æœå…³ç³»ã€‚ å› æœå…³ç³»åˆ†ææ–¹æ³•ï¼šCausality: Models, Reasoning, and Inference æ™šä¸Šå¤ä¹ ç»Ÿè®¡å­¦day Ox 01ï¼ˆæœ¬ç§‘æˆ‘æ€ä¹ˆæ²¡æœ‰ä½œç”µå­ç¨¿ç¬”è®°å•Šï¼Œå“­æ­»äº†ï¼Œè¿˜å»åç¿»çœ‹äº†è¿‡å»çš„ç¬”è®°å’Œåšå®¢ï¼Œèœæ­»äº†ï¼‰ã€‚åŠ ä¸ªå­¦ä¹ å°ç»„ï¼Œæ„Ÿè§‰åˆ«äººåšçš„èµ„æ–™ï¼Œå’Œæˆ‘æƒ³è¦çš„æ·±åº¦å·®å¤ªè¿œäº†ã€‚æ•°æ®æŒ–æ˜ä¸Šæ¬¡çœ‹é‚£ä¸ªDr.yuançš„è¯¾ç¨‹ï¼Œç¬”è®°ä¸æ˜¯ç‰¹åˆ«å¥½ï¼è¿˜è¦æŠŠæ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹åšäº†ï¼ æˆ‘å‘ç°ç”³è¯·å®è·µå­¦åˆ†ï¼ŒåšåŠ©æ•™ï¼Œæ€ä¹ˆé‚£ä¹ˆå¤šäººç”³è¯·å•Šï¼ ç»Ÿè®¡å­¦ä¹ æ–¹æ³•é‚£ä¸ªï¼Œæˆ‘å‘ç°æˆ‘åšçš„ç¬”è®°ï¼Œå¥½å·®åŠ²å•Šï¼ 2020-6-28 å…ƒæ°”å°‘å¥³çš„ç‹¬ç™½â€” ä¸ªäººä¹‹æ—… 2020 27å‘¨ï¼šèº¬è¡Œå®è·µ INPUT a. Linear Models &amp; Python å­¦ä¼š https://scikit-learn.org/stable/supervised_learning.html#supervised-learning b. Time series &amp; Feature select tfresh c. English: youtube &amp; shanbei e. reading record f. æ¦‚ç‡è®ºï¼ˆæå¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå‡è®¾æ£€éªŒï¼Œæ˜¾è‘—æ€§æ£€æµ‹ï¼Œå‚æ•°ä¼°è®¡ï¼‰ OUTPUT a. kaggle project b. æŒæ¡ä¸€ä¸ªä¸­é«˜éš¾åº¦çš„æ•°å­¦æ¨¡å‹ c. Reading Record ä»Šå¤©æ—©ä¸Šç¡è§‰å•¦ï¼ ä¸‹åˆå’Œç”µè„‘äººä¸€èµ·ç©éº»å°†ï¼Œæ”¶æ‹¾äº†æœ¬å‘¨çš„èµ„æ–™æ±‡æ€» æ™šä¸Šçœ‹äº†è§†é¢‘å­¦ä¹ å…³äºxgboost,å’Œå…³äºä¸€äº›å…¬ä¼—å·çš„æ–‡ç«  F: â€‹ è¾“å‡ºï¼ˆâœ”ï¸ï¼‰ï¼› è®ºæ–‡é˜…è¯»ï¼ˆâœ”ï¸ï¼‰ï¼›è¯»ä¹¦ï¼ˆâŒï¼Œä¸»è¦æ˜¯æ²¡æœ‰é‚£ç§å¿ƒå¢ƒï¼Œä¸ä¸Šç˜¾ï¼‰ï¼›è‹±è¯­ï¼ˆâœ”ï¸ï¼‰ S: è®ºèµ„æ–™çš„æ”¶é›†çš„é‡è¦æ€§ã€‚çŸ¥è¯†åœ¨è„‘æµ·é‡Œä¼šå¿˜è®°ï¼Œä½†ç¡¬ç›˜ä¸ä¼šã€‚ä¸€å®šè¦æŠŠè‡ªå·±é‡åˆ°çš„é¡¶çº§èµ„æ–™æ”¶é›†å¥½ï¼Œå˜æˆdocã€‚ä¸€å®šæ˜¯é«˜è´¨é‡å’Œé«˜å¯†åº¦çš„èµ„æ–™æ‰è®°å½•ã€‚åŸæ¥ä¸€ç›´æ³¨é‡èµ„æ–™çš„å­¦ä¹ ï¼Œå¿½ç•¥äº†èµ„æ–™æ•´åˆçš„é‡è¦æ€§ã€‚å¹¶ä¸”æœ€å¥½æ¯æ®µæ—¶é—´ï¼Œå†™ä¸€ç¯‡å¤§æ±‡æ€»ã€‚ åˆ‡è®°ä»å¤´å¼€å§‹ã€‚å­¦ä¹ å›è·¯ï¼šèµ„æ–™æ”¶é›†ï¼ˆåˆ†ç­‰çº§ï¼šå…¨å±€è§‚â€”&gt;å…¥é—¨-è¿›é˜¶-é«˜çº§ï¼Œç§‘æ™®)â€”â€”&gt; æŠŠè‡ªå·±çš„è¾“å‡ºæå‡åˆ°åˆ«äººä¹Ÿå¯ä»¥ç›´æ¥ç”¨çš„æ°´å¹³ã€‚ä¸é”™ï¼Œæ˜¯è¿™ä¹ˆå›äº‹ï¼è¿™ä¹Ÿæ˜¯å¯¹è‡ªå·±çš„ä¸€ç§è¦æ±‚ã€‚ å¿«ä¹å¤¹æ‚ç€æ‚²ä¼¤ï¼Œè‡³å°‘ç»“å°¾ä¸èƒ½è®©è‡ªå·±å¤ªéš¾å ªï¼è¿™æ¡è·¯åªä¼šä¸è‡ªå·±ç›¸å…³ã€‚ 2020-6-27 å¤–å…¬å…«åå²ç”Ÿæ—¥ ç™½å¤©åœ¨å¤–å©†å®¶ï¼Œç»™æ•™ä¹¦å…ˆç”Ÿå¤–å…¬è¿‡ç”Ÿæ—¥ã€‚ æ™šä¸Šï¼Œå¬äº†ä¸€åœºè®²åº§ï¼Œå…³äºâ€œå½“äº¤é€šé‡ä¸Šæœºå™¨å­¦ä¹ â€,æ˜¯åŒ—äº¤å‰¯æ•™æˆä¸‡æ€€å®‡åšå£«è®²æˆçš„ä¸“é¢˜ã€‚ä¸»é¡µï¼šhttp://faculty.bjtu.edu.cn/8793/ ã€‚å…¨å½“æ˜¯ç§‘æ™®äº†ï¼Œä¸è¿‡ï¼Œå†…å®¹æŒºæ·±å¥¥çš„ã€‚ ä½ æ°¸è¿œæ— æ³•å«é†’ä¸€ä¸ªè£…ç¡çš„äºº å½“ä½ çœŸå¿ƒæ¸´æœ›æŸæ ·ä¸œè¥¿æ—¶ï¼Œæ•´ä¸ªå®‡å®™éƒ½ä¼šè”åˆèµ·æ¥å¸®åŠ©ä½ å®Œæˆï¼ å­¦åˆ°äº†ä¸¤å¥è¯ï¼Œæˆ‘ä¸çŸ¥é“é€‰å“ªä¸ªï¼ å…³é”®è¯: ç¡¬æ ¸ 2020-6-26 ä»Šå¤©æ—©ä¸Šï¼Œç¡åˆ°äº†11ï¼š00 ä¸‹åˆï¼ŒæŸ¥é‡ï¼Œå¿ƒç´¯ï¼æ—¶é—´åºåˆ—ï¼ æ™šä¸Šï¼Œè¯»äº†ä¸€ç¯‡æ—¶é—´åºåˆ—åœ¨é¢„æµ‹èƒ½æºæ¶ˆè´¹é‡Œé¢çš„å¤§ç»¼è¿°ã€‚å’Œæœ¬ç§‘çš„ç»å†å¥‘åˆã€‚é‡ç‚¹çœ‹äº†æœ€å°äºŒä¹˜æ”¯æŒå‘é‡æœºçš„åº”ç”¨ï¼Œç ”ç©¶ç»“æœæ‹Ÿåˆç²¾åº¦å’Œé¢„æµ‹ç²¾åº¦è¿˜è¡Œã€‚è¿™äº›æ¨¡å‹ï¼Œæˆ‘è¿˜æŒºç†Ÿæ‚‰çš„ã€‚ 2020-6-25 ç«¯åˆå¿«ä¹,biubiubiu æ—©ä¸Šï¼Œç¡åˆ°äº†ä¸­åˆï¼Œæ„Ÿè§‰å¤ªçƒ­äº†ï¼Œä¸æƒ³æ—©èµ·ã€‚ ä¸­åˆï¼Œæˆ‘å’Œå¼Ÿå¼Ÿå»è¡—ä¸Šåƒé¥­äº†ï¼šè±†è…ã€æ°´é¥ºã€æ°´ç…®è‚‰ç‰‡ã€‚æ„Ÿè§‰æˆ‘è¦æ˜¯æ„¿æ„åšä¸€æ¬¡é¥­ï¼Œé‚£ç®€ç›´æ˜¯å¤ªé˜³ä»è¥¿æ–¹å‡ºæ¥äº†ã€‚å¦ˆå¦ˆæœç„¶æ˜¯ä¸–ç•Œä¸Šæœ€è¾›è‹¦çš„äººäº†ã€‚ ä¸‹åˆï¼Œäº¤æ¥ä¸€ä¸‹æ—¶é—´åºåˆ—é¡¹ç›®ï¼Œè¯è¯´è¿™ä¸ªä¸œè¥¿ä¸æ˜¯å¾ˆç«å—ï¼Œä¸ºä»€ä¹ˆèµ„æ–™è¿™ä¹ˆå°‘å•Šï¼ï¼ï¼è·‘äº†ä¸€å¤©ä¸€å¤œARIMAäº†ã€‚å¸®æˆ‘è¡¨å¼Ÿå†™ä¸€ç¯‡ä¸­å°ä¼ä¸šå‘å±•ç°çŠ¶çš„è®ºæ–‡ï¼Œæ‰¾äº†å‡ ç¯‡æ–‡ç« æŠ„è¢­ï¼Œçœ‹äº†åˆ«äººçš„ç¡•å£«å­¦ä½è®ºæ–‡ï¼Œæˆ‘æ‰æ„è¯†åˆ°æˆ‘è¿˜æ˜¯æœ¬ç§‘è®ºæ–‡çš„æ°´å¹³ã€‚ æ™šä¸Šï¼Œç ”è¯»è®ºæ–‡ã€‚ 2020-6-24 7hç¡çœ ä¸è¶³çš„æˆ‘.jpg ä»Šå¤©æ—©ä¸Šè¿·è¿·ç³Šç³Šèµ·åºŠï¼Œå’ŒåŒå­¦å” å—‘ï¼Œæ˜¨å¤©ç¡çš„å¥½ç©ï¼Œ1ï¼š30ï¼Œå¬è¯´å¢¨è¥¿å“¥åœ°éœ‡äº†ï¼Œç„¶åæˆ‘å‘äº†æ¶ˆæ¯ï¼Œå±…ç„¶å¿ƒå®‰ç†å¾—çš„ç¡ç€äº†ï¼ ä¸‹åˆï¼Œæ‰æ‰è¯´å¯ä»¥å·å·æ‘¸æ‘¸å›å»ï¼Œæˆ‘å¿ƒé‡Œæš—è‡ªä¸€æƒ³ï¼Œåœ¨å®¶é‡Œä¹Ÿå¾ˆå¥½å•Šï¼Œç¡-åƒ-ç”µè„‘-åƒ-ç¡-é†’çš„æ— çº¿æ­»å¾ªç¯ã€‚ã€‚ã€‚ã€‚ã€‚çœ‹äº†æœ¬ç§‘çš„å­¦å¼Ÿå­¦å¦¹æ¯•ä¸šäº†ï¼Œæ„Ÿå¹æ—¶å…‰å•Šï¼Œæˆ‘è¿™ä¸€å¹´å­¦äº†ä»€ä¹ˆï¼Œæ—¶é—´éƒ½å»å“ªäº†äº†ï¼Ÿæ—¶é—´éƒ½å»é‚£å„¿äº†ï¼Ÿæˆ‘è§‰å¾—è‡ªå·±ä¸€å¹´ä»€ä¹ˆæˆåŠŸéƒ½æ²¡æœ‰ï¼Œè®ºæ–‡è¢«æ‹’ç¨¿ï¼Œè¢«å›°å®¶ä¸­åŠå¹´äº†å§ï¼Œæ„Ÿè§‰æœ¬ç§‘å››å¹´éƒ½æ²¡æœ‰åœ¨å®¶å‘†é‚£ä¹ˆé•¿çš„æ—¶é—´ã€‚è¿™ä¸æ˜¯æœ¬ç§‘çš„æ‰€æœ‰æ—¶é—´ï¼Œå…¨éƒ¨å›å»äº†å—ï¼Ÿ æ™šä¸Šï¼Œäº†è§£æ—¶é—´åºåˆ—çš„ç‰¹å¾æå–ï¼Œä»€ä¹ˆé¬¼ï¼Œæ€ä¹ˆé‚£ä¹ˆéš¾å•Šï¼æ™šä¸Šçœ‹äº†å¤§æ•°æ®æœºå™¨å­¦ä¹ æ—¶ä»£ï¼Œç§‘æ™®ã€‚ çªç„¶æƒ³åˆ°è¿˜æœ‰å¥½å¤šå¤ä¹ çš„è¯¾ç¨‹è¦è€ƒè¯•å•Šï¼Œçªç„¶æƒ³åˆ°äº†ã€‚ çœ‹äº†å¾ˆä¹…å¾ˆä¹…çš„è¯´è¯´äº†ï¼Œæˆ‘å‘ç°å¤§å­¦æˆ‘é”™è¿‡äº†å¾ˆå¤šçš„ç¾å¥½ï¼Œ æ€€å¿µå¤§å­¦çš„æ—¶å…‰ï¼Œæ— æ‹˜æ— æŸï¼Œå¯ä»¥èµ·å¾ˆæ—©å»å®éªŒå®¤ï¼Œå¯ä»¥è®¤è®¤çœŸçœŸçš„ä¸Šè¯¾ï¼Œå¯ä»¥å’ŒåŒå­¦ä¸€èµ·å»ºæ¨¡å’Œç†¬å¤œé€šå®µåšä½œä¸šï¼Œå°¤å…¶æ˜¯å’Œç¯å¤œä¸€èµ·å¤§æ™šä¸Šå¾…åœ¨å®éªŒå®¤çš„æ—¥å­ã€‚ Probit vs logit https://www.econometrics-with-r.org/11-2-palr.html 2020-6-23 æˆ‘è¦æ”¾é•¿å‡.mp4 ä»Šå¤©ç¡äº†10hå¤šã€‚æ™šä¸Šåä¸€ç‚¹ç¡åˆ°æ—©ä¸Š11.00ï¼Œä¸­é€”è¿˜è¿·è¿·ç³Šç³Šçš„åœ¨ç ”ç©¶ç”Ÿç³»ç»Ÿæ‰“å¡ï¼ï¼ï¼ï¼å·²ç»æ˜¯è‡ªç„¶çŠ¶æ€äº†å•Šï¼ ä¸‹åˆï¼šç»§ç»­æ—¶é—´åºåˆ—ï¼Œç†è®ºå®Œå…¨ä¸æ‡‚ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ã€‚ æ™šä¸Šï¼šå¼€å¼€å¿ƒå¿ƒå¤ä¹ å››å·å¤§å­¦çš„æ¦‚ç‡è®ºã€‚å¥½ä¹…æ²¡æœ‰æ¥è§¦æœºå™¨å­¦ä¹ äº†ï¼Œå·®ä¸å¤šè¿˜ç»™ä¹¦æœ¬äº†ã€‚ æœºå™¨å­¦ä¹ ç®—æ³•+æ¦‚ç‡è®ºç»Ÿè®¡å­¦ 2020-6-22 å¦‚æœå¯ä»¥ä¸€ç›´ä¸€ç›´ç¡ä¸‹å»å¤šå¥½å•Š.eps ä»Šå¤©ç¡äº†11å¤šä¸ªå°æ—¶ï¼Œå¤ªå¹¸ç¦äº†å•Šï¼ ä¸‹åˆç©äº†ä¼šæ—¶é—´åºåˆ—ã€‚å’Œç¯å¤œèŠäº†å¾ˆä¹…çš„å¤©ï¼Œå°±æ˜¯å…³äºå…´è¶£å’Œäººç”Ÿè¿½æ±‚ã€‚ 2020-6-21 ä»Šå¤©ä¸Šè¡—å»äº†ï¼Œä¹°äº†ä¸€ä¸ªå¤§å¤§çš„å†°æ·‡æ·‹ã€‚ è¾“å‡º å®Œæˆä¸€ç¯‡åšå®¢ æ¨è¿›æ—¶é—´åºåˆ—é¡¹ç›®ï¼ˆè¯»ç›¸å…³è®ºæ–‡ï¼‰ è®ºæ–‡é˜…è¯» ä»Šå¤©æ—©ä¸Šå’Œä¸‹åˆç¡äº†å¥½ä¹…å•Šï¼ ä¸‹å‘¨è§„åˆ’ï¼š æ—¶é—´åºåˆ—é¡¹ç›®ï¼ˆä¸»çº¿1ï¼‰ï¼šå…·ä½“æŠŠç›¸å…³çš„æ–¹æ³•æ•´ç†æˆç¬”è®° ç»Ÿè®¡å­¦ï¼ˆä¸»çº¿2ï¼‰ï¼šç»Ÿè®¡å­¦è¯¾ç¨‹æ¯å¤©å­¦ä¸€å­¦ï¼Œåšç»ƒä¹ ã€‚ mooc: https://www.icourse163.org/learn/NJUE-1001752031?tid=1206103246&amp;from=study#/learn/content ç¼–ç¨‹ï¼šSQLã€Excelã€Pythonçš„ç²¾é«“ç”¨æ³•ï¼Œæœ¬ç€æé«˜æ•ˆç‡å»çš„ã€‚ çœ‹å‰§ ã€Šç™½ç®±ã€‹ çœ‹ä¸¤ç¯‡æœºå™¨å­¦ä¹ å›å½’åˆ†æçš„è®ºæ–‡ ç»Ÿè®¡å­¦ä¹ è¡¥ä¸Š ä¹¦ç±é˜…è¯»ï¼š â€‹ ã€Šå¤§ç§¦å¸å›½ã€‹ â€‹ ã€Šäººæ€§çš„å¼±ç‚¹ã€‹ æ¯å¤©2hçš„è‹±è¯­å­¦ä¹ ï¼Œè¿‡å…­çº§å•Š åæ€ï¼š â€‹ æ—¥å‡ºè€Œä½œï¼Œæ—¥è½è€Œæ¯ã€‚ 2020-6-20 å¿ƒå¡ ä»Šå¤©è‚šå­ä¸èˆ’æœï¼Œä»€ä¹ˆéƒ½ä¸æƒ³å¹²äº†ã€‚å¥½ç—›ï¼Œå¥½ç—›ï¼Œå¥½ç—›ï¼ï¼ï¼ï¼ ä¸‹åˆå­¦äº†pythonæŠ€å·§ç»˜åˆ¶å„ç±»bar,barh 2020-06-19 æˆ‘ä¸æ˜¥é£çš†è¿‡å®¢ï¼Œä½ æºç§‹æ°´æ½æ˜Ÿæ²³ï¼›æ®Šé€”åŒå½’æ˜¯å¶ç„¶ï¼ŒèƒŒé“è€Œé©°æ˜¯å¸¸æ€ã€‚ ä¸‹å‘¨è§„åˆ’ï¼š æ—¶é—´åºåˆ—é¡¹ç›®ï¼ˆä¸»çº¿1ï¼‰ï¼šå…·ä½“æŠŠç›¸å…³çš„æ–¹æ³•æ•´ç†æˆç¬”è®° ç»Ÿè®¡å­¦ï¼ˆä¸»çº¿2ï¼‰ï¼šç»Ÿè®¡å­¦è¯¾ç¨‹æ¯å¤©å­¦ä¸€å­¦ï¼Œåšç»ƒä¹ ã€‚ ç¼–ç¨‹ï¼šSQLã€Excelã€Pythonçš„ç²¾é«“ç”¨æ³•ï¼Œæœ¬ç€æé«˜æ•ˆç‡å»çš„ã€‚ ä¹¦ç±é˜…è¯»ï¼š â€‹ ã€Šå¤§ç§¦å¸å›½ã€‹ â€‹ ã€Šäººæ€§çš„å¼±ç‚¹ã€‹ æ—©ä¸Šèµ·çš„æ™šï¼Œè¿˜è·Ÿå¯¼å¸ˆæ‰¯äº†çš®ï¼Œä½œä¸ºä¸€ä¸ªä»å°å°±é€ƒé¿è€å¸ˆçš„äººï¼Œå±…ç„¶è¿˜å»æ‰“æ‰°å¤§å¿™äººçš„æ—¶é—´ï¼Œç½ªè¿‡å•Šã€‚ ä¸‹åˆï¼šæäº†ä¼šç§‘ç ”ï¼Œæ•°æ®ä¸ç»™åŠ›å•Šã€‚å“ï¼Œå†…å¿ƒå¥”æºƒäº†ã€‚ æ™šä¸Šï¼šæ¶è¡¥pythonicå’Œç»Ÿè®¡å­¦ https://mp.weixin.qq.com/s?__biz=MzI1MzAwODMyMQ==&amp;mid=2650338461&amp;idx=1&amp;sn=be67a2565cf5f0922e84e5076fe1c0d2&amp;chksm=f1d75433c6a0dd25fa6e25fae624cb21738b0fc4b28f833db0844f8bbb6e02c1dc9dfddac03a&amp;scene=0&amp;xtrack=1#rd 2020-06-18 ğŸ˜´ å¿ƒä¸åœ¨ç„‰ ã€‚å…¨æ ˆã€‚ ä»Šå¤©å‘ç°è‡ªå·±ç¦»å…¨æ ˆåœ¨ç¨‹åº¦åœ¨é™ä½ã€‚ â€‹ 1. ä½œå›¾ã€å†™ä½œã€çœ‹æ–‡çŒ®ã€æƒ³ç§‘ç ”æƒ³æ³•ã€ç¼–ç¨‹å‡ ä¹éƒ½å¯ä»¥åŠç‹¬ç«‹ã€‚ä½†æ˜¯æˆ‘çªç ´ä¸äº†ï¼Œå°±æ˜¯å¾€é«˜è´¨é‡åœ¨æœŸåˆŠå‘ï¼Œæ„Ÿè§‰å·²ç»è¾¾åˆ°äº†è‡ªå·±èƒ½åŠ›çš„é¡¶å³°äº†ã€‚åœ¨ç»§ç»­ï¼Œå¯èƒ½å°±æ˜¯æ•°å­¦å±‚é¢ã€‚è¦æå‡å•Š è‡ªå·±å­¦äº†å¾ˆå¤šä¸œè¥¿ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰ç‹¬ç‰¹çš„ä¼˜åŠ¿åœ¨ï¼Œé—®é¢˜å°±æ˜¯ä¸ä¸“ä¸šï¼Œä¸é€å½»ã€‚è¦æŠŠè‡ªå·±å–œæ¬¢åœ¨çš„æ¶‰åŠçš„çŸ¥è¯†ã€ç¼–ç¨‹éƒ½è¦å­¦åˆ°ä½ï¼Œè¿™å¾ˆå…³é”®ã€‚ ä»Šå¤©å’ŒèŒèŒç»„ä¸ªå­¦ä¹ é˜Ÿï¼ŒåŠ æ²¹ï¼Œè€ƒç ”åŠ æ²¹ï¼ï¼ï¼ï¼ï¼ï¼ å°±æ˜¯å‚è€ƒæ–‡çŒ®çš„æ’å…¥ã€‚ 2020-06-17 ç©çš„fun æ˜å¤©ï¼š å¦‚æœä¸å‡ºæ„å¤–ï¼Œå°½é‡ç¡åˆ°ä¹ç‚¹ï¼çœ‹ä¼šç”µè§†å‰§ï¼ ç»§ç»­è·‘ç¨‹åº å­¦ä¹ ç»Ÿè®¡å­¦ ä»Šå¤©æ—©ä¸Šèµ·çš„å¾ˆæ™šï¼Œç¡äº†å¾ˆä¹…ï¼æ˜¨å¤©çœ‹äº†å¥½ä¹…çš„ç”µè§†å‰§ï¼Œåˆ·bç«™ã€‚çœ‹äº†å…³äºäº¤é€šæ²»ç†ä¸ç–«æƒ…é˜²æ§çš„æ–‡ç« ã€‚ç‰¹åˆ«å­¦åˆ°äº†æ–°ä¸œè¥¿ï¼Œå°±æ˜¯çŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£ï¼Œæ‰€äº§ç”Ÿçš„ç°å®æ„ä¹‰ï¼Œå¯é€šè¿‡é™ç»´ï¼Œè·å–å…³é”®æ€§ä¿¡æ¯ï¼Œå¯å¾—ç»“æ„ä¿¡æ¯ã€‚https://mp.weixin.qq.com/s?__biz=MjM5MTM5NDAzNA==&amp;mid=2651320319&amp;idx=1&amp;sn=6a0e27ff1e5b9d0f3cc1d4ac5fff2ef0&amp;scene=19#wechat_redirect ä¸‹åˆæäº†ä¼šæ•°æ® æ™šä¸Šï¼š è§„åˆ’ä¸€ä¼šç»Ÿè®¡å­¦å­¦ä¹  çœ‹äº†ä¸‹è‡ªå·±çš„å¡‘èº«è®¡åˆ’ï¼Œçº æ­£ä½“å‹ï¼Œæ„Ÿè§‰è¿˜å·®å¥½å¤šå•Š çœ‹ä¸‹è‡ªå·±çš„æŠ€èƒ½æ ‘ https://github.com/xiemaycherry/picture/blob/master/%E6%88%91%E7%9A%84%E6%8A%80%E8%83%BD%E6%A0%91.png 2020-06-16 ä»Šå¤©æ—©ä¸Šæ²‰æ€äº†è‡ªå·±æœ€è¿‘çš„è¡Œä¸ºã€‚é‡å»ºäº†è‡ªå·±çš„å„ç§è¡Œä¸ºï¼Œæˆ‘å¯èƒ½è„‘å­é‡Œé¢å°‘äº†ä¸€æ ¹ç­‹ã€‚å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ ä¸‹åˆç»§ç»­æ¬ç –ã€‚æ—©ç‚¹åŠå®Œå§ã€‚å¸Œæœ›æ¯ä¸€æ®µæ²‰æ½œçš„æ—¶å…‰éƒ½å¯ä»¥é—ªé—ªå‘å…‰ã€‚è™½ç„¶åœ¨åˆ«äººçœ‹æ¥æ²¡æœ‰ä»€ä¹ˆæ„æ€ï¼Œä½†æ˜¯æˆ‘ä¾ç„¶è¦åŠªåŠ›!å‘ç°è‡ªå·±ç‰¹åˆ«æ²¡æœ‰è„‘å­å•Šï¼å‘è§‰è‡ªå·±å¤ªç¬¨äº†å§ï¼ï¼ï¼ï¼ï¼ï¼ ä¸‹åˆå’Œçˆ·çˆ·èŠå¤©äº†ï¼Œ æ™šä¸Šå­¦ä¹ äº†æ–°çŸ¥è¯† ç»§ç»­å­¦ä¹ ç»Ÿè®¡å­¦ é‡å¤–ä¸€æ¸¸ å¤è¯—è¯ â€‹ æ„¿æˆ‘å¦‚æ˜Ÿå›å¦‚æœˆï¼Œå¤œå¤œæµå…‰ç›¸çšæ´ã€‚ â€‹ äº‘æƒ³è¡£è£³èŠ±æƒ³å®¹ï¼Œæ˜¥é£æ‹‚æ§›éœ²åæµ“ã€‚ â€‹ æ˜”æˆ‘å¾€çŸ£ï¼Œæ¨æŸ³ä¾ä¾ã€‚ä»Šæˆ‘æ¥æ€ï¼Œé›¨é›ªéœéœã€‚ â€‹ æˆ‘æ–­ä¸æ€é‡ï¼Œä½ è«æ€é‡æˆ‘ã€‚ â€‹ è½çº¢ä¸æ˜¯æ— æƒ…ç‰©ï¼ŒåŒ–ä½œæ˜¥æ³¥æ›´æŠ¤èŠ±ã€‚ â€‹ æ›¾ç»æ²§æµ·éš¾ä¸ºæ°´,é™¤å´å·«å±±ä¸æ˜¯äº‘ã€‚ â€‹ ç§‹é£ç”Ÿæ¸­æ°´ï¼Œè½å¶æ»¡é•¿å®‰ã€‚ 2020-6-15 äºŒæ¬¡å…ƒå°‘å¥³çš„å¾®ç¬‘.jpg å“ï¼Œæˆ‘è¿™æ˜¯æ€ä¹ˆäº†ã€‚è€æ˜¯è¯ä¸è¾¾æ„å•Šï¼ å¸Œæœ›å¤§å®¶ç†è§£æˆ‘ã€‚æˆ‘æ˜¯ä¸€ä¸ªå¾ˆä¸åˆç¾¤çš„äººï¼Œè¿˜æœ‰ç‚¹åæ¿€çš„äººã€‚ä½†ä¸åˆ†åœºåˆçš„å­¦ä¹ ï¼Œæ²¡å…³ç³»çš„å•¦ï¼Œä¸è¦ç®¡æˆ‘ï¼Œæ‰€æœ‰ä»¥åæˆ‘æ³¨æ„ä¸‹è‡ªå·±çš„æ–¹å¼æ–¹æ³•å‡å°‘è¯¯ä¼šå“ˆï¼ï¼ï¼ï¼ï¼å¯¹ä¸èµ·ï¼Œå¯¹ä¸èµ·ï¼Œå¯¹ä¸èµ·ï¼Œå¯¹ä¸èµ·ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ 2020-6-14 å¼€å¿ƒç¡è§‰ing ä»Šå¤©å®¶é‡Œæ²¡æœ‰ç½‘ï¼Œæ–­ç½‘å•Šï¼ å¤ç›˜è¿™å‘¨å·¥ä½œï¼Œæ„Ÿè§‰è¦æŠŠæŸä¸ªçŸ¥è¯†ã€ç†è®ºå­¦åˆ°è„‘å­é‡Œï¼Œä¸å¿˜è®°ï¼Œéšæœºåº”å˜ï¼Œå¤ªéš¾äº†ï¼ â€‹ ç¬¬ä¸€ï¼šè·‘ç¨‹åºã€‚æˆ‘è§‰å¾—è¦è·‘å¤§ç¨‹åºï¼Œæ‰æ˜¯æŠŠç¨‹åºç²¾é«“å­¦åˆ°å®¶ï¼Œæ—¶é—´æ•ˆç‡ã€‚ â€‹ ç¬¬äºŒï¼šé˜…è¯»ã€‚æ˜¾è€Œæ˜“è§çš„ç°è±¡é—®é¢˜å•Šã€‚ â€‹ ç¬¬ä¸‰ï¼šè¯¾ç¨‹ç»“è¯¾ã€‚ å‡ é—¨è¯¾ç¨‹ï¼Œæ„Ÿè§‰ä¸æ˜¯è‡ªå·±å½“åˆæƒ³é€‰çš„ï¼Œå­¦èµ·æ¥æ€ä¹ˆéƒ½ä¸é¡ºå¿ƒã€‚æˆ‘å°±å­¦ä¸æ¥äº†ï¼Œé…ä¸ä¸Šï¼ æœ€ä¸»è¦çš„æ”¶è· â€‹ pandasä¸æ–­æ–°å¢è¡Œçš„æ–¹æ³•ã€‚ â€‹ pandas if çš„ç”¨æ³• 2020-6-15â€”2020-6-21è®¡åˆ’ æ„Ÿè§‰è‡ªå·±æ˜¯å¬è ¢ç¬¨çš„å•Šã€‚ 2020-6-13 ä¸æ‚²ä¸å–œ.png ä»Šå¤©a .å‡ºé—¨æ‹œè®¿äº²æˆšï¼Œèº«å¿ƒç–²æƒ« b. å¥½æƒ³å›å­¦æ ¡å•Šï¼Œæƒ³å¿µé£Ÿå ‚ï¼Œæƒ³å¿µæ‰æ‰å®è´ c. ä»€ä¹ˆèƒ½åŠ›éƒ½åœ¨ä¸‹é™ã€‚ã€‚ã€‚ã€‚ä¸å¥½çš„é¢„æ„Ÿå•Šï¼è¿‡å»å­¦çš„ä¸œè¥¿ï¼Œé•¿æ—¶é—´æç½®ï¼Œå·²ç»å‘éœ‰äº†ï¼Œå•Šï¼Œå•Šï¼Œå•Šï¼Œå•Šï¼Œå•Šï¼Œ å•Šâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” d. è¿˜æ˜¯è¦å¤šå…ƒåŒ–å‘å±•ï¼Œæ„Ÿè§‰è‡ªå·±å·²ç»æ˜¯å•ä¸€ç»´åº¦äº†ï¼Œä¸çŸ¥é“æ€ä¹ˆå›äº‹ã€‚ e. æˆ‘å‘ç°æˆ‘è®°å¿†åŠ›è¡°é€€çš„å¤ªå‰å®³äº†ï¼Œè„‘å­ä¸å¤Ÿçµæ´»ï¼Œä¸ºä»€ä¹ˆå‘¢ã€‚è¦åŠæ—¶è®°å½•å•Šã€‚ å¥½æœ‰æ•ˆç‡é—®é¢˜å•Šï¼Œæ•ˆç‡å•Šï¼Œæ•ˆç‡å•Šï¼Œæ•ˆç‡å•Šï¼ f. çœ‹æ¸…è‡ªå·±ï¼Œç»ˆèƒ½çœ‹ç ´çº¢å°˜ã€‚ ä»Šå¤©ï¼šé‡åˆ°çš„ä¸€äº›é—®é¢˜ï¼š â€‹ 1. å¯¹åº”DataFrameæ•°æ®ç±»å‹çš„è¡Œç´¢å¼•ã€‚åœ¨æ’å…¥æ–°è¡Œçš„é—®é¢˜ï¼Œä»å…¶ä»–DataFrameæˆ–è€…è‡ªå®šä¹‰æ’å…¥ã€‚å¯ä»¥ç”¨append()åœ¨æœ«å°¾æ–°å¢è¡Œï¼Œä½†ä¼ å‚æ•°åˆ‡è®°æ˜¯åˆ—è¡¨ï¼Œæœ€å¥½ç”¨DataFrame 2. è¿˜æœ‰åˆ—è¡¨å’Œå­—ç¬¦ä¸²çš„ç›¸äº’è½¬æ¢ã€‚å¦‚æœè¦æŠŠ[]ä¼ å…¥DataFrame 2020-6-12 ä¸çº ç»“äº†.svg æ˜å¤©å‘¨æœ«äº†ã€‚ä»Šæ™šè¦è¿½å‰§ï¼›è½¦æ°´é©¬é¾™ï¼›åœ¨æœˆå…‰ä¸‹å¥”è·‘ï¼Œæˆ‘ä»€ä¹ˆéƒ½ä¸æƒ³è¦ï¼Œä½ çˆ±æˆ‘å°±å¥½ ä»Šå¤©æ˜¯æ²¡æœ‰è¯¾çš„ä¸€å¤©ã€‚è¿˜æœ‰æ‰æ‰åœ¨å­¦æ ¡äº†ã€‚ 2020-6-11 åŠç¡åŠé†’ : æ˜å¤© â€‹ ä»Šå¤©çš„ä»»åŠ¡æ²¡æœ‰åšå®Œï¼Œæ˜å¤©ç»§ç»­ ä»Šå¤© è·‘ç¨‹åºçš„è¿‡ç¨‹ä¸­ï¼ŒæŠŠæ–‡ä»¶å¤¹æ¸…ç†äº† é‚£ä¹ˆæœ‰è¶£ï¼Œé‚£ä¹ˆæœ‰ä»·å€¼-â€”â€”è¯„åˆ¤å…¬å¹³æ€§æ ‡å‡† å“è¯»äº†ã€Šå–œæ¬¢ä½ æ˜¯å¯‚é™çš„ã€‹ å¬äº†é™ˆå¥•è¿…ã€Šæˆ‘è¦ç¨³ç¨³çš„å¹¸ç¦ã€‹ 2020-6-10 å¼€å¿ƒ.eps æ˜å¤©ï¼š è°ƒç”¨æ—¶é—´åºåˆ—æŒ‡æ ‡ 2. çº¿æ€§å›å½’æ¨¡å‹ 3. è·‘ç¨‹åºï¼Œè®¡ç®—äººæ‰æµåŠ¨æŒ‡æ ‡ ä»Šå¤© æ€è€ƒäº†ä¸€ä¸ªé—®é¢˜ï¼šèŒä¸šè§„åˆ’ã€‚æˆ‘åº”è¯¥æ€ä¹ˆç»™è‡ªå·±ä¸€ä¸ªå®šä½ï¼Ÿæˆ‘å–œæ¬¢ä»€ä¹ˆï¼Ÿæˆ‘å—ä»€ä¹ˆé©±åŠ¨ï¼Ÿ äº¤æ¥äº†ä»»åŠ¡ï¼Œè¢«é—®æƒ¨äº†ã€‚ 2020-6-9 æ„‰æ‚¦.jpg ä»Šå¤©ï¼š ç²¾è¯»äº†ä¸€ç¯‡è®ºæ–‡ï¼Œæ”¶è·æ»¡æ»¡ï¼Œå› ä¸ºéƒ½æ˜¯è‡ªå·±å­¦è¿‡ï¼Œçœ‹è¿‡çš„æ–¹æ³•ï¼Œçœ‹åˆ«äººè®ºæ–‡é‡Œé¢çš„åº”ç”¨ï¼Œæœ‰æ‰€å¯å‘ï¼ä»¥åè¦çœ‹é¡¶çº§çš„èµ„æ–™ å–ç€å®‰æ…•å¸Œï¼Œçœ‹åˆ«äººçš„æ•°æ®åˆ†ææŠ¥å‘Šã€‚ æœ€è¿‘çŸ¥è¯†è¾“å…¥å¤ªè¿‡äº†ï¼Œè™½ç„¶éƒ½æ˜¯æœ¬ç§‘äº†è§£è¿‡çš„ï¼ˆæ•°å­¦æ–¹é¢ï¼‰ é‡è¦è¦æ¸…æ´—å‡ºæ•°æ®ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œæˆ‘å‘ç°æˆ‘çš„æ•°æ®ï¼Œå±…ç„¶åªè¯»äº†åå‡ ä¸‡æ¡ï¼Œç„¶åé‡æ–°è·‘ã€‚ ç­‰å¿™è¿‡äº†è¿™æ®µæ—¶é—´ï¼Œä¸€å®šè¦å¥½å¥½å˜æ¸…æœ€è¿‘çš„æ€è·¯ å¯è§†åŒ– æ•°æ®æ¸…æ´—ï¼špython çº¿æ€§é¢„æµ‹æ¨¡å‹ è®¡é‡ç»æµå­¦ 2020-6-8 å…ƒæ°” å¼€å¿ƒ å–œå‡ºæœ›å¤– æ˜å¤©1. åŸºæœ¬æ•°æ®ç»Ÿè®¡ç»“æœ 2. é¡¹ç›®äº¤æ¥ï¼3. good night ä»Šå¤©æ—©ä¸Šï¼Œå‘ç°å±…ç„¶é”™è¿‡æ–°å‹å† çŠ¶ç—…æ¯’çš„è¯¾ç¨‹ï¼Œå·²ç»ç½‘ä¸Šç»“è¯¾ï¼Œä¸å¾—ä»¥è¯¢é—®è¾…å¯¼å‘˜ã€ç ”ç®¡ç§‘ï¼Œæ‰“äº†å¥½å¤šç”µè¯ã€‚ç ”ç©¶ç”Ÿçš„è€å¸ˆå±…ç„¶ç»™æˆ‘ä»¬é‡æ–°ç»“è¯¾çš„æ—¶é—´ï¼Œå¤ªçˆ±äº†ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼å¤ªæ„Ÿè°¢ï¼Œæ„ŸåŠ¨äº†ï¼ ä»Šå¤©åšäº†çš„æ•°æ®åºåˆ—é¡¹ç›®ä¸Šå‘¨çš„æŠ¥å‘Šï¼ä¸å¾—ä¸è¯´è‡ªå·±æ’ç‰ˆèƒ½åŠ›è¶Šæ¥è¶Šå‰å®³äº†ï¼ ä½†æ˜¯è·‘å¤„ç†çš„æ¨¡å‹ARIMAæ•ˆæœä¸è¡Œï¼è¿˜æœ‰æ„Ÿè°¢å¼ è€å¸ˆæä¾›çš„æœåŠ¡å™¨ï¼æ‰¾åˆ°è·‘ä»£ç çš„æ„Ÿè§‰äº† ä»Šå¤©ç»ˆäºé¢„å¤„ç†å®Œè®ºæ–‡æ•°æ®äº†ï¼Œä½†æ˜¯èƒ½ä¸èƒ½ç”¨å¥½ï¼ŒæŒ–æ˜æ›´å¤§éšè—ä¿¡æ¯ï¼Œè¿˜å¾—åŠ æŠŠåŠ²ï¼ è¿˜æ˜¯è¦å†™å‡½æ•°ï¼Œè€Œä¸æ˜¯å¤åˆ¶ç²˜è´´çš„ ä»Šå¤©é˜…è¯»äº†æœ¬ç§‘åšçš„é¡¹ç›®ï¼Œæ‰¾äº†ä¸¤å¼ å›¾ç‰‡ï¼Œè™½ç„¶å·²ç»è¢«æ‹’ç¨¿äº†ä¸¤æ¬¡ï¼Œä½†æ˜¯æˆ‘åšçš„è¿‡ç¨‹è¿˜æ˜¯æ„‰å¿«ï¼Œæ›´é‡è¦çš„æ‹¿åˆ°è‹±è¯­è¯¾ä¸Šå»å¹ç‰›ï¼å¸Œæœ›å¥½å¥½ææ¥ä¸‹æ¥çš„ç ”ç©¶ï¼ï¼ï¼ï¼ ä¸€äº›è¯»æ–‡çŒ®çš„ç»éªŒå€¼ï¼›æ€ä¹ˆç”¨è¯­è¨€è¡¨è¾¾ä¸åŒåœºæ™¯çš„æ–‡çŒ®å†…å®¹ï¼Œè¿™æ˜¯éœ€è¦åŠ å¼ºçš„ã€‚ è¿™å‘¨åŸºæœ¬ä¸Šç†Ÿæ‚‰äº†pandas,numpyçš„ç›¸å…³æ“ä½œå’Œæ³¨æ„äº‹é¡¹ï¼Œæ¥ä¸‹æ¥è¦æå¥½è¿™ä¸ªé¡¹ç›®(ä¸»çº¿2) ç»§ç»­é˜…è¯»æ–‡çŒ®ï¼Œè§å“¥çš„æ–‡ç«  2020-6-6 ä»Šå¤©åˆæ˜¯å…ƒæ°”æ»¡æ»¡çš„ä¸€å¤©ï¼Œå’Œå¤–å©†ã€å§¨å¦ˆç­‰äº²äººåˆ°æˆ‘å®¶é‡Œé¢åšå®¢ï¼Œåƒäº†ğŸŸï¼›è¿˜æœ‰é‚»å±…è€äººèµ é€çš„ğŸ‘ æ¸©ä¹ äº†numpyçš„ç”¨æ³•ï¼Œnumpy,pandas,listç›´æ¥çš„ç›¸äº’è½¬æ¢å…³ç³»ï¼Œä»¥åŠsklearn metricé‡Œé¢çš„å„ç±»æŒ‡æ ‡ï¼Œä»€ä¹ˆå«æŒ‡æ ‡çš„é²æ£’æ€§ï¼Œæ€ä¹ˆæŒ‰éœ€æ±‚é€‰æˆ–è€…æ„é€ é€‚åˆè‡ªå·±çš„è¯„ä¼°æŒ‡æ ‡ã€‚ è¯»äº†é«˜è§å¸ˆå…„çš„ç»¼è¿°ã€‚ åšäº†æŒ‡æ ‡ä½“ç³»å›¾å’Œé«˜é“ç«™ç‚¹ï¼ˆEdrawä¸­æ–‡å‘ï¼Œæ€ä¹ˆä¸æ˜¯çŸ¢é‡å›¾å•Šï¼ŒVisioç ´è§£ä¸å®‰å…¨ï¼ŒAIè¿˜ä¸çŸ¥é“æ€ä¹ˆæ“ä½œï¼‰ æ˜å¤©å½•è§†é¢‘ï¼Œ 2020-6-5 ä»Šå¤©ç†Ÿæ‚‰äº†æ—¶é—´åºåˆ—æµç¨‹ï¼›1. å¹³ç¨³æ€§ã€‚åºåˆ—å¹³ç¨³æ€§æ˜¯åšåˆ†æçš„åŸºç¡€ã€‚å¹³ç¨³æ€§æ£€æµ‹â€”å•ä½æ ¹ï¼›éå¹³ç¨³æ€§å¤„ç†ï¼šå·®åˆ†~log~åˆ†è§£~å¹³æ»‘å¤„ç†ï¼›2. ARIMAæ¨¡å‹ åŸºæœ¬æ€è·¯ï¼›ç›¸å…³æ€§å’Œåç›¸å…³æ€§å®šé˜¶æ•° 3. ç½‘æ ¼+ä¿¡æ¯å‡†åˆ™ è°ƒå‚ï¼šæƒ©ç½šæ€§ nbeatså·¥å…·å°è£…å¥½äº† 4. predictæ ·æœ¬å†…ï¼ŒåŠ¨æ€å’Œé™æ€é¢„æµ‹ forecaseå¤–æ¨ï¼Œtimedelt ç»˜å›¾ï¼ŒæŒ‡æ ‡ å‡è®¾æ£€éªŒï¼šç»Ÿè®¡é‡å’Œæ˜¾è‘—æ€§æ°´å¹³ï¼Œæ€»æ„Ÿè§‰ç†è§£èµ·æ¥å¤ªéš¾äº†ï¼Œç­‰å¿™äº†ä¸€å®šè¦å¥½å¥½å¤ä¹ ç»Ÿè®¡å­¦ï¼Œå‚æ•°ä¼°è®¡ï¼Œæ˜¾è‘—æ€§æ£€æµ‹ï¼Œå¥½å¥½è¡¥ã€‚ è®°ä¸ä½çš„å‡½æ•° pd.date_range(start = sub.index[-1],end = sub.index[-1]+timedelta(days = 2),freq = â€˜1hâ€™) stat_rawdata = rawdata[rawdata[â€˜ç«™ç‚¹åç§°â€™]==stat] å¸ƒå°”ç±»å‹çš„åˆ‡ç‰‡ï¼Œä¸ä¸Šå¾ˆæ˜ç™½åŸç† plt.xlim(sub.index[0],sub.index[-1]+timedelta(days = 2)) ç»˜åˆ¶çƒ­åŠ›å›¾ seaborné‡Œé¢çš„heamap()123456import numpy as npimport seaborn as snsx = np.random.rand(10, 10)sns.heatmap(x, vmin=0, vmax=1, center=0)plt.show() 2020-6-4ä»Šå¤©æœ€å¤§çš„å¤´ç–¼ä¹‹å¤„å’Œé¢†æ‚Ÿå°±æ˜¯ï¼Œè·‘å¤§å‹ç¨‹åºï¼Œä¸€å®šè¦å‡†å¤‡ä¸€ä»½ä¸‹ç¨‹åºï¼Œè°ƒå¥½ç»“æœæ‰æ”¾åœ¨æœåŠ¡å™¨ä¸Šé¢è·‘ï¼Œä¸ç„¶ç»“æœéš¾ä»¥æƒ³è±¡ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ æ„Ÿè§‰è°ƒåŒ…ä¾ ä¹Ÿä¸æ˜¯æƒ³è±¡ä¸­é‚£ä¹ˆå¥½å½“çš„ï¼Œä¸€æ˜¯ç°å®ä¸­çš„æ•°æ®ä¸€èˆ¬èˆ¬ä¸è§„åˆ™ï¼Œæˆ‘å‘èª“ä»¥åä¸€å®šè¦åšä¸ªåˆæ ¼çš„å®¢æˆ·ï¼ŒäºŒæ˜¯å‚æ•°é»˜è®¤æ˜¯æœ€è®¨åŒçš„ ä»Šå¤©åˆæ”¹ç¨‹åºï¼Œæ•°æ®é¢„å¤„ç†æœç„¶å¤´ç–¼å•Šï¼å¸Œæœ›å‘¨æœ«å¯ä»¥å‡ºä¸ªå¤§æ¦‚ç»“æœï¼Œå†é‡æ–°è·‘æ•°æ® ç»çŸ¥æ­¤äº‹è¦èº¬è¡Œï¼ŒåŸæ¥è§‰å¾—è‡ªå·±å­¦å„ç§åº“è¿˜ä¸é”™ï¼Œå®è·µçš„æ—¶å€™è¿˜æ˜¯ç”¨ä¸ä¸Šçš„æ—¶å€™ï¼ŒğŸ˜” è¿˜æœ‰å°±æ˜¯å‘½åçš„é‡è¦æ€§ï¼Œ å‡†å¤‡å‡ºä¸€ç¯‡å®è·µçš„å¿ƒå¾—ï¼Œæœˆæœ«ï¼Œä¸»è¦æ˜¯ç°åœ¨å†™ç¨‹åºå¤ªå®‰é€¸äº†ï¼Œ çŸ¥è¯† pandasæ–°å¢åˆ— æ›´æ”¹ç´¢å¼• range() è¡Œæ”¿å•ä½ï¼Œå˜æ›´æƒ…å†µ å‡½æ•°ï¼Œå†™å‡½æ•°ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œåƒpythonè¿™ç§è§£é‡Šå‹çš„è¯­è¨€ï¼Œè‡ªå·±è€æ˜¯é‡å¤ï¼Œä¸å¥½ï¼Œä¸å¥½ï¼Œ 2020-6-3ä»Šå¤©è¿˜æ˜¯å­¦äº†ä¸å°‘ä¸œè¥¿ï¼Œæ•ˆç‡ä¸é«˜ï¼Œä¸»è¦æ˜¯è®°ä¸ä½å‡½æ•°ä¼ å‚æ•°ï¼ æŒæ¡äº†ä¸€äº›pythonicçš„ç”¨æ³•ï¼Œæƒ³in for if ; if else çš„ä¸€è¡Œä»£ç ï¼›lambdaå•è¡Œå‡½æ•°åŠŸèƒ½çš„ç®€åŒ–ç­‰ç­‰ ä¸€äº›å¸¸ç”¨çš„æ•°æ®åˆ†æå‡½æ•°ï¼Œsort_values();concat; append; time_range();ç»˜å›¾åŠŸèƒ½ï¼›å°±æ˜¯å°±ä¸çŸ¥é“ï¼Œè‚¯å®šæ˜¯åˆ«äººå·²ç»å°è£…å¥½äº†ï¼ 2020-6-2ä»Šå¤©æ€»ä½“è¿˜æ˜¯æ»¡ä¸é”™çš„ï¼ è·‘äº†å¤§ç¨‹åºï¼Œè‡ªå·±çš„ç”µè„‘å’ŒæœåŠ¡å™¨çš„æ•ˆæœè¿˜çœŸæ˜¯ä¸ç›¸åŒã€‚ä¸è¿‡ï¼Œèƒ½å¤Ÿåšåˆ°200è¡Œå†…ä¸è°ƒè¯•å°±èƒ½å¥½äº†ï¼Œç°åœ¨æ‰¾åˆ°äº†å†™ä»£ç çš„æ„Ÿè§‰ï¼Œè™½ç„¶è¿˜æ˜¯bug~bug~bug, åŸå› åœ¨äºå¼€å§‹äº¤æ¥å·¥ä½œæ²¡æœ‰åšå¥½ï¼Œå¯¼è‡´ååå¤å¤çš„ä¿®æ”¹codes. åœ¨å¸ˆå…„çš„ä»‹ç»ä¸‹ï¼Œæ¥äº†ä¸€ä¸ªæ—¶é—´åºåˆ—çš„é¡¹ç›®ã€‚åœ¨æ¯•ä¸šè®¾è®¡é‚£ä¼šï¼Œè·‘å¤©ç„¶æ°”æ•°æ®ï¼Œå‡ºæ¥äº†çš„ç»“æœå¤ªå·®äº†ï¼Œä¹Ÿä¸çŸ¥é“why,è¿™æ¬¡å¸Œæœ›èƒ½å¤Ÿè·Ÿè¿›è¿™ä¸ªé¡¹ç›®ã€‚ æ„Ÿè§‰è‡ªå·±è¿˜ç•™æœ‰ä½™åœ°ï¼Œè¿˜æ²¡æœ‰æ¢å¤åˆ°æœ€ä½³çŠ¶æ€å‘~ 2020-6-1ä»Šå¤©åˆšå¥½æ˜¯2020å¹´çš„ä¸€åŠï¼Œå¿™å®Œç¬¬ä¸€å­¦æœŸï¼ˆåŠæ¢¦åŠé†’ï¼‰,æœ€ç»ˆå¦‚æ¢¦åˆé†’ï¼ä»Šå¤©æ¥è§¦è®¸å¤šæ–°é²œçš„ç©æ„ï¼š ArcMapç»˜åˆ¶åœ°å›¾ã€æµå‘å›¾ï¼ˆå…³é”®æ˜¯èµ·ç‚¹å’Œç»ˆç‚¹åæ ‡ï¼Œå¦‚ä½•æ ¹æ®åç§°è·å–åæ ‡ï¼Œè¦åšè¿æ¥ã€‚Arc ToolBoxä¸­æä¾›äº†è®¸å¤šå·¥å…·ï¼Œæ–¹ä¾¿äº†ç”¨æˆ·å®Œæˆä¸€äº›ç®€å•çš„æ“ä½œï¼Œå¦‚Joinã€Excel to Tabelå¸¸ç”¨çš„å·¥å…·ç®±ã€‚ä»Šå¤©å­¦ä¹ ç»˜åˆ¶åœ°å›¾å’Œæµå‘å›¾æ¶‰åŠçš„æ“ä½œåŒ…æ‹¬ï¼šæ–‡ä»¶å¤¹é“¾æ¥åˆ°å·¥ä½œç›®å½•ï¼›ArcMapå¯¼å…¥Excelåæ ‡æ•°æ®å¹¶æ˜¾ç¤ºï¼›XY to Lineå·¥å…·æµå‘å›¾ï¼›æå–é¢è¦ç´ çš„è´¨å¿ƒç‚¹ï¼›å¤šè¡¨é“¾æ¥æ“ä½œï¼›å±æ€§è®¾ç½®ï¼ˆbar)ã€‚æ¸²æŸ“ç»“æœçš„ç¡®æ¼‚äº® linuxç³»ç»Ÿåç«¯è¿è¡Œ nohup &amp;å‘½ä»¤çš„ä½¿ç”¨ï¼Œå¦‚ä½•è®°å½•æ—¥å¿—æ–‡ä»¶ï¼Œå®šå‘è¾“å‡ºï¼›å­¦äº†pså‘½ä»¤ ps æŸ¥çœ‹è¿›ç¨‹ï¼›è¿˜æœ‰|é€šé“ï¼ŒgrepæŸ¥æ‰¾ï¼› ps -ef| grep pyton matplotlibç»˜å›¾çš„åŸç†ã€‚ 123456789101112131415åˆ›å»ºfigureåï¼Œè¿˜éœ€è¦è½´fig = plt.figure()ax1 = fig.add_subplot(221)ax2 = fig.add_subplot(222)ax3 = fig.add_subplot(224)fig, axes = plt.subplots(nrows=2, ncols=2)axes[0,0].set(title=&apos;Upper Left&apos;)axes[0,1].set(title=&apos;Upper Right&apos;)axes[1,0].set(title=&apos;Lower Left&apos;)axes[1,1].set(title=&apos;Lower Right&apos;)axes[0,0].plot()axes[0,0].set_xlim([-1,6])axes[0,0].legend() matplotlib.plotçš„åŸºç¡€ç»˜å›¾æµç¨‹ï¼š åˆ›å»ºç”»å¸ƒï¼ˆé€‰æ‹©æ˜¯å¦ç»˜åˆ¶å­å›¾ï¼ŒæŒ‡å®šç”»å¸ƒå¤§å°ï¼Œåƒç´ ï¼‰æ·»åŠ æ ‡é¢˜â€”æ·»åŠ xè½´çš„åç§°ï¼Œåˆ»åº¦ä¸èŒƒå›´â€”æ·»åŠ yè½´çš„åç§°ï¼Œåˆ»åº¦ä¸èŒƒå›´ç»˜åˆ¶å›¾å½¢ï¼Œè®¾ç½®å›¾å½¢çš„æ ·å¼ï¼Œé¢œè‰²ï¼ŒèƒŒæ™¯ï¼Œå¹¶æ·»åŠ å›¾ä¾‹ä¿å­˜å›¾å½¢ï¼Œæ˜¾ç¤ºå›¾å½¢ æ„Ÿè°¢çˆ·çˆ·æä¾›çš„CSDNè´¦å· ä¸‹è½½ä¸å°‘èµ„æ–™ï¼Œä¸€æ¬¡æ€§è§£å†³å®Œäº†ï¼ 2020-5-31 è¿™æ˜¯ä¸Šå®Œç ”ç©¶ç”Ÿç¬¬ä¸€å­¦æœŸä¸Šï¼Œç¬¬äºŒå­¦æœŸä¸‹ä¸­æ—¬ï¼ä¹Ÿæ˜¯éš”äº†å¾ˆä¹…æ‰æ›´æ–°ä¸ªäººè®°å½•ã€‚ç ”ä¸€ä¸Šï¼Œæ¢äº†ä¸€ä¸ªæ–°ç¯å¢ƒï¼Œç»ˆäºæœ‰ä¸ªç‰¹åˆ«èˆ’é€‚çš„ç¯å¢ƒäº†ï¼å¤§å±å¹•ï¼ŒæŸ”è½¯çš„å‡³å­,å¤ªèˆ’æœäº†ï¼æ€å¯è¾œè´Ÿå‘¢ã€‚ç”µç§‘çš„è¯¾ç¨‹å®åœ¨æ˜¯å¤ªå¤šäº†ï¼Œéƒ½ä¸èƒ½å®‰å¿ƒç©è€äº†ï¼è¿™æ®µæ—¶é—´ç®—ä¸ªç§¯æ·€å§ï¼ 2019.6.2 ä»Šå¤©æ‰æ¥å†™ï¼Œç½ªè¿‡å•Šï¼è€å¸ˆä¸åœ¨ï¼Œå®¤å‹ä¸åœ¨ï¼Œæ— èŠè‡³æï¼Œåªèƒ½ä»¥è§†é¢‘å”¯å‹ï¼Œè§£é—·ä¹Ÿï¼ç¡äº†ä¸€ä¸ªæ˜ŸæœŸï¼Œä½†æ˜¯æˆ‘ç˜¦äº†2æ–¤äº†ã€‚å¼€å§‹ä¸åœ¨æ‡’æƒ°äº†ï¼Œåœ¨è¿™æ ·ä¸‹å»æˆ‘å°±å®Œè›‹äº†ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ ä¸çŸ¥é“æ€ä¹ˆå›äº‹ï¼ŒVPNè€æ˜¯ time out ,æ˜æ˜è¿˜æœ‰$å•Šï¼ é€ æˆäº†åªèƒ½ä¸€æ®µä¸€æ®µç¿»è¯‘ï¼Œæ— è¯­å‡å™ing è¿˜æœ‰ç™¾åº¦ä¸Šè¯´æ˜¯ä¸¤ç¯‡ï¼Œå¯æ˜¯è¦æ±‚æ˜¯ä¸€ç¯‡ï¼Œäºæ˜¯æˆ‘å¤šèŠ±äº†2h,å¤©æ€çš„ï¼ï¼ï¼ ä¸‹åˆè·‘äº†ä¸ªæ­¥ï¼Œ è¶Šæ¥è¶Šå‘ç°ï¼Œäº‹å…ˆè®¡åˆ’ä¸€ä¸‹ï¼Œå†å»åšï¼Œæ•ˆç‡æ›´å¥½äº†ï¼ 2019.5.12 ä»Šå¤©æ‰æ¥æ›´æ–°è¿™ä¸ªæ—¥å¸¸ï¼ŒçœŸæ˜¯ç½ªè¿‡ï¼Œä¸Šæ®µæ—¶é—´ä¸€ç›´å¿™å…¶ä»–çš„äº‹æƒ…ï¼Œæ¯•ä¸šè®¾è®¡ï¼Œå›å®¶ï¼Œå¤„ç†å®¶åŠ¡å•Šã€‚ç›´åˆ°ä»Šå¤©å­¦å®Œäº†Course 3,å¦‚ä½•æ”¹å–„ç¥ç»ç½‘ç»œçš„æ€§èƒ½ï¼Œè¿˜æœ‰è‹±è¯­å­¦ä¹ ï¼Œä¸€å®šè¦åŠ æ²¹å•Šï¼ 2019.4.18 ä»Šå¤©å­¦äº†ä¸€éƒ¨åˆ†course two week twoçš„è¯¾ç¨‹ï¼Œç»ˆäºå­¦åˆ°ç²¾å½©çš„éƒ¨åˆ†äº†ï¼Œç”±äºä»Šå¤©æƒ³ç»ƒå½©é“…å’Œå¸®å¿™æ”¶æ‹¾æ•™å®¤ï¼Œæ‰€ä»¥å°±æ²¡æœ‰å­¦å®Œäº†ï¼Œå­¦äº†å‡ ç§å˜ç§çš„æ¢¯åº¦ä¸‹é™æ³•ï¼Œæé«˜é€Ÿåº¦ï¼Œå¤ªæ£’äº†ï¼Œå¤ªæ£’äº†ï¼Œå¤ªæ£’äº†ï¼ï¼ï¼ï¼ï¼ï¼ 2019.4.17 ä»Šå¤©å­¦å®Œå›½course twoçš„ç¬¬ä¸€å‘¨è¯¾ç¨‹ï¼Œå¤§æ¦‚è®°æ—¶4hï¼Œè¿˜æ˜¯é¢‡å¤šæ”¶è·ï¼Œå­¦åˆ°äº†ä»¥å‰å®Œå…¨æ²¡æœ‰æ¥è§¦çš„ä¸œè¥¿ï¼Œæ­£åˆ™åŒ–æ–¹æ³•ï¼Œæ¢¯åº¦æ¶ˆå¤±çš„å’Œçˆ†ç‚¸çš„é—®é¢˜ï¼Œæ„Ÿè§‰å¾ˆæ£’ï¼Œ 2019.4.16 ä»Šå¤©å­¦äº†å´æ©è¾¾è€å¸ˆçš„ç¬¬ä¸€å‘¨å…³äºç¥ç»ç½‘ç»œçš„åŸºç¡€çš„è¯¾ç¨‹ï¼Œå¥½å‰å®³çš„ 2019.4.15 ä»Šå¤©å­¦ä¹ äº†deep-layer neural networkçš„æ­£å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„è¿‡ç¨‹ï¼ŒçŸ©é˜µåŒ–è®¡ç®—çš„æ–¹å¼ã€‚ 2019.4.14 ä»Šå¤©å­¦ä¹ äº†ç¬¬ä¸‰å‘¨è¯¾ç¨‹ï¼Œshallow (2å±‚)ç¥ç»ç½‘ç»œçš„æ­£å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œä»¥åŠçŸ©é˜µåŒ–çš„è®¡ç®—æ–¹å¼ï¼Œä»¥åŠå’Œlogistics regressionçš„è¡¨ç¤ºä¸Šçš„ä¸åŒåœ°æ–¹ 2019.4.13 ä»Šå¤©ç»§ç»­å­¦ä¹ ç¬¬äºŒå‘¨è¯¾ç¨‹ï¼Œlogistics regression çš„æ¨¡å‹ï¼Œç­–ç•¥ï¼Œç®—æ³•çš„ç›¸å…³ï¼Œå¦‚ä½•æŠŠå­¦ä¹ çš„åˆ°æ•°å­¦çŸ¥è¯†åº”ç”¨ä¸Šå»ã€‚ 2019.4.12 ä»Šå¤©æ²¡æœ‰å»è·‘æ­¥ï¼Œå¤„ç†ä¸€äº›æƒ…æ„Ÿé—®é¢˜å»äº†ï¼Œå­¦äº†Androw Ngçš„ ç¬¬äºŒå‘¨çš„éƒ¨åˆ†è¯¾ç¨‹ï¼Œä¸»è¦æ˜¯é“¾å¼æ±‚å¯¼æ³•åˆ™ï¼Œé€šè¿‡è®¡ç®—å›¾ï¼Œä¸€æ­¥ä¸€æ­¥çš„å¤åˆæ±‚å¯¼ï¼Œå¤åˆå‡½æ•°ç”¨è®¡ç®—å›¾è¡¨ç¤ºï¼Œå¹¶é“¾å¼æ±‚å¯¼ 2019.4.11 ä»Šå¤©æ˜¯å¾ˆæ„‰å¿«çš„ä¸€å¤©ï¼Œèµ·çš„å¾ˆæ—©ï¼Œç²¾ç¥å¾ˆè¶³ï¼Œå­¦äº†å­¦ä¹ ï¼Œå†™å®Œäº†å´æ©è¾¾è€å¸ˆçš„ç¬¬ä¸€å‘¨æ·±åº¦å­¦ä¹ ã€‚ 2019.4.10 ä»Šå¤©åˆ·å®Œäº†ç¬¬ä¸€éï¼Œå®Œäº†è¥¿ç“œä¹¦ç¬¬ä¸€ç« åˆ°ç¬¬åä¸€ç« ï¼Œä¸è¿‡å‘¢ï¼Œè¿˜æ˜¯è¦ç»§ç»­åœ¨åˆ·åŸºç¡€è¿˜çœ‹è®ºæ–‡ è¿™æ®µæ—¶é—´ï¼Œè·‘æ­¥é”»ç‚¼ç¬¬ä¸€ï¼Œç¡è§‰ï¼Œè´ªç¡ç¬¬äºŒï¼Œç¬¬ä¸‰ï¼Œå¼€å§‹æ•£æ¼«äº†ï¼Œè‡ªå¾‹çš„æˆ‘ï¼Œåœ¨å“ªé‡Œå»äº†å•Šï¼ äº‰å–åœ¨ä¸Šç ”ç©¶ç”Ÿè¿™æ®µæ—¶é—´ï¼ŒæŠŠæœºå™¨å­¦ä¹ ã€Pythonç¼–ç¨‹èƒ½åŠ›æå‡ä¸Šå» ä»Šå¤©æ™šä¸Šå¼„äº†ä¸€ä¸ªï¼Œå´æ©è¾¾çš„deep Learning Aiè¯¾ç¨‹ç¬”è®°ï¼Œå¼€å§‹å­¦ä¹ è¿™ä¸ªç³»åˆ—çš„è¯¾ç¨‹äº† ç¬”è®°æ¨¡æ¿ è‹±æ–‡ï¼šhttp://dl-notes.imshuai.com/#/](http://dl-notes.imshuai.com/#/c1w1) ä»€ä¹ˆéƒ½æœ‰çš„ https://redstonewill.com/category/deeplearning/ ä¸­æ–‡ç¬”è®°ï¼š è¯¦ç»†ï¼Œç›¸å½“äºç¿»è¯‘ï¼š http://www.ai-start.com/dl2017/html/lesson1-week1.html æ€è€ƒå’Œæ€»ç»“ï¼š https://link.zhihu.com/?target=http%3A//kyonhuang.top/Andrew-Ng-Deep-Learning-notes/ https://zhuanlan.zhihu.com/p/35333489 http://imshuai.com/tag/deeplearning-ai-notes/ https://zhuanlan.zhihu.com/koalatree ä¸Šç­æ—çš„å­¦ä¹ æ—¶é•¿ï¼š æ•´ç†ç¬”è®°è¦æ˜æ˜¾æ¶ˆè€—æ›´å¤šçš„æ—¶é—´ï¼ŒåŸºæœ¬ä¸Š10åˆ†é’Ÿçš„è§†é¢‘ï¼Œåšç¬”è®°è‡³å°‘è¦50åˆ†é’Ÿæ‰èƒ½çœ‹å®Œã€‚æ¯å‘¨çš„è§†é¢‘å¤§æ¦‚åœ¨2-3ä¸ªå°æ—¶ï¼Œè¿™å°±æ„å‘³ç€çœ‹å­¦ä¹ è§†é¢‘å°±è¦10-15ä¸ªå°æ—¶ã€‚ç¼–ç¨‹ä½œä¸š3ä¸ªå°æ—¶å·¦å³ï¼Œæ¯å‘¨å¹³å‡åœ¨15ä¸ªå°æ—¶ï¼Œ16å‘¨çš„è¯¾ï¼Œå‡€æ—¶é—´å°±èŠ±äº†240ä¸ªå°æ—¶ï¼ video https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists è¥¿ç“œä¹¦çš„å…¬å¼æ¨å¯¼ï¼š https://datawhalechina.github.io/pumpkin-book/#/chapter1/chapter1 ç»Ÿè®¡æœºå™¨å­¦ä¹ ï¼š https://github.com/SmirkCao/Lihang 2019.3.23-2019.3.24 ä»Šå¤©ï¼ˆä»Šå¤©ï¼‰æ˜¯å‘¨æœ«ï¼Œä¸¤ä¸ªæ—©ä¸Šéƒ½ç¡è§‰å»äº†ï¼Œå¤„ç†ä¸€ä¸‹ï¼Œæˆ‘å¼Ÿå¼Ÿçš„é—®é¢˜ï¼Œå’Œå­©å­äº¤æµçš„é‡è¦æ€§ï¼Œæ™šä¸Šä»€ä¹ˆéƒ½æ²¡æœ‰å¹²ï¼Œå‘¨æ—¥ä¸‹åˆè·‘äº†æ­¥ï¼Œå­¦ä¹ äº†python sci-learné‡Œé¢çš„äº¤å‰éªŒè¯ã€è¶…å‚æ•°é€‰æ‹©ï¼Œé›†æˆå­¦ä¹ åº“çš„ç”¨æ³•ï¼Œç»ˆäºä¸å†è¿·èŒ«äº†ï¼Œæ…¢æ…¢æ¥ åŠæ—¶çš„è®°å½•å­¦ä¹ è¿‡ç¨‹ å¤šå»çœ‹åˆ«äººçš„è¿›å±• å»åšåˆ«äººæ²¡æœ‰åšè¿‡çš„äº‹æƒ… åªæœ‰ä½ åŠªåŠ›ï¼ŒåŠªåŠ›çš„æ–¹å‘æ˜¯æ­£ç¡®çš„ï¼Œå°±å¯ä»¥åšå‡ºä¼Ÿå¤§çš„æˆå°± https://zhuanlan.zhihu.com/p/29704017 2019.3.21 ä»Šå¤©äº†è§£ä¸€ä¸‹æ“ç›˜ï¼Œå°±æ˜¯é‚£ä¸ªè‚¡ç¥¨ï¼Œæ„Ÿè§‰åšæ•°æ®ç§‘å­¦å®¶å¥½åƒé¦™å•Šï¼ŒåŠ æ²¹ï¼Œæ¥ä¸‹æ¥æœ‰å¾—å¿™äº† 2019.3.20 ä»Šå¤©ç»ˆäºçœ‹äº†æ–‡çŒ®ï¼Œæƒ³å‡ºäº†ä¸€ä¸ªåˆ›æ–°ç‚¹å­ï¼Œå¯ä»¥å‘æ–‡ç« äº†ï¼ŒåŠ æ²¹å–”ã€‚ ç¼–å†™å®Œäº†æµ‹è¯•ç¨‹åºï¼ŒåŠ æ²¹ 2019.3.19 ä»Šå¤©æ—©ä¸Šçœ‹äº†å…³äºè®¸å¤šç°è‰²æ¨¡å‹çš„ç°é˜¶æ®µæ–‡çŒ®ï¼Œå¾ˆå—å¯å‘ï¼Œæ„Ÿè§‰è¯»æ–‡çŒ®çœŸçš„å¯¹èƒ½åŠ›ã€æ€ç»´çš„æé«˜å¾ˆå¤§ï¼Œä¹Ÿå‘ç°è‡ªå·±çš„æ½œåŠ›å¾ˆå¤§ï¼ŒåŠ æ²¹ï¼ŒåŠ æ²¹ï¼ŒåŠ æ²¹ï¼Œç»§ç»­è¯»ï¼Œäº§ç”Ÿä¸€äº›å°ç‚¹å­ï¼Œè™½ç„¶ä¸å¤Ÿå¥½ï¼Œä½†æ˜¯ä¹Ÿæ˜¯çªç ´ 2019.3.18 ä»Šå¤©çœ‹ç—…å»äº†ï¼Œç¡äº†å¥½ä¹…ï¼Œè¯ç‰©ä½œç”¨æœç„¶å‡ºä¹æ„æ–™ï¼Œ 2019.3.17 ä»Šå¤©ä¸»è¦å­¦ä¹ æ”¯æŒå‘é‡æœºçš„å‰ä¸–ä»Šç”Ÿï¼Œæ€ä¹ˆç”±æ¥çš„ 2019.3.16 ä»Šå¤©å‘¨å…­ï¼Œæ”¾æ¾äº†ä¸€ä¸‹è‡ªå·±ï¼Œé‡æ–°å›å½’ä¸€ä¸‹ç°è‰²é¢„æµ‹æ¨¡å‹ï¼Œå°¤å…¶æ˜¯ç¦»æ•£æ–¹ç¨‹ï¼Œå…¶å®å»æ‰èƒŒæ™¯ï¼ŒæŠ“ä½æ•°å­¦æ¨¡å‹ï¼Œæ‰çŸ¥é“å…¶å®å°±æ˜¯è¿™æ ·çš„ï¼Œå¸Œæœ›æ—©æ—¥çªç ´è‡ªå·±çš„ç•Œé™ 2019.3.14 ä»Šå¤©æ”¹äº†è®ºæ–‡ï¼Œæ„Ÿè§‰å¿«å®Œäº†ï¼›å­¦ä¹ äº†BPçŸ©é˜µæ¨å¯¼ï¼ŒäººçœŸçš„æ˜¯è¶Šæ¥è¶Šèªæ˜å’Œçµæ´» 2019.3.13 ä»Šå¤©æ™šä¸Šå­¦å®Œäº†å›å½’æ ‘ï¼Œå¥½æ£’ï¼Œè™½ç„¶åŸç†ç»™äººçš„æ„Ÿè§‰å¾ˆç›´æ¥ï¼Œä½†æ˜¯ä¹Ÿæ˜¯ä¸€ç§ä½“ç° 2019.3.12 ä»Šå¤©è·‘äº†æ­¥ï¼Œæ—©ä¸Šæ”¹äº†æ¯•ä¸šè®¾è®¡ï¼Œä¸‹åˆé…ç½®äº†æ–°æ‰‹æœºï¼Œæ™šä¸Šå†™äº†æ—¥è®° 2019.3.11 ä»Šå¤©æ—©ä¸Šå¬äº†å¬åŠ›ï¼Œä¿®æ”¹äº†æ¯•ä¸šè®¾è®¡ï¼Œæ ¸å‡½æ•°è¿˜æ˜¯ä¸æ˜¯å¾ˆæ‡‚ï¼›ä¸‹åˆçœ‹äº†å†³ç­–å›å½’æ ‘ï¼Œæ„Ÿè§‰å¾ˆæ£’ï¼Œè¿‡æ‹Ÿåˆæ‰æ˜¯è¯¥è§£å†³çš„å…³é”®é—®é¢˜ï¼è·‘äº†æ­¥ï¼Œæ„Ÿè§‰è‡ªå·±èº«ä½“çŠ¶å†µå¾ˆä¸å¥½å•Šï¼ æ™šä¸Šå¬åŠ›ç”µå°ï¼Œå†™äº†ç¨‹åºï¼ æ…¢æ…¢çš„å­¦ä¹ ï¼Œæ…¢æ…¢çš„åŠªåŠ›ï¼Œæ…¢æ…¢çš„åŠ æ²¹ï¼Œæ…¢æ…¢çš„é‡è§è‡ªå·±çš„æ†§æ†¬å¤©ç©º 2019.3.10 ä»Šå¤©å†™äº†æ—¥è®°ï¼Œè¯´ä¸ä¸Šè‡ªå·±å“ªé‡Œéƒé—·ï¼Œå“ªé‡Œå¼€å¿ƒï¼å¸Œæœ›æ—©ç‚¹è·‘å®Œç¨‹åºï¼Œæ—©ç‚¹å®Œäº‹ 2019.3.9 ä»Šå¤©æ‰å‘ç°ï¼Œæœ€è¿‘çŠ¶æ€éå¸¸çš„ä¸å¥½ï¼Œå¯èƒ½æ˜¯æ— æ‰€äº‹äº‹å§ï¼Œå¯æ˜¯æˆ‘æœ‰å¾ˆå¤šäº‹æƒ…è¦åšï¼ŒåŠ æ²¹ï¼Œå°‘å¥³ï¼ŒåŠ æ²¹ï¼Œå°‘å¥³ï¼Œä»¥åä¸€å®šè¦è®°å¾—å†™äº†!æ€»è§‰å¾—è‡ªå·±é€ƒä¸å‡ºè‡ªå·±çš„ç¾ç»Šï¼Œè¢«æŸç¼š 2019.2.28ä»Šå¤©è°ƒæ•´è‡ªå·±çš„å¿ƒæ€ï¼Œå›é¡¾è‡ªå·±çš„ç”Ÿæ´»ï¼Œè‡ªå·±å¤ªæ€¥äºæ±‚æˆäº†ï¼Œå¿ƒæ€¥åƒä¸äº†çƒ­è±†è…å•Šï¼ï¼ï¼ï¼ï¼ä¸­å›½æœ‰å¥è€è¯è¯´å¾—å¯¹ï¼Œç§¯å°‘æˆå¤šï¼Œä¸ç§¯è·¬æ­¥æ— ä»¥è‡³åƒé‡Œï¼Œä¸ç§¯å°æµæ— ä»¥æˆæ±Ÿæ²³ï¼Œæ…¢æ…¢æ¥ï¼Œå¼„é€å¼„æ¸…æ¥š æœ€åï¼Œè‹±è¯­+æ•°å­¦+ç¼–ç¨‹+è§£å†³é—®é¢˜çš„èƒ½åŠ› 2019.2.27ä»Šå¤©æ—©ä¸Šï¼Œæˆ‘è¯»äº†åŒæ ¡åŒå­¦å†™çš„ç®€ä¹¦æ–‡ç« ï¼Œå®åœ¨æ˜¯æ„Ÿåˆ°å¥½æƒ³ç¬‘ï¼Œæœç´¢äº†åˆ«äººçš„è§£å†³æ–¹æ³•ï¼Œè¿˜æ˜¯è‡ªå·±çš„çŸ¥è¯†é‡ä¸è¶³å•Šï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ä¸‹åˆçœ‹äº†ä¸‹å‡è®¾æ£€éªŒçš„è§†é¢‘ï¼Œå†å»è·‘äº†ä¸¤ä¸ªå°æ—¶çš„æ­¥ æ™šä¸Šé€›äº†ä¸€ä¸‹åˆå„ä½ç½‘ç«™ 2019.2.26ä»Šå¤©çœ‹äº†ä¸‹æŸä¸ªè®¡ç®—æœºå¤§ä½¬çš„å†ç¨‹ï¼Œæ·±æ·±åœ°æ„Ÿåˆ°ä½©æœã€‚ã€Šæ¢¦æƒ³å°é•‡ã€‹åˆå¤šäº†ä¸€å—åœ°ç›˜äº†ï¼Œ åˆé‡æ–°å­¦ä¹ äº†matplotlib,æ‰å‘ç°,ç„¶åäº†ç©äº†ä¸€ä¸‹sklearné‡Œé¢çš„å¸¦cross-validationçš„lassoçš„regression å†kaggle housr-prices é‡Œé¢ï¼Œrmse=$0.15386$,rank = 2903,ä¸è¿‡åšå¾—ä¹Ÿç›¸å½“ 2019.02.25 ä»Šå¤©å¥½åƒä¸åœ¨çŠ¶æ€ï¼Œå¯èƒ½æ˜¯ç„¦è™‘+è¿·èŒ«ï¼Œæœ‰åŠ¨åŠ›ï¼ŒåŠ¨åŠ›çš„æ–¹å‘åœ¨å“ªé‡Œå•Šï¼ï¼Œè¿˜æ˜¯å¥½å¥½çš„åšå¥½å½“ä¸‹å§ï¼ é˜¿è¥¿å§ 2019.02.24ä»Šå¤©ç‰¹åˆ«ä¸æƒ³èµ·åºŠï¼Œæœ‰ç‚¹å°æ„Ÿå†’ï¼Œæ•´ç†å‘¨å¿—åçš„ç¬¬ä¸€ç« ç¬”è®°ä¸‹åˆæ€»ç»“æ—¥å‰å­¦ä¹ çš„pythonåº“é¡ºä¾¿å»kaggleåšäº†å°ç»ƒä¹ ï¼Œæ•°æ®çš„é¢„å¤„ç†å·¥ä½œã€‚]]></content>
      <categories>
        <category>å­¦ä¹ ã®å†ç¨‹(Journal of Studying)</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
</search>
