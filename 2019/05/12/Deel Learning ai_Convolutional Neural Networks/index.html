<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="baidu-site-verification" content="E1Di33CelZ">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<meta name="google-site-verification" content="WsojkhmMcOefku3B2Vxp02NtxlUt_JzBP1fVPrFk3Gw">


  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.0.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.4">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.4" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.0.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: 'WGLQQAQKBA',
      apiKey: '',
      indexName: 'xiemay',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  



<meta name="baidu-site-verification" content="z0tVDge8Pe">

  
  <meta name="keywords" content="Deep learning,">


<meta name="description" content="C4 : Convolutional Neural Networks(卷积神经网络)W1 :Convolutional Neural Networks(卷积神经网络)L1: Computer Vision Image classification Object detection Neural Style Transfer  Problem : input big  神经网络结构复杂，数据量相对较">
<meta name="keywords" content="Deep learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Networks">
<meta property="og:url" content="http://xiemaycherry.github.io/2019/05/12/Deel Learning ai_Convolutional Neural Networks/index.html">
<meta property="og:site_name" content="welcome">
<meta property="og:description" content="C4 : Convolutional Neural Networks(卷积神经网络)W1 :Convolutional Neural Networks(卷积神经网络)L1: Computer Vision Image classification Object detection Neural Style Transfer  Problem : input big  神经网络结构复杂，数据量相对较">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Different-edges.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1——2.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_3png.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_4png.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutional-operation.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_5.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_1.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_2.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_3.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_4.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_5.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Padding.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Stride.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutions-on-RGB-image.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_8.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_9.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_10.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_11.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_12.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_13.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-33.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_14.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_15.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_16.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_17.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/CNN.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_18.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_19.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_20.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-34.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-35.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-36.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_21.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Residual-Network.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/ResNet-Training-Error.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_22.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-37.jpg">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_23.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/99f8fc7dbe7cd0726f5271aae11b9872.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/The-problem-of-computational-cost.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Using-1x1-convolution.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_24.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_25.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_1.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_2.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_3.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_4.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_5.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_1.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_2.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_3.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_4.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_5.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_6.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_7.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_8.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_10.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_11.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_12.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_13.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_14.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_16.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_15.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_17.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_18.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_19.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_20.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_21.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_22.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_23.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_24.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_25.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_26.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_27.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_28.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_29.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_1.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_2.png">
<meta property="og:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_3.png">
<meta property="og:updated_time" content="2019-05-21T09:01:58.955Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Networks">
<meta name="twitter:description" content="C4 : Convolutional Neural Networks(卷积神经网络)W1 :Convolutional Neural Networks(卷积神经网络)L1: Computer Vision Image classification Object detection Neural Style Transfer  Problem : input big  神经网络结构复杂，数据量相对较">
<meta name="twitter:image" content="http://xiemaycherry.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/MyBlog/hexo/source/_posts/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Different-edges.png">






  <link rel="canonical" href="http://xiemaycherry.github.io/2019/05/12/Deel Learning ai_Convolutional Neural Networks/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>Networks | welcome</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
<meta name="baidu-site-verification" content="3BmH9zSH5h"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">welcome</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
        </li>
      
        
        <li class="menu-item menu-item-留言">
          <a href="/guestbook/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-commenting"></i> <br>留言</a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>Schedule</a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>Sitemap</a>
        </li>
      
        
        <li class="menu-item menu-item-baidusitmap">
          <a href="/baidusitmap.xml" rel="section">
            <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>baidusitmap</a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/05/12/Deel Learning ai_Convolutional Neural Networks/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Networks</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-12T19:31:06+08:00">2019-05-12</time>
            

            
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                14k字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="C4-Convolutional-Neural-Networks-卷积神经网络"><a href="#C4-Convolutional-Neural-Networks-卷积神经网络" class="headerlink" title="C4 : Convolutional Neural Networks(卷积神经网络)"></a>C4 : Convolutional Neural Networks(卷积神经网络)</h1><h2 id="W1-Convolutional-Neural-Networks-卷积神经网络"><a href="#W1-Convolutional-Neural-Networks-卷积神经网络" class="headerlink" title="W1 :Convolutional Neural Networks(卷积神经网络)"></a>W1 :Convolutional Neural Networks(卷积神经网络)</h2><h3 id="L1-Computer-Vision"><a href="#L1-Computer-Vision" class="headerlink" title="L1: Computer Vision"></a>L1: Computer Vision</h3><ol>
<li>Image classification</li>
<li>Object detection</li>
<li>Neural Style Transfer</li>
</ol>
<p>Problem : input big</p>
<ol>
<li>神经网络结构复杂，数据量相对较少，容易出现过拟合；</li>
<li>所需内存和计算量巨大。</li>
</ol>
<h3 id="L2-Edge-detection-example"><a href="#L2-Edge-detection-example" class="headerlink" title="L2: Edge detection example"></a>L2: Edge detection example</h3><p>我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。</p>
<p><strong>卷积运算（Convolutional Operation）</strong>是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。</p>
<ol>
<li><p>常见的边缘检测</p>
<p>垂直边缘（Vertical Edges) 和 水平边缘（horizontal Edges)</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Different-edges.png" alt=""></p>
</li>
</ol>
<p>这张图的栏杆就对应垂直线，栏杆的水平线是水平边缘。</p>
<p>那么图片是怎么检测边缘的呢？</p>
<p>过滤器：filter</p>
<p>在数学中“”就是卷积的标准标志，但是在<strong>Python</strong>中，这个标识常常被用来表示乘法或者元素乘法。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_1.png" alt=""></p>
<p>Output; 4 by 4</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_1——2.png" alt=""></p>
<p>具体运算：</p>
<p>1）</p>
<p>为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（<strong>element-wise products</strong>）运算</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_1_3png.png" alt=""></p>
<p>2）为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_1_4png.png" alt=""></p>
<p>6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Convolutional-operation.jpg" alt=""></p>
<p>举例说明： Vertical edge detection</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_1_5.png" alt=""></p>
<p>这里在结果可能有点不对头，检测到的边缘太粗了，主要是图片太小了，</p>
<p>卷积操作API</p>
<ul>
<li>在 Python 中，卷积用<code>conv_forward()</code>表示；</li>
<li>在 Tensorflow 中，卷积用<code>tf.nn.conv2d()</code>表示；</li>
<li>在 keras 中，卷积用<code>Conv2D()</code>表示。</li>
</ul>
<h3 id="L3-Edge-Detection-Example"><a href="#L3-Edge-Detection-Example" class="headerlink" title="L3: Edge Detection Example"></a>L3: Edge Detection Example</h3><ol>
<li><p>颜色由暗到亮，还是亮到暗</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_1.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_2.png" alt=""></p>
</li>
</ol>
<p>这种滤波器可以区分明暗变化，取绝对值没有区别了</p>
<ol>
<li><p>水平边缘</p>
<p>上边相对较亮，而下方相对较暗</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_3.png" alt=""></p>
<ol>
<li>复杂栗子</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_4.png" alt=""></p>
</li>
</ol>
<p>这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。</p>
<ol>
<li>filter</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_5.png" alt=""></p>
<p>sobel过滤器，优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。</p>
<p>charr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。</p>
<p>学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_6.png" alt=""></p>
<p>这样可能得到一个出色的边缘检测</p>
<p>相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。</p>
<p>不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。</p>
<h3 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h3><p>按照我们上面讲的图片卷积，如果原始图片尺寸为$n x n$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n-f+1) x (n-f+1)$，注意f一般为奇数。这样会带来两个问题：</p>
<ul>
<li><p><strong>卷积运算后，输出图片尺寸缩小</strong></p>
</li>
<li><p><strong>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</strong></p>
<p>边缘像素点只被一个输出所触碰或者使用，</p>
</li>
</ul>
<p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行<strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Padding.jpg" alt=""></p>
<p>经过padding之后，填充p,原始图片尺寸为$(n+2p) x (n+2p)$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n+2p-f+1) x (n+2p-f+1)$。若要保证卷积前后图片尺寸不变，则p应满足：$ p=(f-1)/2$,f通常是奇数，如果是偶数，造成不对称填充，第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置</p>
<ol>
<li>p=0,Valid convolution</li>
<li>p=((f-1))/2,Same convolution</li>
</ol>
<h3 id="L05-Strided-convolution（卷积步长）"><a href="#L05-Strided-convolution（卷积步长）" class="headerlink" title="L05: Strided convolution（卷积步长）"></a>L05: Strided convolution（卷积步长）</h3><p>Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Stride.jpg" alt=""></p>
<p>我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为：</p>
<script type="math/tex; mode=display">
\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor</script><p>向下取整</p>
<p>目前为止我们学习的“卷积”实际上被称为<strong>互相关（cross-correlation）</strong>，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_6.png" alt=""></p>
<p>互相关：过滤器沿水平和垂直轴翻转，元素相乘来计算，这些视频中定义卷积运算时，我们跳过了这个镜像操作。（不进行翻转操作）叫做卷积操作</p>
<h3 id="L06-Convolution-over-volumes-三维卷积"><a href="#L06-Convolution-over-volumes-三维卷积" class="headerlink" title="L06: Convolution over volumes(三维卷积)"></a>L06: Convolution over volumes(三维卷积)</h3><ol>
<li><p>卷积运算</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Convolutions-on-RGB-image.png" alt=""></p>
</li>
</ol>
<p>过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。</p>
<p>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_8.png" alt=""></p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_9.png" alt=""></p>
<p>若输入图片的尺寸为n x n x nc，nc: 通道数目，filter尺寸为f x f x nc，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x nc′。其中，nc为图片通道数目，nc′为滤波器组个数。</p>
<h3 id="L7-One-layer-of-a-convolution-network-单层神经网络"><a href="#L7-One-layer-of-a-convolution-network-单层神经网络" class="headerlink" title="L7 : One layer of a convolution network (单层神经网络)"></a>L7 : One layer of a convolution network (单层神经网络)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_10.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_11.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_12.png" alt=""></p>
<p>CNN单层的所以标记符号，设层数$l$,</p>
<script type="math/tex; mode=display">
\begin{array}{l}{f^{[l]}=\text { filter size }} \\ {p^{[l]}=\text { padding }} \\ {g^{[l]}=\text { stride }} \\ {n_{c}^{[l]}=\text { number of filters }}\end{array}</script><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_13.png" alt=""></p>
<script type="math/tex; mode=display">
\begin{array}{c}{n_{H}^{[l]}=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor} \\ { n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor}\end{array}</script><p>如果$m$个样本，进行向量化运算，相应的输出维度，为</p>
<script type="math/tex; mode=display">
\mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}</script><h3 id="L8-A-simple-convolution-network-example（简单卷积网络示例）"><a href="#L8-A-simple-convolution-network-example（简单卷积网络示例）" class="headerlink" title="L8 : A simple convolution network example（简单卷积网络示例）"></a>L8 : A simple convolution network example（简单卷积网络示例）</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-33.jpg" alt=""></p>
<ul>
<li>一般而言，<strong>图片的height $n^{[l]}_{H}$和width $n^{[l]}_W$随着层数的增加逐渐降低，但channel $n^{[l]}_C$逐渐增加</strong>。</li>
</ul>
<p>CNN有三种类型的layer：</p>
<ul>
<li>Convolution层（CONV）</li>
<li>Pooling层（POOL）</li>
<li>Fully connected层（FC）</li>
</ul>
<h3 id="L9-Pooling-layers-池化层"><a href="#L9-Pooling-layers-池化层" class="headerlink" title="L9: Pooling layers(池化层)"></a>L9: Pooling layers(池化层)</h3><p>卷积神经网络除了卷积层，还有池化层来缩减模型的大小，提高运算速度和鲁棒性</p>
<ol>
<li>池的类型有max pooling(最大池化)</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_14.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_15.png" alt=""></p>
<p>这里步幅是s=2，filter = 2*2是最大池化的超参数,如果是三维，则单独在每个通道执行最大池化操作</p>
<p>关于max pooling的直觉解释： 元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。</p>
<ol>
<li><p>Pooling layer: Average pooling</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_16.png" alt=""></p>
<p>但是最大池化更好用</p>
</li>
</ol>
<p>summary : 输入$n_H<em>n_W</em>n_C$,如果没有padding,输出$(n_h-f)/s+1<em>(n_w-f)/s+1</em>n_c$</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_17.png" alt=""></p>
<h3 id="L10-Convolutional-neural-network-example-卷积神经网络实例"><a href="#L10-Convolutional-neural-network-example-卷积神经网络实例" class="headerlink" title="L10: Convolutional neural network example (卷积神经网络实例)"></a>L10: Convolutional neural network example (卷积神经网络实例)</h3><p>做一个识别数字的CNN网络</p>
<ol>
<li><p>LeNet-5架构如下：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\CNN.jpg" alt=""></p>
<ul>
<li>通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练</li>
</ul>
</li>
</ol>
<ul>
<li>常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax</li>
<li>最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。</li>
<li>在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。</li>
<li>关于CNN如何选择超参：可以参考论文的经验。</li>
<li><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_18.png" alt=""></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Activation shape</th>
<th style="text-align:center">Activation Size</th>
<th>#parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Input:</strong></td>
<td style="text-align:center">(32, 32, 3)</td>
<td style="text-align:center">3072</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV1(f=5, s=1)</strong></td>
<td style="text-align:center">(28, 28, 6)</td>
<td style="text-align:center">4704</td>
<td>156 (=5<em>5</em>6+6)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL1</strong></td>
<td style="text-align:center">(14, 14, 6)</td>
<td style="text-align:center">1176</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV2(f=5, s=1)</strong></td>
<td style="text-align:center">(10, 10, 16)</td>
<td style="text-align:center">1600</td>
<td>416 (=5<em>5</em>16+16)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL2</strong></td>
<td style="text-align:center">(5, 5, 16)</td>
<td style="text-align:center">400</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC3</strong></td>
<td style="text-align:center">(120, 1)</td>
<td style="text-align:center">120</td>
<td>48120 (=120*400+120)</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC4</strong></td>
<td style="text-align:center">(84, 1)</td>
<td style="text-align:center">84</td>
<td>10164 (=84*120+84)</td>
</tr>
<tr>
<td style="text-align:center"><strong>Softmax</strong></td>
<td style="text-align:center">(10, 1)</td>
<td style="text-align:center">10</td>
<td>850 (=10*84+10)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="L11-Why-convolution"><a href="#L11-Why-convolution" class="headerlink" title="L11 Why convolution"></a>L11 Why convolution</h3><ul>
<li><p>参数共享（parameter sharing)</p>
<p> 如果用FC的话，参数爆炸啊！如果conv layer 就需要filter检测器，这个参数就少了，还参数共享</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_19.png" alt=""></p>
</li>
<li><p>稀疏连接(sparsity of connection)</p>
<p>输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。</p>
</li>
</ul>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_20.png" alt=""></p>
<h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><font color="read">1. 卷积神经网络的基本构造和计算过程 2. 如何整合这些模型 3.  哪些超参数 4. 为什么使用卷积 </font>

<h2 id="W2-Deep-convolutional-models-case-studies-深度卷积网络：实例探究"><a href="#W2-Deep-convolutional-models-case-studies-深度卷积网络：实例探究" class="headerlink" title="W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)"></a>W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)</h2><h3 id="L1-Why-look-at-case-studies-为什么要进行实例探究？"><a href="#L1-Why-look-at-case-studies-为什么要进行实例探究？" class="headerlink" title="L1 : Why look at case studies?(为什么要进行实例探究？)"></a>L1 : Why look at case studies?(为什么要进行实例探究？)</h3><p>本文将主要介绍几个典型的CNN案例。通过对具体CNN模型及案例的研究，来帮助我们理解知识并训练实际的模型。</p>
<p>典型的CNN模型包括：</p>
<ul>
<li><strong>LeNet-5</strong></li>
<li><strong>AlexNet</strong></li>
<li><strong>VGG</strong></li>
</ul>
<p>还会介绍Residual Network（ResNet）。其特点是可以构建很深很深的神经网络（目前最深的好像有152层）。还会介绍Inception Neural Network</p>
<h3 id="L2-Classic-networks-经典网络"><a href="#L2-Classic-networks-经典网络" class="headerlink" title="L2 : Classic networks(经典网络)"></a>L2 : Classic networks(经典网络)</h3><h4 id="1-LeNet-5"><a href="#1-LeNet-5" class="headerlink" title="1. LeNet-5"></a>1. LeNet-5</h4><p><strong>LeNet-5</strong>是针对灰度图片训练的，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，<strong>padding</strong>为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-34.jpg" alt=""></p>
<p>该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。</p>
<h4 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1. AlexNet"></a>1. AlexNet</h4><p>AlexNet模型是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton共同提出的，其结构如下所示：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-35.jpg" alt=""></p>
<p><strong>AlexNet</strong>首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层,f=3，步幅为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，<strong>padding</strong>之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次<strong>same</strong>卷积，相同的<strong>padding</strong>，得到的结果是13×13×384，384个过滤器。再做一次<strong>same</strong>卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用<strong>softmax</strong>函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。</p>
<p>实际上，这种神经网络与<strong>LeNet</strong>有很多相似之处，不过<strong>AlexNet</strong>要大得多。正如前面讲到的<strong>LeNet</strong>或<strong>LeNet-5</strong>大约有6万个参数，而<strong>AlexNet</strong>包含约6000万个参数。当用于训练图像和数据集时，<strong>AlexNet</strong>能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点<strong>AlexNet</strong>表现出色。<strong>AlexNet</strong>比<strong>LeNet</strong>表现更为出色的另一个原因是它使用了<strong>ReLu</strong>激活函数。原作者还提到了一种优化技巧，叫做Local Response Normalization(LRN)。 而在实际应用中，LRN的效果并不突出。</p>
<h4 id="3-VGG-16"><a href="#3-VGG-16" class="headerlink" title="3. VGG-16"></a>3. VGG-16</h4><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-36.jpg" alt=""></p>
<p>首先用3×3，步幅为1的过滤器构建卷积层，<strong>padding</strong>参数为<strong>same</strong>卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此<strong>VGG</strong>网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。</p>
<p>数字16，就是指在这个网络中包含16个卷积层和全连接层。总共包含约1.38亿个参数</p>
<h3 id="L3-Residual-Networks-ResNets-残差网络-ResNets"><a href="#L3-Residual-Networks-ResNets-残差网络-ResNets" class="headerlink" title="L3 : Residual Networks (ResNets)(残差网络(ResNets))"></a>L3 : Residual Networks (ResNets)(残差网络(ResNets))</h3><p>我们知道，如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功。解决的方法之一是人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为Residual Networks(ResNets)。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_21.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Residual-Network.jpg" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\ResNet-Training-Error.jpg" alt=""></p>
<h3 id="L4-Why-ResNets-work-残差网络为什么有用？"><a href="#L4-Why-ResNets-work-残差网络为什么有用？" class="headerlink" title="L4: Why ResNets work?(残差网络为什么有用？)"></a>L4: Why ResNets work?(残差网络为什么有用？)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_22.png" alt=""></p>
<p>因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。</p>
<p>注意，如果$ a[l]$与 $a[l+2]$的维度不同，需要引入矩阵 $W_s$与 $a_{[l]}$相乘，使得二者的维度相匹配。参数矩阵 $W_s$既可以通过模型训练得到，也可以作为固定值，仅使 $a[l]$截断或者补零。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Xnip2018-07-04_08-28-37.jpg" alt=""></p>
<h3 id="L5-Network-in-Network-and-1×1-convolutions-网络中的网络以及-1×1-卷积"><a href="#L5-Network-in-Network-and-1×1-convolutions-网络中的网络以及-1×1-卷积" class="headerlink" title="L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积)"></a>L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积)</h3><ol>
<li>作用 </li>
</ol>
<p>假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_c$）的方法，对于池化层我只是压缩了这些层的高度和宽度</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_23.png" alt=""></p>
<ol>
<li><strong>doing something pretty non-trivial</strong></li>
</ol>
<p>它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。</p>
<h3 id="L6-Inception-network-motivation-谷歌-Inception-网络简介"><a href="#L6-Inception-network-motivation-谷歌-Inception-网络简介" class="headerlink" title="L6 : Inception network motivation(谷歌 Inception 网络简介)"></a>L6 : Inception network motivation(谷歌 Inception 网络简介)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\99f8fc7dbe7cd0726f5271aae11b9872.png" alt=""></p>
<p>有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。</p>
<p> 1x1 的卷积层通常被称作<strong>瓶颈层（Bottleneck layer）</strong></p>
<p>计算量为 28x28x32x5x5x192 = 1.2亿</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\The-problem-of-computational-cost.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Using-1x1-convolution.png" alt=""></p>
<p>28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。</p>
<h3 id="L7-Inception-network-Inception-网络"><a href="#L7-Inception-network-Inception-网络" class="headerlink" title="L7 : Inception network(Inception 网络)"></a>L7 : Inception network(Inception 网络)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_24.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\example_2_25.png" alt=""></p>
<h3 id="L8-Using-open-source-implementations-使用开源的实现方案"><a href="#L8-Using-open-source-implementations-使用开源的实现方案" class="headerlink" title="L8 : Using open-source implementations( 使用开源的实现方案)"></a>L8 : Using open-source implementations( 使用开源的实现方案)</h3><p>开源项目</p>
<h3 id="L9-：-Transfer-Learning（迁移学习）"><a href="#L9-：-Transfer-Learning（迁移学习）" class="headerlink" title="L9 ： Transfer Learning（迁移学习）"></a>L9 ： Transfer Learning（迁移学习）</h3><p>如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。</p>
<ol>
<li>只有很小数据集： 可以你只需要训练<strong>softmax</strong>层的权重，把前面这些层的权重都冻结。</li>
<li>稍微更大的数据集： 你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元；或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的<strong>softmax</strong>输出层，这些方法值得一试。</li>
<li>大量数据： 你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。</li>
</ol>
<h3 id="L10-：-Data-augmentation（数据增强）"><a href="#L10-：-Data-augmentation（数据增强）" class="headerlink" title="L10 ： Data augmentation（数据增强）"></a>L10 ： Data augmentation（数据增强）</h3><p>数据量远远不够</p>
<ol>
<li>Mirroring</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring.png" alt=""></p>
<ol>
<li>Random Cropping</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring_1.png" alt=""></p>
<ol>
<li><p>彩色转换color shifting</p>
<p>r,g,b数据改变</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring_2.png" alt=""></p>
<p>除了随意改变RGB通道数值外，还可以更有针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法。这样也能增加有效的样本数量。具体的PCA color augmentation做法可以查阅AlexNet的相关论文。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring_3.png" alt=""></p>
<p>常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。</p>
<h3 id="L11：The-state-of-computer-vision-计算机视觉现状"><a href="#L11：The-state-of-computer-vision-计算机视觉现状" class="headerlink" title="L11：The state of computer vision(计算机视觉现状)"></a>L11：The state of computer vision(计算机视觉现状)</h3><ol>
<li>神经网络需要数据，不同的网络模型所需的数据量是不同的。Object dection，Image recognition，Speech recognition所需的数据量依次增加。一般来说，如果data较少，那么就需要更多的hand-engineering，对已有data进行处理。</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring_4.png" alt=""></p>
<p>hand-engineering是一项非常重要也比较困难的工作。很多时候，hand-engineering对模型训练效果影响很大，特别是在数据量不多的情况下。</p>
<p>当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。在别人做好的基础上研究</p>
<ol>
<li><p>提升性能</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Mirroring_5.png" alt="">*</p>
</li>
</ol>
<p>由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。</p>
<p>所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。</p>
<h2 id="summary-1"><a href="#summary-1" class="headerlink" title="summary"></a>summary</h2><font color="red">1. CNN的常见网络结构 重点说了一些残差网络 2.数据增加的方法 3. 多用开源框架，不用从头开始训练 </font>

<h1 id="W3-Object-detection-目标检测"><a href="#W3-Object-detection-目标检测" class="headerlink" title="W3 Object detection(目标检测)"></a>W3 Object detection(目标检测)</h1><h3 id="L1-Object-localization-目标定位"><a href="#L1-Object-localization-目标定位" class="headerlink" title="L1 :Object localization(目标定位)"></a>L1 :Object localization(目标定位)</h3><p>目标定位和目标检测</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_1.png" alt=""></p>
<p>模型</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_2.png" alt=""></p>
<p>输入还包括位置信息</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_3.png" alt=""></p>
<p>损失函数</p>
<p>情况一：检测到了</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_4.png" alt=""></p>
<p>情况二：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_5.png" alt=""></p>
<h3 id="L2-Landmark-detection-特征点检测"><a href="#L2-Landmark-detection-特征点检测" class="headerlink" title="L2: Landmark detection(特征点检测)"></a>L2: Landmark detection(特征点检测)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_6.png" alt=""></p>
<p>该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值。通过检测人脸特征点可以进行情绪分类与判断，或者应用于AR领域等等。</p>
<p>除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_7.png" alt=""></p>
<h3 id="L3-Object-detection-目标检测"><a href="#L3-Object-detection-目标检测" class="headerlink" title="L3 :Object detection(目标检测)"></a>L3 :Object detection(目标检测)</h3><p>学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_8.png" alt=""></p>
<p>训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。</p>
<p>选定特定大小的窗口，窗口圈定输入卷积神经网络，卷积神经网络开始预测。</p>
<p>重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或<img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_10.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_11.png" alt=""></p>
<p>如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。</p>
<p>这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。</p>
<p>滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。但是其缺点也很明显，首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。所以，滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活。</p>
<h3 id="L-4-Convolutional-implementation-of-sliding-windows-滑动窗口的卷积实现"><a href="#L-4-Convolutional-implementation-of-sliding-windows-滑动窗口的卷积实现" class="headerlink" title="L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现)"></a>L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现)</h3><ol>
<li><p>全连接层转化为卷积层</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_12.png" alt=""></p>
</li>
</ol>
<p>单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，步进长度为2，CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_13.png" alt=""></p>
<p>之前的滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。值得一提的是，窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。</p>
<h3 id="L5-：-Bounding-box-predictions（Bounding-Box预测）"><a href="#L5-：-Bounding-box-predictions（Bounding-Box预测）" class="headerlink" title="L5 ： Bounding box predictions（Bounding Box预测）"></a>L5 ： Bounding box predictions（Bounding Box预测）</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_14.png" alt=""></p>
<ol>
<li><p>YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_16.png" alt=""></p>
</li>
<li><p>如果目标中心坐标(bx,by)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。判断有目标的网格中，bx,by,bh,bw限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(bx,by)范围限定在[0,1]之间，但是bh,bw可以大于1。因为目标可能超出该网格，横跨多个区域，如上图所示。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_15.png" alt=""></p>
<h3 id="L6-：Intersection-over-union（交并比"><a href="#L6-：Intersection-over-union（交并比" class="headerlink" title="L6 ：Intersection over union（交并比)"></a>L6 ：Intersection over union（交并比)</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_17.png" alt=""></p>
<p>一般约定，在计算机检测任务中，如果lou&gt;=0.5，就说检测正确，如果预测器和实际边界框完美重叠，<strong>loU</strong>就是1，因为交集就等于并集。但一般来说只要lou&gt;=0.5，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将<strong>loU</strong>定得更高，比如说大于0.6或者更大的数字，但<strong>loU</strong>越高，边界框越精确。</p>
<h3 id="L7-Non-max-suppression-非极大值抑制"><a href="#L7-Non-max-suppression-非极大值抑制" class="headerlink" title="L7: Non-max suppression(非极大值抑制)"></a>L7: Non-max suppression(非极大值抑制)</h3><p>到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_18.png" alt=""></p>
<p>假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_19.png" alt=""></p>
<p>实际情况是格子1，2，3，4，5，6都认为里面有车。因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc,我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。</p>
<p>非最大值抑制（Non-max Suppression）做法很简单，图示每个网格的Pc值可以求出，Pc值反映了该网格包含目标中心坐标的可信度。首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示：</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_20.png" alt=""></p>
<p>总结一下非最大值抑制算法的流程：</p>
<ol>
<li><strong>剔除Pc值小于某阈值（例如0.6）的所有网格；</strong></li>
<li><strong>选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格；</strong></li>
<li><strong>对剩下的网格，重复步骤2。</strong></li>
</ol>
<p>到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用<strong>anchor box</strong>这个概念，我们从一个例子开始讲吧。方法是使用不同形状的Anchor Boxes。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_21.png" alt=""></p>
<p>这就是<strong>anchor box</strong>的概念，我们建立<strong>anchor box</strong>这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生</p>
<h3 id="L9-YOLO-算法（Putting-it-together-YOLO-algorithm）"><a href="#L9-YOLO-算法（Putting-it-together-YOLO-algorithm）" class="headerlink" title="L9 :  YOLO 算法（Putting it together: YOLO algorithm）"></a>L9 :  YOLO 算法（Putting it together: YOLO algorithm）</h3><p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_22.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_23.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_24.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_25.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_26.png" alt=""></p>
<p>这就是<strong>YOLO</strong>对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路</p>
<h3 id="Region-proposals-Optional-（候选区域（选修））"><a href="#Region-proposals-Optional-（候选区域（选修））" class="headerlink" title="Region proposals (Optional)（候选区域（选修））"></a>Region proposals (Optional)（候选区域（选修））</h3><p>之前介绍的滑动窗算法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，例如下图所示。这样会降低算法运行效率，耗费时间。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_27.png" alt=""></p>
<p>为了解决这一问题，尽量避免对无用区域的扫描，可以使用Region Proposals的方法。具体做法是先对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_28.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\Detering_29.png" alt=""></p>
<p>Region Proposals共有三种方法：</p>
<ul>
<li><strong>R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。</strong></li>
<li><strong>Fast R-CNN: 利用卷积实现滑动窗算法，类似第4节做法。</strong></li>
<li><strong>Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。</strong></li>
</ul>
<h2 id="W4：Special-applications-Face-recognition-amp-Neural-style-transfer-特殊应用：人脸识别和神经风格转换"><a href="#W4：Special-applications-Face-recognition-amp-Neural-style-transfer-特殊应用：人脸识别和神经风格转换" class="headerlink" title="W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)"></a>W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)</h2><h3 id="C1-：-What-is-face-recognition"><a href="#C1-：-What-is-face-recognition" class="headerlink" title="C1 ： What is face recognition?"></a>C1 ： What is face recognition?</h3><p>首先简单介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。</p>
<ul>
<li><strong>人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。</strong></li>
<li><strong>人脸识别：输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题。</strong></li>
</ul>
<h3 id="L2-：-One-shot-learning"><a href="#L2-：-One-shot-learning" class="headerlink" title="L2 ： One-shot learning"></a>L2 ： One-shot learning</h3><p>One-shot learning就是说数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型来进行人脸识别。若数据库有K个人，则CNN模型输出softmax层就是K维的。</p>
<p>但是One-shot learning的性能并不好，其包含了两个缺点：</p>
<ul>
<li><strong>每个人只有一张图片，训练样本少，构建的CNN网络不够健壮。</strong></li>
<li><strong>若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活。</strong></li>
</ul>
<p>为了解决One-shot learning的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用：</p>
<ul>
<li><strong>d(img1,img2)≤τ : 一样</strong></li>
<li><strong>d(img1,img2)&gt;τ : 不一样</strong></li>
</ul>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\congtion_1.png" alt=""></p>
<p>现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数。</p>
<h3 id="L3-Siamese-network"><a href="#L3-Siamese-network" class="headerlink" title="L3: Siamese network"></a>L3: Siamese network</h3><p>最后一层去掉softmax单元做分类</p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\congtion_2.png" alt=""></p>
<p><img src="/2019/05/12/Deel Learning ai_Convolutional Neural Networks/MyBlog\hexo\source\_posts\Deel Learning ai_Convolutional Neural Networks\congtion_3.png" alt=""></p>
<p>如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x^{(2)})$。这里我用$x^{(1)}$和$x^{(2)}$仅仅代表两个输入图片,</p>
<script type="math/tex; mode=display">
d(x^{(1)},x^{(2)})=||f(x^{(1)}-f(x^{(2)}||^2</script><p>不同的图片的CNN网络结构和参数都是一样的，目标就是利用梯度下降算法，调整网络参数</p>

      
    </div>

    

    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author: </strong>XieMay</li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="http://xiemaycherry.github.io/2019/05/12/Deel Learning ai_Convolutional Neural Networks/" title="Networks">http://xiemaycherry.github.io/2019/05/12/Deel Learning ai_Convolutional Neural Networks/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.</li>
</ul>

      </div>
    
<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

  
</div>
    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-learning/" rel="tag"># Deep learning</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/05/05/Deep Learning ai_Deep Learning Specialization/" rel="next" title="The Deep Learning Specialization">
                <i class="fa fa-chevron-left"></i> The Deep Learning Specialization
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/22/Pandas 做数据分析/" rel="prev" title="数据分析">
                数据分析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">XieMay</p>
              <p class="site-description motion-element" itemprop="description">期待花开</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">49</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">39</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="http://www.cnblogs.com/shiyiandchuixue/" target="_blank" title="BLOGS"><i class="fa fa-fw fa-globe"></i>BLOGS</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:2323020965@qq.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/shiyichuixue" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#C4-Convolutional-Neural-Networks-卷积神经网络"><span class="nav-number">1.</span> <span class="nav-text">C4 : Convolutional Neural Networks(卷积神经网络)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#W1-Convolutional-Neural-Networks-卷积神经网络"><span class="nav-number">1.1.</span> <span class="nav-text">W1 :Convolutional Neural Networks(卷积神经网络)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-Computer-Vision"><span class="nav-number">1.1.1.</span> <span class="nav-text">L1: Computer Vision</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L2-Edge-detection-example"><span class="nav-number">1.1.2.</span> <span class="nav-text">L2: Edge detection example</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L3-Edge-Detection-Example"><span class="nav-number">1.1.3.</span> <span class="nav-text">L3: Edge Detection Example</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Padding"><span class="nav-number">1.1.4.</span> <span class="nav-text">Padding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L05-Strided-convolution（卷积步长）"><span class="nav-number">1.1.5.</span> <span class="nav-text">L05: Strided convolution（卷积步长）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L06-Convolution-over-volumes-三维卷积"><span class="nav-number">1.1.6.</span> <span class="nav-text">L06: Convolution over volumes(三维卷积)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L7-One-layer-of-a-convolution-network-单层神经网络"><span class="nav-number">1.1.7.</span> <span class="nav-text">L7 : One layer of a convolution network (单层神经网络)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L8-A-simple-convolution-network-example（简单卷积网络示例）"><span class="nav-number">1.1.8.</span> <span class="nav-text">L8 : A simple convolution network example（简单卷积网络示例）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L9-Pooling-layers-池化层"><span class="nav-number">1.1.9.</span> <span class="nav-text">L9: Pooling layers(池化层)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L10-Convolutional-neural-network-example-卷积神经网络实例"><span class="nav-number">1.1.10.</span> <span class="nav-text">L10: Convolutional neural network example (卷积神经网络实例)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L11-Why-convolution"><span class="nav-number">1.1.11.</span> <span class="nav-text">L11 Why convolution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary"><span class="nav-number">1.2.</span> <span class="nav-text">summary</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#W2-Deep-convolutional-models-case-studies-深度卷积网络：实例探究"><span class="nav-number">1.3.</span> <span class="nav-text">W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-Why-look-at-case-studies-为什么要进行实例探究？"><span class="nav-number">1.3.1.</span> <span class="nav-text">L1 : Why look at case studies?(为什么要进行实例探究？)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L2-Classic-networks-经典网络"><span class="nav-number">1.3.2.</span> <span class="nav-text">L2 : Classic networks(经典网络)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-LeNet-5"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">1. LeNet-5</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-AlexNet"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">1. AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-VGG-16"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">3. VGG-16</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L3-Residual-Networks-ResNets-残差网络-ResNets"><span class="nav-number">1.3.3.</span> <span class="nav-text">L3 : Residual Networks (ResNets)(残差网络(ResNets))</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L4-Why-ResNets-work-残差网络为什么有用？"><span class="nav-number">1.3.4.</span> <span class="nav-text">L4: Why ResNets work?(残差网络为什么有用？)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L5-Network-in-Network-and-1×1-convolutions-网络中的网络以及-1×1-卷积"><span class="nav-number">1.3.5.</span> <span class="nav-text">L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L6-Inception-network-motivation-谷歌-Inception-网络简介"><span class="nav-number">1.3.6.</span> <span class="nav-text">L6 : Inception network motivation(谷歌 Inception 网络简介)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L7-Inception-network-Inception-网络"><span class="nav-number">1.3.7.</span> <span class="nav-text">L7 : Inception network(Inception 网络)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L8-Using-open-source-implementations-使用开源的实现方案"><span class="nav-number">1.3.8.</span> <span class="nav-text">L8 : Using open-source implementations( 使用开源的实现方案)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L9-：-Transfer-Learning（迁移学习）"><span class="nav-number">1.3.9.</span> <span class="nav-text">L9 ： Transfer Learning（迁移学习）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L10-：-Data-augmentation（数据增强）"><span class="nav-number">1.3.10.</span> <span class="nav-text">L10 ： Data augmentation（数据增强）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L11：The-state-of-computer-vision-计算机视觉现状"><span class="nav-number">1.3.11.</span> <span class="nav-text">L11：The state of computer vision(计算机视觉现状)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary-1"><span class="nav-number">1.4.</span> <span class="nav-text">summary</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#W3-Object-detection-目标检测"><span class="nav-number">2.</span> <span class="nav-text">W3 Object detection(目标检测)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-Object-localization-目标定位"><span class="nav-number">2.0.1.</span> <span class="nav-text">L1 :Object localization(目标定位)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L2-Landmark-detection-特征点检测"><span class="nav-number">2.0.2.</span> <span class="nav-text">L2: Landmark detection(特征点检测)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L3-Object-detection-目标检测"><span class="nav-number">2.0.3.</span> <span class="nav-text">L3 :Object detection(目标检测)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L-4-Convolutional-implementation-of-sliding-windows-滑动窗口的卷积实现"><span class="nav-number">2.0.4.</span> <span class="nav-text">L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L5-：-Bounding-box-predictions（Bounding-Box预测）"><span class="nav-number">2.0.5.</span> <span class="nav-text">L5 ： Bounding box predictions（Bounding Box预测）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L6-：Intersection-over-union（交并比"><span class="nav-number">2.0.6.</span> <span class="nav-text">L6 ：Intersection over union（交并比)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L7-Non-max-suppression-非极大值抑制"><span class="nav-number">2.0.7.</span> <span class="nav-text">L7: Non-max suppression(非极大值抑制)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L9-YOLO-算法（Putting-it-together-YOLO-algorithm）"><span class="nav-number">2.0.8.</span> <span class="nav-text">L9 :  YOLO 算法（Putting it together: YOLO algorithm）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Region-proposals-Optional-（候选区域（选修））"><span class="nav-number">2.0.9.</span> <span class="nav-text">Region proposals (Optional)（候选区域（选修））</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#W4：Special-applications-Face-recognition-amp-Neural-style-transfer-特殊应用：人脸识别和神经风格转换"><span class="nav-number">2.1.</span> <span class="nav-text">W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#C1-：-What-is-face-recognition"><span class="nav-number">2.1.1.</span> <span class="nav-text">C1 ： What is face recognition?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L2-：-One-shot-learning"><span class="nav-number">2.1.2.</span> <span class="nav-text">L2 ： One-shot learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L3-Siamese-network"><span class="nav-number">2.1.3.</span> <span class="nav-text">L3: Siamese network</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="powered-by">
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XieMay</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Symbols count total&#58;</span>
    
    <span title="Symbols count total">273k</span>
  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Pisces</a> v6.0.4</div>



</div>
        








        
      </div>
    </footer>

    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


















  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.4"></script>



  



	





  









  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
    
  
  <script src="[object Object]"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '1Dfsb4DwGQPCIlbyCKt9egUR-gzGzoHsz',
        appKey: '8OKqJPeMRRQnxx2vaAwIkM8y',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":"wanko","bottom":-30,"mobileShow":false,"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body>
</html>
