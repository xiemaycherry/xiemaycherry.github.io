<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Times New Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mycherrymay.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"WGLQQAQKBA","indexName":"xiemay","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="[TOC] 概率论的知识">
<meta property="og:type" content="article">
<meta property="og:title" content="贝叶斯分类器">
<meta property="og:url" content="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/index.html">
<meta property="og:site_name" content="Welcome to shiyi&#39;s world">
<meta property="og:description" content="[TOC] 概率论的知识">
<meta property="og:locale">
<meta property="og:image" content="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/MyBlog/hexo/source/_posts/贝叶斯分类器/熵.png">
<meta property="og:image" content="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/MyBlog/hexo/source/_posts/贝叶斯分类器/2.png">
<meta property="article:published_time" content="2019-03-28T00:50:42.000Z">
<meta property="article:modified_time" content="2020-07-25T07:52:54.000Z">
<meta property="article:author" content="XieMay">
<meta property="article:tag" content="贝叶斯分类器">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/MyBlog/hexo/source/_posts/贝叶斯分类器/熵.png">

<link rel="canonical" href="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>贝叶斯分类器 | Welcome to shiyi's world</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Welcome to shiyi's world</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          贝叶斯分类器
        </h1>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-28 08:50:42" itemprop="dateCreated datePublished" datetime="2019-03-28T08:50:42+08:00">2019-03-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-07-25 15:52:54" itemprop="dateModified" datetime="2020-07-25T15:52:54+08:00">2020-07-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>[TOC]</p>
<h1><span id="gai-lu-lun-de-zhi-shi">概率论的知识</span><a href="#gai-lu-lun-de-zhi-shi" class="header-anchor">#</a></h1><a id="more"></a>
<h2><span id="tiao-jian-gai-lu">条件概率</span><a href="#tiao-jian-gai-lu" class="header-anchor">#</a></h2><script type="math/tex; mode=display">
P(A|B)=P(A\cap B)/P(B)</script><p>已知B发生的概率，求A发生的概率</p>
<h2><span id="quan-gai-lu">全概率</span><a href="#quan-gai-lu" class="header-anchor">#</a></h2><script type="math/tex; mode=display">
P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i)</script><h2><span id="bei-xie-si-tui-duan">贝叶斯推断</span><a href="#bei-xie-si-tui-duan" class="header-anchor">#</a></h2><script type="math/tex; mode=display">
P(A|B)=P(A)\frac{P(B|A)}{P(B)}</script><script type="math/tex; mode=display">
P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)}</script><p>$P(A)$：Prior probability 先验概率，在B事件发生之前，对A事件做一个判断</p>
<p>$P(A|B)$:Posterior probability 后验概率，在B事件发生之后，对A事件的概率重新评估</p>
<p>$P(B|A)/P(B)$:称为可能性函数，一个调整因子</p>
<p>后验概率=先验概率*调整因子 （可知，调整因此&gt;1,发生概率增大了，</p>
<h1><span id="bei-xie-si-jue-ce-lun">贝叶斯决策论</span><a href="#bei-xie-si-jue-ce-lun" class="header-anchor">#</a></h1><p>英文：Bayesian decision theory</p>
<p>设有$N$种可能的类别, 即γ=${c_1,c_2,…,c_N}$. $λ_ij$是将一个真实类别为$c_j$的样本判为$c_x$的损失。 基于后验概率可得将样本分类所产生的期望损失, 或者成为条件风险(Conditional Risk) </p>
<script type="math/tex; mode=display">
R(C_i|x)=∑_{j=1}^Nλ_{ij}P(c_j|x)</script><p>于是， 我们的任务就是寻找判定准则h， 令$χ→γ$ 使得最小化总体风险，$R(h)=E_x[R(h(x)|x]$最小. 对于每一个$x$，若$h$都能最小化条件风险，那么总体也被最小化了。 可以简化为对每个样本选择其条件风险最小的分类, 即: </p>
<script type="math/tex; mode=display">
h(x)=arg \min_{c⊂λ}R(c|x)</script><p>此$h(x)$就是贝叶斯最优分类器。 $R(h)$为贝叶斯风险(Bayes Risk), $1−R(h)$反映了分类器的最优性能. </p>
<p>具体来说，如果目标是最小化分类错误率，</p>
<script type="math/tex; mode=display">\lambda_{ij}=\begin{cases} 0\ \  i==j\\1 \ \ \ i!=j \end{cases}</script><p>则$R(c|x)=1-p(c|x)$，因此可知，$h(x)=\max_{c\in C} p(c|x)$</p>
<p>对于样本$x$,选择后验概率$P(c|X)$最大的类别为标记。</p>
<p>问题转换为</p>
<script type="math/tex; mode=display">
P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)}</script><p>求先验概率和似然($P(x|c)$)</p>
<p>其中</p>
<p>$P(c)$表达了样本空间种各类样本所占的比列，根据大数定律，当样本足够充分的独立同分布样本是，可以频率估计</p>
<p>$P(x|c)$,涉及关于x所以属性的联合概率，用频率估计概率可能不太好，对于估计类条件概率的一种宠用策略是先假设具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。</p>
<p>$P(x|c)$是类条件概率，由某个分布决定，$P(x|\theta_c)$来表示了</p>
<p>频率注意派认为可以通过优化似然函数估计参数。$D_c$类别c的样本集合，独立同分布</p>
<script type="math/tex; mode=display">
P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c)</script><script type="math/tex; mode=display">
LL(\theta_c)=log  P(D_c|\theta_c)</script><h1><span id="po-su-bei-xie-si-fen-lei-qi">朴素贝叶斯分类器</span><a href="#po-su-bei-xie-si-fen-lei-qi" class="header-anchor">#</a></h1><p>英文：naive Bayes classifier</p>
<p>假设：属性条件独立性假设，每个属性独立性对分类结果发生影响</p>
<script type="math/tex; mode=display">
P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)\Pi_{i=1}^{d}P(x_i|c)}{P(x)}</script><p>对于一个$x$，$P(x)$都是相同的，因此贝叶斯模型可写为</p>
<script type="math/tex; mode=display">
h_{nb}(x)=arg max_{c\in y}P(c)\Pi_{i=1}^{d}P(x_i|c)</script><h2><span id="ji-suan-guo-cheng">计算过程</span><a href="#ji-suan-guo-cheng" class="header-anchor">#</a></h2><p>假设$D_{c_i}$表示第i类的样本集合，</p>
<ol>
<li><p>$P(c_i)=\frac{|D_{c_i}|}{|D|}$</p>
</li>
<li><p>如果是离散属性</p>
</li>
</ol>
<script type="math/tex; mode=display">
P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|}</script><p>如果是连续属性，$P(x_i|c_i)$服从$N(u_{c,i},\theta_{c,i}^2)$的分布</p>
<script type="math/tex; mode=display">
P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><ol>
<li>$P(c_i)\Pi_{i=1}^{N}P(x_i|c_i)$</li>
</ol>
<p>注意为了避免其他属性携带的信息被训练集中未出现的属性值抹去，因此用拉普拉斯修正（Laplacian correction)</p>
<script type="math/tex; mode=display">
P(c)=\frac{|D_{c_i}|+1}{|D|+N}\\
P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}</script><p>$N$:训练集可能出现的类别数</p>
<p>$N_i$:第i个属性可能的取值数</p>
<p>显然，拉普拉斯修正避免因训练集不充分导出的概率估值为0的情况</p>
<h1><span id="po-su-bei-xie-si-de-chong-lei">朴素贝叶斯的种类</span><a href="#po-su-bei-xie-si-de-chong-lei" class="header-anchor">#</a></h1><p>再scikit-learn中，一共有三个朴素贝叶斯，分别是</p>
<h2><span id="gaussiannb">GaussianNB</span><a href="#gaussiannb" class="header-anchor">#</a></h2><script type="math/tex; mode=display">
P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris=datasets.load_iris()</span><br><span class="line"><span class="comment">#切分数据集</span></span><br><span class="line">Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data,</span><br><span class="line">                                                iris.target,</span><br><span class="line">                                                random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment">#建模</span></span><br><span class="line">clf = GaussianNB()</span><br><span class="line">clf.fit(Xtrain, ytrain)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在测试集上执行预测，proba导出的是每个样本属于某类的概率</span></span><br><span class="line">clf.predict(Xtest)</span><br><span class="line">clf.predict_proba(Xtest) <span class="comment">#每一类计算结果都输出</span></span><br><span class="line"><span class="comment">#测试准确率</span></span><br><span class="line">accuracy_score(ytest, clf.predict(Xtest))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">dataSet =pd.read_csv(<span class="string">'iris.txt'</span>,header = <span class="literal">None</span>)</span><br><span class="line">dataSet.head()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randSplit</span>(<span class="params">dataSet, rate</span>):</span></span><br><span class="line">    l = list(dataSet.index) <span class="comment">#提取出索引</span></span><br><span class="line">    random.shuffle(l) <span class="comment">#随机打乱索引</span></span><br><span class="line">    dataSet.index = l <span class="comment">#将打乱后的索引重新赋值给原数据集</span></span><br><span class="line">    n = dataSet.shape[<span class="number">0</span>] <span class="comment">#总行数</span></span><br><span class="line">    m = int(n * rate) <span class="comment">#训练集的数量</span></span><br><span class="line">    train = dataSet.loc[range(m), :] <span class="comment">#提取前m个记录作为训练集</span></span><br><span class="line">    test = dataSet.loc[range(m, n), :] <span class="comment">#剩下的作为测试集</span></span><br><span class="line">    dataSet.index = range(dataSet.shape[<span class="number">0</span>]) <span class="comment">#更新原数据集的索引</span></span><br><span class="line">    test.index = range(test.shape[<span class="number">0</span>]) <span class="comment">#更新测试集的索引</span></span><br><span class="line"></span><br><span class="line">train,test=randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gnb_classify</span>(<span class="params">train,test</span>):</span></span><br><span class="line">    labels = train.iloc[:,<span class="number">-1</span>].value_counts().index <span class="comment">#提取训练集的标签种类</span></span><br><span class="line">    mean =[] <span class="comment">#存放每个类别的均值</span></span><br><span class="line">    std =[] <span class="comment">#存放每个类别的方差</span></span><br><span class="line">    result = [] <span class="comment">#存放测试集的预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> labels:</span><br><span class="line">        item = train.loc[train.iloc[:,<span class="number">-1</span>]==i,:] <span class="comment">#分别提取出每一种类别</span></span><br><span class="line">        m = item.iloc[:,:<span class="number">-1</span>].mean() <span class="comment">#当前类别的平均值</span></span><br><span class="line">        s = np.sum((item.iloc[:,:<span class="number">-1</span>]-m)**<span class="number">2</span>)/(item.shape[<span class="number">0</span>]) <span class="comment">#当前类别的方差</span></span><br><span class="line">        mean.append(m) <span class="comment">#将当前类别的平均值追加至列表</span></span><br><span class="line">        std.append(s) <span class="comment">#将当前类别的方差追加至列表</span></span><br><span class="line">    means = pd.DataFrame(mean,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    stds = pd.DataFrame(std,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(test.shape[<span class="number">0</span>]):</span><br><span class="line">        iset = test.iloc[j,:<span class="number">-1</span>].tolist() <span class="comment">#当前测试实例</span></span><br><span class="line">        iprob = np.exp(<span class="number">-1</span>*(iset-means)**<span class="number">2</span>/(stds*<span class="number">2</span>))/(np.sqrt(<span class="number">2</span>*np.pi*stds)) <span class="comment">#正态分布公式</span></span><br><span class="line">        prob = train.iloc[:,<span class="number">-1</span>].value_counts()/len(train.iloc[:,<span class="number">-1</span>]) <span class="comment">#初始化当前实例总概率</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(test.shape[<span class="number">1</span>]<span class="number">-1</span>): <span class="comment">#遍历每个特征</span></span><br><span class="line">            prob *= iprob[k] <span class="comment">#特征概率之积即为当前实例概率</span></span><br><span class="line">        cla = prob.index[np.argmax(prob.values)] <span class="comment">#返回最大概率的类别</span></span><br><span class="line">        result.append(cla)</span><br><span class="line">    test[<span class="string">'predict'</span>]=result</span><br><span class="line">    acc = (test.iloc[:,<span class="number">-1</span>]==test.iloc[:,<span class="number">-2</span>]).mean() <span class="comment">#计算预测准确率</span></span><br><span class="line">    print(<span class="string">f'模型预测准确率为<span class="subst">{acc}</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> test</span><br><span class="line"></span><br><span class="line">gnb_classify(train,test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    train,test= randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line">    gnb_classify(train,test)</span><br><span class="line">   </span><br></pre></td></tr></tbody></table></figure>
<h2><span id="multinomialnb">MultinomialNB</span><a href="#multinomialnb" class="header-anchor">#</a></h2><p>先验概率多项式分布的朴素贝叶斯，假设特征是由一共简单多项式分布生成，多项分布可以描述各种类型样本出现的频率，该模型常用于文本分类，特别表示次数。$\lambda$常取值1</p>
<script type="math/tex; mode=display">
P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    dataSet=[[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">             [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">             [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">             [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">             [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">             [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]] <span class="comment">#切分好的词条</span></span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>] <span class="comment">#类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇</span></span><br><span class="line">    <span class="keyword">return</span> dataSet,classVec</span><br><span class="line">dataSet,classVec = loadDataSet()</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    vocabSet = set() <span class="comment">#创建一个空的集合</span></span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> dataSet: <span class="comment">#遍历dataSet中的每一条言论</span></span><br><span class="line">        vocabSet = vocabSet | set(doc) <span class="comment">#取并集</span></span><br><span class="line">        vocabList = list(vocabSet)</span><br><span class="line">    <span class="keyword">return</span> vocabList</span><br><span class="line"></span><br><span class="line">vocabList = createVocabList(dataSet)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span>(<span class="params">vocabList, inputSet</span>):</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList) <span class="comment">#创建一个其中所含元素都为0的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet: <span class="comment">#遍历每个词条</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList: <span class="comment">#如果词条存在于词汇表中，则变为1</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">f" <span class="subst">{word}</span> is not in my Vocabulary!"</span> )</span><br><span class="line">    <span class="keyword">return</span> returnVec <span class="comment">#返回文档向量</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_trainMat</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    trainMat = [] <span class="comment">#初始化向量列表</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#生成词汇表</span></span><br><span class="line">    <span class="keyword">for</span> inputSet <span class="keyword">in</span> dataSet: <span class="comment">#遍历样本词条中的每一条样本</span></span><br><span class="line">        returnVec=setOfWords2Vec(vocabList, inputSet) <span class="comment">#将当前词条向量化</span></span><br><span class="line">        trainMat.append(returnVec) <span class="comment">#追加到向量列表中</span></span><br><span class="line">    <span class="keyword">return</span> trainMat</span><br><span class="line">trainMat = get_trainMat(dataSet)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB</span>(<span class="params">trainMat,classVec</span>):</span></span><br><span class="line">    n = len(trainMat) <span class="comment">#计算训练的文档数目</span></span><br><span class="line">    m = len(trainMat[<span class="number">0</span>]) <span class="comment">#计算每篇文档的词条数</span></span><br><span class="line">    pAb = sum(classVec)/n <span class="comment">#文档属于侮辱类的概率</span></span><br><span class="line">    p0Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p1Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p0Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    p1Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n): <span class="comment">#遍历每一个文档</span></span><br><span class="line">        <span class="keyword">if</span> classVec[i] == <span class="number">1</span>: <span class="comment">#统计属于侮辱类的条件概率所需的数据</span></span><br><span class="line">            p1Num += trainMat[i]</span><br><span class="line">            p1Denom += sum(trainMat[i])</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">#统计属于非侮辱类的条件概率所需的数据</span></span><br><span class="line">            p0Num += trainMat[i]</span><br><span class="line">            p0Denom += sum(trainMat[i])</span><br><span class="line">    p1V = p1Num/p1Denom</span><br><span class="line">    p0V = p0Num/p0Denom</span><br><span class="line">    <span class="keyword">return</span> p0V,p1V,pAb <span class="comment">#返回属于非侮辱类,侮辱类和文档属于侮辱类的概率</span></span><br><span class="line"></span><br><span class="line">p0V,p1V,pAb=trainNB(trainMat,classVec)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span>(<span class="params">vec2Classify, p0V, p1V, pAb</span>):</span></span><br><span class="line">    p1 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p1V) * pAb   <span class="comment">#对应元素相乘</span></span><br><span class="line">    p0 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p0V) * (<span class="number">1</span> - pAb)</span><br><span class="line">    print(<span class="string">'p0:'</span>,p0)</span><br><span class="line">    print(<span class="string">'p1:'</span>,p1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span>(<span class="params">testVec</span>):</span></span><br><span class="line">    dataSet,classVec = loadDataSet() <span class="comment">#创建实验样本</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#创建词汇表</span></span><br><span class="line">    trainMat= get_trainMat(dataSet) <span class="comment">#将实验样本向量化</span></span><br><span class="line">    p0V,p1V,pAb = trainNB(trainMat,classVec) <span class="comment">#训练朴素贝叶斯分类器</span></span><br><span class="line">    thisone = setOfWords2Vec(vocabList, testVec) <span class="comment">#测试样本向量化</span></span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisone,p0V,p1V,pAb):</span><br><span class="line">        print(testVec,<span class="string">'属于侮辱类'</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(testVec,<span class="string">'属于非侮辱类'</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">        </span><br><span class="line">testVec1 = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">testingNB(testVec1)</span><br></pre></td></tr></tbody></table></figure>
<h2><span id="bernoullinb">BernoulliNB</span><a href="#bernoullinb" class="header-anchor">#</a></h2><p>伯努利分布，如果是二元伯努利分布</p>
<script type="math/tex; mode=display">
P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il})</script><p>如果样本属性大多数属于连续，GaussionNB</p>
<p>如果是离散值，使用MultinomialNB</p>
<p>如果样本特征是二元离散值或者稀疏离散值，BernoulliNB</p>
<h1><span id="ban-po-su-bei-xie-si">半朴素贝叶斯</span><a href="#ban-po-su-bei-xie-si" class="header-anchor">#</a></h1><h2><span id="xin-xi-liang-shang-lian-he-shang-tiao-jian-shang-hu-xin-xi">信息量、熵、联合熵、条件熵、互信息</span><a href="#xin-xi-liang-shang-lian-he-shang-tiao-jian-shang-hu-xin-xi" class="header-anchor">#</a></h2><h3><span id="xin-xi-liang">信息量</span><a href="#xin-xi-liang" class="header-anchor">#</a></h3><p>反应了随机变量取某个值含的可能性大小，或者是含有的信息多少</p>
<script type="math/tex; mode=display">
I(X=x)=-log_2^{p(x）}</script><h3><span id="shang-entropy">熵(entropy)</span><a href="#shang-entropy" class="header-anchor">#</a></h3><p>反应了信源平均每个符号的信息量,或者是随机变量不确定性的衡量</p>
<script type="math/tex; mode=display">
H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)})</script><h2><span id="lian-he-shang">联合熵</span><a href="#lian-he-shang" class="header-anchor">#</a></h2><p>反应了多个随机变量的平均信息量</p>
<script type="math/tex; mode=display">
H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)})</script><h3><span id="tiao-jian-shang-conditional-entropy">条件熵（Conditional entropy）</span><a href="#tiao-jian-shang-conditional-entropy" class="header-anchor">#</a></h3><p>反应了已知一个随机变量下，另一个随机变量的不确定性</p>
<script type="math/tex; mode=display">
H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)}</script><h3><span id="hu-xin-xi-mutual-information">互信息(mutual information)</span><a href="#hu-xin-xi-mutual-information" class="header-anchor">#</a></h3><p>反应了已知一个随机变量的情况下，另外一个随机变量不确定性减少了多少,可以把互信息看成由于知道 y 值而造成的 x 的不确定性的减小</p>
<script type="math/tex; mode=display">
I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\\
=H(X)-H(X|Y)=H(Y)-H(Y|X)</script><p>如果两个随机变量独立，则互信息为0,因此，互信息可以衡量两个随机变量的相关程度</p>
<h2><span id="tiao-jian-hu-xin-xi">条件互信息</span><a href="#tiao-jian-hu-xin-xi" class="header-anchor">#</a></h2><p>在条件z发生时的条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}}</script><p><img src="/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/MyBlog\hexo\source\_posts\贝叶斯分类器\熵.png" alt></p>
<h2><span id="ban-po-su-bei-xie-si">半朴素贝叶斯</span><a href="#ban-po-su-bei-xie-si" class="header-anchor">#</a></h2><p>适当的考虑一部分属性间的相互依赖关系，这个关系可以用互信息描述</p>
<h3><span id="du-yi-lai">独依赖</span><a href="#du-yi-lai" class="header-anchor">#</a></h3><p>假设每个属性只有一个其他 的属性.则计算公式改下如下</p>
<script type="math/tex; mode=display">
p(C)\Pi_{i=1}^{d} P(x_i|C_i,pa_i)</script><p>$pa_i$是属性$x_i$所依赖的属性，被称为$x_i$的父属性</p>
<p>1)  <strong>SPODE </strong>最简单的方法是：都选一个属性作为父属性</p>
<p>可以通过交叉验证的方法</p>
<p>2)  TAN :最大带权生成树</p>
<p>权重：当y划分为$c_k$类时条件熵</p>
<script type="math/tex; mode=display">
I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}}</script><p>step 1: 计算任意两个属性之间条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Y)=\sum_{i}I(X;Y|c_i)</script><p>step 2: 以属性为结点构建完全图</p>
<p>step 3: 最大带权生成树，挑选根变量</p>
<p>step 4: 加入类别结点y,增加到每个属性的有向边</p>
<p>条件互信息反应了属性在已知类别下的相关性大小</p>
<p><img src="/2019/03/28/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/MyBlog\hexo\source\_posts\贝叶斯分类器\2.png" alt></p>
<h2><span id="ji-cheng-xue-xi">集成学习</span><a href="#ji-cheng-xue-xi" class="header-anchor">#</a></h2><p>AODE选择模型尝试将每个属性作为超父构建SPODE</p>
<script type="math/tex; mode=display">
P(c_i|X)正比于 \sum_{i=1,|D_{x_i}>=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i)</script><p>$m$通常取30,</p>
<script type="math/tex; mode=display">
P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\\
P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j}</script><h1><span id="bei-xie-si-wang-bayesian-network">贝叶斯网(Bayesian network)</span><a href="#bei-xie-si-wang-bayesian-network" class="header-anchor">#</a></h1><p>借助有向无环图来刻画属性之间的依赖关系，条件概率表来描述属性的联合概率分布。</p>
<p>一个贝叶斯网络$B$,包括结构$G$和参数$\Theta$ ,$B(G,\Theta)$,如果两个属性有直接依赖关系，用边连接，对于属性$x_i$,其父节点集合$G_i$,则$\Theta$包括每个属性条件概率$\Theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$</p>
<h2><span id="jie-gou">结构</span><a href="#jie-gou" class="header-anchor">#</a></h2><script type="math/tex; mode=display">
p(x_1,x_2,...,x_n)=\Pi_{i=1}^{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}^{d}\Theta_{xi|\pi_i}\\
=\Pi_{i=1}^{d}P(x_i|Parents(x_i))</script><h2><span id="tui-duan">推断</span><a href="#tui-duan" class="header-anchor">#</a></h2><p>一旦训练好贝叶斯网后，就能回答query,通过一些属性的观测者来推断其他属性变量的取值，其中，已知变量的值观测推测待查询的过程“推断”,已知变量的观测者”证据“</p>

    </div>

    
    
    


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" rel="tag"><i class="fa fa-tag"></i> 贝叶斯分类器</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/03/25/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92/" rel="prev" title="二次规划">
      <i class="fa fa-chevron-left"></i> 二次规划
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/04/03/deeplearningvideo/" rel="next" title="deeplearningvideo">
      deeplearningvideo <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">概率论的知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.1.</span> <span class="nav-text">条件概率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text">全概率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.3.</span> <span class="nav-text">贝叶斯推断</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">贝叶斯决策论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">朴素贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">3.1.</span> <span class="nav-text">计算过程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">朴素贝叶斯的种类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.1.</span> <span class="nav-text">GaussianNB</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.2.</span> <span class="nav-text">MultinomialNB</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.3.</span> <span class="nav-text">BernoulliNB</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">半朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.1.</span> <span class="nav-text">信息量、熵、联合熵、条件熵、互信息</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.1.1.</span> <span class="nav-text">信息量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.1.2.</span> <span class="nav-text">熵(entropy)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.2.</span> <span class="nav-text">联合熵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.2.1.</span> <span class="nav-text">条件熵（Conditional entropy）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.2.2.</span> <span class="nav-text">互信息(mutual information)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.3.</span> <span class="nav-text">条件互信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.4.</span> <span class="nav-text">半朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.4.1.</span> <span class="nav-text">独依赖</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.5.</span> <span class="nav-text">集成学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">贝叶斯网(Bayesian network)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.1.</span> <span class="nav-text">结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.2.</span> <span class="nav-text">推断</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XieMay</p>
  <div class="site-description" itemprop="description">wise</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/shiyichuixue" title="GitHub → https://github.com/shiyichuixue" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2323020965@qq.com" title="E-Mail → mailto:2323020965@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XieMay</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">495k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">7:30</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共176.7k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '[object Object]';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
