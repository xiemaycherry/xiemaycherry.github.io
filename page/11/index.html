<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="baidu-site-verification" content="E1Di33CelZ">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">
<meta name="google-site-verification" content="WsojkhmMcOefku3B2Vxp02NtxlUt_JzBP1fVPrFk3Gw">


  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.0.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.4">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.4" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.0.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: 'WGLQQAQKBA',
      apiKey: '',
      indexName: 'xiemay',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  



<meta name="baidu-site-verification" content="z0tVDge8Pe">

  
  <meta name="keywords" content="Hexo, NexT">


<meta name="description" content="CAT_cat">
<meta property="og:type" content="website">
<meta property="og:title" content="welcome">
<meta property="og:url" content="http://xiemaycherry.github.io/page/11/index.html">
<meta property="og:site_name" content="welcome">
<meta property="og:description" content="CAT_cat">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="welcome">
<meta name="twitter:description" content="CAT_cat">






  <link rel="canonical" href="http://xiemaycherry.github.io/page/11/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>welcome</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
<meta name="baidu-site-verification" content="3BmH9zSH5h"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">welcome</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
        </li>
      
        
        <li class="menu-item menu-item-留言">
          <a href="/guestbook/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-commenting"></i> <br>留言</a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>Schedule</a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>Sitemap</a>
        </li>
      
        
        <li class="menu-item menu-item-baidusitmap">
          <a href="/baidusitmap.xml" rel="section">
            <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>baidusitmap</a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/03/28/贝叶斯分类器/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/贝叶斯分类器/" itemprop="url">贝叶斯分类器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T08:50:42+08:00">2019-03-28</time>
            

            
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/28/贝叶斯分类器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/28/贝叶斯分类器/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                9.6k字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="概率论的知识"><a href="#概率论的知识" class="headerlink" title="概率论的知识"></a>概率论的知识</h1><h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><script type="math/tex; mode=display">
P(A|B)=P(A\cap B)/P(B)</script><p>已知B发生的概率，求A发生的概率</p>
<h2 id="全概率"><a href="#全概率" class="headerlink" title="全概率"></a>全概率</h2><script type="math/tex; mode=display">
P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i)</script><h2 id="贝叶斯推断"><a href="#贝叶斯推断" class="headerlink" title="贝叶斯推断"></a>贝叶斯推断</h2><script type="math/tex; mode=display">
P(A|B)=P(A)\frac{P(B|A)}{P(B)}</script><script type="math/tex; mode=display">
P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)}</script><p>$P(A)$：Prior probability 先验概率，在B事件发生之前，对A事件做一个判断</p>
<p>$P(A|B)$:Posterior probability 后验概率，在B事件发生之后，对A事件的概率重新评估</p>
<p>$P(B|A)/P(B)$:称为可能性函数，一个调整因子</p>
<p>后验概率=先验概率*调整因子 （可知，调整因此&gt;1,发生概率增大了，</p>
<h1 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h1><p>英文：Bayesian decision theory</p>
<p>设有$N$种可能的类别, 即γ=${c_1,c_2,…,c_N}$. $λ_ij$是将一个真实类别为$c_j$的样本判为$c_x$的损失。 基于后验概率可得将样本分类所产生的期望损失, 或者成为条件风险(Conditional Risk) </p>
<script type="math/tex; mode=display">
R(C_i|x)=∑_{j=1}^Nλ_{ij}P(c_j|x)</script><p>于是， 我们的任务就是寻找判定准则h， 令$χ→γ$ 使得最小化总体风险，$R(h)=E_x[R(h(x)|x]$最小. 对于每一个$x$，若$h$都能最小化条件风险，那么总体也被最小化了。 可以简化为对每个样本选择其条件风险最小的分类, 即: </p>
<script type="math/tex; mode=display">
h(x)=arg \min_{c⊂λ}R(c|x)</script><p>此$h(x)$就是贝叶斯最优分类器。 $R(h)$为贝叶斯风险(Bayes Risk), $1−R(h)$反映了分类器的最优性能. </p>
<p>具体来说，如果目标是最小化分类错误率，</p>
<script type="math/tex; mode=display">\lambda_{ij}=\begin{cases} 0\ \  i==j\\1 \ \ \ i!=j \end{cases}</script><p>则$R(c|x)=1-p(c|x)$，因此可知，$h(x)=\max_{c\in C} p(c|x)$</p>
<p>对于样本$x$,选择后验概率$P(c|X)$最大的类别为标记。</p>
<p>问题转换为</p>
<script type="math/tex; mode=display">
P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)}</script><p>求先验概率和似然($P(x|c)$)</p>
<p>其中</p>
<p>$P(c)$表达了样本空间种各类样本所占的比列，根据大数定律，当样本足够充分的独立同分布样本是，可以频率估计</p>
<p>$P(x|c)$,涉及关于x所以属性的联合概率，用频率估计概率可能不太好，对于估计类条件概率的一种宠用策略是先假设具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。</p>
<p>$P(x|c)$是类条件概率，由某个分布决定，$P(x|\theta_c)$来表示了</p>
<p>频率注意派认为可以通过优化似然函数估计参数。$D_c$类别c的样本集合，独立同分布</p>
<script type="math/tex; mode=display">
P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c)</script><script type="math/tex; mode=display">
LL(\theta_c)=log  P(D_c|\theta_c)</script><h1 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h1><p>英文：naive Bayes classifier</p>
<p>假设：属性条件独立性假设，每个属性独立性对分类结果发生影响</p>
<script type="math/tex; mode=display">
P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)\Pi_{i=1}^{d}P(x_i|c)}{P(x)}</script><p>对于一个$x$，$P(x)$都是相同的，因此贝叶斯模型可写为</p>
<script type="math/tex; mode=display">
h_{nb}(x)=arg max_{c\in y}P(c)\Pi_{i=1}^{d}P(x_i|c)</script><h2 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h2><p>假设$D_{c_i}​$表示第i类的样本集合，</p>
<ol>
<li><p>$P(c_i)=\frac{|D_{c_i}|}{|D|}$</p>
</li>
<li><p>如果是离散属性</p>
</li>
</ol>
<script type="math/tex; mode=display">
P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|}</script><p>如果是连续属性，$P(x_i|c_i)$服从$N(u_{c,i},\theta_{c,i}^2)$的分布</p>
<script type="math/tex; mode=display">
P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><ol>
<li>$P(c_i)\Pi_{i=1}^{N}P(x_i|c_i)$</li>
</ol>
<p>注意为了避免其他属性携带的信息被训练集中未出现的属性值抹去，因此用拉普拉斯修正（Laplacian correction)</p>
<script type="math/tex; mode=display">
P(c)=\frac{|D_{c_i}|+1}{|D|+N}\\
P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}</script><p>$N$:训练集可能出现的类别数</p>
<p>$N_i$:第i个属性可能的取值数</p>
<p>显然，拉普拉斯修正避免因训练集不充分导出的概率估值为0的情况</p>
<h1 id="朴素贝叶斯的种类"><a href="#朴素贝叶斯的种类" class="headerlink" title="朴素贝叶斯的种类"></a>朴素贝叶斯的种类</h1><p>再scikit-learn中，一共有三个朴素贝叶斯，分别是</p>
<h2 id="GaussianNB"><a href="#GaussianNB" class="headerlink" title="GaussianNB"></a>GaussianNB</h2><script type="math/tex; mode=display">
P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris=datasets.load_iris()</span><br><span class="line"><span class="comment">#切分数据集</span></span><br><span class="line">Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data,</span><br><span class="line">                                                iris.target,</span><br><span class="line">                                                random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment">#建模</span></span><br><span class="line">clf = GaussianNB()</span><br><span class="line">clf.fit(Xtrain, ytrain)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在测试集上执行预测，proba导出的是每个样本属于某类的概率</span></span><br><span class="line">clf.predict(Xtest)</span><br><span class="line">clf.predict_proba(Xtest) <span class="comment">#每一类计算结果都输出</span></span><br><span class="line"><span class="comment">#测试准确率</span></span><br><span class="line">accuracy_score(ytest, clf.predict(Xtest))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">dataSet =pd.read_csv(<span class="string">'iris.txt'</span>,header = <span class="keyword">None</span>)</span><br><span class="line">dataSet.head()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randSplit</span><span class="params">(dataSet, rate)</span>:</span></span><br><span class="line">    l = list(dataSet.index) <span class="comment">#提取出索引</span></span><br><span class="line">    random.shuffle(l) <span class="comment">#随机打乱索引</span></span><br><span class="line">    dataSet.index = l <span class="comment">#将打乱后的索引重新赋值给原数据集</span></span><br><span class="line">    n = dataSet.shape[<span class="number">0</span>] <span class="comment">#总行数</span></span><br><span class="line">    m = int(n * rate) <span class="comment">#训练集的数量</span></span><br><span class="line">    train = dataSet.loc[range(m), :] <span class="comment">#提取前m个记录作为训练集</span></span><br><span class="line">    test = dataSet.loc[range(m, n), :] <span class="comment">#剩下的作为测试集</span></span><br><span class="line">    dataSet.index = range(dataSet.shape[<span class="number">0</span>]) <span class="comment">#更新原数据集的索引</span></span><br><span class="line">    test.index = range(test.shape[<span class="number">0</span>]) <span class="comment">#更新测试集的索引</span></span><br><span class="line"></span><br><span class="line">train,test=randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gnb_classify</span><span class="params">(train,test)</span>:</span></span><br><span class="line">    labels = train.iloc[:,<span class="number">-1</span>].value_counts().index <span class="comment">#提取训练集的标签种类</span></span><br><span class="line">    mean =[] <span class="comment">#存放每个类别的均值</span></span><br><span class="line">    std =[] <span class="comment">#存放每个类别的方差</span></span><br><span class="line">    result = [] <span class="comment">#存放测试集的预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> labels:</span><br><span class="line">        item = train.loc[train.iloc[:,<span class="number">-1</span>]==i,:] <span class="comment">#分别提取出每一种类别</span></span><br><span class="line">        m = item.iloc[:,:<span class="number">-1</span>].mean() <span class="comment">#当前类别的平均值</span></span><br><span class="line">        s = np.sum((item.iloc[:,:<span class="number">-1</span>]-m)**<span class="number">2</span>)/(item.shape[<span class="number">0</span>]) <span class="comment">#当前类别的方差</span></span><br><span class="line">        mean.append(m) <span class="comment">#将当前类别的平均值追加至列表</span></span><br><span class="line">        std.append(s) <span class="comment">#将当前类别的方差追加至列表</span></span><br><span class="line">    means = pd.DataFrame(mean,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    stds = pd.DataFrame(std,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(test.shape[<span class="number">0</span>]):</span><br><span class="line">        iset = test.iloc[j,:<span class="number">-1</span>].tolist() <span class="comment">#当前测试实例</span></span><br><span class="line">        iprob = np.exp(<span class="number">-1</span>*(iset-means)**<span class="number">2</span>/(stds*<span class="number">2</span>))/(np.sqrt(<span class="number">2</span>*np.pi*stds)) <span class="comment">#正态分布公式</span></span><br><span class="line">        prob = train.iloc[:,<span class="number">-1</span>].value_counts()/len(train.iloc[:,<span class="number">-1</span>]) <span class="comment">#初始化当前实例总概率</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(test.shape[<span class="number">1</span>]<span class="number">-1</span>): <span class="comment">#遍历每个特征</span></span><br><span class="line">            prob *= iprob[k] <span class="comment">#特征概率之积即为当前实例概率</span></span><br><span class="line">        cla = prob.index[np.argmax(prob.values)] <span class="comment">#返回最大概率的类别</span></span><br><span class="line">        result.append(cla)</span><br><span class="line">    test[<span class="string">'predict'</span>]=result</span><br><span class="line">    acc = (test.iloc[:,<span class="number">-1</span>]==test.iloc[:,<span class="number">-2</span>]).mean() <span class="comment">#计算预测准确率</span></span><br><span class="line">    print(<span class="string">f'模型预测准确率为<span class="subst">&#123;acc&#125;</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> test</span><br><span class="line"></span><br><span class="line">gnb_classify(train,test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    train,test= randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line">    gnb_classify(train,test)</span><br></pre></td></tr></table></figure>
<h2 id="MultinomialNB"><a href="#MultinomialNB" class="headerlink" title="MultinomialNB"></a>MultinomialNB</h2><p>先验概率多项式分布的朴素贝叶斯，假设特征是由一共简单多项式分布生成，多项分布可以描述各种类型样本出现的频率，该模型常用于文本分类，特别表示次数。$\lambda$常取值1</p>
<script type="math/tex; mode=display">
P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet=[[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span>],</span><br><span class="line">             [<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>, <span class="string">'to'</span>, <span class="string">'dog'</span>, <span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">             [<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">             [<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">             [<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">             [<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]] <span class="comment">#切分好的词条</span></span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>] <span class="comment">#类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇</span></span><br><span class="line">    <span class="keyword">return</span> dataSet,classVec</span><br><span class="line">dataSet,classVec = loadDataSet()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    vocabSet = set() <span class="comment">#创建一个空的集合</span></span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> dataSet: <span class="comment">#遍历dataSet中的每一条言论</span></span><br><span class="line">        vocabSet = vocabSet | set(doc) <span class="comment">#取并集</span></span><br><span class="line">        vocabList = list(vocabSet)</span><br><span class="line">    <span class="keyword">return</span> vocabList</span><br><span class="line"></span><br><span class="line">vocabList = createVocabList(dataSet)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">    returnVec = [<span class="number">0</span>] * len(vocabList) <span class="comment">#创建一个其中所含元素都为0的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet: <span class="comment">#遍历每个词条</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList: <span class="comment">#如果词条存在于词汇表中，则变为1</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">f" <span class="subst">&#123;word&#125;</span> is not in my Vocabulary!"</span> )</span><br><span class="line">    <span class="keyword">return</span> returnVec <span class="comment">#返回文档向量</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_trainMat</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    trainMat = [] <span class="comment">#初始化向量列表</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#生成词汇表</span></span><br><span class="line">    <span class="keyword">for</span> inputSet <span class="keyword">in</span> dataSet: <span class="comment">#遍历样本词条中的每一条样本</span></span><br><span class="line">        returnVec=setOfWords2Vec(vocabList, inputSet) <span class="comment">#将当前词条向量化</span></span><br><span class="line">        trainMat.append(returnVec) <span class="comment">#追加到向量列表中</span></span><br><span class="line">    <span class="keyword">return</span> trainMat</span><br><span class="line">trainMat = get_trainMat(dataSet)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB</span><span class="params">(trainMat,classVec)</span>:</span></span><br><span class="line">    n = len(trainMat) <span class="comment">#计算训练的文档数目</span></span><br><span class="line">    m = len(trainMat[<span class="number">0</span>]) <span class="comment">#计算每篇文档的词条数</span></span><br><span class="line">    pAb = sum(classVec)/n <span class="comment">#文档属于侮辱类的概率</span></span><br><span class="line">    p0Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p1Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p0Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    p1Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n): <span class="comment">#遍历每一个文档</span></span><br><span class="line">        <span class="keyword">if</span> classVec[i] == <span class="number">1</span>: <span class="comment">#统计属于侮辱类的条件概率所需的数据</span></span><br><span class="line">            p1Num += trainMat[i]</span><br><span class="line">            p1Denom += sum(trainMat[i])</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">#统计属于非侮辱类的条件概率所需的数据</span></span><br><span class="line">            p0Num += trainMat[i]</span><br><span class="line">            p0Denom += sum(trainMat[i])</span><br><span class="line">    p1V = p1Num/p1Denom</span><br><span class="line">    p0V = p0Num/p0Denom</span><br><span class="line">    <span class="keyword">return</span> p0V,p1V,pAb <span class="comment">#返回属于非侮辱类,侮辱类和文档属于侮辱类的概率</span></span><br><span class="line"></span><br><span class="line">p0V,p1V,pAb=trainNB(trainMat,classVec)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0V, p1V, pAb)</span>:</span></span><br><span class="line">    p1 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p1V) * pAb   <span class="comment">#对应元素相乘</span></span><br><span class="line">    p0 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p0V) * (<span class="number">1</span> - pAb)</span><br><span class="line">    print(<span class="string">'p0:'</span>,p0)</span><br><span class="line">    print(<span class="string">'p1:'</span>,p1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">(testVec)</span>:</span></span><br><span class="line">    dataSet,classVec = loadDataSet() <span class="comment">#创建实验样本</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#创建词汇表</span></span><br><span class="line">    trainMat= get_trainMat(dataSet) <span class="comment">#将实验样本向量化</span></span><br><span class="line">    p0V,p1V,pAb = trainNB(trainMat,classVec) <span class="comment">#训练朴素贝叶斯分类器</span></span><br><span class="line">    thisone = setOfWords2Vec(vocabList, testVec) <span class="comment">#测试样本向量化</span></span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisone,p0V,p1V,pAb):</span><br><span class="line">        print(testVec,<span class="string">'属于侮辱类'</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(testVec,<span class="string">'属于非侮辱类'</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">        </span><br><span class="line">testVec1 = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">testingNB(testVec1)</span><br></pre></td></tr></table></figure>
<h2 id="BernoulliNB"><a href="#BernoulliNB" class="headerlink" title="BernoulliNB"></a>BernoulliNB</h2><p>伯努利分布，如果是二元伯努利分布</p>
<script type="math/tex; mode=display">
P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il})</script><p>如果样本属性大多数属于连续，GaussionNB</p>
<p>如果是离散值，使用MultinomialNB</p>
<p>如果样本特征是二元离散值或者稀疏离散值，BernoulliNB</p>
<h1 id="半朴素贝叶斯"><a href="#半朴素贝叶斯" class="headerlink" title="半朴素贝叶斯"></a>半朴素贝叶斯</h1><h2 id="信息量、熵、联合熵、条件熵、互信息"><a href="#信息量、熵、联合熵、条件熵、互信息" class="headerlink" title="信息量、熵、联合熵、条件熵、互信息"></a>信息量、熵、联合熵、条件熵、互信息</h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p>反应了随机变量取某个值含的可能性大小，或者是含有的信息多少</p>
<script type="math/tex; mode=display">
I(X=x)=-log_2^{p(x）}</script><h3 id="熵-entropy"><a href="#熵-entropy" class="headerlink" title="熵(entropy)"></a>熵(entropy)</h3><p>反应了信源平均每个符号的信息量,或者是随机变量不确定性的衡量</p>
<script type="math/tex; mode=display">
H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)})</script><h2 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h2><p>反应了多个随机变量的平均信息量</p>
<script type="math/tex; mode=display">
H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)})</script><h3 id="条件熵（Conditional-entropy）"><a href="#条件熵（Conditional-entropy）" class="headerlink" title="条件熵（Conditional entropy）"></a>条件熵（Conditional entropy）</h3><p>反应了已知一个随机变量下，另一个随机变量的不确定性</p>
<script type="math/tex; mode=display">
H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)}</script><h3 id="互信息-mutual-information"><a href="#互信息-mutual-information" class="headerlink" title="互信息(mutual information)"></a>互信息(mutual information)</h3><p>反应了已知一个随机变量的情况下，另外一个随机变量不确定性减少了多少,可以把互信息看成由于知道 y 值而造成的 x 的不确定性的减小</p>
<script type="math/tex; mode=display">
I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\\
=H(X)-H(X|Y)=H(Y)-H(Y|X)</script><p>如果两个随机变量独立，则互信息为0,因此，互信息可以衡量两个随机变量的相关程度</p>
<h2 id="条件互信息"><a href="#条件互信息" class="headerlink" title="条件互信息"></a>条件互信息</h2><p>在条件z发生时的条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}}</script><p><img src="/2019/03/28/贝叶斯分类器/MyBlog\hexo\source\_posts\贝叶斯分类器\熵.png" alt=""></p>
<h2 id="半朴素贝叶斯-1"><a href="#半朴素贝叶斯-1" class="headerlink" title="半朴素贝叶斯"></a>半朴素贝叶斯</h2><p>适当的考虑一部分属性间的相互依赖关系，这个关系可以用互信息描述</p>
<h3 id="独依赖"><a href="#独依赖" class="headerlink" title="独依赖"></a>独依赖</h3><p>假设每个属性只有一个其他 的属性.则计算公式改下如下</p>
<script type="math/tex; mode=display">
p(C)\Pi_{i=1}^{d} P(x_i|C_i,pa_i)</script><p>$pa_i$是属性$x_i$所依赖的属性，被称为$x_i$的父属性</p>
<p>1)  <strong>SPODE </strong>最简单的方法是：都选一个属性作为父属性</p>
<p>可以通过交叉验证的方法</p>
<p>2)  TAN :最大带权生成树</p>
<p>权重：当y划分为$c_k$类时条件熵</p>
<script type="math/tex; mode=display">
I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}}</script><p>step 1: 计算任意两个属性之间条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Y)=\sum_{i}I(X;Y|c_i)</script><p>step 2: 以属性为结点构建完全图</p>
<p>step 3: 最大带权生成树，挑选根变量</p>
<p>step 4: 加入类别结点y,增加到每个属性的有向边</p>
<p>条件互信息反应了属性在已知类别下的相关性大小</p>
<p><img src="/2019/03/28/贝叶斯分类器/MyBlog\hexo\source\_posts\贝叶斯分类器\2.png" alt=""></p>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>AODE选择模型尝试将每个属性作为超父构建SPODE</p>
<script type="math/tex; mode=display">
P(c_i|X)正比于 \sum_{i=1,|D_{x_i}>=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i)</script><p>$m$通常取30,</p>
<script type="math/tex; mode=display">
P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\\
P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j}</script><h1 id="贝叶斯网-Bayesian-network"><a href="#贝叶斯网-Bayesian-network" class="headerlink" title="贝叶斯网(Bayesian network)"></a>贝叶斯网(Bayesian network)</h1><p>借助有向无环图来刻画属性之间的依赖关系，条件概率表来描述属性的联合概率分布。</p>
<p>一个贝叶斯网络$B$,包括结构$G$和参数$\Theta$ ,$B(G,\Theta)$,如果两个属性有直接依赖关系，用边连接，对于属性$x_i$,其父节点集合$G_i$,则$\Theta$包括每个属性条件概率$\Theta_{x_i|\pi_i}=P_B(x_i|\pi_i)​$</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><script type="math/tex; mode=display">
p(x_1,x_2,...,x_n)=\Pi_{i=1}^{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}^{d}\Theta_{xi|\pi_i}\\
=\Pi_{i=1}^{d}P(x_i|Parents(x_i))</script><h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><p>一旦训练好贝叶斯网后，就能回答query,通过一些属性的观测者来推断其他属性变量的取值，其中，已知变量的值观测推测待查询的过程“推断”,已知变量的观测者”证据“</p>

          
        
      
    </div>

    

    
    
    

    

    

    
<div>
  
</div>
    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/03/25/二次规划/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/25/二次规划/" itemprop="url">二次规划</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-25T15:28:27+08:00">2019-03-25</time>
            

            
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/25/二次规划/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/25/二次规划/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                548字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="KKT-Karush-Kuhn-Tucher-条件"><a href="#KKT-Karush-Kuhn-Tucher-条件" class="headerlink" title="KKT(Karush-Kuhn-Tucher)条件"></a>KKT(Karush-Kuhn-Tucher)条件</h1><p>给定优化问题</p>
<script type="math/tex; mode=display">
\min f(x)\\
subject\ to \begin{cases}
g_i(x) = 0 (i=1,,,,m\\
h_i(x) <= 0 (i=m+1,...,n)
\end{cases}</script><p>构造lagrange函数</p>
<script type="math/tex; mode=display">
L(x,\lambda) = f(x)+\sum_{i=1}^{m}\lambda_ig_i(x)+\sum_{i=m+1}^{n}\lambda_ih_i(x)</script><p>KKT条件</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial x}=0\\
g_i(x)=0\\
\lambda_i>=0 (i=m+1,...,n)\\
\lambda_i h_i(x)=0(i=m+1,..,n)</script><h1 id="二次规划问题"><a href="#二次规划问题" class="headerlink" title="二次规划问题"></a>二次规划问题</h1><p>问题的数学表达</p>
<script type="math/tex; mode=display">
\min Q(x) = \frac{1}{2}x^THx+g^Tx\\
s.t. a_i^Tx = b_i (i=1,..,m)\\
\ \ \  \ \ \ \ a_i^Tx <= b_i(i=m+1,...n)</script><p>KKT条件</p>
<script type="math/tex; mode=display">
\bigtriangledown f(x)-A^T\lambda =0\\
A_{E}x - b_{E}=0\\
A_{L}x-b_L<=0\\
\lambda_L>=0\\
\lambda_L^T(A_LX_L-b_L)=0</script><p>如果$H$半正定，二次规划问题的全局极小值的充要条件，$x^{*}$是一个K-T条件</p>
<p>证明：</p>
<p>必要性：KKT</p>
<p>充分性：</p>
<script type="math/tex; mode=display">
f(x)-f(x^{*})=\frac{1}{2}x^THx+g^Tx-\frac{1}{2}x^{*T}Hx^{*}-g^Tx^{*}\\
=\frac{1}{2}(x-x^{*})^TH(x-x^{*})+x^{*T}H(x-x^{*})+g^T(x-x^{*})\\
>=x^{*T}H(x-x^{*})+g^T(x-x^{*})=\lambda^TA(x-x^{*})</script><p><a href="http://www.hankcs.com/ml/lagrange-duality.html#h3-7" target="_blank" rel="noopener">http://www.hankcs.com/ml/lagrange-duality.html#h3-7</a></p>
<h1 id="SMO-：Sequential-minimal-optimization"><a href="#SMO-：Sequential-minimal-optimization" class="headerlink" title="SMO ：Sequential minimal optimization"></a>SMO ：Sequential minimal optimization</h1><p>支持向量机的对偶问题</p>
<script type="math/tex; mode=display">
\min \frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jK(x_i,x_j)-\sum_{i=1}^{m}\alpha_i\\
s.t. \sum_{i=1}^{m}\alpha_iy_i=0\\
0<=\alpha_i<=C</script><p>这个优化问题，可以根据二次规划求解，但是如果样本 过多，特别慢</p>
<p>Platt提出了一种更快的方法</p>
<p>SMO算法是一种启发式算法，其基本思路是：</p>
<p>如果所有变量的解都满足此最优化问题的KKT条件（Karush-Kuhn-Tuckerconditions)，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。</p>
<p>否则，选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题。这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小。重要的是，这时子问题可以通过解析方法求解，这样就可以大大提高整个算法的计算速度。子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定。如此，SMO算法将原问题不断分解为子问题并对子问题求解，进而达到求解原问题的目的。</p>
<p>假设$\alpha_i,\alpha_j​$为选择的两个优化变量，则优化问题</p>
<script type="math/tex; mode=display">
\min W(\alpha_i,\alpha_j)=\frac{1}{2}\alpha_i\alpha_iy_iy_iK(x_i,x_i)+\frac{1}{2}\alpha_j\alpha_jy_jy_jK(x_j,x_j)+\alpha_i\alpha_jy_iy_jK(x_i,x_j)\\
+\sum_{k_1,k_2!=i,j}^{m}\alpha_{k_1}\alpha_{k_2}y_{k_1}y_{k_2}K(x_{k_1},x_{k_2})-(\alpha_i+\alpha_j)\\
s.t\ \ \  \alpha_iy_i+\alpha_jy_j=-\sum_{k!=i,j}^{m}\alpha_ky_k=\xi\\
0<=\alpha_i<=C</script><p>上述问题就是关于</p>

          
        
      
    </div>

    

    
    
    

    

    

    
<div>
  
</div>
    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/03/24/kaggle/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/24/kaggle/" itemprop="url">kaggle</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-24T14:24:46+08:00">2019-03-24</time>
            

            
            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/24/kaggle/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/24/kaggle/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                0字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    
    
    

    

    

    
<div>
  
</div>
    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/03/23/scikit-learn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/23/scikit-learn/" itemprop="url">scikit-learn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-23T18:39:47+08:00">2019-03-23</time>
            

            
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/编程语言/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/23/scikit-learn/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/23/scikit-learn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                6.8k字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Cross-validation-evaluating-estimator-performance¶"><a href="#Cross-validation-evaluating-estimator-performance¶" class="headerlink" title="Cross-validation: evaluating estimator performance¶"></a>Cross-validation: evaluating estimator performance<a href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance" target="_blank" rel="noopener">¶</a></h1><p><img src="https://scikit-learn.org/stable/_images/grid_search_workflow.png" alt="Grid Search Workflow"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line"># 调用train_test_split函数 自动划分数据集 40%for testing</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, test_size=0.4, random_state=0)</span><br></pre></td></tr></table></figure>
<h2 id="corss-validation"><a href="#corss-validation" class="headerlink" title="corss validation"></a>corss validation</h2><p><img src="https://scikit-learn.org/stable/_images/grid_search_cross_validation.png" alt="../_images/grid_search_cross_validation.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_validate</span><br><span class="line">from sklearn.metrics import recall_score</span><br><span class="line">scoring = [&apos;precision_macro&apos;, &apos;recall_macro&apos;]</span><br><span class="line">clf = svm.SVC(kernel=&apos;linear&apos;, C=1, random_state=0)</span><br><span class="line">scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,</span><br><span class="line">                        cv=5, return_train_score=False)</span><br><span class="line">sorted(scores.keys())</span><br></pre></td></tr></table></figure>
<h2 id="Cross-validation-of-time-series-data"><a href="#Cross-validation-of-time-series-data" class="headerlink" title="Cross validation of time series data"></a>Cross validation of time series data</h2><p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0101.png" alt="../_images/sphx_glr_plot_cv_indices_0101.png"></p>
<h1 id="Tuning-the-hyper-parameters-of-an-estimator"><a href="#Tuning-the-hyper-parameters-of-an-estimator" class="headerlink" title="Tuning the hyper-parameters of an estimator"></a>Tuning the hyper-parameters of an estimator</h1><p>A search consists of:</p>
<ul>
<li><p>an estimator (regressor or classifier such as <code>sklearn.svm.SVC()</code>);</p>
</li>
<li><p>a parameter space;</p>
</li>
<li><p>a method for searching or sampling candidates;</p>
</li>
<li><p>a cross-validation scheme; and</p>
</li>
<li><p>a <a href="https://scikit-learn.org/stable/modules/grid_search.html#gridsearch-scoring" target="_blank" rel="noopener">score function</a>.</p>
</li>
</ul>
<h2 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">param_grid = [</span><br><span class="line">  &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;kernel&apos;: [&apos;linear&apos;]&#125;,</span><br><span class="line">  &#123;&apos;C&apos;: [1, 10, 100, 1000], &apos;gamma&apos;: [0.001, 0.0001], &apos;kernel&apos;: [&apos;rbf&apos;]&#125;,</span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">print(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loading the Digits dataset</span></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line"></span><br><span class="line"><span class="comment"># To apply an classifier on this data, we need to flatten the image, to</span></span><br><span class="line"><span class="comment"># turn the data in a (samples, feature) matrix:</span></span><br><span class="line">n_samples = len(digits.images)</span><br><span class="line">X = digits.images.reshape((n_samples, <span class="number">-1</span>))</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the dataset in two equal parts</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.5</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the parameters by cross-validation</span></span><br><span class="line">tuned_parameters = [&#123;<span class="string">'kernel'</span>: [<span class="string">'rbf'</span>], <span class="string">'gamma'</span>: [<span class="number">1e-3</span>, <span class="number">1e-4</span>],</span><br><span class="line">                     <span class="string">'C'</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]&#125;,</span><br><span class="line">                    &#123;<span class="string">'kernel'</span>: [<span class="string">'linear'</span>], <span class="string">'C'</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]&#125;]</span><br><span class="line"></span><br><span class="line">scores = [<span class="string">'precision'</span>, <span class="string">'recall'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> score <span class="keyword">in</span> scores:</span><br><span class="line">    print(<span class="string">"# Tuning hyper-parameters for %s"</span> % score)</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line">    clf = GridSearchCV(SVC(), tuned_parameters, cv=<span class="number">5</span>,</span><br><span class="line">                       scoring=<span class="string">'%s_macro'</span> % score)</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Best parameters set found on development set:"</span>)</span><br><span class="line">    print()</span><br><span class="line">    print(clf.best_params_)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">"Grid scores on development set:"</span>)</span><br><span class="line">    print()</span><br><span class="line">    means = clf.cv_results_[<span class="string">'mean_test_score'</span>]</span><br><span class="line">    stds = clf.cv_results_[<span class="string">'std_test_score'</span>]</span><br><span class="line">    <span class="keyword">for</span> mean, std, params <span class="keyword">in</span> zip(means, stds, clf.cv_results_[<span class="string">'params'</span>]):</span><br><span class="line">        print(<span class="string">"%0.3f (+/-%0.03f) for %r"</span></span><br><span class="line">              % (mean, std * <span class="number">2</span>, params))</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Detailed classification report:"</span>)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">"The model is trained on the full development set."</span>)</span><br><span class="line">    print(<span class="string">"The scores are computed on the full evaluation set."</span>)</span><br><span class="line">    print()</span><br><span class="line">    y_true, y_pred = y_test, clf.predict(X_test)</span><br><span class="line">    print(classification_report(y_true, y_pred))</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note the problem is too easy: the hyperparameter plateau is too flat and the</span></span><br><span class="line"><span class="comment"># output model is the same for precision and recall with ties in quality.</span></span><br></pre></td></tr></table></figure>
<h2 id="Randomized-Parameter-Optimization"><a href="#Randomized-Parameter-Optimization" class="headerlink" title="Randomized Parameter Optimization"></a>Randomized Parameter Optimization</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">print(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint <span class="keyword">as</span> sp_randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># get some data</span></span><br><span class="line">digits = load_digits()</span><br><span class="line">X, y = digits.data, digits.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># build a classifier</span></span><br><span class="line">clf = RandomForestClassifier(n_estimators=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Utility function to report best scores</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span><span class="params">(results, n_top=<span class="number">3</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_top + <span class="number">1</span>):</span><br><span class="line">        candidates = np.flatnonzero(results[<span class="string">'rank_test_score'</span>] == i)</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            print(<span class="string">"Model with rank: &#123;0&#125;"</span>.format(i))</span><br><span class="line">            print(<span class="string">"Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)"</span>.format(</span><br><span class="line">                  results[<span class="string">'mean_test_score'</span>][candidate],</span><br><span class="line">                  results[<span class="string">'std_test_score'</span>][candidate]))</span><br><span class="line">            print(<span class="string">"Parameters: &#123;0&#125;"</span>.format(results[<span class="string">'params'</span>][candidate]))</span><br><span class="line">            print(<span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># specify parameters and distributions to sample from</span></span><br><span class="line">param_dist = &#123;<span class="string">"max_depth"</span>: [<span class="number">3</span>, <span class="keyword">None</span>],</span><br><span class="line">              <span class="string">"max_features"</span>: sp_randint(<span class="number">1</span>, <span class="number">11</span>),</span><br><span class="line">              <span class="string">"min_samples_split"</span>: sp_randint(<span class="number">2</span>, <span class="number">11</span>),</span><br><span class="line">              <span class="string">"bootstrap"</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</span><br><span class="line">              <span class="string">"criterion"</span>: [<span class="string">"gini"</span>, <span class="string">"entropy"</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># run randomized search</span></span><br><span class="line">n_iter_search = <span class="number">20</span></span><br><span class="line">random_search = RandomizedSearchCV(clf, param_distributions=param_dist,</span><br><span class="line">                                   n_iter=n_iter_search, cv=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">start = time()</span><br><span class="line">random_search.fit(X, y)</span><br><span class="line">print(<span class="string">"RandomizedSearchCV took %.2f seconds for %d candidates"</span></span><br><span class="line">      <span class="string">" parameter settings."</span> % ((time() - start), n_iter_search))</span><br><span class="line">report(random_search.cv_results_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use a full grid over all parameters</span></span><br><span class="line">param_grid = &#123;<span class="string">"max_depth"</span>: [<span class="number">3</span>, <span class="keyword">None</span>],</span><br><span class="line">              <span class="string">"max_features"</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="string">"min_samples_split"</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>],</span><br><span class="line">              <span class="string">"bootstrap"</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</span><br><span class="line">              <span class="string">"criterion"</span>: [<span class="string">"gini"</span>, <span class="string">"entropy"</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># run grid search</span></span><br><span class="line">grid_search = GridSearchCV(clf, param_grid=param_grid, cv=<span class="number">5</span>)</span><br><span class="line">start = time()</span><br><span class="line">grid_search.fit(X, y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"GridSearchCV took %.2f seconds for %d candidate parameter settings."</span></span><br><span class="line">      % (time() - start, len(grid_search.cv_results_[<span class="string">'params'</span>])))</span><br><span class="line">report(grid_search.cv_results_)</span><br></pre></td></tr></table></figure>
<p>  step1： 交叉验证（评价模型）</p>
<p>step2: 超参数选择，每一组参数：对应一次交叉验证</p>
<p>step 3: 集成学习</p>
<p>也可进行参数的调解</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.ensemble import AdaBoostClassifier</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">clf = AdaBoostClassifier(n_estimators=100)</span><br><span class="line">scores = cross_val_score(clf, iris.data, iris.target, cv=5)</span><br><span class="line">scores.mean()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from itertools import product</span><br><span class="line">from sklearn.ensemble import VotingClassifier</span><br><span class="line"></span><br><span class="line"># Loading some example data</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[:, [0, 2]]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"># Training classifiers</span><br><span class="line">clf1 = DecisionTreeClassifier(max_depth=4)</span><br><span class="line">clf2 = KNeighborsClassifier(n_neighbors=7)</span><br><span class="line">clf3 = SVC(gamma=&apos;scale&apos;, kernel=&apos;rbf&apos;, probability=True)</span><br><span class="line">eclf = VotingClassifier(estimators=[(&apos;dt&apos;, clf1), (&apos;knn&apos;, clf2), (&apos;svc&apos;, clf3)],</span><br><span class="line">                        voting=&apos;soft&apos;, weights=[2, 1, 2])</span><br><span class="line"></span><br><span class="line">clf1 = clf1.fit(X, y)</span><br><span class="line">clf2 = clf2.fit(X, y)</span><br><span class="line">clf3 = clf3.fit(X, y)</span><br><span class="line">eclf = eclf.fit(X, y)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    
<div>
  
</div>
    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xiemaycherry.github.io/2019/03/22/Boosting/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="welcome">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/22/Boosting/" itemprop="url">Boosting</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-22T14:54:29+08:00">2019-03-22</time>
            

            
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/22/Boosting/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/22/Boosting/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article&#58;</span>
                
                <span title="Symbols count in article">
                4k字
              </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Boosting算法是将“弱学习算法“提升为“强学习算法”的过程。</p>
<ol>
<li><p>加法模型</p>
<script type="math/tex; mode=display">
F_n(x;P) = \sum_{t=1}^{n}\alpha_th_t(x;a_t)</script></li>
<li><p>前向分步</p>
<script type="math/tex; mode=display">
F_m(x) = F_{m-1}(x)+\alpha_mh_m(x,a_m)</script><p>如果选取不同损失函数，则产生不同的类型</p>
</li>
</ol>
<h1 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h1><p>AdaBoost就是损失函数为指数损失的Boosting算法。</p>
<ol>
<li><p>每一次迭代的弱学习$h(x;a_m)$有何不一样，如何学习？</p>
<p>AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。</p>
</li>
<li><p>弱分类器权值$β_m$如何确定？</p>
<p>AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。</p>
</li>
</ol>
<h2 id="原理理解"><a href="#原理理解" class="headerlink" title="原理理解"></a>原理理解</h2><p>基于Boosting的理解，对于AdaBoost，我们要搞清楚两点：</p>
<p>每一次迭代的弱学习h(x;am)有何不一样，如何学习？<br>弱分类器权值βm如何确定？<br>对于第一个问题，AdaBoost改变了训练数据的权值，也就是样本的概率分布，其思想是将关注点放在被错误分类的样本上，减小上一轮被正确分类的样本权值，提高那些被错误分类的样本权值。然后，再根据所采用的一些基本机器学习算法进行学习，比如逻辑回归。</p>
<p>对于第二个问题，AdaBoost采用加权多数表决的方法，加大分类误差率小的弱分类器的权重，减小分类误差率大的弱分类器的权重。这个很好理解，正确率高分得好的弱分类器在强分类器中当然应该有较大的发言权。</p>
<h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><p>指数损失函数</p>
<script type="math/tex; mode=display">
L(Y,f(x))=exp(-Yf(x))</script><p>权重更新公式: 采用的指数误差函数</p>
<script type="math/tex; mode=display">
l_{exp}(a_th_t|D_t)=E(exp(-f(x)a_th_t(x)))\\
=p(f(x)=h_t(x))e^{-at}+p(f(x)!=h_t(x))e^{at}\\
=e^{-at}(1-\xi)+e^{at}\xi</script><script type="math/tex; mode=display">
a_t=\frac{1}{2}ln \frac{1-\xi}{\xi}</script><p>分布更新公式</p>
<script type="math/tex; mode=display">
\begin{aligned} l\left(H_{t-1}(x)+\alpha h_{t}(x) | D\right) &=E_{X \sim D}\left(\exp \left(-y(x)\left(H_{t-1}(x)+\alpha h_{t}(x)\right)\right)\right) \\ &=E_{x \sim D}\left(\exp \left(-y(x) H_{t-1}(x)\right) \exp \left(-y(x) \alpha h_{t}(x)\right)\right) \end{aligned}</script><p>在泰勒展开$exp(-y(x)h_t(x))$</p>
<script type="math/tex; mode=display">
\begin{aligned} l\left(H_{t-1}(x)+h_{t}(x) | D\right) & \approx E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-\alpha y(x) h_{t}(x)+\frac{\alpha^{2} y^{2}(x) h_{t}^{2}(x)}{2}\right)\right] \\ &=E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\left(1-y(x) h_{t}(x)+0.5 \alpha^{2}\right)\right] \end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned} h(x) &=\arg \min _{h} l\left(H_{t-1}(x)+\alpha h_{t} | D\right) \\ &=\arg \max _{h} E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right) \alpha y(x) h_{t}(x)\right] \\ &=\arg \max _{h}\left[\frac{\exp \left(-y(x) H_{t-1}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]} y(x) h(x)\right] \end{aligned}</script><script type="math/tex; mode=display">
</script><p>令一个新分布,注意分子是常数</p>
<script type="math/tex; mode=display">
D_{t}(x)=\frac{D(x) \exp \left(-y(x) H_{t-1}(x)\right)^{L}}{E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right]}</script><script type="math/tex; mode=display">
\begin{aligned} h(x) &=\arg \max _{h} E_{x \sim D,}(y(x) h(x)) \\ &=\arg \max _{h} E_{x \sim D_{t}}(1-2 \mathcal{I}(y(x) \neq h(x))) \\ &=\arg \min _{h} E_{x \sim D_{i}}(\mathcal{I}(y(x) \neq h(x))) \end{aligned}</script><p>同理可得</p>
<script type="math/tex; mode=display">
\begin{aligned} D_{t+1} &=\frac{D(x) \exp \left(-y(x) H_{t}(x)\right)}{E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=\frac{D_{t}(x) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t-1}(x)\right)\right] \cdot \exp \left(-y(x) H_{t}(x)\right)}{\exp \left(-y(x) H_{t-1}(x)\right) \cdot E_{x \sim D}\left[\exp \left(-y(x) H_{t}(x)\right)\right]} \\ &=D_{t}(x) \exp \left(-y(x) \alpha h_{t}(x)\right) \cdot C . \quad(C i s a \text {constant}) \end{aligned}</script><script type="math/tex; mode=display">
Z_{t}=\sum_{i}^{m} D_{t}(x) \exp \left(-y(x) \alpha_{t} h_{y}(x)\right)</script><p>指数误差函数</p>
<script type="math/tex; mode=display">
\begin{aligned} l(H(x) | D) &=\frac{1}{m} \sum_{i}^{m} \exp \left(-y_{i} H\left(x_{i}\right)\right) \\ &=\frac{1}{m} \sum_{i}^{m} \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=\sum_{i}^{m} D_{1}\left(x_{i}\right) \exp \left(-\sum_{j}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ &=Z_{1} Z_{2}\left(x_{i}\right) \exp \left(-\sum_{j=2}^{T} \alpha_{j} y_{i} h_{j}\left(x_{i}\right)\right) \\ & \vdots \\ &=\prod_{i=1}^{T} Z_{i} \end{aligned}</script><h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><p>总结一下，得到AdaBoost的算法流程：</p>
<p>输入：训练数据集$T={(x1,y1),(x2,y2),(xN,yN)}T={(x1,y1),(x2,y2),(xN,yN)}​$，其中，$xi∈X⊆Rnxi∈X⊆Rn，yi∈Y=−1,1yi∈Y=−1,1，​$迭代次数M</p>
<p>初始化训练样本的权值分布：$D1=(w1,1,w1,2,…,w1,i),w,i=1,2,…,N$。</p>
<p>对于$m=1,2,…,M​$</p>
<p>(a)　使用具有权值分布$D_m​$的训练数据集进行学习，得到弱分类器$h_m(x)​$　(b)　计算$h_m(x)​$在训练数据集上的分类误差率：</p>
<p>$e_m=∑_{i=1}^{N}w_m,iI(h_m(xi)≠y_i)​$</p>
<p>(c)　计算$h_m(x)$在强分类器中所占的权重：</p>
<p>$\alpha_m=\frac{1}{2}log(\frac{1−e_m}{e_m})​$</p>
<p>(d)　更新训练数据集的权值分布（这里，$z_m是归一化因子，为了使样本的概率分布和为1）：</p>
<script type="math/tex; mode=display">w_{m+1,i}=\frac{w_{m,i}}exp(−α_my_ih_m(xi))，i=1,2,…,10</script><script type="math/tex; mode=display">z_m=∑_{i=1}^{N}w_{m,i}exp(−α_my_ih_m(xi))​</script><p> 得到最终分类器：</p>
<script type="math/tex; mode=display">F(x)=sign(∑_{i=1}^{N}α_mh_m(x))</script><h2 id="面经"><a href="#面经" class="headerlink" title="面经"></a>面经</h2><p>今年8月开始找工作，参加大厂面试问到的相关问题有如下几点：</p>
<ol>
<li>手推AdaBoost</li>
</ol>
<ol>
<li>与GBDT比较</li>
</ol>
<ol>
<li>AdaBoost几种基本机器学习算法哪个抗噪能力最强，哪个对重采样不敏感？</li>
</ol>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><h2 id="实例计算"><a href="#实例计算" class="headerlink" title="实例计算"></a>实例计算</h2><h2 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h2><p><a href="https://www.cnblogs.com/davidwang456/articles/8927029.html" target="_blank" rel="noopener">https://www.cnblogs.com/davidwang456/articles/8927029.html</a></p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>
          
        
      
    </div>

    

    
    
    

    

    

    
<div>
  
</div>
    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">XieMay</p>
              <p class="site-description motion-element" itemprop="description">CAT_cat</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">66</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">46</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="http://www.cnblogs.com/shiyiandchuixue/" target="_blank" title="BLOGS"><i class="fa fa-fw fa-globe"></i>BLOGS</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:2323020965@qq.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/shiyichuixue" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="powered-by">
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XieMay</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Symbols count total&#58;</span>
    
    <span title="Symbols count total">260k</span>
  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Pisces</a> v6.0.4</div>



</div>
        








        
      </div>
    </footer>

    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


















  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.4"></script>



  



	





  









  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
    
  
  <script src="[object Object]"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '1Dfsb4DwGQPCIlbyCKt9egUR-gzGzoHsz',
        appKey: '8OKqJPeMRRQnxx2vaAwIkM8y',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":"wanko","bottom":-30,"mobileShow":false,"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body>
</html>
