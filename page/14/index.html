<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Times New Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mycherrymay.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"WGLQQAQKBA","indexName":"xiemay","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="wise">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcome to shiyi&#39;s world">
<meta property="og:url" content="http://mycherrymay.github.io/page/14/index.html">
<meta property="og:site_name" content="Welcome to shiyi&#39;s world">
<meta property="og:description" content="wise">
<meta property="og:locale">
<meta property="article:author" content="XieMay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://mycherrymay.github.io/page/14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Welcome to shiyi's world</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Welcome to shiyi's world</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/11/20/%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/11/20/%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/" class="post-title-link" itemprop="url">简单的数据探索</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2019-11-20 16:45:03 / 修改时间：18:55:34" itemprop="dateCreated datePublished" datetime="2019-11-20T16:45:03+08:00">2019-11-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" itemprop="url" rel="index"><span itemprop="name">数据分析</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>107</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="简单的探索数据的方法"><a href="#简单的探索数据的方法" class="headerlink" title="简单的探索数据的方法"></a>简单的探索数据的方法</h1><p>总结一些简单的数据分析方法，以及常用的python 库 Pandas里面相应的函数。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/11/20/%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/08/25/%E8%8B%B1%E8%AF%ADDaily/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/25/%E8%8B%B1%E8%AF%ADDaily/" class="post-title-link" itemprop="url">英语Daily</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-25 20:27:40" itemprop="dateCreated datePublished" datetime="2019-08-25T20:27:40+08:00">2019-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-05 08:49:53" itemprop="dateModified" datetime="2020-09-05T08:49:53+08:00">2020-09-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%8B%B1%E8%AF%AD/" itemprop="url" rel="index"><span itemprop="name">英语</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>166</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="2020">2020</span><a href="#2020" class="header-anchor">#</a></h1><h2><span id="09">09</span><a href="#09" class="header-anchor">#</a></h2><h3><span id="05">05</span><a href="#05" class="header-anchor">#</a></h3><p>上星期我去<strong>看戏</strong>。我的<strong>座位</strong>很好，戏很有意思，但我却无法欣赏。一青年男子与一青年女子<strong>坐在我的身后</strong>，大声地说着话。我非常生气，因为我听不见演员在说什么。我<strong>回过头</strong>去<strong>怒视</strong>着那一男一女，他们却毫不理会。最后，我忍不住了，又一次回过头去，<strong>生气地说</strong>：”我一个字也听不见了！”</p>
<p>“<strong>不关你的事</strong>，”那男的毫不客气地说，”这是私人间的谈话！”</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/28/Python-basic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/28/Python-basic/" class="post-title-link" itemprop="url">Python Basics</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-28 10:18:04" itemprop="dateCreated datePublished" datetime="2019-05-28T10:18:04+08:00">2019-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-15 11:08:01" itemprop="dateModified" datetime="2019-11-15T11:08:01+08:00">2019-11-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>41</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id><!-- more  --></span><a href="#" class="header-anchor">#</a></h1><h1><span id="chong-xin-xue-xi">重新学习</span><a href="#chong-xin-xue-xi" class="header-anchor">#</a></h1><p>开始很乱的学习Python，现在想系统学习基础，真正了解pythonic,</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/" class="post-title-link" itemprop="url">Networks</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-12 19:31:06" itemprop="dateCreated datePublished" datetime="2019-05-12T19:31:06+08:00">2019-05-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-08 15:46:14" itemprop="dateModified" datetime="2020-10-08T15:46:14+08:00">2020-10-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="c4-convolutional-neural-networks-juan-ji-shen-jing-wang-luo">C4 : Convolutional Neural Networks(卷积神经网络)</span><a href="#c4-convolutional-neural-networks-juan-ji-shen-jing-wang-luo" class="header-anchor">#</a></h1><h2><span id="w1-convolutional-neural-networks-juan-ji-shen-jing-wang-luo">W1 :Convolutional Neural Networks(卷积神经网络)</span><a href="#w1-convolutional-neural-networks-juan-ji-shen-jing-wang-luo" class="header-anchor">#</a></h2><h3><span id="l1-computer-vision">L1: Computer Vision</span><a href="#l1-computer-vision" class="header-anchor">#</a></h3><ol>
<li>Image classification</li>
<li>Object detection</li>
<li>Neural Style Transfer</li>
</ol>
<p>Problem : input big</p>
<ol>
<li>神经网络结构复杂，数据量相对较少，容易出现过拟合；</li>
<li>所需内存和计算量巨大。</li>
</ol>
<h3><span id="l2-edge-detection-example">L2: Edge detection example</span><a href="#l2-edge-detection-example" class="header-anchor">#</a></h3><p>我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。</p>
<p><strong>卷积运算（Convolutional Operation）</strong>是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。</p>
<ol>
<li><p>常见的边缘检测</p>
<p>垂直边缘（Vertical Edges) 和 水平边缘（horizontal Edges)</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Different-edges.png" alt></p>
</li>
</ol>
<p>这张图的栏杆就对应垂直线，栏杆的水平线是水平边缘。</p>
<p>那么图片是怎么检测边缘的呢？</p>
<p>过滤器：filter</p>
<p>在数学中“”就是卷积的标准标志，但是在<strong>Python</strong>中，这个标识常常被用来表示乘法或者元素乘法。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1.png" alt></p>
<p>Output; 4 by 4</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1——2.png" alt></p>
<p>具体运算：</p>
<p>1）</p>
<p>为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（<strong>element-wise products</strong>）运算</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_3png.png" alt></p>
<p>2）为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_4png.png" alt></p>
<p>6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutional-operation.jpg" alt></p>
<p>举例说明： Vertical edge detection</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_5.png" alt></p>
<p>这里在结果可能有点不对头，检测到的边缘太粗了，主要是图片太小了，</p>
<p>卷积操作API</p>
<ul>
<li>在 Python 中，卷积用<code>conv_forward()</code>表示；</li>
<li>在 Tensorflow 中，卷积用<code>tf.nn.conv2d()</code>表示；</li>
<li>在 keras 中，卷积用<code>Conv2D()</code>表示。</li>
</ul>
<h3><span id="l3-edge-detection-example">L3: Edge Detection Example</span><a href="#l3-edge-detection-example" class="header-anchor">#</a></h3><ol>
<li><p>颜色由暗到亮，还是亮到暗</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_1.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_2.png" alt></p>
</li>
</ol>
<p>这种滤波器可以区分明暗变化，取绝对值没有区别了</p>
<ol>
<li><p>水平边缘</p>
<p>上边相对较亮，而下方相对较暗</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_3.png" alt></p>
<ol>
<li>复杂栗子</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_4.png" alt></p>
</li>
</ol>
<p>这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。</p>
<ol>
<li>filter</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_5.png" alt></p>
<p>sobel过滤器，优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。</p>
<p>charr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。</p>
<p>学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png" alt></p>
<p>这样可能得到一个出色的边缘检测</p>
<p>相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。</p>
<p>不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。</p>
<h3><span id="padding">Padding</span><a href="#padding" class="header-anchor">#</a></h3><p>按照我们上面讲的图片卷积，如果原始图片尺寸为$n x n$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n-f+1) x (n-f+1)$，注意f一般为奇数。这样会带来两个问题：</p>
<ul>
<li><p><strong>卷积运算后，输出图片尺寸缩小</strong></p>
</li>
<li><p><strong>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</strong></p>
<p>边缘像素点只被一个输出所触碰或者使用，</p>
</li>
</ul>
<p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行<strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Padding.jpg" alt></p>
<p>经过padding之后，填充p,原始图片尺寸为$(n+2p) x (n+2p)$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n+2p-f+1) x (n+2p-f+1)$。若要保证卷积前后图片尺寸不变，则p应满足：$ p=(f-1)/2$,f通常是奇数，如果是偶数，造成不对称填充，第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置</p>
<ol>
<li>p=0,Valid convolution</li>
<li>p=((f-1))/2,Same convolution</li>
</ol>
<h3><span id="l05-strided-convolution-juan-ji-bu-chang">L05: Strided convolution（卷积步长）</span><a href="#l05-strided-convolution-juan-ji-bu-chang" class="header-anchor">#</a></h3><p>Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Stride.jpg" alt></p>
<p>我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为：</p>
<script type="math/tex; mode=display">
\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor</script><p>向下取整</p>
<p>目前为止我们学习的“卷积”实际上被称为<strong>互相关（cross-correlation）</strong>，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png" alt></p>
<p>互相关：过滤器沿水平和垂直轴翻转，元素相乘来计算，这些视频中定义卷积运算时，我们跳过了这个镜像操作。（不进行翻转操作）叫做卷积操作</p>
<h3><span id="l06-convolution-over-volumes-san-wei-juan-ji">L06: Convolution over volumes(三维卷积)</span><a href="#l06-convolution-over-volumes-san-wei-juan-ji" class="header-anchor">#</a></h3><ol>
<li><p>卷积运算</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutions-on-RGB-image.png" alt></p>
</li>
</ol>
<p>过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。</p>
<p>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_8.png" alt></p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_9.png" alt></p>
<p>若输入图片的尺寸为n x n x nc，nc: 通道数目，filter尺寸为f x f x nc，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x nc′。其中，nc为图片通道数目，nc′为滤波器组个数。</p>
<h3><span id="l7-one-layer-of-a-convolution-network-dan-ceng-shen-jing-wang-luo">L7 : One layer of a convolution network (单层神经网络)</span><a href="#l7-one-layer-of-a-convolution-network-dan-ceng-shen-jing-wang-luo" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_10.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_11.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_12.png" alt></p>
<p>CNN单层的所以标记符号，设层数$l$,</p>
<script type="math/tex; mode=display">
\begin{array}{l}{f^{[l]}=\text { filter size }} \\ {p^{[l]}=\text { padding }} \\ {g^{[l]}=\text { stride }} \\ {n_{c}^{[l]}=\text { number of filters }}\end{array}</script><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_13.png" alt></p>
<script type="math/tex; mode=display">
\begin{array}{c}{n_{H}^{[l]}=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor} \\ { n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor}\end{array}</script><p>如果$m$个样本，进行向量化运算，相应的输出维度，为</p>
<script type="math/tex; mode=display">
\mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}</script><h3><span id="l8-a-simple-convolution-network-example-jian-dan-juan-ji-wang-luo-shi-li">L8 : A simple convolution network example（简单卷积网络示例）</span><a href="#l8-a-simple-convolution-network-example-jian-dan-juan-ji-wang-luo-shi-li" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-33.jpg" alt></p>
<ul>
<li>一般而言，<strong>图片的height $n^{[l]}_{H}$和width $n^{[l]}_W$随着层数的增加逐渐降低，但channel $n^{[l]}_C$逐渐增加</strong>。</li>
</ul>
<p>CNN有三种类型的layer：</p>
<ul>
<li>Convolution层（CONV）</li>
<li>Pooling层（POOL）</li>
<li>Fully connected层（FC）</li>
</ul>
<h3><span id="l9-pooling-layers-chi-hua-ceng">L9: Pooling layers(池化层)</span><a href="#l9-pooling-layers-chi-hua-ceng" class="header-anchor">#</a></h3><p>卷积神经网络除了卷积层，还有池化层来缩减模型的大小，提高运算速度和鲁棒性</p>
<ol>
<li>池的类型有max pooling(最大池化)</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_14.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_15.png" alt></p>
<p>这里步幅是s=2，filter = 2*2是最大池化的超参数,如果是三维，则单独在每个通道执行最大池化操作</p>
<p>关于max pooling的直觉解释： 元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。</p>
<ol>
<li><p>Pooling layer: Average pooling</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_16.png" alt></p>
<p>但是最大池化更好用</p>
</li>
</ol>
<p>summary : 输入$n_H<em>n_W</em>n_C$,如果没有padding,输出$(n_h-f)/s+1<em>(n_w-f)/s+1</em>n_c$</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_17.png" alt></p>
<h3><span id="l10-convolutional-neural-network-example-juan-ji-shen-jing-wang-luo-shi-li">L10: Convolutional neural network example (卷积神经网络实例)</span><a href="#l10-convolutional-neural-network-example-juan-ji-shen-jing-wang-luo-shi-li" class="header-anchor">#</a></h3><p>做一个识别数字的CNN网络</p>
<ol>
<li><p>LeNet-5架构如下：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/CNN.jpg" alt></p>
<ul>
<li>通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练</li>
</ul>
</li>
</ol>
<ul>
<li>常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax</li>
<li>最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。</li>
<li>在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。</li>
<li>关于CNN如何选择超参：可以参考论文的经验。</li>
<li><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_18.png" alt></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Activation shape</th>
<th style="text-align:center">Activation Size</th>
<th>#parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Input:</strong></td>
<td style="text-align:center">(32, 32, 3)</td>
<td style="text-align:center">3072</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV1(f=5, s=1)</strong></td>
<td style="text-align:center">(28, 28, 6)</td>
<td style="text-align:center">4704</td>
<td>156 (=5<em>5</em>6+6)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL1</strong></td>
<td style="text-align:center">(14, 14, 6)</td>
<td style="text-align:center">1176</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV2(f=5, s=1)</strong></td>
<td style="text-align:center">(10, 10, 16)</td>
<td style="text-align:center">1600</td>
<td>416 (=5<em>5</em>16+16)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL2</strong></td>
<td style="text-align:center">(5, 5, 16)</td>
<td style="text-align:center">400</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC3</strong></td>
<td style="text-align:center">(120, 1)</td>
<td style="text-align:center">120</td>
<td>48120 (=120*400+120)</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC4</strong></td>
<td style="text-align:center">(84, 1)</td>
<td style="text-align:center">84</td>
<td>10164 (=84*120+84)</td>
</tr>
<tr>
<td style="text-align:center"><strong>Softmax</strong></td>
<td style="text-align:center">(10, 1)</td>
<td style="text-align:center">10</td>
<td>850 (=10*84+10)</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="l11-why-convolution">L11 Why convolution</span><a href="#l11-why-convolution" class="header-anchor">#</a></h3><ul>
<li><p>参数共享（parameter sharing)</p>
<p> 如果用FC的话，参数爆炸啊！如果conv layer 就需要filter检测器，这个参数就少了，还参数共享</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_19.png" alt></p>
</li>
<li><p>稀疏连接(sparsity of connection)</p>
<p>输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。</p>
</li>
</ul>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_20.png" alt></p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="read">1. 卷积神经网络的基本构造和计算过程 2. 如何整合这些模型 3.  哪些超参数 4. 为什么使用卷积 </font>

<h2><span id="w2-deep-convolutional-models-case-studies-shen-du-juan-ji-wang-luo-shi-li-tan-jiu">W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)</span><a href="#w2-deep-convolutional-models-case-studies-shen-du-juan-ji-wang-luo-shi-li-tan-jiu" class="header-anchor">#</a></h2><h3><span id="l1-why-look-at-case-studies-wei-shi-me-yao-jin-xing-shi-li-tan-jiu">L1 : Why look at case studies?(为什么要进行实例探究？)</span><a href="#l1-why-look-at-case-studies-wei-shi-me-yao-jin-xing-shi-li-tan-jiu" class="header-anchor">#</a></h3><p>本文将主要介绍几个典型的CNN案例。通过对具体CNN模型及案例的研究，来帮助我们理解知识并训练实际的模型。</p>
<p>典型的CNN模型包括：</p>
<ul>
<li><strong>LeNet-5</strong></li>
<li><strong>AlexNet</strong></li>
<li><strong>VGG</strong></li>
</ul>
<p>还会介绍Residual Network（ResNet）。其特点是可以构建很深很深的神经网络（目前最深的好像有152层）。还会介绍Inception Neural Network</p>
<h3><span id="l2-classic-networks-jing-dian-wang-luo">L2 : Classic networks(经典网络)</span><a href="#l2-classic-networks-jing-dian-wang-luo" class="header-anchor">#</a></h3><h4><span id="1-lenet-5">1. LeNet-5</span><a href="#1-lenet-5" class="header-anchor">#</a></h4><p><strong>LeNet-5</strong>是针对灰度图片训练的，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，<strong>padding</strong>为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-34.jpg" alt></p>
<p>该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。</p>
<h4><span id="1-alexnet">1. AlexNet</span><a href="#1-alexnet" class="header-anchor">#</a></h4><p>AlexNet模型是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton共同提出的，其结构如下所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-35.jpg" alt></p>
<p><strong>AlexNet</strong>首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层,f=3，步幅为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，<strong>padding</strong>之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次<strong>same</strong>卷积，相同的<strong>padding</strong>，得到的结果是13×13×384，384个过滤器。再做一次<strong>same</strong>卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用<strong>softmax</strong>函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。</p>
<p>实际上，这种神经网络与<strong>LeNet</strong>有很多相似之处，不过<strong>AlexNet</strong>要大得多。正如前面讲到的<strong>LeNet</strong>或<strong>LeNet-5</strong>大约有6万个参数，而<strong>AlexNet</strong>包含约6000万个参数。当用于训练图像和数据集时，<strong>AlexNet</strong>能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点<strong>AlexNet</strong>表现出色。<strong>AlexNet</strong>比<strong>LeNet</strong>表现更为出色的另一个原因是它使用了<strong>ReLu</strong>激活函数。原作者还提到了一种优化技巧，叫做Local Response Normalization(LRN)。 而在实际应用中，LRN的效果并不突出。</p>
<h4><span id="3-vgg-16">3. VGG-16</span><a href="#3-vgg-16" class="header-anchor">#</a></h4><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-36.jpg" alt></p>
<p>首先用3×3，步幅为1的过滤器构建卷积层，<strong>padding</strong>参数为<strong>same</strong>卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此<strong>VGG</strong>网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。</p>
<p>数字16，就是指在这个网络中包含16个卷积层和全连接层。总共包含约1.38亿个参数</p>
<h3><span id="l3-residual-networks-resnets-can-chai-wang-luo-resnets">L3 : Residual Networks (ResNets)(残差网络(ResNets))</span><a href="#l3-residual-networks-resnets-can-chai-wang-luo-resnets" class="header-anchor">#</a></h3><p>我们知道，如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功。解决的方法之一是人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为Residual Networks(ResNets)。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_21.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Residual-Network.jpg" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/ResNet-Training-Error.jpg" alt></p>
<h3><span id="l4-why-resnets-work-can-chai-wang-luo-wei-shi-me-you-yong">L4: Why ResNets work?(残差网络为什么有用？)</span><a href="#l4-why-resnets-work-can-chai-wang-luo-wei-shi-me-you-yong" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_22.png" alt></p>
<p>因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。</p>
<p>注意，如果$ a[l]$与 $a[l+2]$的维度不同，需要引入矩阵 $W_s$与 $a_{[l]}$相乘，使得二者的维度相匹配。参数矩阵 $W_s$既可以通过模型训练得到，也可以作为固定值，仅使 $a[l]$截断或者补零。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-37.jpg" alt></p>
<h3><span id="l5-network-in-network-and-1x1-convolutions-wang-luo-zhong-de-wang-luo-yi-ji-1x1-juan-ji">L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积)</span><a href="#l5-network-in-network-and-1x1-convolutions-wang-luo-zhong-de-wang-luo-yi-ji-1x1-juan-ji" class="header-anchor">#</a></h3><ol>
<li>作用 </li>
</ol>
<p>假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_c$）的方法，对于池化层我只是压缩了这些层的高度和宽度</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_23.png" alt></p>
<ol>
<li><strong>doing something pretty non-trivial</strong></li>
</ol>
<p>它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。</p>
<h3><span id="l6-inception-network-motivation-gu-ge-inception-wang-luo-jian-jie">L6 : Inception network motivation(谷歌 Inception 网络简介)</span><a href="#l6-inception-network-motivation-gu-ge-inception-wang-luo-jian-jie" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/99f8fc7dbe7cd0726f5271aae11b9872.png" alt></p>
<p>有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。</p>
<p> 1x1 的卷积层通常被称作<strong>瓶颈层（Bottleneck layer）</strong></p>
<p>计算量为 28x28x32x5x5x192 = 1.2亿</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/The-problem-of-computational-cost.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Using-1x1-convolution.png" alt></p>
<p>28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。</p>
<h3><span id="l7-inception-network-inception-wang-luo">L7 : Inception network(Inception 网络)</span><a href="#l7-inception-network-inception-wang-luo" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_24.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_25.png" alt></p>
<h3><span id="l8-using-open-source-implementations-shi-yong-kai-yuan-de-shi-xian-fang-an">L8 : Using open-source implementations( 使用开源的实现方案)</span><a href="#l8-using-open-source-implementations-shi-yong-kai-yuan-de-shi-xian-fang-an" class="header-anchor">#</a></h3><p>开源项目</p>
<h3><span id="l9-transfer-learning-qian-yi-xue-xi">L9 ： Transfer Learning（迁移学习）</span><a href="#l9-transfer-learning-qian-yi-xue-xi" class="header-anchor">#</a></h3><p>如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。</p>
<ol>
<li>只有很小数据集： 可以你只需要训练<strong>softmax</strong>层的权重，把前面这些层的权重都冻结。</li>
<li>稍微更大的数据集： 你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元；或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的<strong>softmax</strong>输出层，这些方法值得一试。</li>
<li>大量数据： 你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。</li>
</ol>
<h3><span id="l10-data-augmentation-shu-ju-zeng-qiang">L10 ： Data augmentation（数据增强）</span><a href="#l10-data-augmentation-shu-ju-zeng-qiang" class="header-anchor">#</a></h3><p>数据量远远不够</p>
<ol>
<li>Mirroring</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring.png" alt></p>
<ol>
<li>Random Cropping</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_1.png" alt></p>
<ol>
<li><p>彩色转换color shifting</p>
<p>r,g,b数据改变</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_2.png" alt></p>
<p>除了随意改变RGB通道数值外，还可以更有针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法。这样也能增加有效的样本数量。具体的PCA color augmentation做法可以查阅AlexNet的相关论文。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_3.png" alt></p>
<p>常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。</p>
<h3><span id="l11-the-state-of-computer-vision-ji-suan-ji-shi-jue-xian-zhuang">L11：The state of computer vision(计算机视觉现状)</span><a href="#l11-the-state-of-computer-vision-ji-suan-ji-shi-jue-xian-zhuang" class="header-anchor">#</a></h3><ol>
<li>神经网络需要数据，不同的网络模型所需的数据量是不同的。Object dection，Image recognition，Speech recognition所需的数据量依次增加。一般来说，如果data较少，那么就需要更多的hand-engineering，对已有data进行处理。</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_4.png" alt></p>
<p>hand-engineering是一项非常重要也比较困难的工作。很多时候，hand-engineering对模型训练效果影响很大，特别是在数据量不多的情况下。</p>
<p>当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。在别人做好的基础上研究</p>
<ol>
<li><p>提升性能</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_5.png" alt>*</p>
</li>
</ol>
<p>由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。</p>
<p>所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。</p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="red">1. CNN的常见网络结构 重点说了一些残差网络 2.数据增加的方法 3. 多用开源框架，不用从头开始训练 </font>

<h1><span id="w3-object-detection-mu-biao-jian-ce">W3 Object detection(目标检测)</span><a href="#w3-object-detection-mu-biao-jian-ce" class="header-anchor">#</a></h1><h3><span id="l1-object-localization-mu-biao-ding-wei">L1 :Object localization(目标定位)</span><a href="#l1-object-localization-mu-biao-ding-wei" class="header-anchor">#</a></h3><p>目标定位和目标检测</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_1.png" alt></p>
<p>模型</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_2.png" alt></p>
<p>输入还包括位置信息</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_3.png" alt></p>
<p>损失函数</p>
<p>情况一：检测到了</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_4.png" alt></p>
<p>情况二：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_5.png" alt></p>
<h3><span id="l2-landmark-detection-te-zheng-dian-jian-ce">L2: Landmark detection(特征点检测)</span><a href="#l2-landmark-detection-te-zheng-dian-jian-ce" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_6.png" alt></p>
<p>该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值。通过检测人脸特征点可以进行情绪分类与判断，或者应用于AR领域等等。</p>
<p>除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_7.png" alt></p>
<h3><span id="l3-object-detection-mu-biao-jian-ce">L3 :Object detection(目标检测)</span><a href="#l3-object-detection-mu-biao-jian-ce" class="header-anchor">#</a></h3><p>学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_8.png" alt></p>
<p>训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。</p>
<p>选定特定大小的窗口，窗口圈定输入卷积神经网络，卷积神经网络开始预测。</p>
<p>重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或<img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_10.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_11.png" alt></p>
<p>如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。</p>
<p>这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。</p>
<p>滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。但是其缺点也很明显，首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。所以，滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活。</p>
<h3><span id="l-4-convolutional-implementation-of-sliding-windows-hua-dong-chuang-kou-de-juan-ji-shi-xian">L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现)</span><a href="#l-4-convolutional-implementation-of-sliding-windows-hua-dong-chuang-kou-de-juan-ji-shi-xian" class="header-anchor">#</a></h3><ol>
<li><p>全连接层转化为卷积层</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_12.png" alt></p>
</li>
</ol>
<p>单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，步进长度为2，CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_13.png" alt></p>
<p>之前的滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。值得一提的是，窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。</p>
<h3><span id="l5-bounding-box-predictions-bounding-box-yu-ce">L5 ： Bounding box predictions（Bounding Box预测）</span><a href="#l5-bounding-box-predictions-bounding-box-yu-ce" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_14.png" alt></p>
<ol>
<li><p>YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_16.png" alt></p>
</li>
<li><p>如果目标中心坐标(bx,by)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。判断有目标的网格中，bx,by,bh,bw限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(bx,by)范围限定在[0,1]之间，但是bh,bw可以大于1。因为目标可能超出该网格，横跨多个区域，如上图所示。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_15.png" alt></p>
<h3><span id="l6-intersection-over-union-jiao-bing-bi">L6 ：Intersection over union（交并比)</span><a href="#l6-intersection-over-union-jiao-bing-bi" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_17.png" alt></p>
<p>一般约定，在计算机检测任务中，如果lou&gt;=0.5，就说检测正确，如果预测器和实际边界框完美重叠，<strong>loU</strong>就是1，因为交集就等于并集。但一般来说只要lou&gt;=0.5，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将<strong>loU</strong>定得更高，比如说大于0.6或者更大的数字，但<strong>loU</strong>越高，边界框越精确。</p>
<h3><span id="l7-non-max-suppression-fei-ji-da-zhi-yi-zhi">L7: Non-max suppression(非极大值抑制)</span><a href="#l7-non-max-suppression-fei-ji-da-zhi-yi-zhi" class="header-anchor">#</a></h3><p>到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_18.png" alt></p>
<p>假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_19.png" alt></p>
<p>实际情况是格子1，2，3，4，5，6都认为里面有车。因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc,我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。</p>
<p>非最大值抑制（Non-max Suppression）做法很简单，图示每个网格的Pc值可以求出，Pc值反映了该网格包含目标中心坐标的可信度。首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_20.png" alt></p>
<p>总结一下非最大值抑制算法的流程：</p>
<ol>
<li><strong>剔除Pc值小于某阈值（例如0.6）的所有网格；</strong></li>
<li><strong>选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格；</strong></li>
<li><strong>对剩下的网格，重复步骤2。</strong></li>
</ol>
<p>到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用<strong>anchor box</strong>这个概念，我们从一个例子开始讲吧。方法是使用不同形状的Anchor Boxes。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_21.png" alt></p>
<p>这就是<strong>anchor box</strong>的概念，我们建立<strong>anchor box</strong>这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生</p>
<h3><span id="l9-yolo-suan-fa-putting-it-together-yolo-algorithm">L9 :  YOLO 算法（Putting it together: YOLO algorithm）</span><a href="#l9-yolo-suan-fa-putting-it-together-yolo-algorithm" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_22.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_23.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_24.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_25.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_26.png" alt></p>
<p>这就是<strong>YOLO</strong>对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路</p>
<h3><span id="region-proposals-optional-hou-xuan-qu-yu-xuan-xiu">Region proposals (Optional)（候选区域（选修））</span><a href="#region-proposals-optional-hou-xuan-qu-yu-xuan-xiu" class="header-anchor">#</a></h3><p>之前介绍的滑动窗算法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，例如下图所示。这样会降低算法运行效率，耗费时间。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_27.png" alt></p>
<p>为了解决这一问题，尽量避免对无用区域的扫描，可以使用Region Proposals的方法。具体做法是先对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_28.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_29.png" alt></p>
<p>Region Proposals共有三种方法：</p>
<ul>
<li><strong>R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。</strong></li>
<li><strong>Fast R-CNN: 利用卷积实现滑动窗算法，类似第4节做法。</strong></li>
<li><strong>Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。</strong></li>
</ul>
<h2><span id="w4-special-applications-face-recognition-amp-neural-style-transfer-te-shu-ying-yong-ren-lian-shi-bie-he-shen-jing-feng-ge-zhuan-huan">W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)</span><a href="#w4-special-applications-face-recognition-amp-neural-style-transfer-te-shu-ying-yong-ren-lian-shi-bie-he-shen-jing-feng-ge-zhuan-huan" class="header-anchor">#</a></h2><h3><span id="c1-what-is-face-recognition">C1 ： What is face recognition?</span><a href="#c1-what-is-face-recognition" class="header-anchor">#</a></h3><p>首先简单介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。</p>
<ul>
<li><strong>人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。</strong></li>
<li><strong>人脸识别：输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题。</strong></li>
</ul>
<h3><span id="l2-one-shot-learning">L2 ： One-shot learning</span><a href="#l2-one-shot-learning" class="header-anchor">#</a></h3><p>One-shot learning就是说数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型来进行人脸识别。若数据库有K个人，则CNN模型输出softmax层就是K维的。</p>
<p>但是One-shot learning的性能并不好，其包含了两个缺点：</p>
<ul>
<li><strong>每个人只有一张图片，训练样本少，构建的CNN网络不够健壮。</strong></li>
<li><strong>若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活。</strong></li>
</ul>
<p>为了解决One-shot learning的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用：</p>
<ul>
<li><strong>d(img1,img2)≤τ : 一样</strong></li>
<li><strong>d(img1,img2)&gt;τ : 不一样</strong></li>
</ul>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_1.png" alt></p>
<p>现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数。</p>
<h3><span id="l3-siamese-network">L3: Siamese network</span><a href="#l3-siamese-network" class="header-anchor">#</a></h3><p>最后一层去掉softmax单元做分类</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_2.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_3.png" alt></p>
<p>如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x^{(2)})$。这里我用$x^{(1)}$和$x^{(2)}$仅仅代表两个输入图片,</p>
<script type="math/tex; mode=display">
d(x^{(1)},x^{(2)})=||f(x^{(1)}-f(x^{(2)}||^2</script><p>不同的图片的CNN网络结构和参数都是一样的，目标就是利用梯度下降算法，调整网络参数</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/" class="post-title-link" itemprop="url">The Deep Learning Specialization</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-05 19:41:59" itemprop="dateCreated datePublished" datetime="2019-05-05T19:41:59+08:00">2019-05-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-05 21:47:36" itemprop="dateModified" datetime="2020-10-05T21:47:36+08:00">2020-10-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="c3-improving-model-performance">C3 Improving Model Performance</span><a href="#c3-improving-model-performance" class="header-anchor">#</a></h1><h2><span id="w1-ml-strategy-1">W1 ML Strategy(1)</span><a href="#w1-ml-strategy-1" class="header-anchor">#</a></h2><h3><span id="l01-improving-model-performance">L01 Improving Model Performance</span><a href="#l01-improving-model-performance" class="header-anchor">#</a></h3><p>需要提高训练结果的表现，表现得更好的措施 Machine Learning Strategy</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-24_21-03-13.jpg" alt></p>
<h3><span id="l2-orthogonalization-zheng-jiao-hua">L2 : Orthogonalization(正交化)</span><a href="#l2-orthogonalization-zheng-jiao-hua" class="header-anchor">#</a></h3><p>所谓正交，<strong>就是你的操控效果尽量只影响一个方面</strong>。比如以老式电视机为例，调节图像的大小、左右偏移、上下偏移。而不是一个按钮可以同时调节图像大小和左右偏移，那样会很难操作。</p>
<p>具体到supervised learning，有以下4个假设是正交的？</p>
<ol>
<li>Fit <strong>training set</strong> well in cost function If it doesn’t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help.</li>
<li>Fit <strong>development set</strong> well on cost function If it doesn’t fit well, regularization or using bigger training set might help.</li>
<li>Fit <strong>test set</strong> well on cost function If it doesn’t fit well, the use of a bigger development set might help</li>
<li>Performs well in <strong>real world</strong> If it doesn’t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing.</li>
</ol>
<p>在训练集上表现欠佳，需要切换到好的优化算法</p>
<p>在验证集上表现不好，一组正则化按钮</p>
<p>在测试集表现不好，需要更好的验证集</p>
<p>在用户体验不好，需要改变测试集大小或者成本函数</p>
<h3><span id="l3-single-number-evaluation-metric-dan-yi-shu-zi-ping-gu-zhi-biao">L3 Single number evaluation metric(单一数字评估指标)</span><a href="#l3-single-number-evaluation-metric-dan-yi-shu-zi-ping-gu-zhi-biao" class="header-anchor">#</a></h3><h4><span id="classification">classification</span><a href="#classification" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-42-10.jpg" alt></p>
<h4><span id="precesion-cha-zhun-lu">Precesion （查准率）</span><a href="#precesion-cha-zhun-lu" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-47-46.jpg" alt></p>
<h4><span id="recall-cha-quan-lu">recall（查全率）</span><a href="#recall-cha-quan-lu" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-48-11.jpg" alt></p>
<script type="math/tex; mode=display">
F 1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2 P R}{P+R}</script><h3><span id="l4-satisficing-and-optimizing-metrics-man-zu-he-you-hua-zhi-biao">L4  Satisficing and optimizing metrics(满足和优化指标)</span><a href="#l4-satisficing-and-optimizing-metrics-man-zu-he-you-hua-zhi-biao" class="header-anchor">#</a></h3><p>如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。这时，我们可以将某些指标作为<strong>优化指标（Optimizing Matric）</strong>，寻求它们的最优值；而将某些指标作为<strong>满足指标（Satisficing Matric）</strong>，只要在一定阈值以内即可。</p>
<p>在这个例子中，准确率就是一个优化指标，因为我们想要分类器尽可能做到正确分类；而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个阈值，那最终选择的分类器就应该是以这个阈值为界里面准确率最高的那个。</p>
<p>如此，accuracy就变成了<strong>optimizing metric</strong>，而running time则是<strong>satisfying metric</strong>，statisfying metric只要达到标准即可，而optimizing metric则追求更好。一般的，选择一项metric作为optimizing metric，其他的则设置为satisfying metric： </p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-09-36.jpg" alt></p>
<h3><span id="l-5-train-dev-test-distributions-xun-lian-kai-fa-ce-shi-ji-hua-fen">L 5: Train/dev/test distributions(训练/开发/测试集划分)</span><a href="#l-5-train-dev-test-distributions-xun-lian-kai-fa-ce-shi-ji-hua-fen" class="header-anchor">#</a></h3><p>开发（<strong>dev</strong>）集也叫做开发集（<strong>development set</strong>），有时称为保留交叉验证集（<strong>hold out cross validation set</strong>）。</p>
<p>如何设置Train/dev/test集，很大程度上影响了机器学习的速度。</p>
<p>Train/dev/test的区别 Workflow in machine learning is that you try a lot of ideas, train up different models on the training set, and then use the dev set to evaluate the different ideas and pick one. And, keep innovating to improve dev set performance until, finally, you have one class that you’re happy with that you then evaluate on your test set.</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-09-37.jpg" alt></p>
<p>开发集合和开发集合来自同一分布，如果是不同分布，相当于靶心移动了</p>
<h3><span id="l-6-size-of-dev-and-test-sets-kai-fa-ji-he-ce-shi-ji-de-da-xiao">L 6: Size of dev and test sets(开发集和测试集的大小)</span><a href="#l-6-size-of-dev-and-test-sets-kai-fa-ji-he-ce-shi-ji-de-da-xiao" class="header-anchor">#</a></h3><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-29-51.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-25.jpg" alt></p>
<h3><span id="l7-when-to-change-dev-test-sets-and-metrics-shi-me-shi-hou-gai-gai-bian-kai-fa-ce-shi-ji-he-zhi-biao">L7 : When to change dev/test sets and metrics(什么时候该改变开发/测试集和指标)</span><a href="#l7-when-to-change-dev-test-sets-and-metrics-shi-me-shi-hou-gai-gai-bian-kai-fa-ce-shi-ji-he-zhi-biao" class="header-anchor">#</a></h3><p>如果发现设定目标和实际期望不符，那就调整目标。</p>
<ol>
<li><p>举个例子</p>
<p>A可能把一些色情照片也分类成猫了，因此改变优化指标</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-26.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-27.jpg" alt></p>
</li>
</ol>
<p>我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。</p>
<p>后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，$J=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)$你要最小化训练集上的损失。你可以做的其中一件事是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，$J=\frac{1}{\sum w^{(i)}} \sum_{i=1}^{m} w^{(i)} L\left(\hat{y}^{(i)}, y^{(i)}\right)$</p>
<p>再次，如何定义J并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数J。</p>
<h3><span id="l8-why-human-level-performance-wei-shi-me-shi-ren-de-biao-xian">L8 : Why human-level performance?(为什么是人的表现？)</span><a href="#l8-why-human-level-performance-wei-shi-me-shi-ren-de-biao-xian" class="header-anchor">#</a></h3><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Bayes-Optimal-Error.png" alt></p>
<p>上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为<strong>贝叶斯最优误差（Bayes Optimal Error）</strong>。</p>
<p>也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。</p>
<p>当模型的表现超过人类后，这些手段起的作用就微乎其微了。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/e1ef954731399bb4fbf18f2fb99b863a.png" alt></p>
<h3><span id="l9-avoidable-bias-ke-bi-mian-pian-chai">L9 : Avoidable bias(可避免偏差)</span><a href="#l9-avoidable-bias-ke-bi-mian-pian-chai" class="header-anchor">#</a></h3><ol>
<li><p>training error</p>
<p>我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-28.jpg" alt></p>
</li>
</ol>
<ol>
<li><p>dev error</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-29.jpg" alt></p>
</li>
</ol>
<p><strong>贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差</strong></p>
<h3><span id="l-10-understanding-human-level-performance-li-jie-ren-de-biao-xian">L 10: Understanding human-level performance(理解人的表现)</span><a href="#l-10-understanding-human-level-performance-li-jie-ren-de-biao-xian" class="header-anchor">#</a></h3><p>还记得上个视频中，我们用过这个词“人类水平错误率”用来估计贝叶斯误差，那就是理论最低的错误率，任何函数不管是现在还是将来，能够到达的最低值</p>
<h3><span id="l11-surpassing-human-level-performance-chao-guo-ren-de-biao-xian">L11 : Surpassing human- level performance(超过人的表现)</span><a href="#l11-surpassing-human-level-performance-chao-guo-ren-de-biao-xian" class="header-anchor">#</a></h3><p>现在，机器学习有很多问题已经可以大大超越人类水平了。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/de2eb0ddc7918f6e9213871e07b8fa56.png" alt></p>
<h3><span id="l12-improving-your-model-performance-gai-shan-ni-de-mo-xing-de-biao-xian">L12 : Improving your model performance(改善你的模型的表现)</span><a href="#l12-improving-your-model-performance-gai-shan-ni-de-mo-xing-de-biao-xian" class="header-anchor">#</a></h3><p>你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-39.jpg" alt></p>
<p>method</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-49.jpg" alt></p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="red">这一周的内容主要是改善模型的表现，主要是按照正交化，使得更好的满足 1. 评价指标 2. 数据集的划分 3. 人的表现的重要性 4. 当出现表现不好的时候，如何改善呢，有哪些方法呢？ </font>

<h2><span id="w2-ml-strategy-2">W2 ML Strategy(2)</span><a href="#w2-ml-strategy-2" class="header-anchor">#</a></h2><h3><span id="c-1-carrying-out-error-analysis-jin-xing-wu-chai-fen-xi">C 1: Carrying out error analysis(进行误差分析)</span><a href="#c-1-carrying-out-error-analysis-jin-xing-wu-chai-fen-xi" class="header-anchor">#</a></h3><h4><span id="1-simple-analysis">1. simple analysis</span><a href="#1-simple-analysis" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/e1ef954731399bb4fbf18f2fb99b863.png" alt></p>
<p>通过观察发现算法分类出错的例子，是把狗分成猫，提高准确率的方法就是如何针对狗的图片优化算法。你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。现在考虑的是应该不应该这么去做呢？统计一下dev set里面多少是错误标记是狗的个数，分析出可以改善的算法的上限。</p>
<h4><span id="mutiply-analysis">mutiply analysis</span><a href="#mutiply-analysis" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-51.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-50.jpg" alt></p>
<h3><span id="c2-cleaning-up-incorrectly-labeled-data-qing-chu-biao-zhu-cuo-wu-de-shu-ju">C2 : Cleaning up Incorrectly labeled data(清除标注错误的数据)</span><a href="#c2-cleaning-up-incorrectly-labeled-data-qing-chu-biao-zhu-cuo-wu-de-shu-ju" class="header-anchor">#</a></h3><h4><span id="incorrct-label">incorrct label</span><a href="#incorrct-label" class="header-anchor">#</a></h4><h4><span id="traning-set">traning set</span><a href="#traning-set" class="header-anchor">#</a></h4><p>DL algorithms are quite robust to random errors in the traning set so long as your errors or your labeled example to once those errors are not too far from random .</p>
<h4><span id="distribution">distribution</span><a href="#distribution" class="header-anchor">#</a></h4><p>首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。开发集确定了你的目标，当你击中目标后，你希望算法能够推广到测试集上，这样你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正以确保它们继续来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-52.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-53.jpg" alt></p>
<h4><span id="suggestion">suggestion</span><a href="#suggestion" class="header-anchor">#</a></h4><p>最后我讲几个建议：</p>
<p>首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。</p>
<p>其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。</p>
<p>这就是错误分析过程，在下一个视频中，我想分享一下错误分析是如何在启动新的机器学习项目中发挥作用的。</p>
<h3><span id="c3-build-your-first-system-quickly-then-iterate-kuai-su-da-jian-ni-de-di-yi-ge-xi-tong-bing-jin-xing-die-dai">C3: Build your first system quickly, then iterate(快速搭建你的第一个系统，并进行迭代)</span><a href="#c3-build-your-first-system-quickly-then-iterate-kuai-su-da-jian-ni-de-di-yi-ge-xi-tong-bing-jin-xing-die-dai" class="header-anchor">#</a></h3><h4><span id="1-iteration">1. iteration</span><a href="#1-iteration" class="header-anchor">#</a></h4><p>I recommend that you first quickly set up a definition and metrics so this is really you know  deciding where to place your target and you get it wrong you can always move it later we just set up a target somewhere and then I recommend you build an inital machine learning system quickly find the traning set train it and see start to see and understand how well your are doing against your Devon chess setting evaluation metric when you build your initial system you then be able to use bias variance analysis we should talk about earlier as well as error analysis whick we talked about just in last several videos to prioritize the next step in particular if error analysis causes you to realize that a lot of the errors are from the spearker being very far from the mirophone which causes special challenges speech recognitin then that would give you a good reason to focus on techniques to address this it called fast used speech recognition which basically means handling when the speaker is very far from microphone along the value of building this inital  system  it can be a quick  and diry implementation you know do not overthink it but all the value of the inital system is having some learning system having some tranin system allows you lok at bias and variance to do error analysis look at some mistakes to figure out all the different directins you could go in.</p>
<p>我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。</p>
<h3><span id="c4-training-and-testing-on-different-distributions-shi-yong-lai-zi-bu-tong-fen-bu-de-shu-ju-jin-xing-xun-lian-he-ce-shi">C4 : Training and testing on different distributions(使用来自不同分布的数据，进行训练和测试)</span><a href="#c4-training-and-testing-on-different-distributions-shi-yong-lai-zi-bu-tong-fen-bu-de-shu-ju-jin-xing-xun-lian-he-ce-shi" class="header-anchor">#</a></h3><p>this is resulted in many teams sometimes taking one of the days you can find and just shoving it into the training set .</p>
<ol>
<li><p>Cat app example </p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-54.jpg" alt></p>
<p>假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这10,000张图片，因为这样你的训练集就太小了，使用这20万张图片似乎有帮助。但是，困境在于，这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢？</p>
<p>我们真正关心的是来自手机手机收集的数据，而不是来自网页。方法一，随机分配训练集、验证集、测试集，这样的后果就是花了大量时间在实际不关心的数据分布去优化。</p>
<p>训练集20万张网络，5000手机，验证集和测试集各2500，这样可以保证验证集和测试集更接近实际应用场景，我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。</p>
</li>
</ol>
<h2><span id="c5-bias-and-variance-with-mismatched-data-distributions-shu-ju-fen-bu-bu-pi-pei-shi-pian-chai-yu-fang-chai-de-fen-xi">C5: Bias and Variance with mismatched data distributions（数据分布不匹配时，偏差与方差的分析）</span><a href="#c5-bias-and-variance-with-mismatched-data-distributions-shu-ju-fen-bu-bu-pi-pei-shi-pian-chai-yu-fang-chai-de-fen-xi" class="header-anchor">#</a></h2><p>首先算法只看过训练集数据，没看过开发集数据。第二，开发集数据来自不同的分布。很难确认这增加的9%误差率有多少是因为算法没看到开发集中的数据导致的，这么评估呢？到底哪个影响元素更大，</p>
<p>评估方法，训练集的分布挖出，traning-dev set : Same distributation as traning set ,but not used for training.</p>
<p>现在，我们有了<em>训练集</em>错误率、<em>训练-验证集</em>错误率，以及<em>验证集</em>错误率。其中，<em>训练集</em>错误率和<em>训练-验证集</em>错误率的差值反映了方差；而<em>训练-验证集</em>错误率和<em>验证集</em>错误率的差值反映了样本分布不一致的问题，从而说明<strong>模型擅长处理的数据和我们关心的数据来自不同的分布</strong>，我们称之为<strong>数据不匹配（Data Mismatch）</strong>问题。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Analysis-With-Data-Mismatch.png" alt></p>
<h3><span id="c6-addressing-data-mismatch-chu-li-shu-ju-bu-pi-pei-wen-ti">C6: Addressing data mismatch（处理数据不匹配问题）</span><a href="#c6-addressing-data-mismatch-chu-li-shu-ju-bu-pi-pei-wen-ti" class="header-anchor">#</a></h3><p>I<img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-55.jpg" alt></p>
<p>Data: Artifical data synthesis</p>
<p>所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。</p>
<h3><span id="c7-transfer-learning-qian-yi-xue-xi">C7: Transfer learning（迁移学习）</span><a href="#c7-transfer-learning-qian-yi-xue-xi" class="header-anchor">#</a></h3><p><strong>迁移学习（Tranfer Learning）</strong>是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。</p>
<p>例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（$W[L]$、$b[L]$），随后用新的训练集进行训练，就完成了以上的迁移学习。</p>
<p>如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即$W[L]$$、b[L]$，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为<strong>预训练（Pre-Training）</strong>，之后的权重更新过程称为<strong>微调（Fine-Tuning）</strong>。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-56.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-57.jpg" alt></p>
<p>在下述场合进行迁移学习是有意义的：</p>
<p>两个任务有同样的输入（比如都是图像或者都是音频）；<br>拥有更多数据的任务迁移到数据较少的任务；<br>某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-58.jpg" alt></p>
<h3><span id="c8-multi-task-learning-duo-ren-wu-xue-xi">C8; Multi-task learning （多任务学习）</span><a href="#c8-multi-task-learning-duo-ren-wu-xue-xi" class="header-anchor">#</a></h3><p>For example, autonomous driving example,check cars,stop signs,trfffic lights ,输出也是一个向量，</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-59.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-60.jpg" alt></p>
<h3><span id="c9-what-is-end-to-end-deep-learning-shi-me-shi-duan-dao-duan-de-shen-du-xue-xi">C9 :  What is end-to-end deep learning?(什么是端到端的深度学习)</span><a href="#c9-what-is-end-to-end-deep-learning-shi-me-shi-duan-dao-duan-de-shen-du-xue-xi" class="header-anchor">#</a></h3><p>在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而<strong>端到端深度学习（End-to-end Deep Learning）</strong>只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\End-to-end-Deep-Learning.png" alt></p>
<h3><span id="you-dian-yu-que-dian">优点与缺点</span><a href="#you-dian-yu-que-dian" class="header-anchor">#</a></h3><p>应用端到端学习的优点：</p>
<ul>
<li>只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析；</li>
<li>所需手工设计的组件更少，简化设计工作流程；</li>
</ul>
<p>缺点：</p>
<ul>
<li>需要大量的数据；</li>
<li>排除了可能有用的人工设计组件；</li>
</ul>
<p>根据以上分析，决定一个问题是否应用端到端学习的<strong>关键点</strong>是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？</p>
<h3><span id="whether-to-use-end-to-end-learning-shi-fou-yao-shi-yong-duan-dao-duan-de-shen-du-xue-xi">Whether to use end-to-end learning?(是否要使用端到端的深度学习?)</span><a href="#whether-to-use-end-to-end-learning-shi-fou-yao-shi-yong-duan-dao-duan-de-shen-du-xue-xi" class="header-anchor">#</a></h3><p>Pros:</p>
<p>​    let the data speak : x-&gt;y</p>
<p>​    less hand-designing of components needed</p>
<p>Cons:</p>
<p>​    May need large amount of data</p>
<p>​    excludes potentially useful hand-designed components</p>
<p>Key question: Do you hava sufficient data to learn a function of the complexity needed to map x to y?</p>
<p>如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的x到y映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。</p>
<h1><span id="summary"><font color="green">Summary</font></span><a href="#summary" class="header-anchor">#</a></h1><font color="red">学习如何通过一些手段提高模型的表现，首先了解模型的性能的体现，bias、variance、贝叶斯误差。以及如何一步步的改善性能。具体解决了如下问题，1. 数据的划分 2. 人的表现与机器性能的关系、偏差、方差 3. 训练集和验证集的分布问题，当数据样本对于解决问题不足的时候的解决办法，4. 迁移学习 5. 端到端的学习 6. 多任务学习。6. 在性能不好的情况下，可能需要手动的分析误差，对测试集错误样例做统计等等， </font>
      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XieMay</p>
  <div class="site-description" itemprop="description">wise</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/shiyichuixue" title="GitHub → https://github.com/shiyichuixue" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2323020965@qq.com" title="E-Mail → mailto:2323020965@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XieMay</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">493k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">7:28</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共176.1k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '[object Object]';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
