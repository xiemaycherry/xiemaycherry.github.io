<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Times New Roman:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mycherrymay.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"appID":"WGLQQAQKBA","indexName":"xiemay","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="wise">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcome to shiyi&#39;s world">
<meta property="og:url" content="http://mycherrymay.github.io/page/14/index.html">
<meta property="og:site_name" content="Welcome to shiyi&#39;s world">
<meta property="og:description" content="wise">
<meta property="og:locale">
<meta property="article:author" content="XieMay">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://mycherrymay.github.io/page/14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Welcome to shiyi's world</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Welcome to shiyi's world</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/28/Python-basic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/28/Python-basic/" class="post-title-link" itemprop="url">Python Basics</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-28 10:18:04" itemprop="dateCreated datePublished" datetime="2019-05-28T10:18:04+08:00">2019-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-15 11:08:01" itemprop="dateModified" datetime="2019-11-15T11:08:01+08:00">2019-11-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>41</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id><!-- more  --></span><a href="#" class="header-anchor">#</a></h1><h1><span id="chong-xin-xue-xi">重新学习</span><a href="#chong-xin-xue-xi" class="header-anchor">#</a></h1><p>开始很乱的学习Python，现在想系统学习基础，真正了解pythonic,</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/" class="post-title-link" itemprop="url">Networks</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-12 19:31:06" itemprop="dateCreated datePublished" datetime="2019-05-12T19:31:06+08:00">2019-05-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-08 15:46:14" itemprop="dateModified" datetime="2020-10-08T15:46:14+08:00">2020-10-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>12 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="c4-convolutional-neural-networks-juan-ji-shen-jing-wang-luo">C4 : Convolutional Neural Networks(卷积神经网络)</span><a href="#c4-convolutional-neural-networks-juan-ji-shen-jing-wang-luo" class="header-anchor">#</a></h1><h2><span id="w1-convolutional-neural-networks-juan-ji-shen-jing-wang-luo">W1 :Convolutional Neural Networks(卷积神经网络)</span><a href="#w1-convolutional-neural-networks-juan-ji-shen-jing-wang-luo" class="header-anchor">#</a></h2><h3><span id="l1-computer-vision">L1: Computer Vision</span><a href="#l1-computer-vision" class="header-anchor">#</a></h3><ol>
<li>Image classification</li>
<li>Object detection</li>
<li>Neural Style Transfer</li>
</ol>
<p>Problem : input big</p>
<ol>
<li>神经网络结构复杂，数据量相对较少，容易出现过拟合；</li>
<li>所需内存和计算量巨大。</li>
</ol>
<h3><span id="l2-edge-detection-example">L2: Edge detection example</span><a href="#l2-edge-detection-example" class="header-anchor">#</a></h3><p>我们之前提到过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等），到最后面的一层就可以根据前面检测的特征来识别整体面部轮廓。这些工作都是依托卷积神经网络来实现的。</p>
<p><strong>卷积运算（Convolutional Operation）</strong>是卷积神经网络最基本的组成部分。我们以边缘检测为例，来解释卷积是怎样运算的。</p>
<ol>
<li><p>常见的边缘检测</p>
<p>垂直边缘（Vertical Edges) 和 水平边缘（horizontal Edges)</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Different-edges.png" alt></p>
</li>
</ol>
<p>这张图的栏杆就对应垂直线，栏杆的水平线是水平边缘。</p>
<p>那么图片是怎么检测边缘的呢？</p>
<p>过滤器：filter</p>
<p>在数学中“”就是卷积的标准标志，但是在<strong>Python</strong>中，这个标识常常被用来表示乘法或者元素乘法。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1.png" alt></p>
<p>Output; 4 by 4</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1——2.png" alt></p>
<p>具体运算：</p>
<p>1）</p>
<p>为了计算第一个元素，在4×4左上角的那个元素，使用3×3的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（<strong>element-wise products</strong>）运算</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_3png.png" alt></p>
<p>2）为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_4png.png" alt></p>
<p>6×6矩阵和3×3矩阵进行卷积运算得到4×4矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片。这个就是垂直边缘检测器。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutional-operation.jpg" alt></p>
<p>举例说明： Vertical edge detection</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_1_5.png" alt></p>
<p>这里在结果可能有点不对头，检测到的边缘太粗了，主要是图片太小了，</p>
<p>卷积操作API</p>
<ul>
<li>在 Python 中，卷积用<code>conv_forward()</code>表示；</li>
<li>在 Tensorflow 中，卷积用<code>tf.nn.conv2d()</code>表示；</li>
<li>在 keras 中，卷积用<code>Conv2D()</code>表示。</li>
</ul>
<h3><span id="l3-edge-detection-example">L3: Edge Detection Example</span><a href="#l3-edge-detection-example" class="header-anchor">#</a></h3><ol>
<li><p>颜色由暗到亮，还是亮到暗</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_1.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_2.png" alt></p>
</li>
</ol>
<p>这种滤波器可以区分明暗变化，取绝对值没有区别了</p>
<ol>
<li><p>水平边缘</p>
<p>上边相对较亮，而下方相对较暗</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_3.png" alt></p>
<ol>
<li>复杂栗子</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_4.png" alt></p>
</li>
</ol>
<p>这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。</p>
<ol>
<li>filter</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_5.png" alt></p>
<p>sobel过滤器，优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。</p>
<p>charr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。</p>
<p>学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9个参数。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png" alt></p>
<p>这样可能得到一个出色的边缘检测</p>
<p>相比这种单纯的垂直边缘和水平边缘，它可以检测出45°或70°或73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。</p>
<p>不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连名字都没有的过滤器。</p>
<h3><span id="padding">Padding</span><a href="#padding" class="header-anchor">#</a></h3><p>按照我们上面讲的图片卷积，如果原始图片尺寸为$n x n$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n-f+1) x (n-f+1)$，注意f一般为奇数。这样会带来两个问题：</p>
<ul>
<li><p><strong>卷积运算后，输出图片尺寸缩小</strong></p>
</li>
<li><p><strong>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</strong></p>
<p>边缘像素点只被一个输出所触碰或者使用，</p>
</li>
</ul>
<p>为了解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行<strong>填充（Padding）</strong>，以增加矩阵的大小。通常将 0 作为填充值。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Padding.jpg" alt></p>
<p>经过padding之后，填充p,原始图片尺寸为$(n+2p) x (n+2p)$，filter尺寸为$f x f$，则卷积后的图片尺寸为$(n+2p-f+1) x (n+2p-f+1)$。若要保证卷积前后图片尺寸不变，则p应满足：$ p=(f-1)/2$,f通常是奇数，如果是偶数，造成不对称填充，第二个原因是当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。有时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置</p>
<ol>
<li>p=0,Valid convolution</li>
<li>p=((f-1))/2,Same convolution</li>
</ol>
<h3><span id="l05-strided-convolution-juan-ji-bu-chang">L05: Strided convolution（卷积步长）</span><a href="#l05-strided-convolution-juan-ji-bu-chang" class="header-anchor">#</a></h3><p>Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Stride.jpg" alt></p>
<p>我们用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为：</p>
<script type="math/tex; mode=display">
\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor X\left\lfloor\frac{n+2 p-f}{s}+1\right\rfloor</script><p>向下取整</p>
<p>目前为止我们学习的“卷积”实际上被称为<strong>互相关（cross-correlation）</strong>，而非数学意义上的卷积。真正的卷积操作在做元素乘积求和之前，要将滤波器沿水平和垂直轴翻转（相当于旋转 180 度）。因为这种翻转对一般为水平或垂直对称的滤波器影响不大，按照机器学习的惯例，我们通常不进行翻转操作，在简化代码的同时使神经网络能够正常工作。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_6.png" alt></p>
<p>互相关：过滤器沿水平和垂直轴翻转，元素相乘来计算，这些视频中定义卷积运算时，我们跳过了这个镜像操作。（不进行翻转操作）叫做卷积操作</p>
<h3><span id="l06-convolution-over-volumes-san-wei-juan-ji">L06: Convolution over volumes(三维卷积)</span><a href="#l06-convolution-over-volumes-san-wei-juan-ji" class="header-anchor">#</a></h3><ol>
<li><p>卷积运算</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Convolutions-on-RGB-image.png" alt></p>
</li>
</ol>
<p>过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值。</p>
<p>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_8.png" alt></p>
<p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_9.png" alt></p>
<p>若输入图片的尺寸为n x n x nc，nc: 通道数目，filter尺寸为f x f x nc，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x nc′。其中，nc为图片通道数目，nc′为滤波器组个数。</p>
<h3><span id="l7-one-layer-of-a-convolution-network-dan-ceng-shen-jing-wang-luo">L7 : One layer of a convolution network (单层神经网络)</span><a href="#l7-one-layer-of-a-convolution-network-dan-ceng-shen-jing-wang-luo" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_10.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_11.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_12.png" alt></p>
<p>CNN单层的所以标记符号，设层数$l$,</p>
<script type="math/tex; mode=display">
\begin{array}{l}{f^{[l]}=\text { filter size }} \\ {p^{[l]}=\text { padding }} \\ {g^{[l]}=\text { stride }} \\ {n_{c}^{[l]}=\text { number of filters }}\end{array}</script><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_13.png" alt></p>
<script type="math/tex; mode=display">
\begin{array}{c}{n_{H}^{[l]}=\left\lfloor\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor} \\ { n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right\rfloor}\end{array}</script><p>如果$m$个样本，进行向量化运算，相应的输出维度，为</p>
<script type="math/tex; mode=display">
\mathrm{m} \times n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}</script><h3><span id="l8-a-simple-convolution-network-example-jian-dan-juan-ji-wang-luo-shi-li">L8 : A simple convolution network example（简单卷积网络示例）</span><a href="#l8-a-simple-convolution-network-example-jian-dan-juan-ji-wang-luo-shi-li" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-33.jpg" alt></p>
<ul>
<li>一般而言，<strong>图片的height $n^{[l]}_{H}$和width $n^{[l]}_W$随着层数的增加逐渐降低，但channel $n^{[l]}_C$逐渐增加</strong>。</li>
</ul>
<p>CNN有三种类型的layer：</p>
<ul>
<li>Convolution层（CONV）</li>
<li>Pooling层（POOL）</li>
<li>Fully connected层（FC）</li>
</ul>
<h3><span id="l9-pooling-layers-chi-hua-ceng">L9: Pooling layers(池化层)</span><a href="#l9-pooling-layers-chi-hua-ceng" class="header-anchor">#</a></h3><p>卷积神经网络除了卷积层，还有池化层来缩减模型的大小，提高运算速度和鲁棒性</p>
<ol>
<li>池的类型有max pooling(最大池化)</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_14.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_15.png" alt></p>
<p>这里步幅是s=2，filter = 2*2是最大池化的超参数,如果是三维，则单独在每个通道执行最大池化操作</p>
<p>关于max pooling的直觉解释： 元素较大的值，可能是卷积过程中提取到的某些特征（比如边界），而max pooling则在压缩了矩阵大小的情况下，保留每个分区内最大的输出，即保留了提取的特征。但理论上还没有证明max pooling的原理，max pooling应用的原因是在实践中效果很好。</p>
<ol>
<li><p>Pooling layer: Average pooling</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_16.png" alt></p>
<p>但是最大池化更好用</p>
</li>
</ol>
<p>summary : 输入$n_H<em>n_W</em>n_C$,如果没有padding,输出$(n_h-f)/s+1<em>(n_w-f)/s+1</em>n_c$</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_17.png" alt></p>
<h3><span id="l10-convolutional-neural-network-example-juan-ji-shen-jing-wang-luo-shi-li">L10: Convolutional neural network example (卷积神经网络实例)</span><a href="#l10-convolutional-neural-network-example-juan-ji-shen-jing-wang-luo-shi-li" class="header-anchor">#</a></h3><p>做一个识别数字的CNN网络</p>
<ol>
<li><p>LeNet-5架构如下：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/CNN.jpg" alt></p>
<ul>
<li>通常Conv Layer和Pooling Layer合在一起算一个layer，因为pooling layer并没有参数训练</li>
</ul>
</li>
</ol>
<ul>
<li>常见的结构：Conv ==&gt; Pool ==&gt; Conv ==&gt; Pool ==&gt; FC ==&gt; FC ==&gt; softmax</li>
<li>最终还会用FC层（全连接层），与一般NN的处理一样；并在输出层，应用softmax得到10个数字的概率。</li>
<li>在整个网络中，Height和Width是逐渐递减的，但channel和filter是递增的。</li>
<li>关于CNN如何选择超参：可以参考论文的经验。</li>
<li><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_18.png" alt></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Activation shape</th>
<th style="text-align:center">Activation Size</th>
<th>#parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>Input:</strong></td>
<td style="text-align:center">(32, 32, 3)</td>
<td style="text-align:center">3072</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV1(f=5, s=1)</strong></td>
<td style="text-align:center">(28, 28, 6)</td>
<td style="text-align:center">4704</td>
<td>156 (=5<em>5</em>6+6)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL1</strong></td>
<td style="text-align:center">(14, 14, 6)</td>
<td style="text-align:center">1176</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV2(f=5, s=1)</strong></td>
<td style="text-align:center">(10, 10, 16)</td>
<td style="text-align:center">1600</td>
<td>416 (=5<em>5</em>16+16)</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL2</strong></td>
<td style="text-align:center">(5, 5, 16)</td>
<td style="text-align:center">400</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC3</strong></td>
<td style="text-align:center">(120, 1)</td>
<td style="text-align:center">120</td>
<td>48120 (=120*400+120)</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC4</strong></td>
<td style="text-align:center">(84, 1)</td>
<td style="text-align:center">84</td>
<td>10164 (=84*120+84)</td>
</tr>
<tr>
<td style="text-align:center"><strong>Softmax</strong></td>
<td style="text-align:center">(10, 1)</td>
<td style="text-align:center">10</td>
<td>850 (=10*84+10)</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="l11-why-convolution">L11 Why convolution</span><a href="#l11-why-convolution" class="header-anchor">#</a></h3><ul>
<li><p>参数共享（parameter sharing)</p>
<p> 如果用FC的话，参数爆炸啊！如果conv layer 就需要filter检测器，这个参数就少了，还参数共享</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_19.png" alt></p>
</li>
<li><p>稀疏连接(sparsity of connection)</p>
<p>输出中的每个单元仅和输入的一个小分区相关，比如输出的左上角的像素仅仅由输入左上角的9个像素决定（假设filter大小是3*3），而其他输入都不会影响。</p>
</li>
</ul>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_20.png" alt></p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="read">1. 卷积神经网络的基本构造和计算过程 2. 如何整合这些模型 3.  哪些超参数 4. 为什么使用卷积 </font>

<h2><span id="w2-deep-convolutional-models-case-studies-shen-du-juan-ji-wang-luo-shi-li-tan-jiu">W2 : Deep convolutional models: case studies(深度卷积网络：实例探究)</span><a href="#w2-deep-convolutional-models-case-studies-shen-du-juan-ji-wang-luo-shi-li-tan-jiu" class="header-anchor">#</a></h2><h3><span id="l1-why-look-at-case-studies-wei-shi-me-yao-jin-xing-shi-li-tan-jiu">L1 : Why look at case studies?(为什么要进行实例探究？)</span><a href="#l1-why-look-at-case-studies-wei-shi-me-yao-jin-xing-shi-li-tan-jiu" class="header-anchor">#</a></h3><p>本文将主要介绍几个典型的CNN案例。通过对具体CNN模型及案例的研究，来帮助我们理解知识并训练实际的模型。</p>
<p>典型的CNN模型包括：</p>
<ul>
<li><strong>LeNet-5</strong></li>
<li><strong>AlexNet</strong></li>
<li><strong>VGG</strong></li>
</ul>
<p>还会介绍Residual Network（ResNet）。其特点是可以构建很深很深的神经网络（目前最深的好像有152层）。还会介绍Inception Neural Network</p>
<h3><span id="l2-classic-networks-jing-dian-wang-luo">L2 : Classic networks(经典网络)</span><a href="#l2-classic-networks-jing-dian-wang-luo" class="header-anchor">#</a></h3><h4><span id="1-lenet-5">1. LeNet-5</span><a href="#1-lenet-5" class="header-anchor">#</a></h4><p><strong>LeNet-5</strong>是针对灰度图片训练的，使用6个5×5的过滤器，步幅为1。由于使用了6个过滤器，步幅为1，<strong>padding</strong>为0，输出结果为28×28×6，图像尺寸从32×32缩小到28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池化，过滤器的宽度为2，步幅为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是一个14×14×6的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘制，新图像的尺寸应该刚好是原图像的一半。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-34.jpg" alt></p>
<p>该LeNet模型总共包含了大约6万个参数。值得一提的是，当时Yann LeCun提出的LeNet-5模型池化层使用的是average pool，而且各层激活函数一般是Sigmoid和tanh。现在，我们可以根据需要，做出改进，使用max pool和激活函数ReLU。</p>
<h4><span id="1-alexnet">1. AlexNet</span><a href="#1-alexnet" class="header-anchor">#</a></h4><p>AlexNet模型是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton共同提出的，其结构如下所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-35.jpg" alt></p>
<p><strong>AlexNet</strong>首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现227×227这个尺寸更好一些。第一层我们使用96个11×11的过滤器，步幅为4，由于步幅是4，因此尺寸缩小到55×55，缩小了4倍左右。然后用一个3×3的过滤器构建最大池化层,f=3，步幅为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的卷积，<strong>padding</strong>之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行一次<strong>same</strong>卷积，相同的<strong>padding</strong>，得到的结果是13×13×384，384个过滤器。再做一次<strong>same</strong>卷积，就像这样。再做一次同样的操作，最后再进行一次最大池化，尺寸缩小到6×6×256。6×6×256等于9216，将其展开为9216个单元，然后是一些全连接层。最后使用<strong>softmax</strong>函数输出识别的结果，看它究竟是1000个可能的对象中的哪一个。</p>
<p>实际上，这种神经网络与<strong>LeNet</strong>有很多相似之处，不过<strong>AlexNet</strong>要大得多。正如前面讲到的<strong>LeNet</strong>或<strong>LeNet-5</strong>大约有6万个参数，而<strong>AlexNet</strong>包含约6000万个参数。当用于训练图像和数据集时，<strong>AlexNet</strong>能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点<strong>AlexNet</strong>表现出色。<strong>AlexNet</strong>比<strong>LeNet</strong>表现更为出色的另一个原因是它使用了<strong>ReLu</strong>激活函数。原作者还提到了一种优化技巧，叫做Local Response Normalization(LRN)。 而在实际应用中，LRN的效果并不突出。</p>
<h4><span id="3-vgg-16">3. VGG-16</span><a href="#3-vgg-16" class="header-anchor">#</a></h4><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-36.jpg" alt></p>
<p>首先用3×3，步幅为1的过滤器构建卷积层，<strong>padding</strong>参数为<strong>same</strong>卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。因此<strong>VGG</strong>网络的一大优点是它确实简化了神经网络结构，下面我们具体讲讲这种网络结构。</p>
<p>数字16，就是指在这个网络中包含16个卷积层和全连接层。总共包含约1.38亿个参数</p>
<h3><span id="l3-residual-networks-resnets-can-chai-wang-luo-resnets">L3 : Residual Networks (ResNets)(残差网络(ResNets))</span><a href="#l3-residual-networks-resnets-can-chai-wang-luo-resnets" class="header-anchor">#</a></h3><p>我们知道，如果神经网络层数越多，网络越深，源于梯度消失和梯度爆炸的影响，整个模型难以训练成功。解决的方法之一是人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为Residual Networks(ResNets)。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_21.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Residual-Network.jpg" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/ResNet-Training-Error.jpg" alt></p>
<h3><span id="l4-why-resnets-work-can-chai-wang-luo-wei-shi-me-you-yong">L4: Why ResNets work?(残差网络为什么有用？)</span><a href="#l4-why-resnets-work-can-chai-wang-luo-wei-shi-me-you-yong" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_22.png" alt></p>
<p>因此，这两层额外的残差块不会降低网络性能。而如果没有发生梯度消失时，训练得到的非线性关系会使得表现效果进一步提高。</p>
<p>注意，如果$ a[l]$与 $a[l+2]$的维度不同，需要引入矩阵 $W_s$与 $a_{[l]}$相乘，使得二者的维度相匹配。参数矩阵 $W_s$既可以通过模型训练得到，也可以作为固定值，仅使 $a[l]$截断或者补零。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Xnip2018-07-04_08-28-37.jpg" alt></p>
<h3><span id="l5-network-in-network-and-1x1-convolutions-wang-luo-zhong-de-wang-luo-yi-ji-1x1-juan-ji">L5 : Network in Network and 1×1 convolutions(网络中的网络以及 1×1 卷积)</span><a href="#l5-network-in-network-and-1x1-convolutions-wang-luo-zhong-de-wang-luo-yi-ji-1x1-juan-ji" class="header-anchor">#</a></h3><ol>
<li>作用 </li>
</ol>
<p>假设这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（$n_c$）的方法，对于池化层我只是压缩了这些层的高度和宽度</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_23.png" alt></p>
<ol>
<li><strong>doing something pretty non-trivial</strong></li>
</ol>
<p>它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。</p>
<h3><span id="l6-inception-network-motivation-gu-ge-inception-wang-luo-jian-jie">L6 : Inception network motivation(谷歌 Inception 网络简介)</span><a href="#l6-inception-network-motivation-gu-ge-inception-wang-luo-jian-jie" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/99f8fc7dbe7cd0726f5271aae11b9872.png" alt></p>
<p>有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。有了这样的<strong>Inception</strong>模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为32+32+128+64=256。Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。</p>
<p> 1x1 的卷积层通常被称作<strong>瓶颈层（Bottleneck layer）</strong></p>
<p>计算量为 28x28x32x5x5x192 = 1.2亿</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/The-problem-of-computational-cost.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Using-1x1-convolution.png" alt></p>
<p>28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。</p>
<h3><span id="l7-inception-network-inception-wang-luo">L7 : Inception network(Inception 网络)</span><a href="#l7-inception-network-inception-wang-luo" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_24.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/example_2_25.png" alt></p>
<h3><span id="l8-using-open-source-implementations-shi-yong-kai-yuan-de-shi-xian-fang-an">L8 : Using open-source implementations( 使用开源的实现方案)</span><a href="#l8-using-open-source-implementations-shi-yong-kai-yuan-de-shi-xian-fang-an" class="header-anchor">#</a></h3><p>开源项目</p>
<h3><span id="l9-transfer-learning-qian-yi-xue-xi">L9 ： Transfer Learning（迁移学习）</span><a href="#l9-transfer-learning-qian-yi-xue-xi" class="header-anchor">#</a></h3><p>如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。</p>
<ol>
<li>只有很小数据集： 可以你只需要训练<strong>softmax</strong>层的权重，把前面这些层的权重都冻结。</li>
<li>稍微更大的数据集： 你应该冻结更少的层，比如只把这些层冻结，然后训练后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元；或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的<strong>softmax</strong>输出层，这些方法值得一试。</li>
<li>大量数据： 你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。</li>
</ol>
<h3><span id="l10-data-augmentation-shu-ju-zeng-qiang">L10 ： Data augmentation（数据增强）</span><a href="#l10-data-augmentation-shu-ju-zeng-qiang" class="header-anchor">#</a></h3><p>数据量远远不够</p>
<ol>
<li>Mirroring</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring.png" alt></p>
<ol>
<li>Random Cropping</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_1.png" alt></p>
<ol>
<li><p>彩色转换color shifting</p>
<p>r,g,b数据改变</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_2.png" alt></p>
<p>除了随意改变RGB通道数值外，还可以更有针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，对主要的通道颜色进行增加或减少，可以采用高斯扰动做法。这样也能增加有效的样本数量。具体的PCA color augmentation做法可以查阅AlexNet的相关论文。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_3.png" alt></p>
<p>常用的实现数据扩充的方法是使用一个线程或者是多线程，这些可以用来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号2）和这个（编号1），可以并行实现。</p>
<h3><span id="l11-the-state-of-computer-vision-ji-suan-ji-shi-jue-xian-zhuang">L11：The state of computer vision(计算机视觉现状)</span><a href="#l11-the-state-of-computer-vision-ji-suan-ji-shi-jue-xian-zhuang" class="header-anchor">#</a></h3><ol>
<li>神经网络需要数据，不同的网络模型所需的数据量是不同的。Object dection，Image recognition，Speech recognition所需的数据量依次增加。一般来说，如果data较少，那么就需要更多的hand-engineering，对已有data进行处理。</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_4.png" alt></p>
<p>hand-engineering是一项非常重要也比较困难的工作。很多时候，hand-engineering对模型训练效果影响很大，特别是在数据量不多的情况下。</p>
<p>当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。在别人做好的基础上研究</p>
<ol>
<li><p>提升性能</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Mirroring_5.png" alt>*</p>
</li>
</ol>
<p>由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计算机视觉问题。</p>
<p>所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比如学习率衰减方式或者超参数。</p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="red">1. CNN的常见网络结构 重点说了一些残差网络 2.数据增加的方法 3. 多用开源框架，不用从头开始训练 </font>

<h1><span id="w3-object-detection-mu-biao-jian-ce">W3 Object detection(目标检测)</span><a href="#w3-object-detection-mu-biao-jian-ce" class="header-anchor">#</a></h1><h3><span id="l1-object-localization-mu-biao-ding-wei">L1 :Object localization(目标定位)</span><a href="#l1-object-localization-mu-biao-ding-wei" class="header-anchor">#</a></h3><p>目标定位和目标检测</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_1.png" alt></p>
<p>模型</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_2.png" alt></p>
<p>输入还包括位置信息</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_3.png" alt></p>
<p>损失函数</p>
<p>情况一：检测到了</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_4.png" alt></p>
<p>情况二：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_5.png" alt></p>
<h3><span id="l2-landmark-detection-te-zheng-dian-jian-ce">L2: Landmark detection(特征点检测)</span><a href="#l2-landmark-detection-te-zheng-dian-jian-ce" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_6.png" alt></p>
<p>该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值。通过检测人脸特征点可以进行情绪分类与判断，或者应用于AR领域等等。</p>
<p>除了人脸特征点检测之外，还可以检测人体姿势动作，如下图所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_7.png" alt></p>
<h3><span id="l3-object-detection-mu-biao-jian-ce">L3 :Object detection(目标检测)</span><a href="#l3-object-detection-mu-biao-jian-ce" class="header-anchor">#</a></h3><p>学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_8.png" alt></p>
<p>训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。</p>
<p>选定特定大小的窗口，窗口圈定输入卷积神经网络，卷积神经网络开始预测。</p>
<p>重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出0或<img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_10.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_11.png" alt></p>
<p>如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。</p>
<p>这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。</p>
<p>滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。但是其缺点也很明显，首先滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。而且，每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。所以，滑动窗算法虽然简单，但是性能不佳，不够快，不够灵活。</p>
<h3><span id="l-4-convolutional-implementation-of-sliding-windows-hua-dong-chuang-kou-de-juan-ji-shi-xian">L 4 : Convolutional implementation of sliding windows(滑动窗口的卷积实现)</span><a href="#l-4-convolutional-implementation-of-sliding-windows-hua-dong-chuang-kou-de-juan-ji-shi-xian" class="header-anchor">#</a></h3><ol>
<li><p>全连接层转化为卷积层</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_12.png" alt></p>
</li>
</ol>
<p>单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，步进长度为2，CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_13.png" alt></p>
<p>之前的滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。值得一提的是，窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。</p>
<h3><span id="l5-bounding-box-predictions-bounding-box-yu-ce">L5 ： Bounding box predictions（Bounding Box预测）</span><a href="#l5-bounding-box-predictions-bounding-box-yu-ce" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_14.png" alt></p>
<ol>
<li><p>YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_16.png" alt></p>
</li>
<li><p>如果目标中心坐标(bx,by)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。判断有目标的网格中，bx,by,bh,bw限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(bx,by)范围限定在[0,1]之间，但是bh,bw可以大于1。因为目标可能超出该网格，横跨多个区域，如上图所示。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。</p>
</li>
</ol>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_15.png" alt></p>
<h3><span id="l6-intersection-over-union-jiao-bing-bi">L6 ：Intersection over union（交并比)</span><a href="#l6-intersection-over-union-jiao-bing-bi" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_17.png" alt></p>
<p>一般约定，在计算机检测任务中，如果lou&gt;=0.5，就说检测正确，如果预测器和实际边界框完美重叠，<strong>loU</strong>就是1，因为交集就等于并集。但一般来说只要lou&gt;=0.5，那么结果是可以接受的，看起来还可以。一般约定，0.5是阈值，用来判断预测的边界框是否正确。一般是这么约定，但如果你希望更严格一点，你可以将<strong>loU</strong>定得更高，比如说大于0.6或者更大的数字，但<strong>loU</strong>越高，边界框越精确。</p>
<h3><span id="l7-non-max-suppression-fei-ji-da-zhi-yi-zhi">L7: Non-max suppression(非极大值抑制)</span><a href="#l7-non-max-suppression-fei-ji-da-zhi-yi-zhi" class="header-anchor">#</a></h3><p>到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_18.png" alt></p>
<p>假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_19.png" alt></p>
<p>实际情况是格子1，2，3，4，5，6都认为里面有车。因为你要在361个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc,我这个格子里有车的概率很高，而不是361个格子中仅有两个格子会报告它们检测出一个对象。</p>
<p>非最大值抑制（Non-max Suppression）做法很简单，图示每个网格的Pc值可以求出，Pc值反映了该网格包含目标中心坐标的可信度。首先选取Pc最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示：</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_20.png" alt></p>
<p>总结一下非最大值抑制算法的流程：</p>
<ol>
<li><strong>剔除Pc值小于某阈值（例如0.6）的所有网格；</strong></li>
<li><strong>选取Pc值最大的网格，利用IoU，摒弃与该网格交叠较大的网格；</strong></li>
<li><strong>对剩下的网格，重复步骤2。</strong></li>
</ol>
<p>到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用<strong>anchor box</strong>这个概念，我们从一个例子开始讲吧。方法是使用不同形状的Anchor Boxes。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_21.png" alt></p>
<p>这就是<strong>anchor box</strong>的概念，我们建立<strong>anchor box</strong>这个概念，是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生</p>
<h3><span id="l9-yolo-suan-fa-putting-it-together-yolo-algorithm">L9 :  YOLO 算法（Putting it together: YOLO algorithm）</span><a href="#l9-yolo-suan-fa-putting-it-together-yolo-algorithm" class="header-anchor">#</a></h3><p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_22.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_23.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_24.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_25.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_26.png" alt></p>
<p>这就是<strong>YOLO</strong>对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算机视觉对象检测领域文献中很多最精妙的思路</p>
<h3><span id="region-proposals-optional-hou-xuan-qu-yu-xuan-xiu">Region proposals (Optional)（候选区域（选修））</span><a href="#region-proposals-optional-hou-xuan-qu-yu-xuan-xiu" class="header-anchor">#</a></h3><p>之前介绍的滑动窗算法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，例如下图所示。这样会降低算法运行效率，耗费时间。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_27.png" alt></p>
<p>为了解决这一问题，尽量避免对无用区域的扫描，可以使用Region Proposals的方法。具体做法是先对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_28.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/Detering_29.png" alt></p>
<p>Region Proposals共有三种方法：</p>
<ul>
<li><strong>R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。</strong></li>
<li><strong>Fast R-CNN: 利用卷积实现滑动窗算法，类似第4节做法。</strong></li>
<li><strong>Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。</strong></li>
</ul>
<h2><span id="w4-special-applications-face-recognition-amp-neural-style-transfer-te-shu-ying-yong-ren-lian-shi-bie-he-shen-jing-feng-ge-zhuan-huan">W4：Special applications: Face recognition &amp;Neural style transfer( 特殊应用：人脸识别和神经风格转换)</span><a href="#w4-special-applications-face-recognition-amp-neural-style-transfer-te-shu-ying-yong-ren-lian-shi-bie-he-shen-jing-feng-ge-zhuan-huan" class="header-anchor">#</a></h2><h3><span id="c1-what-is-face-recognition">C1 ： What is face recognition?</span><a href="#c1-what-is-face-recognition" class="header-anchor">#</a></h3><p>首先简单介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。</p>
<ul>
<li><strong>人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。</strong></li>
<li><strong>人脸识别：输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题。</strong></li>
</ul>
<h3><span id="l2-one-shot-learning">L2 ： One-shot learning</span><a href="#l2-one-shot-learning" class="header-anchor">#</a></h3><p>One-shot learning就是说数据库中每个人的训练样本只包含一张照片，然后训练一个CNN模型来进行人脸识别。若数据库有K个人，则CNN模型输出softmax层就是K维的。</p>
<p>但是One-shot learning的性能并不好，其包含了两个缺点：</p>
<ul>
<li><strong>每个人只有一张图片，训练样本少，构建的CNN网络不够健壮。</strong></li>
<li><strong>若数据库增加另一个人，输出层softmax的维度就要发生变化，相当于要重新构建CNN网络，使模型计算量大大增加，不够灵活。</strong></li>
</ul>
<p>为了解决One-shot learning的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用：</p>
<ul>
<li><strong>d(img1,img2)≤τ : 一样</strong></li>
<li><strong>d(img1,img2)&gt;τ : 不一样</strong></li>
</ul>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_1.png" alt></p>
<p>现在你已经知道函数d是如何工作的，通过输入两张照片，它将让你能够解决一次学习问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数。</p>
<h3><span id="l3-siamese-network">L3: Siamese network</span><a href="#l3-siamese-network" class="header-anchor">#</a></h3><p>最后一层去掉softmax单元做分类</p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_2.png" alt></p>
<p><img src="/2019/05/12/Deel%20Learning%20ai_Convolutional%20Neural%20Networks/congtion_3.png" alt></p>
<p>如果你要比较两个图片的话，例如这里的第一张（编号1）和第二张图片（编号2），你要做的就是把第二张图片喂给有同样参数的同样的神经网络，然后得到一个不同的128维的向量（编号3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做$f(x^{(2)})$。这里我用$x^{(1)}$和$x^{(2)}$仅仅代表两个输入图片,</p>
<script type="math/tex; mode=display">
d(x^{(1)},x^{(2)})=||f(x^{(1)}-f(x^{(2)}||^2</script><p>不同的图片的CNN网络结构和参数都是一样的，目标就是利用梯度下降算法，调整网络参数</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/" class="post-title-link" itemprop="url">The Deep Learning Specialization</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-05 19:41:59" itemprop="dateCreated datePublished" datetime="2019-05-05T19:41:59+08:00">2019-05-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-05 21:47:36" itemprop="dateModified" datetime="2020-10-05T21:47:36+08:00">2020-10-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="c3-improving-model-performance">C3 Improving Model Performance</span><a href="#c3-improving-model-performance" class="header-anchor">#</a></h1><h2><span id="w1-ml-strategy-1">W1 ML Strategy(1)</span><a href="#w1-ml-strategy-1" class="header-anchor">#</a></h2><h3><span id="l01-improving-model-performance">L01 Improving Model Performance</span><a href="#l01-improving-model-performance" class="header-anchor">#</a></h3><p>需要提高训练结果的表现，表现得更好的措施 Machine Learning Strategy</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-24_21-03-13.jpg" alt></p>
<h3><span id="l2-orthogonalization-zheng-jiao-hua">L2 : Orthogonalization(正交化)</span><a href="#l2-orthogonalization-zheng-jiao-hua" class="header-anchor">#</a></h3><p>所谓正交，<strong>就是你的操控效果尽量只影响一个方面</strong>。比如以老式电视机为例，调节图像的大小、左右偏移、上下偏移。而不是一个按钮可以同时调节图像大小和左右偏移，那样会很难操作。</p>
<p>具体到supervised learning，有以下4个假设是正交的？</p>
<ol>
<li>Fit <strong>training set</strong> well in cost function If it doesn’t fit well, the use of a bigger neural network or switching to a better optimization algorithm might help.</li>
<li>Fit <strong>development set</strong> well on cost function If it doesn’t fit well, regularization or using bigger training set might help.</li>
<li>Fit <strong>test set</strong> well on cost function If it doesn’t fit well, the use of a bigger development set might help</li>
<li>Performs well in <strong>real world</strong> If it doesn’t perform well, the development test set is not set correctly or the cost function is not evaluating the right thing.</li>
</ol>
<p>在训练集上表现欠佳，需要切换到好的优化算法</p>
<p>在验证集上表现不好，一组正则化按钮</p>
<p>在测试集表现不好，需要更好的验证集</p>
<p>在用户体验不好，需要改变测试集大小或者成本函数</p>
<h3><span id="l3-single-number-evaluation-metric-dan-yi-shu-zi-ping-gu-zhi-biao">L3 Single number evaluation metric(单一数字评估指标)</span><a href="#l3-single-number-evaluation-metric-dan-yi-shu-zi-ping-gu-zhi-biao" class="header-anchor">#</a></h3><h4><span id="classification">classification</span><a href="#classification" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-42-10.jpg" alt></p>
<h4><span id="precesion-cha-zhun-lu">Precesion （查准率）</span><a href="#precesion-cha-zhun-lu" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-47-46.jpg" alt></p>
<h4><span id="recall-cha-quan-lu">recall（查全率）</span><a href="#recall-cha-quan-lu" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-25_20-48-11.jpg" alt></p>
<script type="math/tex; mode=display">
F 1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2 P R}{P+R}</script><h3><span id="l4-satisficing-and-optimizing-metrics-man-zu-he-you-hua-zhi-biao">L4  Satisficing and optimizing metrics(满足和优化指标)</span><a href="#l4-satisficing-and-optimizing-metrics-man-zu-he-you-hua-zhi-biao" class="header-anchor">#</a></h3><p>如果我们还想要将分类器的运行时间也纳入考虑范围，将其和精确率、召回率组合成一个单值评价指标显然不那么合适。这时，我们可以将某些指标作为<strong>优化指标（Optimizing Matric）</strong>，寻求它们的最优值；而将某些指标作为<strong>满足指标（Satisficing Matric）</strong>，只要在一定阈值以内即可。</p>
<p>在这个例子中，准确率就是一个优化指标，因为我们想要分类器尽可能做到正确分类；而运行时间就是一个满足指标，如果你想要分类器的运行时间不多于某个阈值，那最终选择的分类器就应该是以这个阈值为界里面准确率最高的那个。</p>
<p>如此，accuracy就变成了<strong>optimizing metric</strong>，而running time则是<strong>satisfying metric</strong>，statisfying metric只要达到标准即可，而optimizing metric则追求更好。一般的，选择一项metric作为optimizing metric，其他的则设置为satisfying metric： </p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-09-36.jpg" alt></p>
<h3><span id="l-5-train-dev-test-distributions-xun-lian-kai-fa-ce-shi-ji-hua-fen">L 5: Train/dev/test distributions(训练/开发/测试集划分)</span><a href="#l-5-train-dev-test-distributions-xun-lian-kai-fa-ce-shi-ji-hua-fen" class="header-anchor">#</a></h3><p>开发（<strong>dev</strong>）集也叫做开发集（<strong>development set</strong>），有时称为保留交叉验证集（<strong>hold out cross validation set</strong>）。</p>
<p>如何设置Train/dev/test集，很大程度上影响了机器学习的速度。</p>
<p>Train/dev/test的区别 Workflow in machine learning is that you try a lot of ideas, train up different models on the training set, and then use the dev set to evaluate the different ideas and pick one. And, keep innovating to improve dev set performance until, finally, you have one class that you’re happy with that you then evaluate on your test set.</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-09-37.jpg" alt></p>
<p>开发集合和开发集合来自同一分布，如果是不同分布，相当于靶心移动了</p>
<h3><span id="l-6-size-of-dev-and-test-sets-kai-fa-ji-he-ce-shi-ji-de-da-xiao">L 6: Size of dev and test sets(开发集和测试集的大小)</span><a href="#l-6-size-of-dev-and-test-sets-kai-fa-ji-he-ce-shi-ji-de-da-xiao" class="header-anchor">#</a></h3><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-29-51.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-25.jpg" alt></p>
<h3><span id="l7-when-to-change-dev-test-sets-and-metrics-shi-me-shi-hou-gai-gai-bian-kai-fa-ce-shi-ji-he-zhi-biao">L7 : When to change dev/test sets and metrics(什么时候该改变开发/测试集和指标)</span><a href="#l7-when-to-change-dev-test-sets-and-metrics-shi-me-shi-hou-gai-gai-bian-kai-fa-ce-shi-ji-he-zhi-biao" class="header-anchor">#</a></h3><p>如果发现设定目标和实际期望不符，那就调整目标。</p>
<ol>
<li><p>举个例子</p>
<p>A可能把一些色情照片也分类成猫了，因此改变优化指标</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-26.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-27.jpg" alt></p>
</li>
</ol>
<p>我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。你们要把机器学习任务看成两个独立的步骤，用目标这个比喻，第一步就是设定目标。所以要定义你要瞄准的目标，这是完全独立的一步，这是你可以调节的一个旋钮。如何设立目标是一个完全独立的问题，把它看成是一个单独的旋钮，可以调试算法表现的旋钮，如何精确瞄准，如何命中目标，定义指标是第一步。</p>
<p>后第二步要做别的事情，在逼近目标的时候，也许你的学习算法针对某个长这样的成本函数优化，$J=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)$你要最小化训练集上的损失。你可以做的其中一件事是，修改这个，为了引入这些权重，也许最后需要修改这个归一化常数，$J=\frac{1}{\sum w^{(i)}} \sum_{i=1}^{m} w^{(i)} L\left(\hat{y}^{(i)}, y^{(i)}\right)$</p>
<p>再次，如何定义J并不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。换种说法，我鼓励你们将定义指标看成一步，然后在定义了指标之后，你才能想如何优化系统来提高这个指标评分。比如改变你神经网络要优化的成本函数J。</p>
<h3><span id="l8-why-human-level-performance-wei-shi-me-shi-ren-de-biao-xian">L8 : Why human-level performance?(为什么是人的表现？)</span><a href="#l8-why-human-level-performance-wei-shi-me-shi-ren-de-biao-xian" class="header-anchor">#</a></h3><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Bayes-Optimal-Error.png" alt></p>
<p>上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为<strong>贝叶斯最优误差（Bayes Optimal Error）</strong>。</p>
<p>也因此，只要建立的机器学习模型的表现还没达到人类的表现水平时，就可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过人工误差分析了解为什么人能够正确识别，或者是进行偏差、方差分析。</p>
<p>当模型的表现超过人类后，这些手段起的作用就微乎其微了。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/e1ef954731399bb4fbf18f2fb99b863a.png" alt></p>
<h3><span id="l9-avoidable-bias-ke-bi-mian-pian-chai">L9 : Avoidable bias(可避免偏差)</span><a href="#l9-avoidable-bias-ke-bi-mian-pian-chai" class="header-anchor">#</a></h3><ol>
<li><p>training error</p>
<p>我们经常使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-28.jpg" alt></p>
</li>
</ol>
<ol>
<li><p>dev error</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-29.jpg" alt></p>
</li>
</ol>
<p><strong>贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差</strong></p>
<h3><span id="l-10-understanding-human-level-performance-li-jie-ren-de-biao-xian">L 10: Understanding human-level performance(理解人的表现)</span><a href="#l-10-understanding-human-level-performance-li-jie-ren-de-biao-xian" class="header-anchor">#</a></h3><p>还记得上个视频中，我们用过这个词“人类水平错误率”用来估计贝叶斯误差，那就是理论最低的错误率，任何函数不管是现在还是将来，能够到达的最低值</p>
<h3><span id="l11-surpassing-human-level-performance-chao-guo-ren-de-biao-xian">L11 : Surpassing human- level performance(超过人的表现)</span><a href="#l11-surpassing-human-level-performance-chao-guo-ren-de-biao-xian" class="header-anchor">#</a></h3><p>现在，机器学习有很多问题已经可以大大超越人类水平了。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/de2eb0ddc7918f6e9213871e07b8fa56.png" alt></p>
<h3><span id="l12-improving-your-model-performance-gai-shan-ni-de-mo-xing-de-biao-xian">L12 : Improving your model performance(改善你的模型的表现)</span><a href="#l12-improving-your-model-performance-gai-shan-ni-de-mo-xing-de-biao-xian" class="header-anchor">#</a></h3><p>你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-39.jpg" alt></p>
<p>method</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-49.jpg" alt></p>
<h2><span id="summary">summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="red">这一周的内容主要是改善模型的表现，主要是按照正交化，使得更好的满足 1. 评价指标 2. 数据集的划分 3. 人的表现的重要性 4. 当出现表现不好的时候，如何改善呢，有哪些方法呢？ </font>

<h2><span id="w2-ml-strategy-2">W2 ML Strategy(2)</span><a href="#w2-ml-strategy-2" class="header-anchor">#</a></h2><h3><span id="c-1-carrying-out-error-analysis-jin-xing-wu-chai-fen-xi">C 1: Carrying out error analysis(进行误差分析)</span><a href="#c-1-carrying-out-error-analysis-jin-xing-wu-chai-fen-xi" class="header-anchor">#</a></h3><h4><span id="1-simple-analysis">1. simple analysis</span><a href="#1-simple-analysis" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/e1ef954731399bb4fbf18f2fb99b863.png" alt></p>
<p>通过观察发现算法分类出错的例子，是把狗分成猫，提高准确率的方法就是如何针对狗的图片优化算法。你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫。现在考虑的是应该不应该这么去做呢？统计一下dev set里面多少是错误标记是狗的个数，分析出可以改善的算法的上限。</p>
<h4><span id="mutiply-analysis">mutiply analysis</span><a href="#mutiply-analysis" class="header-anchor">#</a></h4><p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-51.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-50.jpg" alt></p>
<h3><span id="c2-cleaning-up-incorrectly-labeled-data-qing-chu-biao-zhu-cuo-wu-de-shu-ju">C2 : Cleaning up Incorrectly labeled data(清除标注错误的数据)</span><a href="#c2-cleaning-up-incorrectly-labeled-data-qing-chu-biao-zhu-cuo-wu-de-shu-ju" class="header-anchor">#</a></h3><h4><span id="incorrct-label">incorrct label</span><a href="#incorrct-label" class="header-anchor">#</a></h4><h4><span id="traning-set">traning set</span><a href="#traning-set" class="header-anchor">#</a></h4><p>DL algorithms are quite robust to random errors in the traning set so long as your errors or your labeled example to once those errors are not too far from random .</p>
<h4><span id="distribution">distribution</span><a href="#distribution" class="header-anchor">#</a></h4><p>首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。开发集确定了你的目标，当你击中目标后，你希望算法能够推广到测试集上，这样你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正以确保它们继续来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-52.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-53.jpg" alt></p>
<h4><span id="suggestion">suggestion</span><a href="#suggestion" class="header-anchor">#</a></h4><p>最后我讲几个建议：</p>
<p>首先，深度学习研究人员有时会喜欢这样说：“我只是把数据提供给算法，我训练过了，效果拔群”。这话说出了很多深度学习错误的真相，更多时候，我们把数据喂给算法，然后训练它，并减少人工干预，减少使用人类的见解。但我认为，在构造实际系统时，通常需要更多的人工错误分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。</p>
<p>其次，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些样本，也许做这些事情很无聊，坐下来看100或几百个样本来统计错误数量，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它所犯的错误，我会亲自去看看这些数据，尝试和一部分错误作斗争。我想就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。</p>
<p>这就是错误分析过程，在下一个视频中，我想分享一下错误分析是如何在启动新的机器学习项目中发挥作用的。</p>
<h3><span id="c3-build-your-first-system-quickly-then-iterate-kuai-su-da-jian-ni-de-di-yi-ge-xi-tong-bing-jin-xing-die-dai">C3: Build your first system quickly, then iterate(快速搭建你的第一个系统，并进行迭代)</span><a href="#c3-build-your-first-system-quickly-then-iterate-kuai-su-da-jian-ni-de-di-yi-ge-xi-tong-bing-jin-xing-die-dai" class="header-anchor">#</a></h3><h4><span id="1-iteration">1. iteration</span><a href="#1-iteration" class="header-anchor">#</a></h4><p>I recommend that you first quickly set up a definition and metrics so this is really you know  deciding where to place your target and you get it wrong you can always move it later we just set up a target somewhere and then I recommend you build an inital machine learning system quickly find the traning set train it and see start to see and understand how well your are doing against your Devon chess setting evaluation metric when you build your initial system you then be able to use bias variance analysis we should talk about earlier as well as error analysis whick we talked about just in last several videos to prioritize the next step in particular if error analysis causes you to realize that a lot of the errors are from the spearker being very far from the mirophone which causes special challenges speech recognitin then that would give you a good reason to focus on techniques to address this it called fast used speech recognition which basically means handling when the speaker is very far from microphone along the value of building this inital  system  it can be a quick  and diry implementation you know do not overthink it but all the value of the inital system is having some learning system having some tranin system allows you lok at bias and variance to do error analysis look at some mistakes to figure out all the different directins you could go in.</p>
<p>我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。</p>
<h3><span id="c4-training-and-testing-on-different-distributions-shi-yong-lai-zi-bu-tong-fen-bu-de-shu-ju-jin-xing-xun-lian-he-ce-shi">C4 : Training and testing on different distributions(使用来自不同分布的数据，进行训练和测试)</span><a href="#c4-training-and-testing-on-different-distributions-shi-yong-lai-zi-bu-tong-fen-bu-de-shu-ju-jin-xing-xun-lian-he-ce-shi" class="header-anchor">#</a></h3><p>this is resulted in many teams sometimes taking one of the days you can find and just shoving it into the training set .</p>
<ol>
<li><p>Cat app example </p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/Xnip2018-06-26_08-32-54.jpg" alt></p>
<p>假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据，比如右边的应用，这些照片一般更业余，取景不太好，有些甚至很模糊，因为它们都是业余用户拍的。另一个数据来源就是你可以用爬虫程序挖掘网页直接下载，就这个样本而言，可以下载很多取景专业、高分辨率、拍摄专业的猫图片。如果你的应用用户数还不多，也许你只收集到10,000张用户上传的照片，但通过爬虫挖掘网页，你可以下载到海量猫图，也许你从互联网上下载了超过20万张猫图。而你真正关心的算法表现是你的最终系统处理来自应用程序的这个图片分布时效果好不好，因为最后你的用户会上传类似右边这些图片，你的分类器必须在这个任务中表现良好。现在你就陷入困境了，因为你有一个相对小的数据集，只有10,000个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。但你又不想直接用这10,000张图片，因为这样你的训练集就太小了，使用这20万张图片似乎有帮助。但是，困境在于，这20万张图片并不完全来自你想要的分布，那么你可以怎么做呢？</p>
<p>我们真正关心的是来自手机手机收集的数据，而不是来自网页。方法一，随机分配训练集、验证集、测试集，这样的后果就是花了大量时间在实际不关心的数据分布去优化。</p>
<p>训练集20万张网络，5000手机，验证集和测试集各2500，这样可以保证验证集和测试集更接近实际应用场景，我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的训练集分布和你的开发集、测试集分布并不一样。但事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。我们以后会讨论一些特殊的技巧，可以处理 训练集的分布和开发集和测试集分布不一样的情况。</p>
</li>
</ol>
<h2><span id="c5-bias-and-variance-with-mismatched-data-distributions-shu-ju-fen-bu-bu-pi-pei-shi-pian-chai-yu-fang-chai-de-fen-xi">C5: Bias and Variance with mismatched data distributions（数据分布不匹配时，偏差与方差的分析）</span><a href="#c5-bias-and-variance-with-mismatched-data-distributions-shu-ju-fen-bu-bu-pi-pei-shi-pian-chai-yu-fang-chai-de-fen-xi" class="header-anchor">#</a></h2><p>首先算法只看过训练集数据，没看过开发集数据。第二，开发集数据来自不同的分布。很难确认这增加的9%误差率有多少是因为算法没看到开发集中的数据导致的，这么评估呢？到底哪个影响元素更大，</p>
<p>评估方法，训练集的分布挖出，traning-dev set : Same distributation as traning set ,but not used for training.</p>
<p>现在，我们有了<em>训练集</em>错误率、<em>训练-验证集</em>错误率，以及<em>验证集</em>错误率。其中，<em>训练集</em>错误率和<em>训练-验证集</em>错误率的差值反映了方差；而<em>训练-验证集</em>错误率和<em>验证集</em>错误率的差值反映了样本分布不一致的问题，从而说明<strong>模型擅长处理的数据和我们关心的数据来自不同的分布</strong>，我们称之为<strong>数据不匹配（Data Mismatch）</strong>问题。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Analysis-With-Data-Mismatch.png" alt></p>
<h3><span id="c6-addressing-data-mismatch-chu-li-shu-ju-bu-pi-pei-wen-ti">C6: Addressing data mismatch（处理数据不匹配问题）</span><a href="#c6-addressing-data-mismatch-chu-li-shu-ju-bu-pi-pei-wen-ti" class="header-anchor">#</a></h3><p>I<img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-55.jpg" alt></p>
<p>Data: Artifical data synthesis</p>
<p>所以，总而言之，如果你认为存在数据不匹配问题，我建议你做错误分析，或者看看训练集，或者看看开发集，试图找出，试图了解这两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像开发集的数据作训练。</p>
<h3><span id="c7-transfer-learning-qian-yi-xue-xi">C7: Transfer learning（迁移学习）</span><a href="#c7-transfer-learning-qian-yi-xue-xi" class="header-anchor">#</a></h3><p><strong>迁移学习（Tranfer Learning）</strong>是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。</p>
<p>例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（$W[L]$、$b[L]$），随后用新的训练集进行训练，就完成了以上的迁移学习。</p>
<p>如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，即$W[L]$$、b[L]$，并保持其他参数不变；而如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为<strong>预训练（Pre-Training）</strong>，之后的权重更新过程称为<strong>微调（Fine-Tuning）</strong>。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-56.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-57.jpg" alt></p>
<p>在下述场合进行迁移学习是有意义的：</p>
<p>两个任务有同样的输入（比如都是图像或者都是音频）；<br>拥有更多数据的任务迁移到数据较少的任务；<br>某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-58.jpg" alt></p>
<h3><span id="c8-multi-task-learning-duo-ren-wu-xue-xi">C8; Multi-task learning （多任务学习）</span><a href="#c8-multi-task-learning-duo-ren-wu-xue-xi" class="header-anchor">#</a></h3><p>For example, autonomous driving example,check cars,stop signs,trfffic lights ,输出也是一个向量，</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-59.jpg" alt></p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\Xnip2018-06-26_08-32-60.jpg" alt></p>
<h3><span id="c9-what-is-end-to-end-deep-learning-shi-me-shi-duan-dao-duan-de-shen-du-xue-xi">C9 :  What is end-to-end deep learning?(什么是端到端的深度学习)</span><a href="#c9-what-is-end-to-end-deep-learning-shi-me-shi-duan-dao-duan-de-shen-du-xue-xi" class="header-anchor">#</a></h3><p>在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而<strong>端到端深度学习（End-to-end Deep Learning）</strong>只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。</p>
<p><img src="/2019/05/05/Deep%20Learning%20ai_Deep%20Learning%20Specialization/MyBlog\hexo\source\_posts\Deep Learning ai_Deep Learning Specialization\End-to-end-Deep-Learning.png" alt></p>
<h3><span id="you-dian-yu-que-dian">优点与缺点</span><a href="#you-dian-yu-que-dian" class="header-anchor">#</a></h3><p>应用端到端学习的优点：</p>
<ul>
<li>只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析；</li>
<li>所需手工设计的组件更少，简化设计工作流程；</li>
</ul>
<p>缺点：</p>
<ul>
<li>需要大量的数据；</li>
<li>排除了可能有用的人工设计组件；</li>
</ul>
<p>根据以上分析，决定一个问题是否应用端到端学习的<strong>关键点</strong>是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数？</p>
<h3><span id="whether-to-use-end-to-end-learning-shi-fou-yao-shi-yong-duan-dao-duan-de-shen-du-xue-xi">Whether to use end-to-end learning?(是否要使用端到端的深度学习?)</span><a href="#whether-to-use-end-to-end-learning-shi-fou-yao-shi-yong-duan-dao-duan-de-shen-du-xue-xi" class="header-anchor">#</a></h3><p>Pros:</p>
<p>​    let the data speak : x-&gt;y</p>
<p>​    less hand-designing of components needed</p>
<p>Cons:</p>
<p>​    May need large amount of data</p>
<p>​    excludes potentially useful hand-designed components</p>
<p>Key question: Do you hava sufficient data to learn a function of the complexity needed to map x to y?</p>
<p>如果你想使用机器学习或者深度学习来学习某些单独的组件，那么当你应用监督学习时，你应该仔细选择要学习的x到y映射类型，这取决于那些任务你可以收集数据。相比之下，谈论纯端到端深度学习方法是很激动人心的，你输入图像，直接得出方向盘转角，但是就目前能收集到的数据而言，还有我们今天能够用神经网络学习的数据类型而言，这实际上不是最有希望的方法，或者说这个方法并不是团队想出的最好用的方法。而我认为这种纯粹的端到端深度学习方法，其实前景不如这样更复杂的多步方法。因为目前能收集到的数据，还有我们现在训练神经网络的能力是有局限的。</p>
<h1><span id="summary"><font color="green">Summary</font></span><a href="#summary" class="header-anchor">#</a></h1><font color="red">学习如何通过一些手段提高模型的表现，首先了解模型的性能的体现，bias、variance、贝叶斯误差。以及如何一步步的改善性能。具体解决了如下问题，1. 数据的划分 2. 人的表现与机器性能的关系、偏差、方差 3. 训练集和验证集的分布问题，当数据样本对于解决问题不足的时候的解决办法，4. 迁移学习 5. 端到端的学习 6. 多任务学习。6. 在性能不好的情况下，可能需要手动的分析误差，对测试集错误样例做统计等等， </font>
      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/" class="post-title-link" itemprop="url">aiai_</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-17 09:20:51" itemprop="dateCreated datePublished" datetime="2019-04-17T09:20:51+08:00">2019-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-05 21:47:52" itemprop="dateModified" datetime="2020-10-05T21:47:52+08:00">2020-10-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>20k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>18 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="c2w1">C2W1</span><a href="#c2w1" class="header-anchor">#</a></h1><h2><span id="l01-train-dev-test-sets">L01 : Train/Dev/Test Sets</span><a href="#l01-train-dev-test-sets" class="header-anchor">#</a></h2><h3><span id="1-process">1. process</span><a href="#1-process" class="header-anchor">#</a></h3><p>应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更新自己的方案。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_2.png" alt></p>
<h3><span id="2-data-split">2. data split</span><a href="#2-data-split" class="header-anchor">#</a></h3><ul>
<li>训练集（train set）：用训练集对算法或模型进行<strong>训练</strong>过程；</li>
<li>验证集（development set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行<strong>交叉验证</strong>，<strong>选择出最好的模型</strong>或者验证不同算法的有效性。</li>
<li>测试集（test set）：最后利用测试集对模型进行测试，<strong>获取模型运行的无偏估计</strong>（对学习方法进行评估）。</li>
</ul>
<p>假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（<strong>dev set</strong>），其实都是同一个概念，最后一部分则作为测试集。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_3.png" alt></p>
<ol>
<li><p>在机器学习发展的小数据量时代，如 100、1000、10000 的数据量大小，可以将数据集按照以下比例进行划分：</p>
<ul>
<li>无验证集的情况：70% / 30%；</li>
<li>有验证集的情况：60% / 20% / 20%；</li>
</ul>
</li>
<li><p>在如今的<strong>大数据时代</strong>，对于一个问题，我们拥有的数据集的规模可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。</p>
<p>验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大到能够验证大约 2-10 种算法哪种更好，而不需要使用 20% 的数据作为验证集。如百万数据中抽取 1 万的数据作为验证集就可以了。</p>
<p>测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中 1000 条数据足以评估单个模型的效果。</p>
</li>
</ol>
<ul>
<li>100 万数据量：98% / 1% / 1%；</li>
<li>超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）</li>
</ul>
<h3><span id="3-jian-yi">3. 建议</span><a href="#3-jian-yi" class="header-anchor">#</a></h3><p><strong>验证集要和训练集来自于同一个分布</strong>（数据来源一致），可以使得机器学习算法变得更快并获得更好的效果。</p>
<p>如果不需要用<strong>无偏估计</strong>来评估模型的性能，则可以不需要测试集。如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。</p>
<h2><span id="l02-bias-variance">L02 : Bias/Variance</span><a href="#l02-bias-variance" class="header-anchor">#</a></h2><p><strong>“偏差-方差分解”（bias-variance decomposition）</strong>是解释学习算法泛化性能的一种重要工具。</p>
<p>泛化误差可分解为偏差、方差与噪声之和：</p>
<ul>
<li><strong>偏差</strong>：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了<strong>学习算法本身的拟合能力</strong>；</li>
<li><strong>方差</strong>：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了<strong>数据扰动所造成的影响</strong>；</li>
<li><strong>噪声</strong>：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了<strong>学习问题本身的难度</strong>。</li>
</ul>
<p>high bias ,underfitting</p>
<p>high variance, overfitting</p>
<p>just right</p>
<h3><span id="1-example">1. example</span><a href="#1-example" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_5.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_6.png" alt></p>
<p>Your algorithms ever on the training set and dev set you can try to diganose whether has problems high barriers or high variances or both or neither.</p>
<h2><span id="l03-basic-recipe-for-machine-learning">L03 Basic Recipe for Machine learning</span><a href="#l03-basic-recipe-for-machine-learning" class="header-anchor">#</a></h2><h3><span id="1-method">1. METHOD</span><a href="#1-method" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_8.png" alt></p>
<p>Training a bigger network almost never hurts. And the main cost of training a neural network that’s too big is just computational time, so long as you’re regularizing.</p>
<p>今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高，我们下节课再细讲，以便大家更好理解如何实现神经网络的正则化。</p>
<p>第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同</p>
<p>只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。</p>
<h2><span id="l04">L04</span><a href="#l04" class="header-anchor">#</a></h2><h3><span id="1-over-fitting">1. over fitting</span><a href="#1-over-fitting" class="header-anchor">#</a></h3><h3><span id="regularization">regularization</span><a href="#regularization" class="header-anchor">#</a></h3><p>L2 regularization</p>
<p>L1 regularizaion: w will be sparse  L1 正则化最后得到 w 向量中将存在大量的 0</p>
<p>为什么只正则化参数w？为什么不再加上参数b 呢？你可以这么做，只是我习惯省略不写，因为通常w是一个高维参数矢量，w已经可以表达高偏差问题，可能w包含有很多参数，我们不可能拟合所有参数，而只是b单个数字，所以w几乎涵盖所有参数，而不是，如果加了参数b，其实也没太大影响，因为b只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。</p>
<ol>
<li><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_9.png" alt></li>
</ol>
<p>2.<img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_10.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_11.png" alt>矩阵范数被称作“弗罗贝尼乌斯范数”，用下标标注F</p>
<ol>
<li><p>反向传播时，填上正则化的一项</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_12.png" alt></p>
<p>因此L2正则化也被称为“权重衰减”。</p>
</li>
</ol>
<p>to get more training data</p>
<h2><span id="l05-why-regularization-reduces-overfitting">L05 :Why Regularization Reduces Overfitting</span><a href="#l05-why-regularization-reduces-overfitting" class="header-anchor">#</a></h2><p>我们添加正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩范数，或者弗罗贝尼乌斯范数或者参数可以减少过拟合？我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单.Regularization其实是让函数变得<strong>简化</strong>。</p>
<p>直观上理解就是如果正则化设置得足够大，权重矩阵被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。</p>
<p>总结一下，如果正则化参数变得很大，w参数很小，z也会相对变小，此时忽略的b影响，z会相对变小，实际上，z的取值范围很小，这个激活函数tanh，也就是曲线函数会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。</p>
<p><strong>L2 regularization的不足</strong>：要通过不断的选用不同的λ进行测试，计算量加大了。</p>
<h2><span id="l06-dropout-regularization">L06 : Dropout Regularization</span><a href="#l06-dropout-regularization" class="header-anchor">#</a></h2><h3><span id="1-gong-zuo-yuan-li">1. 工作原理</span><a href="#1-gong-zuo-yuan-li" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_15.png" alt></p>
<p>如果上面这幅图存在over fitting。复制这个神经网络，dropout会遍历网络的每一层。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用<strong>backprop</strong>方法进行训练。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_13.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_14.png" alt></p>
<p>我们针对每个训练样本训练规模极小的网络，最后你可能会认识到为什么要正则化网络，因为我们在训练极小的网络。</p>
<h3><span id="2-inverted-dropout-fan-xiang-sui-ji-shi-huo">2. <strong>inverted dropout</strong>（反向随机失活）</span><a href="#2-inverted-dropout-fan-xiang-sui-ji-shi-huo" class="header-anchor">#</a></h3><p>对第L</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = <span class="number">0.8</span>    <span class="comment"># 设置神经元保留概率</span></span><br><span class="line">dl = np.random.rand(al.shape[<span class="number">0</span>], al.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">al = np.multiply(al, dl)</span><br><span class="line">al /= keep_prob</span><br></pre></td></tr></tbody></table></figure>
<p>最后一步<code>al /= keep_prob</code>是因为 a[l]a[l]中的一部分元素失活（相当于被归零），为了在下一层计算时不影响 $Z[l+1]=W[l+1]a[l]+b[l+1]$的期望值，因此除以一个<code>keep_prob</code>。举例解释我们假设第三隐藏层上有50个单元或50个神经元，在一维上是50，我们通过因子分解将它拆分成维的，保留和删除它们的概率分别为80%和20%，这意味着最后被删除或归零的单元平均有10（50×20%=10）个，现在我们看下$z^{[4]}$，，我们的预期是$z^{[4]}=w^{[4]}a^{[3]}$，$a^{[3]}$减少20%，也就是说中有$a^{[3]}$20%的元素被归零，为了不影响的$a^{[4]}$期望值，我们需要用$w^{[4]}a^{[3]}/keep_prob$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变，划线部分就是所谓的<strong>dropout</strong>方法。</p>
<h2><span id="l07-understanding-dropout">L07 : Understanding Dropout</span><a href="#l07-understanding-dropout" class="header-anchor">#</a></h2><p>直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，<strong>dropout</strong>将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施<strong>dropout</strong>的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_16.png" alt></p>
<p>计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以<strong>dropout</strong>在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，<strong>dropout</strong>是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用<strong>dropout</strong>的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于<strong>dropout</strong>函数的原因。直观上我认为不能概括其它学科。<strong>dropout</strong>将产生收缩权重的平方范数的效果。当然，不同的层，值可以设置成不同，如果你觉得某一层容易过拟合，把值设置小一点。</p>
<p>dropout 的一大<strong>缺点</strong>是成本函数无法被明确定义。因为每次迭代都会随机消除一些神经元结点的影响，因此无法确保成本函数单调递减。因此，使用 dropout 时，先将<code>keep_prob</code>全部设置为 1.0 后运行代码，确保 $J(w,b)$函数单调递减，再打开 dropout。</p>
<h2><span id="l08-other-regularization-methods">L08 :  Other Regularization Methods</span><a href="#l08-other-regularization-methods" class="header-anchor">#</a></h2><ul>
<li><p>数据扩增（Data Augmentation）：通过图片的一些变换（翻转，局部放大后切割等），得到更多的训练集和验证集。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_17.png" alt></p>
</li>
<li><p>早停止法（Early Stopping）：将训练集和验证集进行梯度下降时的成本变化曲线画在同一个坐标轴内，当训练集误差降低但验证集误差升高，两者开始发生较大偏差时及时停止迭代，并返回具有最小验证集误差的连接权和阈值，以避免过拟合。这种方法的缺点是无法同时达成偏差和方差的最优。</p>
</li>
</ul>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_18.png" alt></p>
<p>但对我来说<strong>early stopping</strong>的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数，因为现在你不再尝试降低代价函数，所以代价函数的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。</p>
<p><strong>Early stopping</strong>的优点是，只运行一次梯度下降，你可以找出的w较小值，中间值和较大值，而无需尝试正则化超级参数的很多值。</p>
<h2><span id="l09-normalizing-inputs">L09 ： Normalizing inputs</span><a href="#l09-normalizing-inputs" class="header-anchor">#</a></h2><ol>
<li><p>零均值</p>
<p>$u=\frac{1}{m}\sum x^{(i)}$,$x-u$</p>
</li>
<li><p>归一化方差；</p>
<p>$\delta^2=\frac{1}{m}(x^{(i)})^2$,每个特征的方差，每个特征数据除以它，就归一化方差了</p>
</li>
</ol>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_19.png" alt></p>
<h3><span id="why">why</span><a href="#why" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_20.png" alt></p>
<p>在不使用标准化的成本函数中，如果设置一个较小的学习率，可能需要很多次迭代才能到达全局最优解；而如果使用了标准化，那么无论从哪个位置开始迭代，都能以相对较少的迭代次数找到全局最优解。</p>
<h2><span id="l10-vanishing-exploding-gradients">L10 : Vanishing /Exploding Gradients</span><a href="#l10-vanishing-exploding-gradients" class="header-anchor">#</a></h2><p>训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。</p>
<p>在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与相关的指数级数增长或下降，它也适用于与层数相关的导数或梯度函数，也是呈指数级增长或呈指数递减。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_21.png" alt></p>
<p>假定 g(z)=z,b[l]=0g(z)=z,b[l]=0，对于目标输出有：</p>
<p>$y^=W[L]W[L−1]…W[2]W[1]X$</p>
<ul>
<li>对于$ W[l]$的值大于 1 的情况，激活函数的值将以指数级递增；</li>
<li>对于 $W[l]$的值小于 1 的情况，激活函数的值将以指数级递减。</li>
</ul>
<p>对于导数同理。因此，在计算梯度时，根据不同情况梯度函数会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。</p>
<h2><span id="l11-weight-initialization-in-a-deep-network">L11 : Weight initialization in a deep network</span><a href="#l11-weight-initialization-in-a-deep-network" class="header-anchor">#</a></h2><p>为了预防值z过大或过小，你可以看到n越大，你希望w越小，因为z是wx+b的和,最合理的方法$w_i=1/n$</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_22.png" alt></p>
<p>因此，实际上，你要做的就是设置某层权重矩阵</p>
<p>$w^{[l]}=n p . random. randn (shape) * np.sqrt \left(\frac{1}{n^{[l-1]}}\right)$</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_23.png" alt></p>
<p>当多个节点时，也一样的看，使得这个节点$z^{<a href="i">L</a>}$不要太大，单独看每个节点既可以</p>
<p>relu : var(w(i)) = 2/n or $\frac{2}{n^{[l-1]}*n^{[l]}}$</p>
<p>tanh: var(w(i)) = 1/n</p>
<p>通过设置初始化化权重矩阵，使得不会增长太快或者太慢</p>
<h2><span id="l12-numerical-approximations-of-gradients">L12 ： Numerical Approximations of Gradients</span><a href="#l12-numerical-approximations-of-gradients" class="header-anchor">#</a></h2><p>单边误差</p>
<p>$f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0} \frac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}$</p>
<p>误差$O(\varepsilon)$</p>
<p>双边误差</p>
<p>$f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0}=\frac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2 \varepsilon}$</p>
<p>$O\left(\varepsilon^{2}\right)$</p>
<h2><span id="l-13-gradient-checking">L 13 Gradient Checking</span><a href="#l-13-gradient-checking" class="header-anchor">#</a></h2><p>梯度检验帮我们节省了很多时间，也多次帮我发现<strong>backprop</strong>实施过程中的bug，接下来，我们看看如何利用它来调试或检验<strong>backprop</strong>的实施是否正确。</p>
<p>首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵w转换成一个向量，把所有矩阵w转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数J是所有W和b的函数，现在你得到了一个的代价函数（即）。接着，你得到与和顺序相同的数据，你同样可以把$dW^{[l]}$,和$db^{[l]}$ 转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。</p>
<p>梯度的逼近值</p>
<script type="math/tex; mode=display">
d \theta_{\text { approx }}[i]=\frac{J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}+\varepsilon, \ldots\right)-J\left(\theta_{1}, \theta_{2}, \ldots . \theta_{i}-\varepsilon, \ldots\right)}{2 \varepsilon}</script><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_24.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_25.png" alt></p>
<p>现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多<strong>bug</strong>，希望它对你也有所帮助。</p>
<h1><span id="l-14-gradient-checking-implementation-notes">L 14 : Gradient Checking Implementation notes</span><a href="#l-14-gradient-checking-implementation-notes" class="header-anchor">#</a></h1><ol>
<li>不要在训练中使用梯度检验，它只用于调试（debug）。使用完毕关闭梯度检验的功能；太慢了</li>
<li>如果算法的梯度检验失败，要检查所有项，并试着找出 bug，即确定哪个 dθapprox[i] 与 dθ 的值相差比较大；</li>
<li>当成本函数包含正则项时，也需要带上正则项进行检验；</li>
<li>梯度检验不能与 dropout 同时使用。因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的成本函数 J。建议关闭 dropout，用梯度检验进行双重检查，确定在没有 dropout 的情况下算法正确，然后打开 dropout；</li>
</ol>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week1_25.png" alt></p>
<h2><span id="summary">Summary</span><a href="#summary" class="header-anchor">#</a></h2><font color="red">回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如正则化和**dropout**，还有加快神经网络训练速度的技巧，最后是梯度检验。</font>



<h1><span id="c2w2-optimization-algorithm">C2W2 :Optimization Algorithm</span><a href="#c2w2-optimization-algorithm" class="header-anchor">#</a></h1><h2><span id="l-01-mini-batch-gradient-descent">L 01 : Mini Batch Gradient Descent</span><a href="#l-01-mini-batch-gradient-descent" class="header-anchor">#</a></h2><ol>
<li><p>Vectorization</p>
</li>
<li><p>Mini batch</p>
<p>not entire training set </p>
<p>bady training set i，$x^{\{i\}}$</p>
<p>mini batch training set</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_1.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_2.png" alt></p>
</li>
</ol>
<p>mini batch gradient descent</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_3.png" alt></p>
<h2><span id="l-02-understanding-mini-batch-gradient-decent">L 02 : Understanding Mini-Batch Gradient Decent</span><a href="#l-02-understanding-mini-batch-gradient-decent" class="header-anchor">#</a></h2><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_4.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_6.png" alt></p>
<p>左图，随着iterations increased, it should decrease .if it ever goes up on iteration,something is wrong.</p>
<p>右图 : it’s as if on every iteration you’re training on a different training set or really training on a different mini batch. It should trend downwards, but it’s also going to be a little bit noisier.So if you plot J{t}, as you’re training mini batch in descent it may be over multiple epochs,you might expect to see a curve like this.</p>
<h3><span id="choosing-your-mini-batch-size">Choosing your mini-batch size</span><a href="#choosing-your-mini-batch-size" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_5.png" alt></p>
<h3><span id="1-you-que-dian">1. 优缺点</span><a href="#1-you-que-dian" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_7.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_8.png" alt></p>
<p>通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的<strong>mini-batch</strong>尺寸，实际上学习率达到最快。你会发现两个好处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果<strong>mini-batch</strong>大小为1000个样本，你就可以对1000个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每次训练集允许我们采取5000个梯度下降步骤，所以实际上一些位于中间的<strong>mini-batch</strong>大小效果最好。</p>
<p>使用<strong>batch</strong>梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本都会下降，所以如果成本函数是迭代次数的一个函数，它应该会随着每次迭代而减少，如果在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。</p>
<p>在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会一直在最小值附近波动，但它并不会在达到最小值并停留在此。</p>
<p>用<strong>mini-batch</strong>梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会讲到学习率衰减，也就是如何减小学习率。</p>
<p>batch : too long,too time</p>
<p>随机： lose speeding ,噪声大</p>
<p>mini-batch和stochastic都存在噪声问题，且在local optima附近会徘徊。但设置合适大小的mini-batch size，噪声和徘徊问题可接受的范围内。</p>
<p>size=1,又叫随机梯度下降法 stochastic gradient descent </p>
<h3><span id="how">how</span><a href="#how" class="header-anchor">#</a></h3><p>如何选择mini-batch size（这是一个hyperparameter）：</p>
<ul>
<li>小数据量，比如总的样本只有几千个，完全可以直接用batch gradient descent</li>
<li>大数量，mini-batch size倾向于选择2^n个，比如64, 128, 256等</li>
<li><p>mini-batch 与CPU/GPU memory的内存容量。</p>
<p>In practice of course the mini batch size is another hyper parameter that you might do a quick search over to try to figure out which one is most sufficient of reducing the cost function j. 按照上面的方法</p>
</li>
</ul>
<h2><span id="l-03-exponentially-weighted-averages">L 03: Exponentially Weighted Averages</span><a href="#l-03-exponentially-weighted-averages" class="header-anchor">#</a></h2><p>In order to understand those algorithms, you need to be able they use something called exponentially weighted averages. Also called exponentially weighted moving averages in statistics.</p>
<h3><span id="1-zhi-shu-jia-quan-ping-jun-shu-exponentially-weighted-averages">1. 指数加权平均数（Exponentially weighted averages）</span><a href="#1-zhi-shu-jia-quan-ping-jun-shu-exponentially-weighted-averages" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_9.png" alt></p>
<p>$\theta _i$表示每一日的温度值，蓝色的点，$v_t$表示加权平均后的,红色</p>
<p>权平均方法是：每天的温度值加权值$vt$设置为前一天的温度加权值$vt−1$和当天的温度实际值$θt$做加权平均：</p>
<script type="math/tex; mode=display">
v_{t}=\beta v_{t-1}+(1-\beta) \theta_{t}</script><p>由于以后我们要考虑的原因，在计算时可视$v_T$大概是$\frac{1}{(1-\beta)}$的每日温度的加权平均，</p>
<p>如果是$\beta$=0.9，这是十天的平均值，红色</p>
<p>如果$\beta$=0.98,是50天的结果，绿色</p>
<p>如果$beta$=0.5,是2day的结果，黄色</p>
<p>由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。</p>
<p>当 $\beta$较大时，指数加权平均值适应地更缓慢一些。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_10.png" alt></p>
<p>$</p>
<h2><span id="l-04-understanding-exponentially-weighted-averages">L 04 : Understanding Exponentially Weighted Averages</span><a href="#l-04-understanding-exponentially-weighted-averages" class="header-anchor">#</a></h2><p><strong>假如β=0.9，每个v的计算如下：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned} v_{100} &=0.9 v_{99}+0.1 \theta_{100} \\ v_{99} &=0.9 v_{98}+0.1 \theta_{99} \\ v_{98} &=0.9 v_{97}+0.1 \theta_{98} \end{aligned}</script><p>递推可得：</p>
<script type="math/tex; mode=display">
v_{100}=0.1 \theta_{100}+0.1 * 0.9 \theta_{99}+0.1 *(0.9)^{2} \theta_{98}+\ldots</script><p>指数的衰减规律</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_11.png" alt></p>
<p>一般的</p>
<script type="math/tex; mode=display">
v_{t}=\sum_{i=1}^{t}(1-\beta) \beta^{t-i} \theta_{i}</script><p>无穷级数求和：</p>
<script type="math/tex; mode=display">
\sum_{t=1}^{n}(1-\beta) \beta^{t}=1</script><p>因此可以近似的认为所有项的系数之和正好为100%。</p>
<p>即，$vt$是对t日之前<strong>所有的实际温度的加权平均</strong>,权重是指数递减的。</p>
<p>十天后，曲线高度下降到了1/3,赋予权重$\beta^{t-i}$</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_12.png" alt></p>
<script type="math/tex; mode=display">
0.9^{10}~=0.35~=1/e</script><p>一般认为，$v_t$近似前$\frac{1}{1-\beta}$的加权平均值</p>
<h2><span id="l05-bias-correction-in-exponentially-weighted-averages">L05 : Bias correction in exponentially weighted averages</span><a href="#l05-bias-correction-in-exponentially-weighted-averages" class="header-anchor">#</a></h2><p>指数加权平均的偏差修正</p>
<p>由于计算$v1$的时候，并没有历史值做加权，这个时候令其前一个加权值$v0=0$，则会导致$v_1$远小于$\theta_1$,依次类推，<strong>在靠近前面的值会出现显著的小于实际值的情况</strong></p>
<p>因此做一个修正</p>
<script type="math/tex; mode=display">
v_{t}=\frac{\beta v_{t-1}+(1-\beta) \theta_{t}}{1-\beta^{t}}</script><p>你会发现随着$\beta^t$增加，接近于0，所以当t很大的时候，偏差修正几乎没有作用，因此当t较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_13.png" alt></p>
<p>因为在Machine Learning中看重的是很多次迭代后的结果，初期的偏差影响并不大。</p>
<h2><span id="l-06-gradient-descent-with-momentum">L 06 : Gradient Descent With Momentum</span><a href="#l-06-gradient-descent-with-momentum" class="header-anchor">#</a></h2><p>动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_14.png" alt></p>
<p>当慢慢下降到最小值，上下波动的梯度下降法的速度减缓，无法使用更大的学习率，</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_15.png" alt></p>
<p>在纵轴上，希望学校慢一点，不需要摆动，横着上，加快学校，基于此就有了Gradient descent with momentum。</p>
<script type="math/tex; mode=display">
\begin{array}{c}{v_{d W} :=\beta v_{d W}+(1-\beta) d W} \\ {v_{d b} :=\beta v_{d b}+(1-\beta) d b} \\ {w=w-\alpha v_{d W}} \\ {b=b-\alpha v_{d b}}\end{array}</script><p>这样，可以让gradient更平滑</p>
<ul>
<li>对于上图垂直方向，原来是会上下震荡，但引入了exponentially weighted average，相当于对前面的震荡进行了平均，<strong>结果就是上下震荡互相抵消了</strong>。而水平方向都是向右没有震荡，因此平均后还是向右。最终导致呈现上图红色的下降路线。</li>
<li><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_18.png" alt></li>
</ul>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_16.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_17.png" alt></p>
<h2><span id="l-07-rmsprop">L 07 : RMSprop</span><a href="#l-07-rmsprop" class="header-anchor">#</a></h2><p>RMSprop (Root Mean Square Propagation，均方根传递)，<strong>与momentum一样，也是降低梯度的抖动</strong>。<strong>而是平抑不同大小梯度的更新速率。实际上 作用在α上的</strong></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_19.png" alt></p>
<p>回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设b纵轴代表参数，横轴代表参数W，可能有w1，或者w2其它重要的参数，为了便于理解，被称为b和w。</p>
<p>我们希望学习速度快，而在垂直方向，也就是例子中的方向，我们希望减缓纵轴上的摆动，所以有了$S_{d W} $和$ S_{d b}$，我们希望$S_{d W} $会相对较小，所以我们要除以一个较小的数，而希望$ S_{d b}$又较大，所以这里我们要除以较大的数字，这样就可以减缓纵轴上的变化。</p>
<p>这些微分，垂直方向的要比水平方向的大得多，所以斜率在方向特别大，所以这些微分中，db较大，dw较小，因为函数的倾斜程度，在纵轴上，也就是b方向上要大于在横轴上，也就是方向上W。db的平方较大，所以$Sdb$也会较大，而相比之下，dw会小一些，亦或dw平方会小一些，因此$Sdw$会小一些，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。</p>
<p><strong>RMSprop</strong>的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率，然后加快学习，而无须在纵轴上垂直方向偏离。</p>
<p>实际中dw是一个高维度的参数向量，db也是一个高维度参数向量，但是你的直觉是，在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。所以这就是<strong>RMSprop</strong>，全称是均方根，因为你将微分进行平方，然后最后使用平方根。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_20.png" alt></p>
<p>解释平方：</p>
<p>垂直方向，比较陡，梯度比较大，但我们又希望它下降的慢。因此对梯度除以一个较大的值，所以用梯度的平方的平均来表示。让不同的参数拥有不同的learning rate。</p>
<p><strong>从某种角度看，RMSprop会根据当前的梯度自动调整参数的learning rate，梯度大降低learning rate，梯度小的时候提高learning rate，从而一方面避免了震荡，另一方面避免在平坦的地方徘徊太久。</strong></p>
<p>为了避免出现分母为0</p>
<script type="math/tex; mode=display">
\begin{array}{c}{s_{d w}=\beta s_{d w}+(1-\beta)(d w)^{2}} \\ {s_{d b}=\beta s_{d b}+(1-\beta)(d b)^{2}} \\ {w :=w-\alpha \frac{d w}{\sqrt{s_{d w}+\varepsilon}}} \\ {b :=b-\alpha \frac{d b}{\sqrt{s_{d b}+\varepsilon}}}\end{array}</script><p>$\varepsilon$取$10^{-8}$不错的选择.</p>
<p>补充：</p>
<p>RMSProp算法对梯度计算了<strong>微分平方加权平均数</strong>。这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快</p>
<h2><span id="l-08-adam-optimization-algorithm">L 08 Adam optimization algorithm</span><a href="#l-08-adam-optimization-algorithm" class="header-anchor">#</a></h2><p>Adam（Adaptive Moment Estimation，自适应矩估计）就是momentum和RMSprop的结合。momentum负责平滑梯度，而RMSprop负责调解learning rate。</p>
<h3><span id="1-adam">1. Adam</span><a href="#1-adam" class="header-anchor">#</a></h3><p>a. 引入的变量有：</p>
<ul>
<li>$v$ : 计算同momentum算法，将梯度进行指数加权平均</li>
<li>$s$: 计算同RMSprop，将梯度的平方进行指数加权平均</li>
<li>$β1$ : 计算vv的加权参数</li>
<li>$β2$ : 计算ss的加权参数</li>
</ul>
<p>b. 在迭代前，初始化参数v和s</p>
<script type="math/tex; mode=display">
v_{d W}=0, s_{d W}=0, v_{d b}=0, s_{d b}=0</script><p>c. 对第t次梯度下降的迭代 a. 首先计算dw和db的v和s</p>
<script type="math/tex; mode=display">
\begin{array}{c}{v_{d W}=\beta_{1} v_{d W}+\left(1-\beta_{1}\right) d W} \\ {s_{d W}=\beta_{2} s_{d W}+\left(1-\beta_{2}\right)(d W)^{2}} \\ {v_{d b}=\beta_{1} v_{d b}+\left(1-\beta_{1}\right) d b} \\ {s_{d b}=\beta_{2} s_{d b}+\left(1-\beta_{2}\right)(d b)^{2}}\end{array}</script><p>d. 修正</p>
<script type="math/tex; mode=display">
v_{d W}^{\text {corrected}}=\frac{v_{d W}}{1-\left(\beta_{1}\right)^{t}}\\
\begin{aligned} s_{d W}^{\text {corrected}} &=\frac{s_{d W}}{1-\left(\beta_{2}\right)^{t}} \\ v_{d b}^{\text {corrected}} &=\frac{v_{d b}}{1-\left(\beta_{1}\right)^{t}} \\ s_{d b}^{\text {corrected}} &=\frac{s_{d b}}{1-\left(\beta_{2}\right)^{t}} \end{aligned}</script><p>e. 最后更新参数W和b</p>
<script type="math/tex; mode=display">
W=W-\alpha \frac{v_{d W}^{\text {corrected}}}{\sqrt{s_{d W}^{\text { corrected }}+\varepsilon}}\\
b=b-\alpha \frac{v_{d b}^{\text {corrected}}}{\sqrt{s_{d b}^{\text { corrected }}+\varepsilon}}</script><p>超参的选择：</p>
<ul>
<li>α：需要调优</li>
<li>β1: 通常选择为0.9</li>
<li>β2: 通常选择为0.999</li>
<li>ε: 一般不需要调优，选择一个小数，比如10−8</li>
</ul>
<p>你可以尝试一系列值α，然后看哪个有效</p>
<h2><span id="l09-learning-rate-decay">L09 : Learning Rate Decay</span><a href="#l09-learning-rate-decay" class="header-anchor">#</a></h2><ol>
<li><p>why</p>
<p>为什么要做learning rate decay？ 较大的learning rate虽然在算法开始阶段会加快收敛速度，但在收敛接近到优化点的时候，算法会在优化点附近震荡，如下图：</p>
</li>
</ol>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_22.png" alt></p>
<p>2.如何做learning rate decay？ <strong>思路很简单，就是引入一个函数，让α随着迭代（比如min-batch的epoch）递减</strong>。为此可以采用的decay函数有：</p>
<p>倒数：</p>
<script type="math/tex; mode=display">
\alpha :=\frac{1}{1+\text { decay rate * epoch num}} \alpha</script><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_23.png" alt></p>
<h2><span id="l-10-the-problem-of-local-optima">L 10: The Problem of local Optima</span><a href="#l-10-the-problem-of-local-optima" class="header-anchor">#</a></h2><p>事实上，如果你要创建一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。</p>
<p>但是一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但发生的机率也许很小，也许是$2^{-20000}$，因此更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可能碰到鞍点。所有，担心收敛到local optima，真是人们想多了，实际上并没有想象的那么多local optima。在高维空间，几乎不太可能被困在一个local optima，这是一个好消息。</p>
<p>因此，在高维空间遇到的问题是高原问题（Problem of plateaus）</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_27.png" alt></p>
<p>Adam算法可以加速学习</p>
<h1><span id="w3-hyperparameter-tuning">W3 Hyperparameter tuning</span><a href="#w3-hyperparameter-tuning" class="header-anchor">#</a></h1><h2><span id="l01-tuning-process">L01 Tuning process</span><a href="#l01-tuning-process" class="header-anchor">#</a></h2><ol>
<li>到目前为止，我们接触到的hyperparameter有：</li>
<li>learning rate: αα</li>
<li>momentum 参数: ββ</li>
<li>Adam参数: β1β1和 β2β2以及εε</li>
<li>神经网络层数: L</li>
<li>神经网络隐藏层neuron数：n[l]n[l]</li>
<li>learning rate decay参数</li>
<li>min-batch size</li>
<li>这些hyperparameter重要性排序：</li>
<li>最重要的： learning rate: αα</li>
<li>比较重要的： momentum 参数: ββ 神经网络层数: L 神经网络隐藏层neuron数：n[l]n[l]</li>
<li>次重要的： 神经网络隐藏层neuron数 learning rate decay参数</li>
<li>基本不需调整的 β1β1和 β2β2以及ε</li>
</ol>
<h4><span id="1-try-random-values-don-t-use-a-grid">1. Try random values : Don’t use a grid</span><a href="#1-try-random-values-don-t-use-a-grid" class="header-anchor">#</a></h4><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_28.png" alt></p>
<p>why:</p>
<p>举个例子，假设超参数1是（学习速率），取一个极端的例子，假设超参数2是<strong>Adam</strong>算法中，分母中的$\varepsilon$。在这种情况下，a的取值很重要，而$\varepsilon$取值则无关紧要。如果你在网格中取点，接着，你试验了a的5个取值，那你会发现，无论$\varepsilon$取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的值只有5个，我认为这是很重要的。</p>
<p>对比而言，如果你随机取值，你会试验25个独立的a,$\varepsilon$，似乎你更有可能发现效果做好的那个。</p>
<h3><span id="2-you-cu-cao-dao-jing-xi-de-ce-lue">2. 由粗糙到精细的策略</span><a href="#2-you-cu-cao-dao-jing-xi-de-ce-lue" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_29.png" alt></p>
<h2><span id="l-02-using-an-appropriate-scale-to-pick-hyperparameters">L 02: Using an Appropriate Scale to pick hyperparameters</span><a href="#l-02-using-an-appropriate-scale-to-pick-hyperparameters" class="header-anchor">#</a></h2><p>$a$取值0.0001,1,如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。</p>
<p>同时在范围内搜索，也不是均匀分布（uniformly random）的，通常有这个参数的scale，<strong>比如对数scale</strong>。</p>
<p>反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_32.png" alt></p>
<h2><span id="l-03-hyperparameter-tuning-i-practice">L 03 : Hyperparameter tuning i practice</span><a href="#l-03-hyperparameter-tuning-i-practice" class="header-anchor">#</a></h2><ol>
<li>不同的算法和场景，对超参的scale敏感性可能不一样.</li>
<li>根据计算资源和数据量，可以采取两种策略来调参<ul>
<li>Panda（熊猫策略）：对一个模型先后修改参数，查看其表现，最终选择最好的参数。就像熊猫一样，一次只抚养一个后代。</li>
<li>Caviar（鱼子酱策略）：计算资源足够，可以同时运行很多模型实例，采用不同的参数，然后最终选择一个好的。类似鱼类，一次下很多卵，自动竞争成活。 </li>
</ul>
</li>
</ol>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_33.png" alt></p>
<h3><span id="l-04-normalizing-activations-in-a-network">L 04: Normalizing Activations in a Network</span><a href="#l-04-normalizing-activations-in-a-network" class="header-anchor">#</a></h3><h4><span id="1-implementing-batch-normalizing">1. Implementing Batch Normalizing</span><a href="#1-implementing-batch-normalizing" class="header-anchor">#</a></h4><p><strong>Batch</strong>归一化,<strong>Batch</strong>归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。</p>
<p>可以normalize $a^{[l]},z^{[l]}$,选择$z^{[L]}$</p>
<p><strong>设置 γ 和 β 的原因</strong>是，如果各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 γ 和 β 对标准化后的结果做进一步处理。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_34.png" alt></p>
<p>需要注意的是，β和γ不是超参，而是梯度下降需学习的参数。</p>
<h2><span id="l-05-fitting-batch-norm-into-neural-networks">L 05 : Fitting Batch Norm Into Neural Networks</span><a href="#l-05-fitting-batch-norm-into-neural-networks" class="header-anchor">#</a></h2><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_35.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_36.png" alt></p>
<p>注意</p>
<p>先前我说过每层的参数是$w^{[l]}$和$b^{[l]}$，还有$\beta^{[l]}$和$b^{[l]}$，请注意计算的方式如下，$z^{[l]}=w^{[l]} a^{[l-1]}+b^{[l]}$，但<strong>Batch</strong>归一化做的是，它要看这个<strong>mini-batch</strong>，先将$z^{[l]}$归一化，结果为均值0和标准方差，再由$\beta$和b重缩放，但这意味着，无论$b^{[l]}$的值是多少，都是要被减去的，因为在<strong>Batch</strong>归一化的过程中，你要计算的$z^{[l]}$均值，再减去平均值，在此例中的<strong>mini-batch</strong>中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消.</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_37.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_38.png" alt></p>
<p>最后，请记住的维$z^{[l]}$，因为在这个例子中，维数会是$\left(n^{[l]}, 1\right)$，的尺寸为，如果是l层隐藏单元的数量，那$ \beta^{[l]}$和$ \gamma^{[l]}$的维度也是$\left(n^{[l]}, 1\right)$，因为这是你隐藏层的数量，你有隐藏单元，<strong>所以$\gamma^{[l]}$和</strong>$  \beta^{[l]}$用来将每个隐藏层的均值和方差缩放为网络想要的值。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_39.png" alt></p>
<h3><span id="l-06-why-doest-batch-norm-work">L 06 Why Doest Batch Norm Work?</span><a href="#l-06-why-doest-batch-norm-work" class="header-anchor">#</a></h3><ol>
<li>首先，起到了normalization的作用，同对输入数据X的normalization作用类似。</li>
</ol>
<ol>
<li><p>让每一层的学习，<strong>一定程度解耦了前层参数和后层参数，让各层更加独立的学习</strong>。无论前一层如何变，本层输入的数据总是保持稳定的均值和方差。（主要原因）</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_40.png" alt></p>
<p>所以使你数据改变分布的这个想法，有个有点怪的名字“<strong>Covariate shift</strong>”，想法是这样的，如果你已经学习了到 的映射，如果 的分布改变了，那么你可能需要重新训练你的学习算法。这种做法同样适用于，如果真实函数由 到 映射保持不变，正如此例中，因为真实函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情况就更糟了。</p>
<p>关于第二点，如果实际应用样本和训练样本的数据分布不同（例如，橘猫图片和黑猫图片），我们称发生了“<strong>Covariate Shift</strong>”。这种情况下，一般要对模型进行重新训练。Batch Normalization 的作用就是减小 Covariate Shift 所带来的影响，让模型变得更加健壮，鲁棒性（Robustness）更强。</p>
<p>即使输入的值改变了，由于 Batch Normalization 的作用，使得均值和方差保持不变（由 γ 和 β 决定），限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。Batch Normalization 减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_41.png" alt></p>
<p>另外，Batch Normalization 也<strong>起到微弱的正则化</strong>（regularization）效果。因为在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的 z~(i)z~(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。</p>
<p>因为 Batch Normalization 只有微弱的正则化效果，因此可以和 dropout 一起使用，以获得更强大的正则化效果。通过应用更大的 mini-batch 大小，可以减少噪声，从而减少这种正则化效果。</p>
<p>最后，不要将 Batch Normalization 作为正则化的手段，而是当作加速学习的方式。正则化只是一种非期望的副作用，Batch Normalization 解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_42.png" alt></p>
</li>
</ol>
<h3><span id="l-07-batch-norm-at-test-time">L 07 : Batch Norm At Test Time</span><a href="#l-07-batch-norm-at-test-time" class="header-anchor">#</a></h3><p>问题：BN算法在训练时是一个批次的数据训练，能算出每一层Z的均值和方差；而在测试时，输入的则是单个数据，<strong>单条数据没法做均值和方差的计算</strong>，怎么在测试期输入均值和方差呢?</p>
<p>实际应用中一般不使用这种方法，而是使用之前学习过的指数加权平均的方法来预测测试过程单个样本的 μ 和 $σ^2$</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_43.png" alt></p>
<p>计算$z_{\text { norm }}^{(\hat{2})}$，用$\mu$ 和$ \sigma^{2}$的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的和你在神经网络训练过程中得到的$\beta$和$\sigma$参数来计算你那个测试样本的z值。</p>
<h3><span id="l-08-softmax-regression">L 08 : Softmax Regression</span><a href="#l-08-softmax-regression" class="header-anchor">#</a></h3><h4><span id="1-multi-class-classification">1. [Multi-class classification]</span><a href="#1-multi-class-classification" class="header-anchor">#</a></h4><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_44.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_45.png" alt></p>
<p>最后一层是概率，之和为1，要用到<strong>Softmax</strong>层，<strong>Softmax</strong>激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_46.png" alt></p>
<h4><span id="2-softmax-example">2. Softmax example</span><a href="#2-softmax-example" class="header-anchor">#</a></h4><p>没有隐藏层的softmax,代表一些决策边界</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_47.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_48.png" alt></p>
<h3><span id="l-09-training-softmax-classifier">L 09 Training SoftMax classifier</span><a href="#l-09-training-softmax-classifier" class="header-anchor">#</a></h3><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_49.png" alt></p>
<p><strong>Softmax</strong>这个名称的来源是与所谓<strong>hardmax</strong>对比,<strong>Softmax</strong>回归或<strong>Softmax</strong>激活函数将<strong>logistic</strong>激活函数推广到类，而不仅仅是两类，结果就是如果C=2，那么C=2的<strong>Softmax</strong>实际上变回了<strong>logistic</strong>回归，</p>
<h4><span id="loss-function">Loss Function</span><a href="#loss-function" class="header-anchor">#</a></h4><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_50.png" alt></p>
<script type="math/tex; mode=display">
J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)</script><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_51.png" alt></p>
<h4><span id="3-gradient-descent-with-softmax">3. Gradient descent with softmax</span><a href="#3-gradient-descent-with-softmax" class="header-anchor">#</a></h4><p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_52.png" alt></p>
<p>最后一层求导，softmax激活函数</p>
<script type="math/tex; mode=display">
J\left(w^{[1]}, b^{[1]}, \ldots \ldots\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)</script><h2><span id="l11-tensorflow">L11 TensorFlow</span><a href="#l11-tensorflow" class="header-anchor">#</a></h2><h4><span id="1-ji-ben-liu-cheng">1. 基本流程</span><a href="#1-ji-ben-liu-cheng" class="header-anchor">#</a></h4><p>使用tensorflow，只要告诉tensorflow forward prop，它自己就会做backprop，因此不用自己实现backprop</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_53.png" alt></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#导入TensorFlow</span></span><br><span class="line">​</span><br><span class="line">w = tf.Variable(<span class="number">0</span>,dtype = tf.float32)</span><br><span class="line"><span class="comment">#接下来，让我们定义参数w，在TensorFlow中，你要用tf.Variable()来定义参数</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">#然后我们定义损失函数：</span></span><br><span class="line">​</span><br><span class="line">cost = tf.add(tf.add(w**<span class="number">2</span>,tf.multiply(- <span class="number">10.</span>,w)),<span class="number">25</span>)</span><br><span class="line"><span class="comment">#然后我们定义损失函数J</span></span><br><span class="line">然后我们再写：</span><br><span class="line">​</span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost)</span><br><span class="line"><span class="comment">#(让我们用0.01的学习率，目标是最小化损失)。</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">#最后下面的几行是惯用表达式:</span></span><br><span class="line">​</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">​</span><br><span class="line">session = tf.Session()<span class="comment">#这样就开启了一个TensorFlow session。</span></span><br><span class="line">​</span><br><span class="line">session.run(init)<span class="comment">#来初始化全局变量。</span></span><br><span class="line">​</span><br><span class="line"><span class="comment">#然后让TensorFlow评估一个变量，我们要用到:</span></span><br><span class="line">​</span><br><span class="line">session.run(w)</span><br><span class="line">​</span><br><span class="line"><span class="comment">#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以#上面的这一行将w初始化为0，并定义损失函数，我们定义train为学习算法，它用梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以session.run(w)评估了w，让我：：</span></span><br><span class="line">​</span><br><span class="line">print(session.run(w))</span><br><span class="line">​</span><br><span class="line">所以如果我们运行这个，它评估等于<span class="number">0</span>，因为我们什么都还没运行。</span><br><span class="line"></span><br><span class="line"><span class="comment">#现在让我们输入：</span></span><br><span class="line">​</span><br><span class="line">$session.run(train)，它所做的就是运行一步梯度下降法。</span><br><span class="line"><span class="comment">#接下来在运行了一步梯度下降法后，让我们评估一下w的值，再print：</span></span><br><span class="line">​</span><br><span class="line">print(session.run(w))</span><br><span class="line"><span class="comment">#在一步梯度下降法之后，w现在是0.1。</span></span><br></pre></td></tr></tbody></table></figure>
<h4><span id="2-ru-he-yong-xun-lian-shu-ju">2. 如何用训练数据</span><a href="#2-ru-he-yong-xun-lian-shu-ju" class="header-anchor">#</a></h4><p>placeholder 在实际的训练过程中，要用不同的样本反复放到一个待优化函数中的，这个时候就可以用tensorflow的placeholder实现,在run的时候，对应给出<code>feed_dict</code>，表名占位符x的实际值。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># 导入Tensorflow</span></span><br><span class="line"></span><br><span class="line">coefficient = np.array([[<span class="number">2.</span>],[<span class="number">-10.</span>],[<span class="number">25.</span>]])</span><br><span class="line"></span><br><span class="line">w = tf.Variable(<span class="number">0</span>, dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="number">3</span>,<span class="number">1</span>]) <span class="comment"># 3x1大小的placeholder</span></span><br><span class="line">cost = w**x[<span class="number">0</span>][<span class="number">0</span>] - x[<span class="number">1</span>][<span class="number">0</span>]*w + x[<span class="number">2</span>][<span class="number">0</span>] <span class="comment"># 要优化的cost function（即forward prop的形式）</span></span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost) </span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">session = tf.Session()</span><br><span class="line">session.run(init)</span><br><span class="line">print(session.run(w))</span><br><span class="line"></span><br><span class="line">session.run(train, feed_dict={x:coefficient}) <span class="comment"># x占位符替换为coefficient</span></span><br><span class="line">print(session.run(w))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    session.run(train, feed_dict={x:coefficient}) <span class="comment"># # x占位符替换为coefficient</span></span><br><span class="line">print(session.run(w))</span><br></pre></td></tr></tbody></table></figure>
<h4><span id="3-ji-suan-liu">3. 计算流</span><a href="#3-ji-suan-liu" class="header-anchor">#</a></h4><p><strong>TensorFlow</strong>程序的核心是计算损失函数，然后<strong>TensorFlow</strong>自动计算出导数，以及如何最小化损失，因此这个等式或者这行代码所做的就是让<strong>TensorFlow</strong>建立计算图，</p>
<p>with 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。建立计算流的过程，前向传播的过程，operation</p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_56.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_54.png" alt></p>
<p><img src="/2019/04/17/ImprovingDeep%20learning.ai_Deep%20Neural%20NetworksHyperparameter%20tuning,%20Regularization%20and%20Optimization/L2_week2_55.png" alt></p>
<h1><span id="summary">Summary</span><a href="#summary" class="header-anchor">#</a></h1><font color="read">how to systematically organize the hyper parameter search process and  batch normalization and framework </font>

<p><a target="_blank" rel="noopener" href="http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Improving_Deep_Neural_Networks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2">http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/Improving_Deep_Neural_Networks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2</a></p>
<p><a target="_blank" rel="noopener" href="http://www.ai-start.com/dl2017/html/lesson2-week1.html#header-n3">http://www.ai-start.com/dl2017/html/lesson2-week1.html#header-n3</a></p>
<p><a target="_blank" rel="noopener" href="http://dl-notes.imshuai.com/#/c2w1?id=_4-heros-of-deep-learning-yoshua-bengio-interview">http://dl-notes.imshuai.com/#/c2w1?id=_4-heros-of-deep-learning-yoshua-bengio-interview</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4Ct3Yujl1dk&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=14">https://www.youtube.com/watch?v=4Ct3Yujl1dk&amp;list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&amp;index=14</a></p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://mycherrymay.github.io/2019/04/16/%E5%BD%A9%E9%93%85DailyLifeStyle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XieMay">
      <meta itemprop="description" content="wise">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to shiyi's world">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/16/%E5%BD%A9%E9%93%85DailyLifeStyle/" class="post-title-link" itemprop="url">彩铅DailyLifeStyle</a>
        </h2>

        <div class="post-meta">
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-16 20:20:46" itemprop="dateCreated datePublished" datetime="2019-04-16T20:20:46+08:00">2019-04-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-05 21:49:17" itemprop="dateModified" datetime="2020-10-05T21:49:17+08:00">2020-10-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A8%B1%E4%B9%90%E7%94%9F%E6%B4%BB/" itemprop="url" rel="index"><span itemprop="name">娱乐生活</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>218</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1><span id="day-one">Day one</span><a href="#day-one" class="header-anchor">#</a></h1><h2><span id="1-gong-ju-jian-dan-jie-shao">1. 工具简单介绍</span><a href="#1-gong-ju-jian-dan-jie-shao" class="header-anchor">#</a></h2><ol>
<li><p>彩铅</p>
<p>水溶性，油性</p>
</li>
<li><p>彩铅纸</p>
</li>
<li><p>铅笔</p>
<ol>
<li><p>B</p>
<p>2B&lt;4B黑的程度</p>
</li>
<li><p>H</p>
<p>4H&lt;8H软度</p>
</li>
</ol>
</li>
<li><p>橡皮</p>
<ol>
<li>软橡皮</li>
<li>硬橡皮</li>
<li>电动橡皮擦</li>
</ol>
</li>
<li><p>铅笔刀</p>
<ol>
<li>可跳档类型</li>
</ol>
</li>
<li><p>勾线笔</p>
</li>
<li><p>针管笔 （樱花）</p>
</li>
<li><p>笔套</p>
</li>
<li><p>高光笔</p>
<ol>
<li>可以用修正液替换（三棱)</li>
</ol>
</li>
<li><p>纸擦笔</p>
<ol>
<li>玛丽</li>
</ol>
</li>
<li>刷子</li>
<li><p>画板</p>
<ol>
<li>速写板</li>
</ol>
</li>
</ol>
<h2><span id="2-yan-se">2. 颜色</span><a href="#2-yan-se" class="header-anchor">#</a></h2><p>三原色： 红 黄 蓝</p>
<ol>
<li><p>色相</p>
<p>颜色</p>
</li>
<li><p>饱和度</p>
<ol>
<li>鲜艳程度</li>
</ol>
</li>
<li><p>明度</p>
<ol>
<li>明暗程度</li>
</ol>
</li>
<li>邻近色</li>
<li>对比色<ol>
<li>红-绿</li>
<li>蓝-橙</li>
<li>紫-黄</li>
</ol>
</li>
<li>暖色和冷色</li>
</ol>
<h2><span id="3-pai-xian">3. 排线</span><a href="#3-pai-xian" class="header-anchor">#</a></h2><ol>
<li><p>一个方向</p>
<p>往同一个方向排，无连接</p>
</li>
<li><p>来回</p>
<p>相连接，一条线</p>
</li>
<li><p>不同方向排列</p>
</li>
</ol>
<p>注意：力度和间距</p>
<h2><span id="4-ping-tu">4. 平涂</span><a href="#4-ping-tu" class="header-anchor">#</a></h2><p>力度一致</p>
<h2><span id="5-jian-bian">5. 渐变</span><a href="#5-jian-bian" class="header-anchor">#</a></h2><p>力度不一致</p>

      
    </div>

    
    
    

      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XieMay</p>
  <div class="site-description" itemprop="description">wise</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">88</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/shiyichuixue" title="GitHub → https://github.com/shiyichuixue" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2323020965@qq.com" title="E-Mail → mailto:2323020965@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XieMay</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">493k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">7:28</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共176.2k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '[object Object]';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
